26/01/12 01:49:40 INFO SparkContext: Running Spark version 3.3.0
26/01/12 01:49:40 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
26/01/12 01:49:40 INFO ResourceUtils: ==============================================================
26/01/12 01:49:40 INFO ResourceUtils: No custom resources configured for spark.driver.
26/01/12 01:49:40 INFO ResourceUtils: ==============================================================
26/01/12 01:49:40 INFO SparkContext: Submitted application: Load NYC Taxi Data to HDFS
26/01/12 01:49:40 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
26/01/12 01:49:40 INFO ResourceProfile: Limiting resource is cpu
26/01/12 01:49:40 INFO ResourceProfileManager: Added ResourceProfile id: 0
26/01/12 01:49:40 INFO SecurityManager: Changing view acls to: root
26/01/12 01:49:40 INFO SecurityManager: Changing modify acls to: root
26/01/12 01:49:40 INFO SecurityManager: Changing view acls groups to: 
26/01/12 01:49:40 INFO SecurityManager: Changing modify acls groups to: 
26/01/12 01:49:40 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
26/01/12 01:49:40 INFO Utils: Successfully started service 'sparkDriver' on port 44739.
26/01/12 01:49:40 INFO SparkEnv: Registering MapOutputTracker
26/01/12 01:49:40 INFO SparkEnv: Registering BlockManagerMaster
26/01/12 01:49:40 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
26/01/12 01:49:40 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
26/01/12 01:49:40 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
26/01/12 01:49:41 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-5c8b63d7-6d8d-425d-8e94-b6895ac2386b
26/01/12 01:49:41 INFO MemoryStore: MemoryStore started with capacity 366.3 MiB
26/01/12 01:49:41 INFO SparkEnv: Registering OutputCommitCoordinator
26/01/12 01:49:41 INFO Utils: Successfully started service 'SparkUI' on port 4040.
26/01/12 01:49:41 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://spark-master:7077...
26/01/12 01:49:41 INFO TransportClientFactory: Successfully created connection to spark-master/172.18.0.3:7077 after 26 ms (0 ms spent in bootstraps)
26/01/12 01:49:41 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20260112014941-0000
26/01/12 01:49:41 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 45221.
26/01/12 01:49:41 INFO NettyBlockTransferService: Server created on 02926ee04bc9:45221
26/01/12 01:49:41 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
26/01/12 01:49:41 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 02926ee04bc9, 45221, None)
26/01/12 01:49:41 INFO BlockManagerMasterEndpoint: Registering block manager 02926ee04bc9:45221 with 366.3 MiB RAM, BlockManagerId(driver, 02926ee04bc9, 45221, None)
26/01/12 01:49:41 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20260112014941-0000/0 on worker-20260112014647-172.18.0.5-45001 (172.18.0.5:45001) with 2 core(s)
26/01/12 01:49:41 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 02926ee04bc9, 45221, None)
26/01/12 01:49:41 INFO StandaloneSchedulerBackend: Granted executor ID app-20260112014941-0000/0 on hostPort 172.18.0.5:45001 with 2 core(s), 1024.0 MiB RAM
26/01/12 01:49:41 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 02926ee04bc9, 45221, None)
26/01/12 01:49:41 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20260112014941-0000/0 is now RUNNING
26/01/12 01:49:41 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
Cargando: yellow_tripdata_2009-01.parquet en hdfs://hadoop-namenode:8020/data/nyc/raw/taxi-trips/2009...
26/01/12 01:49:42 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
26/01/12 01:49:42 INFO SharedState: Warehouse path is 'file:/spark-warehouse'.
26/01/12 01:49:43 INFO InMemoryFileIndex: It took 47 ms to list leaf files for 1 paths.
26/01/12 01:49:44 INFO SparkContext: Starting job: parquet at NativeMethodAccessorImpl.java:0
26/01/12 01:49:44 INFO DAGScheduler: Got job 0 (parquet at NativeMethodAccessorImpl.java:0) with 1 output partitions
26/01/12 01:49:44 INFO DAGScheduler: Final stage: ResultStage 0 (parquet at NativeMethodAccessorImpl.java:0)
26/01/12 01:49:44 INFO DAGScheduler: Parents of final stage: List()
26/01/12 01:49:44 INFO DAGScheduler: Missing parents: List()
26/01/12 01:49:44 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[1] at parquet at NativeMethodAccessorImpl.java:0), which has no missing parents
26/01/12 01:49:44 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 102.6 KiB, free 366.2 MiB)
26/01/12 01:49:44 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 36.8 KiB, free 366.2 MiB)
26/01/12 01:49:44 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 02926ee04bc9:45221 (size: 36.8 KiB, free: 366.3 MiB)
26/01/12 01:49:44 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1513
26/01/12 01:49:44 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[1] at parquet at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
26/01/12 01:49:44 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
26/01/12 01:49:44 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.5:53550) with ID 0,  ResourceProfileId 0
26/01/12 01:49:44 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.5:42453 with 366.3 MiB RAM, BlockManagerId(0, 172.18.0.5, 42453, None)
26/01/12 01:49:44 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4607 bytes) taskResourceAssignments Map()
26/01/12 01:49:45 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.18.0.5:42453 (size: 36.8 KiB, free: 366.3 MiB)
26/01/12 01:49:46 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 1565 ms on 172.18.0.5 (executor 0) (1/1)
26/01/12 01:49:46 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
26/01/12 01:49:46 INFO DAGScheduler: ResultStage 0 (parquet at NativeMethodAccessorImpl.java:0) finished in 1.944 s
26/01/12 01:49:46 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 01:49:46 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
26/01/12 01:49:46 INFO DAGScheduler: Job 0 finished: parquet at NativeMethodAccessorImpl.java:0, took 2.009918 s
26/01/12 01:49:46 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 02926ee04bc9:45221 in memory (size: 36.8 KiB, free: 366.3 MiB)
26/01/12 01:49:46 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 172.18.0.5:42453 in memory (size: 36.8 KiB, free: 366.3 MiB)
26/01/12 01:49:49 INFO FileSourceStrategy: Pushed Filters: 
26/01/12 01:49:49 INFO FileSourceStrategy: Post-Scan Filters: 
26/01/12 01:49:49 INFO FileSourceStrategy: Output Data Schema: struct<vendor_name: string, Trip_Pickup_DateTime: string, Trip_Dropoff_DateTime: string, Passenger_Count: bigint, Trip_Distance: double ... 16 more fields>
26/01/12 01:49:49 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 01:49:49 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 01:49:49 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 01:49:49 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 01:49:49 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 01:49:49 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 01:49:49 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 01:49:50 INFO CodeGenerator: Code generated in 258.595398 ms
26/01/12 01:49:50 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 358.0 KiB, free 366.0 MiB)
26/01/12 01:49:50 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 35.2 KiB, free 365.9 MiB)
26/01/12 01:49:50 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 02926ee04bc9:45221 (size: 35.2 KiB, free: 366.3 MiB)
26/01/12 01:49:50 INFO SparkContext: Created broadcast 1 from parquet at NativeMethodAccessorImpl.java:0
26/01/12 01:49:50 INFO FileSourceScanExec: Planning scan with bin packing, max size: 134217728 bytes, open cost is considered as scanning 4194304 bytes.
26/01/12 01:49:50 INFO SparkContext: Starting job: parquet at NativeMethodAccessorImpl.java:0
26/01/12 01:49:50 INFO DAGScheduler: Got job 1 (parquet at NativeMethodAccessorImpl.java:0) with 4 output partitions
26/01/12 01:49:50 INFO DAGScheduler: Final stage: ResultStage 1 (parquet at NativeMethodAccessorImpl.java:0)
26/01/12 01:49:50 INFO DAGScheduler: Parents of final stage: List()
26/01/12 01:49:50 INFO DAGScheduler: Missing parents: List()
26/01/12 01:49:50 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[4] at parquet at NativeMethodAccessorImpl.java:0), which has no missing parents
26/01/12 01:49:50 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 224.3 KiB, free 365.7 MiB)
26/01/12 01:49:50 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 77.2 KiB, free 365.6 MiB)
26/01/12 01:49:50 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 02926ee04bc9:45221 (size: 77.2 KiB, free: 366.2 MiB)
26/01/12 01:49:50 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1513
26/01/12 01:49:50 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 1 (MapPartitionsRDD[4] at parquet at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
26/01/12 01:49:50 INFO TaskSchedulerImpl: Adding task set 1.0 with 4 tasks resource profile 0
26/01/12 01:49:50 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 01:49:50 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 2) (172.18.0.5, executor 0, partition 1, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 01:49:50 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 172.18.0.5:42453 (size: 77.2 KiB, free: 366.2 MiB)
26/01/12 01:49:51 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.18.0.5:42453 (size: 35.2 KiB, free: 366.2 MiB)
26/01/12 01:49:52 INFO TaskSetManager: Starting task 2.0 in stage 1.0 (TID 3) (172.18.0.5, executor 0, partition 2, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 01:49:52 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 2543 ms on 172.18.0.5 (executor 0) (1/4)
26/01/12 01:49:52 INFO TaskSetManager: Starting task 3.0 in stage 1.0 (TID 4) (172.18.0.5, executor 0, partition 3, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 01:49:52 INFO TaskSetManager: Finished task 2.0 in stage 1.0 (TID 3) in 74 ms on 172.18.0.5 (executor 0) (2/4)
26/01/12 01:49:52 INFO TaskSetManager: Finished task 3.0 in stage 1.0 (TID 4) in 59 ms on 172.18.0.5 (executor 0) (3/4)
26/01/12 01:50:31 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 2) in 41310 ms on 172.18.0.5 (executor 0) (4/4)
26/01/12 01:50:31 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
26/01/12 01:50:31 INFO DAGScheduler: ResultStage 1 (parquet at NativeMethodAccessorImpl.java:0) finished in 41.383 s
26/01/12 01:50:31 INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 01:50:31 INFO TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished
26/01/12 01:50:31 INFO DAGScheduler: Job 1 finished: parquet at NativeMethodAccessorImpl.java:0, took 41.407420 s
26/01/12 01:50:31 INFO FileFormatWriter: Start to commit write Job 03a691aa-d17f-45f5-b562-2904e21fdeef.
26/01/12 01:50:31 INFO FileFormatWriter: Write Job 03a691aa-d17f-45f5-b562-2904e21fdeef committed. Elapsed time: 275 ms.
26/01/12 01:50:31 INFO FileFormatWriter: Finished processing stats for write job 03a691aa-d17f-45f5-b562-2904e21fdeef.
Cargando: yellow_tripdata_2009-02.parquet en hdfs://hadoop-namenode:8020/data/nyc/raw/taxi-trips/2009...
26/01/12 01:50:31 INFO InMemoryFileIndex: It took 9 ms to list leaf files for 1 paths.
26/01/12 01:50:31 INFO SparkContext: Starting job: parquet at NativeMethodAccessorImpl.java:0
26/01/12 01:50:31 INFO DAGScheduler: Got job 2 (parquet at NativeMethodAccessorImpl.java:0) with 1 output partitions
26/01/12 01:50:31 INFO DAGScheduler: Final stage: ResultStage 2 (parquet at NativeMethodAccessorImpl.java:0)
26/01/12 01:50:31 INFO DAGScheduler: Parents of final stage: List()
26/01/12 01:50:31 INFO DAGScheduler: Missing parents: List()
26/01/12 01:50:31 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[6] at parquet at NativeMethodAccessorImpl.java:0), which has no missing parents
26/01/12 01:50:31 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 102.6 KiB, free 365.5 MiB)
26/01/12 01:50:31 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 36.8 KiB, free 365.5 MiB)
26/01/12 01:50:31 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 02926ee04bc9:45221 (size: 36.8 KiB, free: 366.2 MiB)
26/01/12 01:50:31 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1513
26/01/12 01:50:31 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[6] at parquet at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
26/01/12 01:50:31 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks resource profile 0
26/01/12 01:50:31 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 5) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4607 bytes) taskResourceAssignments Map()
26/01/12 01:50:31 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.18.0.5:42453 (size: 36.8 KiB, free: 366.2 MiB)
26/01/12 01:50:31 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 5) in 68 ms on 172.18.0.5 (executor 0) (1/1)
26/01/12 01:50:31 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
26/01/12 01:50:31 INFO DAGScheduler: ResultStage 2 (parquet at NativeMethodAccessorImpl.java:0) finished in 0.087 s
26/01/12 01:50:31 INFO DAGScheduler: Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 01:50:31 INFO TaskSchedulerImpl: Killing all running tasks in stage 2: Stage finished
26/01/12 01:50:31 INFO DAGScheduler: Job 2 finished: parquet at NativeMethodAccessorImpl.java:0, took 0.096439 s
26/01/12 01:50:32 INFO FileSourceStrategy: Pushed Filters: 
26/01/12 01:50:32 INFO FileSourceStrategy: Post-Scan Filters: 
26/01/12 01:50:32 INFO FileSourceStrategy: Output Data Schema: struct<vendor_name: string, Trip_Pickup_DateTime: string, Trip_Dropoff_DateTime: string, Passenger_Count: bigint, Trip_Distance: double ... 16 more fields>
26/01/12 01:50:32 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 01:50:32 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 01:50:32 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 01:50:32 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 01:50:32 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 01:50:32 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 01:50:32 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 01:50:32 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 358.0 KiB, free 365.1 MiB)
26/01/12 01:50:32 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 35.2 KiB, free 365.1 MiB)
26/01/12 01:50:32 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 02926ee04bc9:45221 (size: 35.2 KiB, free: 366.1 MiB)
26/01/12 01:50:32 INFO SparkContext: Created broadcast 4 from parquet at NativeMethodAccessorImpl.java:0
26/01/12 01:50:32 INFO FileSourceScanExec: Planning scan with bin packing, max size: 134217728 bytes, open cost is considered as scanning 4194304 bytes.
26/01/12 01:50:32 INFO SparkContext: Starting job: parquet at NativeMethodAccessorImpl.java:0
26/01/12 01:50:32 INFO DAGScheduler: Got job 3 (parquet at NativeMethodAccessorImpl.java:0) with 4 output partitions
26/01/12 01:50:32 INFO DAGScheduler: Final stage: ResultStage 3 (parquet at NativeMethodAccessorImpl.java:0)
26/01/12 01:50:32 INFO DAGScheduler: Parents of final stage: List()
26/01/12 01:50:32 INFO DAGScheduler: Missing parents: List()
26/01/12 01:50:32 INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[9] at parquet at NativeMethodAccessorImpl.java:0), which has no missing parents
26/01/12 01:50:32 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 224.3 KiB, free 364.9 MiB)
26/01/12 01:50:32 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 77.2 KiB, free 364.8 MiB)
26/01/12 01:50:32 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 02926ee04bc9:45221 (size: 77.2 KiB, free: 366.0 MiB)
26/01/12 01:50:32 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1513
26/01/12 01:50:32 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 3 (MapPartitionsRDD[9] at parquet at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
26/01/12 01:50:32 INFO TaskSchedulerImpl: Adding task set 3.0 with 4 tasks resource profile 0
26/01/12 01:50:32 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 6) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 01:50:32 INFO TaskSetManager: Starting task 1.0 in stage 3.0 (TID 7) (172.18.0.5, executor 0, partition 1, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 01:50:32 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 172.18.0.5:42453 (size: 77.2 KiB, free: 366.1 MiB)
26/01/12 01:50:32 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.18.0.5:42453 (size: 35.2 KiB, free: 366.0 MiB)
26/01/12 01:50:32 INFO TaskSetManager: Starting task 2.0 in stage 3.0 (TID 8) (172.18.0.5, executor 0, partition 2, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 01:50:32 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 6) in 137 ms on 172.18.0.5 (executor 0) (1/4)
26/01/12 01:50:32 INFO TaskSetManager: Starting task 3.0 in stage 3.0 (TID 9) (172.18.0.5, executor 0, partition 3, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 01:50:32 INFO TaskSetManager: Finished task 2.0 in stage 3.0 (TID 8) in 41 ms on 172.18.0.5 (executor 0) (2/4)
26/01/12 01:50:32 INFO TaskSetManager: Finished task 3.0 in stage 3.0 (TID 9) in 44 ms on 172.18.0.5 (executor 0) (3/4)
26/01/12 01:51:05 INFO TaskSetManager: Finished task 1.0 in stage 3.0 (TID 7) in 33472 ms on 172.18.0.5 (executor 0) (4/4)
26/01/12 01:51:05 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
26/01/12 01:51:05 INFO DAGScheduler: ResultStage 3 (parquet at NativeMethodAccessorImpl.java:0) finished in 33.498 s
26/01/12 01:51:05 INFO DAGScheduler: Job 3 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 01:51:05 INFO TaskSchedulerImpl: Killing all running tasks in stage 3: Stage finished
26/01/12 01:51:05 INFO DAGScheduler: Job 3 finished: parquet at NativeMethodAccessorImpl.java:0, took 33.509579 s
26/01/12 01:51:05 INFO FileFormatWriter: Start to commit write Job e7d3203e-6dae-4357-a646-1544f25c6750.
26/01/12 01:51:05 INFO FileFormatWriter: Write Job e7d3203e-6dae-4357-a646-1544f25c6750 committed. Elapsed time: 40 ms.
26/01/12 01:51:05 INFO FileFormatWriter: Finished processing stats for write job e7d3203e-6dae-4357-a646-1544f25c6750.
Cargando: yellow_tripdata_2009-03.parquet en hdfs://hadoop-namenode:8020/data/nyc/raw/taxi-trips/2009...
26/01/12 01:51:05 INFO InMemoryFileIndex: It took 7 ms to list leaf files for 1 paths.
26/01/12 01:51:05 INFO SparkContext: Starting job: parquet at NativeMethodAccessorImpl.java:0
26/01/12 01:51:05 INFO DAGScheduler: Got job 4 (parquet at NativeMethodAccessorImpl.java:0) with 1 output partitions
26/01/12 01:51:05 INFO DAGScheduler: Final stage: ResultStage 4 (parquet at NativeMethodAccessorImpl.java:0)
26/01/12 01:51:05 INFO DAGScheduler: Parents of final stage: List()
26/01/12 01:51:05 INFO DAGScheduler: Missing parents: List()
26/01/12 01:51:05 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[11] at parquet at NativeMethodAccessorImpl.java:0), which has no missing parents
26/01/12 01:51:05 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 102.6 KiB, free 364.7 MiB)
26/01/12 01:51:05 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 36.8 KiB, free 364.7 MiB)
26/01/12 01:51:05 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 02926ee04bc9:45221 (size: 36.8 KiB, free: 366.0 MiB)
26/01/12 01:51:05 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1513
26/01/12 01:51:05 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[11] at parquet at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
26/01/12 01:51:05 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks resource profile 0
26/01/12 01:51:05 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 10) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4607 bytes) taskResourceAssignments Map()
26/01/12 01:51:05 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.18.0.5:42453 (size: 36.8 KiB, free: 366.0 MiB)
26/01/12 01:51:05 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 10) in 55 ms on 172.18.0.5 (executor 0) (1/1)
26/01/12 01:51:05 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
26/01/12 01:51:05 INFO DAGScheduler: ResultStage 4 (parquet at NativeMethodAccessorImpl.java:0) finished in 0.074 s
26/01/12 01:51:05 INFO DAGScheduler: Job 4 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 01:51:05 INFO TaskSchedulerImpl: Killing all running tasks in stage 4: Stage finished
26/01/12 01:51:05 INFO DAGScheduler: Job 4 finished: parquet at NativeMethodAccessorImpl.java:0, took 0.079563 s
26/01/12 01:51:05 INFO FileSourceStrategy: Pushed Filters: 
26/01/12 01:51:05 INFO FileSourceStrategy: Post-Scan Filters: 
26/01/12 01:51:05 INFO FileSourceStrategy: Output Data Schema: struct<vendor_name: string, Trip_Pickup_DateTime: string, Trip_Dropoff_DateTime: string, Passenger_Count: bigint, Trip_Distance: double ... 16 more fields>
26/01/12 01:51:05 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 01:51:05 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 01:51:05 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 01:51:05 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 01:51:05 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 01:51:05 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 01:51:05 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 01:51:05 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 358.0 KiB, free 364.3 MiB)
26/01/12 01:51:05 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 35.2 KiB, free 364.3 MiB)
26/01/12 01:51:05 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 02926ee04bc9:45221 (size: 35.2 KiB, free: 366.0 MiB)
26/01/12 01:51:05 INFO SparkContext: Created broadcast 7 from parquet at NativeMethodAccessorImpl.java:0
26/01/12 01:51:05 INFO FileSourceScanExec: Planning scan with bin packing, max size: 134217728 bytes, open cost is considered as scanning 4194304 bytes.
26/01/12 01:51:05 INFO SparkContext: Starting job: parquet at NativeMethodAccessorImpl.java:0
26/01/12 01:51:05 INFO DAGScheduler: Got job 5 (parquet at NativeMethodAccessorImpl.java:0) with 4 output partitions
26/01/12 01:51:05 INFO DAGScheduler: Final stage: ResultStage 5 (parquet at NativeMethodAccessorImpl.java:0)
26/01/12 01:51:05 INFO DAGScheduler: Parents of final stage: List()
26/01/12 01:51:05 INFO DAGScheduler: Missing parents: List()
26/01/12 01:51:05 INFO DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[14] at parquet at NativeMethodAccessorImpl.java:0), which has no missing parents
26/01/12 01:51:05 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 224.3 KiB, free 364.1 MiB)
26/01/12 01:51:05 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 77.2 KiB, free 364.0 MiB)
26/01/12 01:51:05 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 02926ee04bc9:45221 (size: 77.2 KiB, free: 365.9 MiB)
26/01/12 01:51:05 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1513
26/01/12 01:51:05 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 5 (MapPartitionsRDD[14] at parquet at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
26/01/12 01:51:05 INFO TaskSchedulerImpl: Adding task set 5.0 with 4 tasks resource profile 0
26/01/12 01:51:05 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 11) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 01:51:05 INFO TaskSetManager: Starting task 1.0 in stage 5.0 (TID 12) (172.18.0.5, executor 0, partition 1, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 01:51:05 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 172.18.0.5:42453 (size: 77.2 KiB, free: 365.9 MiB)
26/01/12 01:51:05 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 172.18.0.5:42453 (size: 35.2 KiB, free: 365.9 MiB)
26/01/12 01:51:06 INFO TaskSetManager: Starting task 2.0 in stage 5.0 (TID 13) (172.18.0.5, executor 0, partition 2, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 01:51:06 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 11) in 555 ms on 172.18.0.5 (executor 0) (1/4)
26/01/12 01:51:06 INFO TaskSetManager: Starting task 3.0 in stage 5.0 (TID 14) (172.18.0.5, executor 0, partition 3, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 01:51:06 INFO TaskSetManager: Finished task 2.0 in stage 5.0 (TID 13) in 46 ms on 172.18.0.5 (executor 0) (2/4)
26/01/12 01:51:06 INFO TaskSetManager: Finished task 3.0 in stage 5.0 (TID 14) in 48 ms on 172.18.0.5 (executor 0) (3/4)
26/01/12 01:51:42 INFO TaskSetManager: Finished task 1.0 in stage 5.0 (TID 12) in 36257 ms on 172.18.0.5 (executor 0) (4/4)
26/01/12 01:51:42 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
26/01/12 01:51:42 INFO DAGScheduler: ResultStage 5 (parquet at NativeMethodAccessorImpl.java:0) finished in 36.282 s
26/01/12 01:51:42 INFO DAGScheduler: Job 5 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 01:51:42 INFO TaskSchedulerImpl: Killing all running tasks in stage 5: Stage finished
26/01/12 01:51:42 INFO DAGScheduler: Job 5 finished: parquet at NativeMethodAccessorImpl.java:0, took 36.291887 s
26/01/12 01:51:42 INFO FileFormatWriter: Start to commit write Job 5708e852-6182-4801-bd5f-9d6d3308205a.
26/01/12 01:51:42 INFO FileFormatWriter: Write Job 5708e852-6182-4801-bd5f-9d6d3308205a committed. Elapsed time: 52 ms.
26/01/12 01:51:42 INFO FileFormatWriter: Finished processing stats for write job 5708e852-6182-4801-bd5f-9d6d3308205a.
Cargando: yellow_tripdata_2009-04.parquet en hdfs://hadoop-namenode:8020/data/nyc/raw/taxi-trips/2009...
26/01/12 01:51:42 INFO InMemoryFileIndex: It took 6 ms to list leaf files for 1 paths.
26/01/12 01:51:42 INFO SparkContext: Starting job: parquet at NativeMethodAccessorImpl.java:0
26/01/12 01:51:42 INFO DAGScheduler: Got job 6 (parquet at NativeMethodAccessorImpl.java:0) with 1 output partitions
26/01/12 01:51:42 INFO DAGScheduler: Final stage: ResultStage 6 (parquet at NativeMethodAccessorImpl.java:0)
26/01/12 01:51:42 INFO DAGScheduler: Parents of final stage: List()
26/01/12 01:51:42 INFO DAGScheduler: Missing parents: List()
26/01/12 01:51:42 INFO DAGScheduler: Submitting ResultStage 6 (MapPartitionsRDD[16] at parquet at NativeMethodAccessorImpl.java:0), which has no missing parents
26/01/12 01:51:42 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 102.6 KiB, free 363.9 MiB)
26/01/12 01:51:42 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 36.8 KiB, free 363.9 MiB)
26/01/12 01:51:42 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 02926ee04bc9:45221 (size: 36.8 KiB, free: 365.9 MiB)
26/01/12 01:51:42 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1513
26/01/12 01:51:42 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[16] at parquet at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
26/01/12 01:51:42 INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks resource profile 0
26/01/12 01:51:42 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 15) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4607 bytes) taskResourceAssignments Map()
26/01/12 01:51:42 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 172.18.0.5:42453 (size: 36.8 KiB, free: 365.9 MiB)
26/01/12 01:51:42 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 15) in 69 ms on 172.18.0.5 (executor 0) (1/1)
26/01/12 01:51:42 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
26/01/12 01:51:42 INFO DAGScheduler: ResultStage 6 (parquet at NativeMethodAccessorImpl.java:0) finished in 0.085 s
26/01/12 01:51:42 INFO DAGScheduler: Job 6 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 01:51:42 INFO TaskSchedulerImpl: Killing all running tasks in stage 6: Stage finished
26/01/12 01:51:42 INFO DAGScheduler: Job 6 finished: parquet at NativeMethodAccessorImpl.java:0, took 0.092694 s
26/01/12 01:51:42 INFO FileSourceStrategy: Pushed Filters: 
26/01/12 01:51:42 INFO FileSourceStrategy: Post-Scan Filters: 
26/01/12 01:51:42 INFO FileSourceStrategy: Output Data Schema: struct<vendor_name: string, Trip_Pickup_DateTime: string, Trip_Dropoff_DateTime: string, Passenger_Count: bigint, Trip_Distance: double ... 16 more fields>
26/01/12 01:51:42 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 01:51:42 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 01:51:42 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 01:51:42 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 01:51:42 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 01:51:42 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 01:51:42 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 01:51:42 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 358.0 KiB, free 363.5 MiB)
26/01/12 01:51:42 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 35.2 KiB, free 363.5 MiB)
26/01/12 01:51:42 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 02926ee04bc9:45221 (size: 35.2 KiB, free: 365.8 MiB)
26/01/12 01:51:42 INFO SparkContext: Created broadcast 10 from parquet at NativeMethodAccessorImpl.java:0
26/01/12 01:51:42 INFO FileSourceScanExec: Planning scan with bin packing, max size: 134217728 bytes, open cost is considered as scanning 4194304 bytes.
26/01/12 01:51:42 INFO SparkContext: Starting job: parquet at NativeMethodAccessorImpl.java:0
26/01/12 01:51:42 INFO DAGScheduler: Got job 7 (parquet at NativeMethodAccessorImpl.java:0) with 4 output partitions
26/01/12 01:51:42 INFO DAGScheduler: Final stage: ResultStage 7 (parquet at NativeMethodAccessorImpl.java:0)
26/01/12 01:51:42 INFO DAGScheduler: Parents of final stage: List()
26/01/12 01:51:42 INFO DAGScheduler: Missing parents: List()
26/01/12 01:51:42 INFO DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[19] at parquet at NativeMethodAccessorImpl.java:0), which has no missing parents
26/01/12 01:51:42 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 224.3 KiB, free 363.3 MiB)
26/01/12 01:51:42 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 77.2 KiB, free 363.2 MiB)
26/01/12 01:51:42 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 02926ee04bc9:45221 (size: 77.2 KiB, free: 365.8 MiB)
26/01/12 01:51:42 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1513
26/01/12 01:51:42 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 7 (MapPartitionsRDD[19] at parquet at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
26/01/12 01:51:42 INFO TaskSchedulerImpl: Adding task set 7.0 with 4 tasks resource profile 0
26/01/12 01:51:42 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 16) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 01:51:42 INFO TaskSetManager: Starting task 1.0 in stage 7.0 (TID 17) (172.18.0.5, executor 0, partition 1, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 01:51:42 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 172.18.0.5:42453 (size: 77.2 KiB, free: 365.8 MiB)
26/01/12 01:51:42 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 172.18.0.5:42453 (size: 35.2 KiB, free: 365.8 MiB)
26/01/12 01:51:43 INFO TaskSetManager: Starting task 2.0 in stage 7.0 (TID 18) (172.18.0.5, executor 0, partition 2, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 01:51:43 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 16) in 549 ms on 172.18.0.5 (executor 0) (1/4)
26/01/12 01:51:43 INFO TaskSetManager: Starting task 3.0 in stage 7.0 (TID 19) (172.18.0.5, executor 0, partition 3, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 01:51:43 INFO TaskSetManager: Finished task 2.0 in stage 7.0 (TID 18) in 46 ms on 172.18.0.5 (executor 0) (2/4)
26/01/12 01:51:43 INFO TaskSetManager: Finished task 3.0 in stage 7.0 (TID 19) in 45 ms on 172.18.0.5 (executor 0) (3/4)
26/01/12 01:52:19 INFO TaskSetManager: Finished task 1.0 in stage 7.0 (TID 17) in 36896 ms on 172.18.0.5 (executor 0) (4/4)
26/01/12 01:52:19 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 
26/01/12 01:52:19 INFO DAGScheduler: ResultStage 7 (parquet at NativeMethodAccessorImpl.java:0) finished in 36.926 s
26/01/12 01:52:19 INFO DAGScheduler: Job 7 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 01:52:19 INFO TaskSchedulerImpl: Killing all running tasks in stage 7: Stage finished
26/01/12 01:52:19 INFO DAGScheduler: Job 7 finished: parquet at NativeMethodAccessorImpl.java:0, took 36.937111 s
26/01/12 01:52:19 INFO FileFormatWriter: Start to commit write Job 6f7ef0c4-6a68-4549-bbc9-f1a68c94d289.
26/01/12 01:52:19 INFO FileFormatWriter: Write Job 6f7ef0c4-6a68-4549-bbc9-f1a68c94d289 committed. Elapsed time: 55 ms.
26/01/12 01:52:19 INFO FileFormatWriter: Finished processing stats for write job 6f7ef0c4-6a68-4549-bbc9-f1a68c94d289.
Cargando: yellow_tripdata_2009-05.parquet en hdfs://hadoop-namenode:8020/data/nyc/raw/taxi-trips/2009...
26/01/12 01:52:19 INFO InMemoryFileIndex: It took 7 ms to list leaf files for 1 paths.
26/01/12 01:52:19 INFO SparkContext: Starting job: parquet at NativeMethodAccessorImpl.java:0
26/01/12 01:52:19 INFO DAGScheduler: Got job 8 (parquet at NativeMethodAccessorImpl.java:0) with 1 output partitions
26/01/12 01:52:19 INFO DAGScheduler: Final stage: ResultStage 8 (parquet at NativeMethodAccessorImpl.java:0)
26/01/12 01:52:19 INFO DAGScheduler: Parents of final stage: List()
26/01/12 01:52:19 INFO DAGScheduler: Missing parents: List()
26/01/12 01:52:19 INFO DAGScheduler: Submitting ResultStage 8 (MapPartitionsRDD[21] at parquet at NativeMethodAccessorImpl.java:0), which has no missing parents
26/01/12 01:52:19 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 102.6 KiB, free 363.1 MiB)
26/01/12 01:52:19 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 36.8 KiB, free 363.0 MiB)
26/01/12 01:52:19 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 02926ee04bc9:45221 (size: 36.8 KiB, free: 365.7 MiB)
26/01/12 01:52:19 INFO SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:1513
26/01/12 01:52:19 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 8 (MapPartitionsRDD[21] at parquet at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
26/01/12 01:52:19 INFO TaskSchedulerImpl: Adding task set 8.0 with 1 tasks resource profile 0
26/01/12 01:52:19 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 20) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4607 bytes) taskResourceAssignments Map()
26/01/12 01:52:19 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 172.18.0.5:42453 (size: 36.8 KiB, free: 365.7 MiB)
26/01/12 01:52:19 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 20) in 73 ms on 172.18.0.5 (executor 0) (1/1)
26/01/12 01:52:19 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
26/01/12 01:52:19 INFO DAGScheduler: ResultStage 8 (parquet at NativeMethodAccessorImpl.java:0) finished in 0.091 s
26/01/12 01:52:19 INFO DAGScheduler: Job 8 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 01:52:19 INFO TaskSchedulerImpl: Killing all running tasks in stage 8: Stage finished
26/01/12 01:52:19 INFO DAGScheduler: Job 8 finished: parquet at NativeMethodAccessorImpl.java:0, took 0.097114 s
26/01/12 01:52:19 INFO FileSourceStrategy: Pushed Filters: 
26/01/12 01:52:19 INFO FileSourceStrategy: Post-Scan Filters: 
26/01/12 01:52:19 INFO FileSourceStrategy: Output Data Schema: struct<vendor_name: string, Trip_Pickup_DateTime: string, Trip_Dropoff_DateTime: string, Passenger_Count: bigint, Trip_Distance: double ... 16 more fields>
26/01/12 01:52:19 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 01:52:19 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 01:52:19 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 01:52:19 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 01:52:19 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 01:52:19 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 01:52:19 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 01:52:19 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 358.0 KiB, free 362.7 MiB)
26/01/12 01:52:19 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 35.2 KiB, free 362.7 MiB)
26/01/12 01:52:19 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 02926ee04bc9:45221 (size: 35.2 KiB, free: 365.7 MiB)
26/01/12 01:52:19 INFO SparkContext: Created broadcast 13 from parquet at NativeMethodAccessorImpl.java:0
26/01/12 01:52:19 INFO FileSourceScanExec: Planning scan with bin packing, max size: 134217728 bytes, open cost is considered as scanning 4194304 bytes.
26/01/12 01:52:19 INFO SparkContext: Starting job: parquet at NativeMethodAccessorImpl.java:0
26/01/12 01:52:19 INFO DAGScheduler: Got job 9 (parquet at NativeMethodAccessorImpl.java:0) with 4 output partitions
26/01/12 01:52:19 INFO DAGScheduler: Final stage: ResultStage 9 (parquet at NativeMethodAccessorImpl.java:0)
26/01/12 01:52:19 INFO DAGScheduler: Parents of final stage: List()
26/01/12 01:52:19 INFO DAGScheduler: Missing parents: List()
26/01/12 01:52:19 INFO DAGScheduler: Submitting ResultStage 9 (MapPartitionsRDD[24] at parquet at NativeMethodAccessorImpl.java:0), which has no missing parents
26/01/12 01:52:19 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 224.3 KiB, free 362.4 MiB)
26/01/12 01:52:19 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 77.2 KiB, free 362.4 MiB)
26/01/12 01:52:19 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 02926ee04bc9:45221 (size: 77.2 KiB, free: 365.6 MiB)
26/01/12 01:52:19 INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:1513
26/01/12 01:52:19 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 9 (MapPartitionsRDD[24] at parquet at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
26/01/12 01:52:19 INFO TaskSchedulerImpl: Adding task set 9.0 with 4 tasks resource profile 0
26/01/12 01:52:19 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 21) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 01:52:19 INFO TaskSetManager: Starting task 1.0 in stage 9.0 (TID 22) (172.18.0.5, executor 0, partition 1, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 01:52:19 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 172.18.0.5:42453 (size: 77.2 KiB, free: 365.6 MiB)
26/01/12 01:52:19 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 172.18.0.5:42453 (size: 35.2 KiB, free: 365.6 MiB)
26/01/12 01:52:20 INFO TaskSetManager: Starting task 2.0 in stage 9.0 (TID 23) (172.18.0.5, executor 0, partition 2, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 01:52:20 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 21) in 534 ms on 172.18.0.5 (executor 0) (1/4)
26/01/12 01:52:20 INFO TaskSetManager: Starting task 3.0 in stage 9.0 (TID 24) (172.18.0.5, executor 0, partition 3, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 01:52:20 INFO TaskSetManager: Finished task 2.0 in stage 9.0 (TID 23) in 49 ms on 172.18.0.5 (executor 0) (2/4)
26/01/12 01:52:20 INFO TaskSetManager: Finished task 3.0 in stage 9.0 (TID 24) in 46 ms on 172.18.0.5 (executor 0) (3/4)
26/01/12 01:53:00 INFO TaskSetManager: Finished task 1.0 in stage 9.0 (TID 22) in 40511 ms on 172.18.0.5 (executor 0) (4/4)
26/01/12 01:53:00 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool 
26/01/12 01:53:00 INFO DAGScheduler: ResultStage 9 (parquet at NativeMethodAccessorImpl.java:0) finished in 40.542 s
26/01/12 01:53:00 INFO DAGScheduler: Job 9 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 01:53:00 INFO TaskSchedulerImpl: Killing all running tasks in stage 9: Stage finished
26/01/12 01:53:00 INFO DAGScheduler: Job 9 finished: parquet at NativeMethodAccessorImpl.java:0, took 40.550915 s
26/01/12 01:53:00 INFO FileFormatWriter: Start to commit write Job a61186fe-443d-4766-a990-ec00250d652b.
26/01/12 01:53:00 INFO FileFormatWriter: Write Job a61186fe-443d-4766-a990-ec00250d652b committed. Elapsed time: 50 ms.
26/01/12 01:53:00 INFO FileFormatWriter: Finished processing stats for write job a61186fe-443d-4766-a990-ec00250d652b.
Cargando: yellow_tripdata_2009-06.parquet en hdfs://hadoop-namenode:8020/data/nyc/raw/taxi-trips/2009...
26/01/12 01:53:00 INFO InMemoryFileIndex: It took 5 ms to list leaf files for 1 paths.
26/01/12 01:53:00 INFO SparkContext: Starting job: parquet at NativeMethodAccessorImpl.java:0
26/01/12 01:53:00 INFO DAGScheduler: Got job 10 (parquet at NativeMethodAccessorImpl.java:0) with 1 output partitions
26/01/12 01:53:00 INFO DAGScheduler: Final stage: ResultStage 10 (parquet at NativeMethodAccessorImpl.java:0)
26/01/12 01:53:00 INFO DAGScheduler: Parents of final stage: List()
26/01/12 01:53:00 INFO DAGScheduler: Missing parents: List()
26/01/12 01:53:00 INFO DAGScheduler: Submitting ResultStage 10 (MapPartitionsRDD[26] at parquet at NativeMethodAccessorImpl.java:0), which has no missing parents
26/01/12 01:53:00 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 102.6 KiB, free 362.3 MiB)
26/01/12 01:53:00 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 36.8 KiB, free 362.2 MiB)
26/01/12 01:53:00 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on 02926ee04bc9:45221 (size: 36.8 KiB, free: 365.6 MiB)
26/01/12 01:53:00 INFO SparkContext: Created broadcast 15 from broadcast at DAGScheduler.scala:1513
26/01/12 01:53:00 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 10 (MapPartitionsRDD[26] at parquet at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
26/01/12 01:53:00 INFO TaskSchedulerImpl: Adding task set 10.0 with 1 tasks resource profile 0
26/01/12 01:53:00 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 25) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4607 bytes) taskResourceAssignments Map()
26/01/12 01:53:00 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on 172.18.0.5:42453 (size: 36.8 KiB, free: 365.6 MiB)
26/01/12 01:53:00 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 25) in 52 ms on 172.18.0.5 (executor 0) (1/1)
26/01/12 01:53:00 INFO TaskSchedulerImpl: Removed TaskSet 10.0, whose tasks have all completed, from pool 
26/01/12 01:53:00 INFO DAGScheduler: ResultStage 10 (parquet at NativeMethodAccessorImpl.java:0) finished in 0.069 s
26/01/12 01:53:00 INFO DAGScheduler: Job 10 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 01:53:00 INFO TaskSchedulerImpl: Killing all running tasks in stage 10: Stage finished
26/01/12 01:53:00 INFO DAGScheduler: Job 10 finished: parquet at NativeMethodAccessorImpl.java:0, took 0.074351 s
26/01/12 01:53:00 INFO FileSourceStrategy: Pushed Filters: 
26/01/12 01:53:00 INFO FileSourceStrategy: Post-Scan Filters: 
26/01/12 01:53:00 INFO FileSourceStrategy: Output Data Schema: struct<vendor_name: string, Trip_Pickup_DateTime: string, Trip_Dropoff_DateTime: string, Passenger_Count: bigint, Trip_Distance: double ... 16 more fields>
26/01/12 01:53:00 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 01:53:00 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 01:53:00 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 01:53:00 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 01:53:00 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 01:53:00 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 01:53:00 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 01:53:00 INFO MemoryStore: Block broadcast_16 stored as values in memory (estimated size 358.0 KiB, free 361.9 MiB)
26/01/12 01:53:00 INFO MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 35.2 KiB, free 361.8 MiB)
26/01/12 01:53:00 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on 02926ee04bc9:45221 (size: 35.2 KiB, free: 365.5 MiB)
26/01/12 01:53:00 INFO SparkContext: Created broadcast 16 from parquet at NativeMethodAccessorImpl.java:0
26/01/12 01:53:00 INFO FileSourceScanExec: Planning scan with bin packing, max size: 134217728 bytes, open cost is considered as scanning 4194304 bytes.
26/01/12 01:53:00 INFO SparkContext: Starting job: parquet at NativeMethodAccessorImpl.java:0
26/01/12 01:53:00 INFO DAGScheduler: Got job 11 (parquet at NativeMethodAccessorImpl.java:0) with 4 output partitions
26/01/12 01:53:00 INFO DAGScheduler: Final stage: ResultStage 11 (parquet at NativeMethodAccessorImpl.java:0)
26/01/12 01:53:00 INFO DAGScheduler: Parents of final stage: List()
26/01/12 01:53:00 INFO DAGScheduler: Missing parents: List()
26/01/12 01:53:00 INFO DAGScheduler: Submitting ResultStage 11 (MapPartitionsRDD[29] at parquet at NativeMethodAccessorImpl.java:0), which has no missing parents
26/01/12 01:53:00 INFO MemoryStore: Block broadcast_17 stored as values in memory (estimated size 224.3 KiB, free 361.6 MiB)
26/01/12 01:53:00 INFO MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 77.2 KiB, free 361.5 MiB)
26/01/12 01:53:00 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on 02926ee04bc9:45221 (size: 77.2 KiB, free: 365.5 MiB)
26/01/12 01:53:00 INFO SparkContext: Created broadcast 17 from broadcast at DAGScheduler.scala:1513
26/01/12 01:53:00 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 11 (MapPartitionsRDD[29] at parquet at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
26/01/12 01:53:00 INFO TaskSchedulerImpl: Adding task set 11.0 with 4 tasks resource profile 0
26/01/12 01:53:00 INFO TaskSetManager: Starting task 0.0 in stage 11.0 (TID 26) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 01:53:00 INFO TaskSetManager: Starting task 1.0 in stage 11.0 (TID 27) (172.18.0.5, executor 0, partition 1, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 01:53:00 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on 172.18.0.5:42453 (size: 77.2 KiB, free: 365.5 MiB)
26/01/12 01:53:00 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on 172.18.0.5:42453 (size: 35.2 KiB, free: 365.5 MiB)
26/01/12 01:53:01 INFO TaskSetManager: Starting task 2.0 in stage 11.0 (TID 28) (172.18.0.5, executor 0, partition 2, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 01:53:01 INFO TaskSetManager: Finished task 0.0 in stage 11.0 (TID 26) in 535 ms on 172.18.0.5 (executor 0) (1/4)
26/01/12 01:53:01 INFO TaskSetManager: Starting task 3.0 in stage 11.0 (TID 29) (172.18.0.5, executor 0, partition 3, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 01:53:01 INFO TaskSetManager: Finished task 2.0 in stage 11.0 (TID 28) in 39 ms on 172.18.0.5 (executor 0) (2/4)
26/01/12 01:53:01 INFO TaskSetManager: Finished task 3.0 in stage 11.0 (TID 29) in 36 ms on 172.18.0.5 (executor 0) (3/4)
26/01/12 01:53:37 INFO TaskSetManager: Finished task 1.0 in stage 11.0 (TID 27) in 36756 ms on 172.18.0.5 (executor 0) (4/4)
26/01/12 01:53:37 INFO TaskSchedulerImpl: Removed TaskSet 11.0, whose tasks have all completed, from pool 
26/01/12 01:53:37 INFO DAGScheduler: ResultStage 11 (parquet at NativeMethodAccessorImpl.java:0) finished in 36.779 s
26/01/12 01:53:37 INFO DAGScheduler: Job 11 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 01:53:37 INFO TaskSchedulerImpl: Killing all running tasks in stage 11: Stage finished
26/01/12 01:53:37 INFO DAGScheduler: Job 11 finished: parquet at NativeMethodAccessorImpl.java:0, took 36.791149 s
26/01/12 01:53:37 INFO FileFormatWriter: Start to commit write Job 7cd1772f-5514-47c0-b098-ed7bbc3bee72.
26/01/12 01:53:37 INFO FileFormatWriter: Write Job 7cd1772f-5514-47c0-b098-ed7bbc3bee72 committed. Elapsed time: 56 ms.
26/01/12 01:53:37 INFO FileFormatWriter: Finished processing stats for write job 7cd1772f-5514-47c0-b098-ed7bbc3bee72.
Cargando: yellow_tripdata_2009-07.parquet en hdfs://hadoop-namenode:8020/data/nyc/raw/taxi-trips/2009...
26/01/12 01:53:37 INFO InMemoryFileIndex: It took 6 ms to list leaf files for 1 paths.
26/01/12 01:53:37 INFO SparkContext: Starting job: parquet at NativeMethodAccessorImpl.java:0
26/01/12 01:53:37 INFO DAGScheduler: Got job 12 (parquet at NativeMethodAccessorImpl.java:0) with 1 output partitions
26/01/12 01:53:37 INFO DAGScheduler: Final stage: ResultStage 12 (parquet at NativeMethodAccessorImpl.java:0)
26/01/12 01:53:37 INFO DAGScheduler: Parents of final stage: List()
26/01/12 01:53:37 INFO DAGScheduler: Missing parents: List()
26/01/12 01:53:37 INFO DAGScheduler: Submitting ResultStage 12 (MapPartitionsRDD[31] at parquet at NativeMethodAccessorImpl.java:0), which has no missing parents
26/01/12 01:53:37 INFO BlockManagerInfo: Removed broadcast_12_piece0 on 02926ee04bc9:45221 in memory (size: 36.8 KiB, free: 365.5 MiB)
26/01/12 01:53:37 INFO BlockManagerInfo: Removed broadcast_12_piece0 on 172.18.0.5:42453 in memory (size: 36.8 KiB, free: 365.5 MiB)
26/01/12 01:53:37 INFO MemoryStore: Block broadcast_18 stored as values in memory (estimated size 102.6 KiB, free 361.6 MiB)
26/01/12 01:53:37 INFO MemoryStore: Block broadcast_18_piece0 stored as bytes in memory (estimated size 36.8 KiB, free 361.5 MiB)
26/01/12 01:53:37 INFO BlockManagerInfo: Added broadcast_18_piece0 in memory on 02926ee04bc9:45221 (size: 36.8 KiB, free: 365.5 MiB)
26/01/12 01:53:37 INFO BlockManagerInfo: Removed broadcast_14_piece0 on 02926ee04bc9:45221 in memory (size: 77.2 KiB, free: 365.5 MiB)
26/01/12 01:53:37 INFO SparkContext: Created broadcast 18 from broadcast at DAGScheduler.scala:1513
26/01/12 01:53:37 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 12 (MapPartitionsRDD[31] at parquet at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
26/01/12 01:53:37 INFO TaskSchedulerImpl: Adding task set 12.0 with 1 tasks resource profile 0
26/01/12 01:53:37 INFO BlockManagerInfo: Removed broadcast_14_piece0 on 172.18.0.5:42453 in memory (size: 77.2 KiB, free: 365.6 MiB)
26/01/12 01:53:37 INFO TaskSetManager: Starting task 0.0 in stage 12.0 (TID 30) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4607 bytes) taskResourceAssignments Map()
26/01/12 01:53:37 INFO BlockManagerInfo: Removed broadcast_2_piece0 on 02926ee04bc9:45221 in memory (size: 77.2 KiB, free: 365.6 MiB)
26/01/12 01:53:37 INFO BlockManagerInfo: Removed broadcast_2_piece0 on 172.18.0.5:42453 in memory (size: 77.2 KiB, free: 365.6 MiB)
26/01/12 01:53:37 INFO BlockManagerInfo: Added broadcast_18_piece0 in memory on 172.18.0.5:42453 (size: 36.8 KiB, free: 365.6 MiB)
26/01/12 01:53:37 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 02926ee04bc9:45221 in memory (size: 35.2 KiB, free: 365.6 MiB)
26/01/12 01:53:37 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 172.18.0.5:42453 in memory (size: 35.2 KiB, free: 365.6 MiB)
26/01/12 01:53:37 INFO BlockManagerInfo: Removed broadcast_7_piece0 on 02926ee04bc9:45221 in memory (size: 35.2 KiB, free: 365.7 MiB)
26/01/12 01:53:37 INFO BlockManagerInfo: Removed broadcast_7_piece0 on 172.18.0.5:42453 in memory (size: 35.2 KiB, free: 365.7 MiB)
26/01/12 01:53:37 INFO BlockManagerInfo: Removed broadcast_6_piece0 on 02926ee04bc9:45221 in memory (size: 36.8 KiB, free: 365.7 MiB)
26/01/12 01:53:37 INFO BlockManagerInfo: Removed broadcast_6_piece0 on 172.18.0.5:42453 in memory (size: 36.8 KiB, free: 365.7 MiB)
26/01/12 01:53:37 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 02926ee04bc9:45221 in memory (size: 35.2 KiB, free: 365.8 MiB)
26/01/12 01:53:37 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 172.18.0.5:42453 in memory (size: 35.2 KiB, free: 365.8 MiB)
26/01/12 01:53:37 INFO BlockManagerInfo: Removed broadcast_9_piece0 on 02926ee04bc9:45221 in memory (size: 36.8 KiB, free: 365.8 MiB)
26/01/12 01:53:37 INFO BlockManagerInfo: Removed broadcast_9_piece0 on 172.18.0.5:42453 in memory (size: 36.8 KiB, free: 365.8 MiB)
26/01/12 01:53:37 INFO TaskSetManager: Finished task 0.0 in stage 12.0 (TID 30) in 78 ms on 172.18.0.5 (executor 0) (1/1)
26/01/12 01:53:37 INFO TaskSchedulerImpl: Removed TaskSet 12.0, whose tasks have all completed, from pool 
26/01/12 01:53:37 INFO DAGScheduler: ResultStage 12 (parquet at NativeMethodAccessorImpl.java:0) finished in 0.102 s
26/01/12 01:53:37 INFO DAGScheduler: Job 12 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 01:53:37 INFO TaskSchedulerImpl: Killing all running tasks in stage 12: Stage finished
26/01/12 01:53:37 INFO DAGScheduler: Job 12 finished: parquet at NativeMethodAccessorImpl.java:0, took 0.109217 s
26/01/12 01:53:37 INFO BlockManagerInfo: Removed broadcast_10_piece0 on 02926ee04bc9:45221 in memory (size: 35.2 KiB, free: 365.8 MiB)
26/01/12 01:53:37 INFO BlockManagerInfo: Removed broadcast_10_piece0 on 172.18.0.5:42453 in memory (size: 35.2 KiB, free: 365.8 MiB)
26/01/12 01:53:37 INFO BlockManagerInfo: Removed broadcast_17_piece0 on 02926ee04bc9:45221 in memory (size: 77.2 KiB, free: 365.9 MiB)
26/01/12 01:53:37 INFO BlockManagerInfo: Removed broadcast_17_piece0 on 172.18.0.5:42453 in memory (size: 77.2 KiB, free: 365.9 MiB)
26/01/12 01:53:37 INFO BlockManagerInfo: Removed broadcast_5_piece0 on 02926ee04bc9:45221 in memory (size: 77.2 KiB, free: 366.0 MiB)
26/01/12 01:53:37 INFO BlockManagerInfo: Removed broadcast_5_piece0 on 172.18.0.5:42453 in memory (size: 77.2 KiB, free: 366.0 MiB)
26/01/12 01:53:37 INFO FileSourceStrategy: Pushed Filters: 
26/01/12 01:53:37 INFO FileSourceStrategy: Post-Scan Filters: 
26/01/12 01:53:37 INFO FileSourceStrategy: Output Data Schema: struct<vendor_name: string, Trip_Pickup_DateTime: string, Trip_Dropoff_DateTime: string, Passenger_Count: bigint, Trip_Distance: double ... 16 more fields>
26/01/12 01:53:37 INFO BlockManagerInfo: Removed broadcast_8_piece0 on 02926ee04bc9:45221 in memory (size: 77.2 KiB, free: 366.0 MiB)
26/01/12 01:53:37 INFO BlockManagerInfo: Removed broadcast_8_piece0 on 172.18.0.5:42453 in memory (size: 77.2 KiB, free: 366.0 MiB)
26/01/12 01:53:37 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 01:53:37 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 01:53:37 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 01:53:37 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 01:53:37 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 01:53:37 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 01:53:37 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 01:53:37 INFO BlockManagerInfo: Removed broadcast_13_piece0 on 02926ee04bc9:45221 in memory (size: 35.2 KiB, free: 366.1 MiB)
26/01/12 01:53:37 INFO BlockManagerInfo: Removed broadcast_13_piece0 on 172.18.0.5:42453 in memory (size: 35.2 KiB, free: 366.1 MiB)
26/01/12 01:53:37 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 02926ee04bc9:45221 in memory (size: 36.8 KiB, free: 366.1 MiB)
26/01/12 01:53:37 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 172.18.0.5:42453 in memory (size: 36.8 KiB, free: 366.1 MiB)
26/01/12 01:53:37 INFO MemoryStore: Block broadcast_19 stored as values in memory (estimated size 358.0 KiB, free 365.0 MiB)
26/01/12 01:53:37 INFO BlockManagerInfo: Removed broadcast_15_piece0 on 02926ee04bc9:45221 in memory (size: 36.8 KiB, free: 366.2 MiB)
26/01/12 01:53:37 INFO BlockManagerInfo: Removed broadcast_15_piece0 on 172.18.0.5:42453 in memory (size: 36.8 KiB, free: 366.2 MiB)
26/01/12 01:53:37 INFO MemoryStore: Block broadcast_19_piece0 stored as bytes in memory (estimated size 35.2 KiB, free 365.1 MiB)
26/01/12 01:53:37 INFO BlockManagerInfo: Added broadcast_19_piece0 in memory on 02926ee04bc9:45221 (size: 35.2 KiB, free: 366.1 MiB)
26/01/12 01:53:37 INFO BlockManagerInfo: Removed broadcast_11_piece0 on 02926ee04bc9:45221 in memory (size: 77.2 KiB, free: 366.2 MiB)
26/01/12 01:53:37 INFO SparkContext: Created broadcast 19 from parquet at NativeMethodAccessorImpl.java:0
26/01/12 01:53:37 INFO BlockManagerInfo: Removed broadcast_11_piece0 on 172.18.0.5:42453 in memory (size: 77.2 KiB, free: 366.2 MiB)
26/01/12 01:53:37 INFO FileSourceScanExec: Planning scan with bin packing, max size: 134217728 bytes, open cost is considered as scanning 4194304 bytes.
26/01/12 01:53:37 INFO SparkContext: Starting job: parquet at NativeMethodAccessorImpl.java:0
26/01/12 01:53:37 INFO DAGScheduler: Got job 13 (parquet at NativeMethodAccessorImpl.java:0) with 4 output partitions
26/01/12 01:53:37 INFO DAGScheduler: Final stage: ResultStage 13 (parquet at NativeMethodAccessorImpl.java:0)
26/01/12 01:53:37 INFO DAGScheduler: Parents of final stage: List()
26/01/12 01:53:37 INFO DAGScheduler: Missing parents: List()
26/01/12 01:53:37 INFO DAGScheduler: Submitting ResultStage 13 (MapPartitionsRDD[34] at parquet at NativeMethodAccessorImpl.java:0), which has no missing parents
26/01/12 01:53:37 INFO MemoryStore: Block broadcast_20 stored as values in memory (estimated size 224.3 KiB, free 365.2 MiB)
26/01/12 01:53:37 INFO MemoryStore: Block broadcast_20_piece0 stored as bytes in memory (estimated size 77.2 KiB, free 365.1 MiB)
26/01/12 01:53:37 INFO BlockManagerInfo: Added broadcast_20_piece0 in memory on 02926ee04bc9:45221 (size: 77.2 KiB, free: 366.1 MiB)
26/01/12 01:53:37 INFO SparkContext: Created broadcast 20 from broadcast at DAGScheduler.scala:1513
26/01/12 01:53:37 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 13 (MapPartitionsRDD[34] at parquet at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
26/01/12 01:53:37 INFO TaskSchedulerImpl: Adding task set 13.0 with 4 tasks resource profile 0
26/01/12 01:53:37 INFO TaskSetManager: Starting task 0.0 in stage 13.0 (TID 31) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 01:53:37 INFO TaskSetManager: Starting task 1.0 in stage 13.0 (TID 32) (172.18.0.5, executor 0, partition 1, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 01:53:37 INFO BlockManagerInfo: Added broadcast_20_piece0 in memory on 172.18.0.5:42453 (size: 77.2 KiB, free: 366.2 MiB)
26/01/12 01:53:37 INFO BlockManagerInfo: Added broadcast_19_piece0 in memory on 172.18.0.5:42453 (size: 35.2 KiB, free: 366.1 MiB)
26/01/12 01:53:37 INFO TaskSetManager: Starting task 2.0 in stage 13.0 (TID 33) (172.18.0.5, executor 0, partition 2, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 01:53:37 INFO TaskSetManager: Finished task 0.0 in stage 13.0 (TID 31) in 120 ms on 172.18.0.5 (executor 0) (1/4)
26/01/12 01:53:37 INFO TaskSetManager: Starting task 3.0 in stage 13.0 (TID 34) (172.18.0.5, executor 0, partition 3, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 01:53:37 INFO TaskSetManager: Finished task 2.0 in stage 13.0 (TID 33) in 39 ms on 172.18.0.5 (executor 0) (2/4)
26/01/12 01:53:37 INFO TaskSetManager: Finished task 3.0 in stage 13.0 (TID 34) in 33 ms on 172.18.0.5 (executor 0) (3/4)
26/01/12 01:54:13 INFO TaskSetManager: Finished task 1.0 in stage 13.0 (TID 32) in 36232 ms on 172.18.0.5 (executor 0) (4/4)
26/01/12 01:54:13 INFO TaskSchedulerImpl: Removed TaskSet 13.0, whose tasks have all completed, from pool 
26/01/12 01:54:13 INFO DAGScheduler: ResultStage 13 (parquet at NativeMethodAccessorImpl.java:0) finished in 36.254 s
26/01/12 01:54:13 INFO DAGScheduler: Job 13 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 01:54:13 INFO TaskSchedulerImpl: Killing all running tasks in stage 13: Stage finished
26/01/12 01:54:13 INFO DAGScheduler: Job 13 finished: parquet at NativeMethodAccessorImpl.java:0, took 36.264717 s
26/01/12 01:54:13 INFO FileFormatWriter: Start to commit write Job b4b37b98-b820-424f-85ad-04b99c6baf74.
26/01/12 01:54:13 INFO FileFormatWriter: Write Job b4b37b98-b820-424f-85ad-04b99c6baf74 committed. Elapsed time: 54 ms.
26/01/12 01:54:13 INFO FileFormatWriter: Finished processing stats for write job b4b37b98-b820-424f-85ad-04b99c6baf74.
Cargando: yellow_tripdata_2009-08.parquet en hdfs://hadoop-namenode:8020/data/nyc/raw/taxi-trips/2009...
26/01/12 01:54:14 INFO InMemoryFileIndex: It took 8 ms to list leaf files for 1 paths.
26/01/12 01:54:14 INFO SparkContext: Starting job: parquet at NativeMethodAccessorImpl.java:0
26/01/12 01:54:14 INFO DAGScheduler: Got job 14 (parquet at NativeMethodAccessorImpl.java:0) with 1 output partitions
26/01/12 01:54:14 INFO DAGScheduler: Final stage: ResultStage 14 (parquet at NativeMethodAccessorImpl.java:0)
26/01/12 01:54:14 INFO DAGScheduler: Parents of final stage: List()
26/01/12 01:54:14 INFO DAGScheduler: Missing parents: List()
26/01/12 01:54:14 INFO DAGScheduler: Submitting ResultStage 14 (MapPartitionsRDD[36] at parquet at NativeMethodAccessorImpl.java:0), which has no missing parents
26/01/12 01:54:14 INFO MemoryStore: Block broadcast_21 stored as values in memory (estimated size 102.6 KiB, free 365.0 MiB)
26/01/12 01:54:14 INFO MemoryStore: Block broadcast_21_piece0 stored as bytes in memory (estimated size 36.8 KiB, free 365.0 MiB)
26/01/12 01:54:14 INFO BlockManagerInfo: Added broadcast_21_piece0 in memory on 02926ee04bc9:45221 (size: 36.8 KiB, free: 366.1 MiB)
26/01/12 01:54:14 INFO SparkContext: Created broadcast 21 from broadcast at DAGScheduler.scala:1513
26/01/12 01:54:14 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 14 (MapPartitionsRDD[36] at parquet at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
26/01/12 01:54:14 INFO TaskSchedulerImpl: Adding task set 14.0 with 1 tasks resource profile 0
26/01/12 01:54:14 INFO TaskSetManager: Starting task 0.0 in stage 14.0 (TID 35) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4607 bytes) taskResourceAssignments Map()
26/01/12 01:54:14 INFO BlockManagerInfo: Added broadcast_21_piece0 in memory on 172.18.0.5:42453 (size: 36.8 KiB, free: 366.1 MiB)
26/01/12 01:54:14 INFO TaskSetManager: Finished task 0.0 in stage 14.0 (TID 35) in 59 ms on 172.18.0.5 (executor 0) (1/1)
26/01/12 01:54:14 INFO TaskSchedulerImpl: Removed TaskSet 14.0, whose tasks have all completed, from pool 
26/01/12 01:54:14 INFO DAGScheduler: ResultStage 14 (parquet at NativeMethodAccessorImpl.java:0) finished in 0.077 s
26/01/12 01:54:14 INFO DAGScheduler: Job 14 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 01:54:14 INFO TaskSchedulerImpl: Killing all running tasks in stage 14: Stage finished
26/01/12 01:54:14 INFO DAGScheduler: Job 14 finished: parquet at NativeMethodAccessorImpl.java:0, took 0.084862 s
26/01/12 01:54:14 INFO FileSourceStrategy: Pushed Filters: 
26/01/12 01:54:14 INFO FileSourceStrategy: Post-Scan Filters: 
26/01/12 01:54:14 INFO FileSourceStrategy: Output Data Schema: struct<vendor_name: string, Trip_Pickup_DateTime: string, Trip_Dropoff_DateTime: string, Passenger_Count: bigint, Trip_Distance: double ... 16 more fields>
26/01/12 01:54:14 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 01:54:14 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 01:54:14 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 01:54:14 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 01:54:14 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 01:54:14 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 01:54:14 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 01:54:14 INFO MemoryStore: Block broadcast_22 stored as values in memory (estimated size 358.0 KiB, free 364.6 MiB)
26/01/12 01:54:14 INFO MemoryStore: Block broadcast_22_piece0 stored as bytes in memory (estimated size 35.2 KiB, free 364.6 MiB)
26/01/12 01:54:14 INFO BlockManagerInfo: Added broadcast_22_piece0 in memory on 02926ee04bc9:45221 (size: 35.2 KiB, free: 366.0 MiB)
26/01/12 01:54:14 INFO SparkContext: Created broadcast 22 from parquet at NativeMethodAccessorImpl.java:0
26/01/12 01:54:14 INFO FileSourceScanExec: Planning scan with bin packing, max size: 134217728 bytes, open cost is considered as scanning 4194304 bytes.
26/01/12 01:54:14 INFO SparkContext: Starting job: parquet at NativeMethodAccessorImpl.java:0
26/01/12 01:54:14 INFO DAGScheduler: Got job 15 (parquet at NativeMethodAccessorImpl.java:0) with 4 output partitions
26/01/12 01:54:14 INFO DAGScheduler: Final stage: ResultStage 15 (parquet at NativeMethodAccessorImpl.java:0)
26/01/12 01:54:14 INFO DAGScheduler: Parents of final stage: List()
26/01/12 01:54:14 INFO DAGScheduler: Missing parents: List()
26/01/12 01:54:14 INFO DAGScheduler: Submitting ResultStage 15 (MapPartitionsRDD[39] at parquet at NativeMethodAccessorImpl.java:0), which has no missing parents
26/01/12 01:54:14 INFO MemoryStore: Block broadcast_23 stored as values in memory (estimated size 224.3 KiB, free 364.4 MiB)
26/01/12 01:54:14 INFO MemoryStore: Block broadcast_23_piece0 stored as bytes in memory (estimated size 77.2 KiB, free 364.3 MiB)
26/01/12 01:54:14 INFO BlockManagerInfo: Added broadcast_23_piece0 in memory on 02926ee04bc9:45221 (size: 77.2 KiB, free: 366.0 MiB)
26/01/12 01:54:14 INFO SparkContext: Created broadcast 23 from broadcast at DAGScheduler.scala:1513
26/01/12 01:54:14 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 15 (MapPartitionsRDD[39] at parquet at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
26/01/12 01:54:14 INFO TaskSchedulerImpl: Adding task set 15.0 with 4 tasks resource profile 0
26/01/12 01:54:14 INFO TaskSetManager: Starting task 0.0 in stage 15.0 (TID 36) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 01:54:14 INFO TaskSetManager: Starting task 1.0 in stage 15.0 (TID 37) (172.18.0.5, executor 0, partition 1, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 01:54:14 INFO BlockManagerInfo: Added broadcast_23_piece0 in memory on 172.18.0.5:42453 (size: 77.2 KiB, free: 366.0 MiB)
26/01/12 01:54:14 INFO BlockManagerInfo: Added broadcast_22_piece0 in memory on 172.18.0.5:42453 (size: 35.2 KiB, free: 366.0 MiB)
26/01/12 01:54:14 INFO TaskSetManager: Starting task 2.0 in stage 15.0 (TID 38) (172.18.0.5, executor 0, partition 2, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 01:54:14 INFO TaskSetManager: Finished task 0.0 in stage 15.0 (TID 36) in 526 ms on 172.18.0.5 (executor 0) (1/4)
26/01/12 01:54:14 INFO TaskSetManager: Starting task 3.0 in stage 15.0 (TID 39) (172.18.0.5, executor 0, partition 3, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 01:54:14 INFO TaskSetManager: Finished task 2.0 in stage 15.0 (TID 38) in 37 ms on 172.18.0.5 (executor 0) (2/4)
26/01/12 01:54:14 INFO TaskSetManager: Finished task 3.0 in stage 15.0 (TID 39) in 32 ms on 172.18.0.5 (executor 0) (3/4)
26/01/12 01:54:49 INFO TaskSetManager: Finished task 1.0 in stage 15.0 (TID 37) in 35644 ms on 172.18.0.5 (executor 0) (4/4)
26/01/12 01:54:49 INFO TaskSchedulerImpl: Removed TaskSet 15.0, whose tasks have all completed, from pool 
26/01/12 01:54:49 INFO DAGScheduler: ResultStage 15 (parquet at NativeMethodAccessorImpl.java:0) finished in 35.675 s
26/01/12 01:54:49 INFO DAGScheduler: Job 15 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 01:54:49 INFO TaskSchedulerImpl: Killing all running tasks in stage 15: Stage finished
26/01/12 01:54:49 INFO DAGScheduler: Job 15 finished: parquet at NativeMethodAccessorImpl.java:0, took 35.683797 s
26/01/12 01:54:49 INFO FileFormatWriter: Start to commit write Job 1704e514-4a90-4d8a-a8cf-19e5e7a3c0e1.
26/01/12 01:54:49 INFO FileFormatWriter: Write Job 1704e514-4a90-4d8a-a8cf-19e5e7a3c0e1 committed. Elapsed time: 49 ms.
26/01/12 01:54:49 INFO FileFormatWriter: Finished processing stats for write job 1704e514-4a90-4d8a-a8cf-19e5e7a3c0e1.
Cargando: yellow_tripdata_2009-09.parquet en hdfs://hadoop-namenode:8020/data/nyc/raw/taxi-trips/2009...
26/01/12 01:54:49 INFO InMemoryFileIndex: It took 7 ms to list leaf files for 1 paths.
26/01/12 01:54:50 INFO SparkContext: Starting job: parquet at NativeMethodAccessorImpl.java:0
26/01/12 01:54:50 INFO DAGScheduler: Got job 16 (parquet at NativeMethodAccessorImpl.java:0) with 1 output partitions
26/01/12 01:54:50 INFO DAGScheduler: Final stage: ResultStage 16 (parquet at NativeMethodAccessorImpl.java:0)
26/01/12 01:54:50 INFO DAGScheduler: Parents of final stage: List()
26/01/12 01:54:50 INFO DAGScheduler: Missing parents: List()
26/01/12 01:54:50 INFO DAGScheduler: Submitting ResultStage 16 (MapPartitionsRDD[41] at parquet at NativeMethodAccessorImpl.java:0), which has no missing parents
26/01/12 01:54:50 INFO MemoryStore: Block broadcast_24 stored as values in memory (estimated size 102.6 KiB, free 364.2 MiB)
26/01/12 01:54:50 INFO MemoryStore: Block broadcast_24_piece0 stored as bytes in memory (estimated size 36.8 KiB, free 364.2 MiB)
26/01/12 01:54:50 INFO BlockManagerInfo: Added broadcast_24_piece0 in memory on 02926ee04bc9:45221 (size: 36.8 KiB, free: 365.9 MiB)
26/01/12 01:54:50 INFO SparkContext: Created broadcast 24 from broadcast at DAGScheduler.scala:1513
26/01/12 01:54:50 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 16 (MapPartitionsRDD[41] at parquet at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
26/01/12 01:54:50 INFO TaskSchedulerImpl: Adding task set 16.0 with 1 tasks resource profile 0
26/01/12 01:54:50 INFO TaskSetManager: Starting task 0.0 in stage 16.0 (TID 40) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4607 bytes) taskResourceAssignments Map()
26/01/12 01:54:50 INFO BlockManagerInfo: Added broadcast_24_piece0 in memory on 172.18.0.5:42453 (size: 36.8 KiB, free: 365.9 MiB)
26/01/12 01:54:50 INFO TaskSetManager: Finished task 0.0 in stage 16.0 (TID 40) in 82 ms on 172.18.0.5 (executor 0) (1/1)
26/01/12 01:54:50 INFO TaskSchedulerImpl: Removed TaskSet 16.0, whose tasks have all completed, from pool 
26/01/12 01:54:50 INFO DAGScheduler: ResultStage 16 (parquet at NativeMethodAccessorImpl.java:0) finished in 0.100 s
26/01/12 01:54:50 INFO DAGScheduler: Job 16 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 01:54:50 INFO TaskSchedulerImpl: Killing all running tasks in stage 16: Stage finished
26/01/12 01:54:50 INFO DAGScheduler: Job 16 finished: parquet at NativeMethodAccessorImpl.java:0, took 0.107593 s
26/01/12 01:54:50 INFO FileSourceStrategy: Pushed Filters: 
26/01/12 01:54:50 INFO FileSourceStrategy: Post-Scan Filters: 
26/01/12 01:54:50 INFO FileSourceStrategy: Output Data Schema: struct<vendor_name: string, Trip_Pickup_DateTime: string, Trip_Dropoff_DateTime: string, Passenger_Count: bigint, Trip_Distance: double ... 16 more fields>
26/01/12 01:54:50 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 01:54:50 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 01:54:50 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 01:54:50 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 01:54:50 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 01:54:50 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 01:54:50 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 01:54:50 INFO MemoryStore: Block broadcast_25 stored as values in memory (estimated size 358.0 KiB, free 363.8 MiB)
26/01/12 01:54:50 INFO MemoryStore: Block broadcast_25_piece0 stored as bytes in memory (estimated size 35.2 KiB, free 363.8 MiB)
26/01/12 01:54:50 INFO BlockManagerInfo: Added broadcast_25_piece0 in memory on 02926ee04bc9:45221 (size: 35.2 KiB, free: 365.9 MiB)
26/01/12 01:54:50 INFO SparkContext: Created broadcast 25 from parquet at NativeMethodAccessorImpl.java:0
26/01/12 01:54:50 INFO FileSourceScanExec: Planning scan with bin packing, max size: 134217728 bytes, open cost is considered as scanning 4194304 bytes.
26/01/12 01:54:50 INFO SparkContext: Starting job: parquet at NativeMethodAccessorImpl.java:0
26/01/12 01:54:50 INFO DAGScheduler: Got job 17 (parquet at NativeMethodAccessorImpl.java:0) with 4 output partitions
26/01/12 01:54:50 INFO DAGScheduler: Final stage: ResultStage 17 (parquet at NativeMethodAccessorImpl.java:0)
26/01/12 01:54:50 INFO DAGScheduler: Parents of final stage: List()
26/01/12 01:54:50 INFO DAGScheduler: Missing parents: List()
26/01/12 01:54:50 INFO DAGScheduler: Submitting ResultStage 17 (MapPartitionsRDD[44] at parquet at NativeMethodAccessorImpl.java:0), which has no missing parents
26/01/12 01:54:50 INFO MemoryStore: Block broadcast_26 stored as values in memory (estimated size 224.3 KiB, free 363.5 MiB)
26/01/12 01:54:50 INFO MemoryStore: Block broadcast_26_piece0 stored as bytes in memory (estimated size 77.2 KiB, free 363.5 MiB)
26/01/12 01:54:50 INFO BlockManagerInfo: Added broadcast_26_piece0 in memory on 02926ee04bc9:45221 (size: 77.2 KiB, free: 365.8 MiB)
26/01/12 01:54:50 INFO SparkContext: Created broadcast 26 from broadcast at DAGScheduler.scala:1513
26/01/12 01:54:50 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 17 (MapPartitionsRDD[44] at parquet at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
26/01/12 01:54:50 INFO TaskSchedulerImpl: Adding task set 17.0 with 4 tasks resource profile 0
26/01/12 01:54:50 INFO TaskSetManager: Starting task 0.0 in stage 17.0 (TID 41) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 01:54:50 INFO TaskSetManager: Starting task 1.0 in stage 17.0 (TID 42) (172.18.0.5, executor 0, partition 1, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 01:54:50 INFO BlockManagerInfo: Added broadcast_26_piece0 in memory on 172.18.0.5:42453 (size: 77.2 KiB, free: 365.9 MiB)
26/01/12 01:54:50 INFO BlockManagerInfo: Added broadcast_25_piece0 in memory on 172.18.0.5:42453 (size: 35.2 KiB, free: 365.8 MiB)
26/01/12 01:54:50 INFO TaskSetManager: Starting task 2.0 in stage 17.0 (TID 43) (172.18.0.5, executor 0, partition 2, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 01:54:50 INFO TaskSetManager: Finished task 0.0 in stage 17.0 (TID 41) in 154 ms on 172.18.0.5 (executor 0) (1/4)
26/01/12 01:54:50 INFO TaskSetManager: Starting task 3.0 in stage 17.0 (TID 44) (172.18.0.5, executor 0, partition 3, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 01:54:50 INFO TaskSetManager: Finished task 2.0 in stage 17.0 (TID 43) in 40 ms on 172.18.0.5 (executor 0) (2/4)
26/01/12 01:54:50 INFO TaskSetManager: Finished task 3.0 in stage 17.0 (TID 44) in 48 ms on 172.18.0.5 (executor 0) (3/4)
26/01/12 01:55:24 INFO TaskSetManager: Finished task 1.0 in stage 17.0 (TID 42) in 34589 ms on 172.18.0.5 (executor 0) (4/4)
26/01/12 01:55:24 INFO TaskSchedulerImpl: Removed TaskSet 17.0, whose tasks have all completed, from pool 
26/01/12 01:55:24 INFO DAGScheduler: ResultStage 17 (parquet at NativeMethodAccessorImpl.java:0) finished in 34.640 s
26/01/12 01:55:24 INFO DAGScheduler: Job 17 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 01:55:24 INFO TaskSchedulerImpl: Killing all running tasks in stage 17: Stage finished
26/01/12 01:55:24 INFO DAGScheduler: Job 17 finished: parquet at NativeMethodAccessorImpl.java:0, took 34.649631 s
26/01/12 01:55:24 INFO FileFormatWriter: Start to commit write Job a6816bcb-be4e-407b-9bdd-fdaa393adcda.
26/01/12 01:55:25 INFO FileFormatWriter: Write Job a6816bcb-be4e-407b-9bdd-fdaa393adcda committed. Elapsed time: 52 ms.
26/01/12 01:55:25 INFO FileFormatWriter: Finished processing stats for write job a6816bcb-be4e-407b-9bdd-fdaa393adcda.
Cargando: yellow_tripdata_2009-10.parquet en hdfs://hadoop-namenode:8020/data/nyc/raw/taxi-trips/2009...
26/01/12 01:55:25 INFO InMemoryFileIndex: It took 5 ms to list leaf files for 1 paths.
26/01/12 01:55:25 INFO SparkContext: Starting job: parquet at NativeMethodAccessorImpl.java:0
26/01/12 01:55:25 INFO DAGScheduler: Got job 18 (parquet at NativeMethodAccessorImpl.java:0) with 1 output partitions
26/01/12 01:55:25 INFO DAGScheduler: Final stage: ResultStage 18 (parquet at NativeMethodAccessorImpl.java:0)
26/01/12 01:55:25 INFO DAGScheduler: Parents of final stage: List()
26/01/12 01:55:25 INFO DAGScheduler: Missing parents: List()
26/01/12 01:55:25 INFO DAGScheduler: Submitting ResultStage 18 (MapPartitionsRDD[46] at parquet at NativeMethodAccessorImpl.java:0), which has no missing parents
26/01/12 01:55:25 INFO MemoryStore: Block broadcast_27 stored as values in memory (estimated size 102.6 KiB, free 363.4 MiB)
26/01/12 01:55:25 INFO MemoryStore: Block broadcast_27_piece0 stored as bytes in memory (estimated size 36.8 KiB, free 363.3 MiB)
26/01/12 01:55:25 INFO BlockManagerInfo: Added broadcast_27_piece0 in memory on 02926ee04bc9:45221 (size: 36.8 KiB, free: 365.8 MiB)
26/01/12 01:55:25 INFO SparkContext: Created broadcast 27 from broadcast at DAGScheduler.scala:1513
26/01/12 01:55:25 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 18 (MapPartitionsRDD[46] at parquet at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
26/01/12 01:55:25 INFO TaskSchedulerImpl: Adding task set 18.0 with 1 tasks resource profile 0
26/01/12 01:55:25 INFO TaskSetManager: Starting task 0.0 in stage 18.0 (TID 45) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4607 bytes) taskResourceAssignments Map()
26/01/12 01:55:25 INFO BlockManagerInfo: Added broadcast_27_piece0 in memory on 172.18.0.5:42453 (size: 36.8 KiB, free: 365.8 MiB)
26/01/12 01:55:25 INFO TaskSetManager: Finished task 0.0 in stage 18.0 (TID 45) in 55 ms on 172.18.0.5 (executor 0) (1/1)
26/01/12 01:55:25 INFO TaskSchedulerImpl: Removed TaskSet 18.0, whose tasks have all completed, from pool 
26/01/12 01:55:25 INFO DAGScheduler: ResultStage 18 (parquet at NativeMethodAccessorImpl.java:0) finished in 0.072 s
26/01/12 01:55:25 INFO DAGScheduler: Job 18 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 01:55:25 INFO TaskSchedulerImpl: Killing all running tasks in stage 18: Stage finished
26/01/12 01:55:25 INFO DAGScheduler: Job 18 finished: parquet at NativeMethodAccessorImpl.java:0, took 0.078527 s
26/01/12 01:55:25 INFO FileSourceStrategy: Pushed Filters: 
26/01/12 01:55:25 INFO FileSourceStrategy: Post-Scan Filters: 
26/01/12 01:55:25 INFO FileSourceStrategy: Output Data Schema: struct<vendor_name: string, Trip_Pickup_DateTime: string, Trip_Dropoff_DateTime: string, Passenger_Count: bigint, Trip_Distance: double ... 16 more fields>
26/01/12 01:55:25 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 01:55:25 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 01:55:25 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 01:55:25 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 01:55:25 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 01:55:25 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 01:55:25 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 01:55:25 INFO MemoryStore: Block broadcast_28 stored as values in memory (estimated size 358.0 KiB, free 363.0 MiB)
26/01/12 01:55:25 INFO MemoryStore: Block broadcast_28_piece0 stored as bytes in memory (estimated size 35.2 KiB, free 363.0 MiB)
26/01/12 01:55:25 INFO BlockManagerInfo: Added broadcast_28_piece0 in memory on 02926ee04bc9:45221 (size: 35.2 KiB, free: 365.8 MiB)
26/01/12 01:55:25 INFO SparkContext: Created broadcast 28 from parquet at NativeMethodAccessorImpl.java:0
26/01/12 01:55:25 INFO FileSourceScanExec: Planning scan with bin packing, max size: 134217728 bytes, open cost is considered as scanning 4194304 bytes.
26/01/12 01:55:25 INFO SparkContext: Starting job: parquet at NativeMethodAccessorImpl.java:0
26/01/12 01:55:25 INFO DAGScheduler: Got job 19 (parquet at NativeMethodAccessorImpl.java:0) with 4 output partitions
26/01/12 01:55:25 INFO DAGScheduler: Final stage: ResultStage 19 (parquet at NativeMethodAccessorImpl.java:0)
26/01/12 01:55:25 INFO DAGScheduler: Parents of final stage: List()
26/01/12 01:55:25 INFO DAGScheduler: Missing parents: List()
26/01/12 01:55:25 INFO DAGScheduler: Submitting ResultStage 19 (MapPartitionsRDD[49] at parquet at NativeMethodAccessorImpl.java:0), which has no missing parents
26/01/12 01:55:25 INFO MemoryStore: Block broadcast_29 stored as values in memory (estimated size 224.3 KiB, free 362.7 MiB)
26/01/12 01:55:25 INFO MemoryStore: Block broadcast_29_piece0 stored as bytes in memory (estimated size 77.2 KiB, free 362.7 MiB)
26/01/12 01:55:25 INFO BlockManagerInfo: Added broadcast_29_piece0 in memory on 02926ee04bc9:45221 (size: 77.2 KiB, free: 365.7 MiB)
26/01/12 01:55:25 INFO SparkContext: Created broadcast 29 from broadcast at DAGScheduler.scala:1513
26/01/12 01:55:25 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 19 (MapPartitionsRDD[49] at parquet at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
26/01/12 01:55:25 INFO TaskSchedulerImpl: Adding task set 19.0 with 4 tasks resource profile 0
26/01/12 01:55:25 INFO TaskSetManager: Starting task 0.0 in stage 19.0 (TID 46) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 01:55:25 INFO TaskSetManager: Starting task 1.0 in stage 19.0 (TID 47) (172.18.0.5, executor 0, partition 1, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 01:55:25 INFO BlockManagerInfo: Added broadcast_29_piece0 in memory on 172.18.0.5:42453 (size: 77.2 KiB, free: 365.7 MiB)
26/01/12 01:55:25 INFO BlockManagerInfo: Added broadcast_28_piece0 in memory on 172.18.0.5:42453 (size: 35.2 KiB, free: 365.7 MiB)
26/01/12 01:55:25 INFO TaskSetManager: Starting task 2.0 in stage 19.0 (TID 48) (172.18.0.5, executor 0, partition 2, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 01:55:25 INFO TaskSetManager: Finished task 0.0 in stage 19.0 (TID 46) in 501 ms on 172.18.0.5 (executor 0) (1/4)
26/01/12 01:55:25 INFO TaskSetManager: Starting task 3.0 in stage 19.0 (TID 49) (172.18.0.5, executor 0, partition 3, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 01:55:25 INFO TaskSetManager: Finished task 2.0 in stage 19.0 (TID 48) in 35 ms on 172.18.0.5 (executor 0) (2/4)
26/01/12 01:55:25 INFO TaskSetManager: Finished task 3.0 in stage 19.0 (TID 49) in 32 ms on 172.18.0.5 (executor 0) (3/4)
26/01/12 01:56:13 INFO TaskSetManager: Finished task 1.0 in stage 19.0 (TID 47) in 48039 ms on 172.18.0.5 (executor 0) (4/4)
26/01/12 01:56:13 INFO TaskSchedulerImpl: Removed TaskSet 19.0, whose tasks have all completed, from pool 
26/01/12 01:56:13 INFO DAGScheduler: ResultStage 19 (parquet at NativeMethodAccessorImpl.java:0) finished in 48.075 s
26/01/12 01:56:13 INFO DAGScheduler: Job 19 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 01:56:13 INFO TaskSchedulerImpl: Killing all running tasks in stage 19: Stage finished
26/01/12 01:56:13 INFO DAGScheduler: Job 19 finished: parquet at NativeMethodAccessorImpl.java:0, took 48.089492 s
26/01/12 01:56:13 INFO FileFormatWriter: Start to commit write Job d63579e8-722e-417c-9ac3-6d37ecc2d106.
26/01/12 01:56:13 INFO FileFormatWriter: Write Job d63579e8-722e-417c-9ac3-6d37ecc2d106 committed. Elapsed time: 43 ms.
26/01/12 01:56:13 INFO FileFormatWriter: Finished processing stats for write job d63579e8-722e-417c-9ac3-6d37ecc2d106.
Cargando: yellow_tripdata_2009-11.parquet en hdfs://hadoop-namenode:8020/data/nyc/raw/taxi-trips/2009...
26/01/12 01:56:13 INFO InMemoryFileIndex: It took 5 ms to list leaf files for 1 paths.
26/01/12 01:56:13 INFO SparkContext: Starting job: parquet at NativeMethodAccessorImpl.java:0
26/01/12 01:56:13 INFO DAGScheduler: Got job 20 (parquet at NativeMethodAccessorImpl.java:0) with 1 output partitions
26/01/12 01:56:13 INFO DAGScheduler: Final stage: ResultStage 20 (parquet at NativeMethodAccessorImpl.java:0)
26/01/12 01:56:13 INFO DAGScheduler: Parents of final stage: List()
26/01/12 01:56:13 INFO DAGScheduler: Missing parents: List()
26/01/12 01:56:13 INFO DAGScheduler: Submitting ResultStage 20 (MapPartitionsRDD[51] at parquet at NativeMethodAccessorImpl.java:0), which has no missing parents
26/01/12 01:56:13 INFO MemoryStore: Block broadcast_30 stored as values in memory (estimated size 102.6 KiB, free 362.6 MiB)
26/01/12 01:56:13 INFO MemoryStore: Block broadcast_30_piece0 stored as bytes in memory (estimated size 36.8 KiB, free 362.5 MiB)
26/01/12 01:56:13 INFO BlockManagerInfo: Added broadcast_30_piece0 in memory on 02926ee04bc9:45221 (size: 36.8 KiB, free: 365.6 MiB)
26/01/12 01:56:13 INFO SparkContext: Created broadcast 30 from broadcast at DAGScheduler.scala:1513
26/01/12 01:56:13 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 20 (MapPartitionsRDD[51] at parquet at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
26/01/12 01:56:13 INFO TaskSchedulerImpl: Adding task set 20.0 with 1 tasks resource profile 0
26/01/12 01:56:13 INFO TaskSetManager: Starting task 0.0 in stage 20.0 (TID 50) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4607 bytes) taskResourceAssignments Map()
26/01/12 01:56:13 INFO BlockManagerInfo: Added broadcast_30_piece0 in memory on 172.18.0.5:42453 (size: 36.8 KiB, free: 365.6 MiB)
26/01/12 01:56:13 INFO TaskSetManager: Finished task 0.0 in stage 20.0 (TID 50) in 69 ms on 172.18.0.5 (executor 0) (1/1)
26/01/12 01:56:13 INFO TaskSchedulerImpl: Removed TaskSet 20.0, whose tasks have all completed, from pool 
26/01/12 01:56:13 INFO DAGScheduler: ResultStage 20 (parquet at NativeMethodAccessorImpl.java:0) finished in 0.096 s
26/01/12 01:56:13 INFO DAGScheduler: Job 20 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 01:56:13 INFO TaskSchedulerImpl: Killing all running tasks in stage 20: Stage finished
26/01/12 01:56:13 INFO DAGScheduler: Job 20 finished: parquet at NativeMethodAccessorImpl.java:0, took 0.102891 s
26/01/12 01:56:13 INFO FileSourceStrategy: Pushed Filters: 
26/01/12 01:56:13 INFO FileSourceStrategy: Post-Scan Filters: 
26/01/12 01:56:13 INFO FileSourceStrategy: Output Data Schema: struct<vendor_name: string, Trip_Pickup_DateTime: string, Trip_Dropoff_DateTime: string, Passenger_Count: bigint, Trip_Distance: double ... 16 more fields>
26/01/12 01:56:13 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 01:56:13 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 01:56:13 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 01:56:13 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 01:56:13 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 01:56:13 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 01:56:13 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 01:56:13 INFO MemoryStore: Block broadcast_31 stored as values in memory (estimated size 358.0 KiB, free 362.2 MiB)
26/01/12 01:56:13 INFO MemoryStore: Block broadcast_31_piece0 stored as bytes in memory (estimated size 35.2 KiB, free 362.1 MiB)
26/01/12 01:56:13 INFO BlockManagerInfo: Added broadcast_31_piece0 in memory on 02926ee04bc9:45221 (size: 35.2 KiB, free: 365.6 MiB)
26/01/12 01:56:13 INFO SparkContext: Created broadcast 31 from parquet at NativeMethodAccessorImpl.java:0
26/01/12 01:56:13 INFO FileSourceScanExec: Planning scan with bin packing, max size: 134217728 bytes, open cost is considered as scanning 4194304 bytes.
26/01/12 01:56:13 INFO SparkContext: Starting job: parquet at NativeMethodAccessorImpl.java:0
26/01/12 01:56:13 INFO DAGScheduler: Got job 21 (parquet at NativeMethodAccessorImpl.java:0) with 4 output partitions
26/01/12 01:56:13 INFO DAGScheduler: Final stage: ResultStage 21 (parquet at NativeMethodAccessorImpl.java:0)
26/01/12 01:56:13 INFO DAGScheduler: Parents of final stage: List()
26/01/12 01:56:13 INFO DAGScheduler: Missing parents: List()
26/01/12 01:56:13 INFO DAGScheduler: Submitting ResultStage 21 (MapPartitionsRDD[54] at parquet at NativeMethodAccessorImpl.java:0), which has no missing parents
26/01/12 01:56:13 INFO MemoryStore: Block broadcast_32 stored as values in memory (estimated size 224.3 KiB, free 361.9 MiB)
26/01/12 01:56:13 INFO MemoryStore: Block broadcast_32_piece0 stored as bytes in memory (estimated size 77.2 KiB, free 361.8 MiB)
26/01/12 01:56:13 INFO BlockManagerInfo: Added broadcast_32_piece0 in memory on 02926ee04bc9:45221 (size: 77.2 KiB, free: 365.5 MiB)
26/01/12 01:56:13 INFO SparkContext: Created broadcast 32 from broadcast at DAGScheduler.scala:1513
26/01/12 01:56:13 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 21 (MapPartitionsRDD[54] at parquet at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
26/01/12 01:56:13 INFO TaskSchedulerImpl: Adding task set 21.0 with 4 tasks resource profile 0
26/01/12 01:56:13 INFO TaskSetManager: Starting task 0.0 in stage 21.0 (TID 51) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 01:56:13 INFO TaskSetManager: Starting task 1.0 in stage 21.0 (TID 52) (172.18.0.5, executor 0, partition 1, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 01:56:13 INFO BlockManagerInfo: Added broadcast_32_piece0 in memory on 172.18.0.5:42453 (size: 77.2 KiB, free: 365.6 MiB)
26/01/12 01:56:13 INFO BlockManagerInfo: Added broadcast_31_piece0 in memory on 172.18.0.5:42453 (size: 35.2 KiB, free: 365.5 MiB)
26/01/12 01:56:13 INFO TaskSetManager: Starting task 2.0 in stage 21.0 (TID 53) (172.18.0.5, executor 0, partition 2, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 01:56:13 INFO TaskSetManager: Finished task 0.0 in stage 21.0 (TID 51) in 126 ms on 172.18.0.5 (executor 0) (1/4)
26/01/12 01:56:13 INFO TaskSetManager: Starting task 3.0 in stage 21.0 (TID 54) (172.18.0.5, executor 0, partition 3, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 01:56:13 INFO TaskSetManager: Finished task 2.0 in stage 21.0 (TID 53) in 39 ms on 172.18.0.5 (executor 0) (2/4)
26/01/12 01:56:13 INFO TaskSetManager: Finished task 3.0 in stage 21.0 (TID 54) in 44 ms on 172.18.0.5 (executor 0) (3/4)
26/01/12 01:56:59 INFO TaskSetManager: Finished task 1.0 in stage 21.0 (TID 52) in 45739 ms on 172.18.0.5 (executor 0) (4/4)
26/01/12 01:56:59 INFO TaskSchedulerImpl: Removed TaskSet 21.0, whose tasks have all completed, from pool 
26/01/12 01:56:59 INFO DAGScheduler: ResultStage 21 (parquet at NativeMethodAccessorImpl.java:0) finished in 45.789 s
26/01/12 01:56:59 INFO DAGScheduler: Job 21 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 01:56:59 INFO TaskSchedulerImpl: Killing all running tasks in stage 21: Stage finished
26/01/12 01:56:59 INFO DAGScheduler: Job 21 finished: parquet at NativeMethodAccessorImpl.java:0, took 45.798293 s
26/01/12 01:56:59 INFO FileFormatWriter: Start to commit write Job 22c555e8-1aa9-468c-be85-ccfcb7a499d1.
26/01/12 01:56:59 INFO FileFormatWriter: Write Job 22c555e8-1aa9-468c-be85-ccfcb7a499d1 committed. Elapsed time: 54 ms.
26/01/12 01:56:59 INFO FileFormatWriter: Finished processing stats for write job 22c555e8-1aa9-468c-be85-ccfcb7a499d1.
Cargando: yellow_tripdata_2009-12.parquet en hdfs://hadoop-namenode:8020/data/nyc/raw/taxi-trips/2009...
26/01/12 01:56:59 INFO InMemoryFileIndex: It took 8 ms to list leaf files for 1 paths.
26/01/12 01:56:59 INFO SparkContext: Starting job: parquet at NativeMethodAccessorImpl.java:0
26/01/12 01:56:59 INFO DAGScheduler: Got job 22 (parquet at NativeMethodAccessorImpl.java:0) with 1 output partitions
26/01/12 01:56:59 INFO DAGScheduler: Final stage: ResultStage 22 (parquet at NativeMethodAccessorImpl.java:0)
26/01/12 01:56:59 INFO DAGScheduler: Parents of final stage: List()
26/01/12 01:56:59 INFO DAGScheduler: Missing parents: List()
26/01/12 01:56:59 INFO DAGScheduler: Submitting ResultStage 22 (MapPartitionsRDD[56] at parquet at NativeMethodAccessorImpl.java:0), which has no missing parents
26/01/12 01:56:59 INFO MemoryStore: Block broadcast_33 stored as values in memory (estimated size 102.6 KiB, free 361.7 MiB)
26/01/12 01:56:59 INFO MemoryStore: Block broadcast_33_piece0 stored as bytes in memory (estimated size 36.8 KiB, free 361.7 MiB)
26/01/12 01:56:59 INFO BlockManagerInfo: Added broadcast_33_piece0 in memory on 02926ee04bc9:45221 (size: 36.8 KiB, free: 365.5 MiB)
26/01/12 01:56:59 INFO SparkContext: Created broadcast 33 from broadcast at DAGScheduler.scala:1513
26/01/12 01:56:59 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 22 (MapPartitionsRDD[56] at parquet at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
26/01/12 01:56:59 INFO TaskSchedulerImpl: Adding task set 22.0 with 1 tasks resource profile 0
26/01/12 01:56:59 INFO TaskSetManager: Starting task 0.0 in stage 22.0 (TID 55) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4607 bytes) taskResourceAssignments Map()
26/01/12 01:56:59 INFO BlockManagerInfo: Added broadcast_33_piece0 in memory on 172.18.0.5:42453 (size: 36.8 KiB, free: 365.5 MiB)
26/01/12 01:56:59 INFO TaskSetManager: Finished task 0.0 in stage 22.0 (TID 55) in 62 ms on 172.18.0.5 (executor 0) (1/1)
26/01/12 01:56:59 INFO TaskSchedulerImpl: Removed TaskSet 22.0, whose tasks have all completed, from pool 
26/01/12 01:56:59 INFO DAGScheduler: ResultStage 22 (parquet at NativeMethodAccessorImpl.java:0) finished in 0.075 s
26/01/12 01:56:59 INFO DAGScheduler: Job 22 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 01:56:59 INFO TaskSchedulerImpl: Killing all running tasks in stage 22: Stage finished
26/01/12 01:56:59 INFO DAGScheduler: Job 22 finished: parquet at NativeMethodAccessorImpl.java:0, took 0.080348 s
26/01/12 01:56:59 INFO FileSourceStrategy: Pushed Filters: 
26/01/12 01:56:59 INFO FileSourceStrategy: Post-Scan Filters: 
26/01/12 01:56:59 INFO FileSourceStrategy: Output Data Schema: struct<vendor_name: string, Trip_Pickup_DateTime: string, Trip_Dropoff_DateTime: string, Passenger_Count: bigint, Trip_Distance: double ... 16 more fields>
26/01/12 01:56:59 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 01:56:59 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 01:56:59 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 01:56:59 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 01:56:59 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 01:56:59 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 01:56:59 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 01:56:59 INFO MemoryStore: Block broadcast_34 stored as values in memory (estimated size 358.0 KiB, free 361.4 MiB)
26/01/12 01:56:59 INFO MemoryStore: Block broadcast_34_piece0 stored as bytes in memory (estimated size 35.2 KiB, free 361.3 MiB)
26/01/12 01:56:59 INFO BlockManagerInfo: Added broadcast_34_piece0 in memory on 02926ee04bc9:45221 (size: 35.2 KiB, free: 365.5 MiB)
26/01/12 01:56:59 INFO SparkContext: Created broadcast 34 from parquet at NativeMethodAccessorImpl.java:0
26/01/12 01:56:59 INFO FileSourceScanExec: Planning scan with bin packing, max size: 134217728 bytes, open cost is considered as scanning 4194304 bytes.
26/01/12 01:56:59 INFO BlockManagerInfo: Removed broadcast_29_piece0 on 02926ee04bc9:45221 in memory (size: 77.2 KiB, free: 365.5 MiB)
26/01/12 01:56:59 INFO BlockManagerInfo: Removed broadcast_29_piece0 on 172.18.0.5:42453 in memory (size: 77.2 KiB, free: 365.6 MiB)
26/01/12 01:56:59 INFO SparkContext: Starting job: parquet at NativeMethodAccessorImpl.java:0
26/01/12 01:56:59 INFO DAGScheduler: Got job 23 (parquet at NativeMethodAccessorImpl.java:0) with 4 output partitions
26/01/12 01:56:59 INFO DAGScheduler: Final stage: ResultStage 23 (parquet at NativeMethodAccessorImpl.java:0)
26/01/12 01:56:59 INFO DAGScheduler: Parents of final stage: List()
26/01/12 01:56:59 INFO DAGScheduler: Missing parents: List()
26/01/12 01:56:59 INFO DAGScheduler: Submitting ResultStage 23 (MapPartitionsRDD[59] at parquet at NativeMethodAccessorImpl.java:0), which has no missing parents
26/01/12 01:56:59 INFO BlockManagerInfo: Removed broadcast_28_piece0 on 02926ee04bc9:45221 in memory (size: 35.2 KiB, free: 365.6 MiB)
26/01/12 01:56:59 INFO BlockManagerInfo: Removed broadcast_28_piece0 on 172.18.0.5:42453 in memory (size: 35.2 KiB, free: 365.6 MiB)
26/01/12 01:56:59 INFO BlockManagerInfo: Removed broadcast_27_piece0 on 02926ee04bc9:45221 in memory (size: 36.8 KiB, free: 365.6 MiB)
26/01/12 01:56:59 INFO BlockManagerInfo: Removed broadcast_27_piece0 on 172.18.0.5:42453 in memory (size: 36.8 KiB, free: 365.6 MiB)
26/01/12 01:56:59 INFO BlockManagerInfo: Removed broadcast_31_piece0 on 02926ee04bc9:45221 in memory (size: 35.2 KiB, free: 365.6 MiB)
26/01/12 01:56:59 INFO BlockManagerInfo: Removed broadcast_31_piece0 on 172.18.0.5:42453 in memory (size: 35.2 KiB, free: 365.7 MiB)
26/01/12 01:56:59 INFO MemoryStore: Block broadcast_35 stored as values in memory (estimated size 224.3 KiB, free 362.3 MiB)
26/01/12 01:56:59 INFO BlockManagerInfo: Removed broadcast_25_piece0 on 02926ee04bc9:45221 in memory (size: 35.2 KiB, free: 365.7 MiB)
26/01/12 01:56:59 INFO MemoryStore: Block broadcast_35_piece0 stored as bytes in memory (estimated size 77.2 KiB, free 362.6 MiB)
26/01/12 01:56:59 INFO BlockManagerInfo: Added broadcast_35_piece0 in memory on 02926ee04bc9:45221 (size: 77.2 KiB, free: 365.6 MiB)
26/01/12 01:56:59 INFO BlockManagerInfo: Removed broadcast_25_piece0 on 172.18.0.5:42453 in memory (size: 35.2 KiB, free: 365.7 MiB)
26/01/12 01:56:59 INFO SparkContext: Created broadcast 35 from broadcast at DAGScheduler.scala:1513
26/01/12 01:56:59 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 23 (MapPartitionsRDD[59] at parquet at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
26/01/12 01:56:59 INFO TaskSchedulerImpl: Adding task set 23.0 with 4 tasks resource profile 0
26/01/12 01:56:59 INFO TaskSetManager: Starting task 0.0 in stage 23.0 (TID 56) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 01:56:59 INFO TaskSetManager: Starting task 1.0 in stage 23.0 (TID 57) (172.18.0.5, executor 0, partition 1, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 01:56:59 INFO BlockManagerInfo: Removed broadcast_32_piece0 on 02926ee04bc9:45221 in memory (size: 77.2 KiB, free: 365.7 MiB)
26/01/12 01:56:59 INFO BlockManagerInfo: Removed broadcast_32_piece0 on 172.18.0.5:42453 in memory (size: 77.2 KiB, free: 365.8 MiB)
26/01/12 01:56:59 INFO BlockManagerInfo: Removed broadcast_23_piece0 on 02926ee04bc9:45221 in memory (size: 77.2 KiB, free: 365.8 MiB)
26/01/12 01:56:59 INFO BlockManagerInfo: Added broadcast_35_piece0 in memory on 172.18.0.5:42453 (size: 77.2 KiB, free: 365.7 MiB)
26/01/12 01:56:59 INFO BlockManagerInfo: Removed broadcast_23_piece0 on 172.18.0.5:42453 in memory (size: 77.2 KiB, free: 365.8 MiB)
26/01/12 01:56:59 INFO BlockManagerInfo: Removed broadcast_33_piece0 on 02926ee04bc9:45221 in memory (size: 36.8 KiB, free: 365.8 MiB)
26/01/12 01:56:59 INFO BlockManagerInfo: Removed broadcast_33_piece0 on 172.18.0.5:42453 in memory (size: 36.8 KiB, free: 365.8 MiB)
26/01/12 01:56:59 INFO BlockManagerInfo: Removed broadcast_16_piece0 on 02926ee04bc9:45221 in memory (size: 35.2 KiB, free: 365.8 MiB)
26/01/12 01:56:59 INFO BlockManagerInfo: Removed broadcast_16_piece0 on 172.18.0.5:42453 in memory (size: 35.2 KiB, free: 365.9 MiB)
26/01/12 01:56:59 INFO BlockManagerInfo: Added broadcast_34_piece0 in memory on 172.18.0.5:42453 (size: 35.2 KiB, free: 365.8 MiB)
26/01/12 01:56:59 INFO BlockManagerInfo: Removed broadcast_30_piece0 on 02926ee04bc9:45221 in memory (size: 36.8 KiB, free: 365.9 MiB)
26/01/12 01:56:59 INFO BlockManagerInfo: Removed broadcast_30_piece0 on 172.18.0.5:42453 in memory (size: 36.8 KiB, free: 365.9 MiB)
26/01/12 01:56:59 INFO BlockManagerInfo: Removed broadcast_20_piece0 on 02926ee04bc9:45221 in memory (size: 77.2 KiB, free: 365.9 MiB)
26/01/12 01:56:59 INFO BlockManagerInfo: Removed broadcast_20_piece0 on 172.18.0.5:42453 in memory (size: 77.2 KiB, free: 365.9 MiB)
26/01/12 01:56:59 INFO BlockManagerInfo: Removed broadcast_18_piece0 on 02926ee04bc9:45221 in memory (size: 36.8 KiB, free: 366.0 MiB)
26/01/12 01:56:59 INFO BlockManagerInfo: Removed broadcast_18_piece0 on 172.18.0.5:42453 in memory (size: 36.8 KiB, free: 366.0 MiB)
26/01/12 01:56:59 INFO BlockManagerInfo: Removed broadcast_19_piece0 on 02926ee04bc9:45221 in memory (size: 35.2 KiB, free: 366.0 MiB)
26/01/12 01:56:59 INFO BlockManagerInfo: Removed broadcast_19_piece0 on 172.18.0.5:42453 in memory (size: 35.2 KiB, free: 366.0 MiB)
26/01/12 01:56:59 INFO BlockManagerInfo: Removed broadcast_26_piece0 on 02926ee04bc9:45221 in memory (size: 77.2 KiB, free: 366.1 MiB)
26/01/12 01:56:59 INFO BlockManagerInfo: Removed broadcast_26_piece0 on 172.18.0.5:42453 in memory (size: 77.2 KiB, free: 366.1 MiB)
26/01/12 01:56:59 INFO BlockManagerInfo: Removed broadcast_21_piece0 on 02926ee04bc9:45221 in memory (size: 36.8 KiB, free: 366.1 MiB)
26/01/12 01:56:59 INFO BlockManagerInfo: Removed broadcast_21_piece0 on 172.18.0.5:42453 in memory (size: 36.8 KiB, free: 366.1 MiB)
26/01/12 01:56:59 INFO BlockManagerInfo: Removed broadcast_24_piece0 on 02926ee04bc9:45221 in memory (size: 36.8 KiB, free: 366.2 MiB)
26/01/12 01:56:59 INFO BlockManagerInfo: Removed broadcast_24_piece0 on 172.18.0.5:42453 in memory (size: 36.8 KiB, free: 366.2 MiB)
26/01/12 01:56:59 INFO BlockManagerInfo: Removed broadcast_22_piece0 on 02926ee04bc9:45221 in memory (size: 35.2 KiB, free: 366.2 MiB)
26/01/12 01:56:59 INFO BlockManagerInfo: Removed broadcast_22_piece0 on 172.18.0.5:42453 in memory (size: 35.2 KiB, free: 366.2 MiB)
26/01/12 01:57:00 INFO TaskSetManager: Starting task 2.0 in stage 23.0 (TID 58) (172.18.0.5, executor 0, partition 2, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 01:57:00 INFO TaskSetManager: Finished task 0.0 in stage 23.0 (TID 56) in 611 ms on 172.18.0.5 (executor 0) (1/4)
26/01/12 01:57:00 INFO TaskSetManager: Starting task 3.0 in stage 23.0 (TID 59) (172.18.0.5, executor 0, partition 3, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 01:57:00 INFO TaskSetManager: Finished task 2.0 in stage 23.0 (TID 58) in 34 ms on 172.18.0.5 (executor 0) (2/4)
26/01/12 01:57:00 INFO TaskSetManager: Finished task 3.0 in stage 23.0 (TID 59) in 32 ms on 172.18.0.5 (executor 0) (3/4)
26/01/12 01:57:45 INFO TaskSetManager: Finished task 1.0 in stage 23.0 (TID 57) in 45593 ms on 172.18.0.5 (executor 0) (4/4)
26/01/12 01:57:45 INFO TaskSchedulerImpl: Removed TaskSet 23.0, whose tasks have all completed, from pool 
26/01/12 01:57:45 INFO DAGScheduler: ResultStage 23 (parquet at NativeMethodAccessorImpl.java:0) finished in 45.631 s
26/01/12 01:57:45 INFO DAGScheduler: Job 23 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 01:57:45 INFO TaskSchedulerImpl: Killing all running tasks in stage 23: Stage finished
26/01/12 01:57:45 INFO DAGScheduler: Job 23 finished: parquet at NativeMethodAccessorImpl.java:0, took 45.643076 s
26/01/12 01:57:45 INFO FileFormatWriter: Start to commit write Job 84aaa8c1-ce42-471c-aa45-88efe66cdedf.
26/01/12 01:57:45 INFO FileFormatWriter: Write Job 84aaa8c1-ce42-471c-aa45-88efe66cdedf committed. Elapsed time: 53 ms.
26/01/12 01:57:45 INFO FileFormatWriter: Finished processing stats for write job 84aaa8c1-ce42-471c-aa45-88efe66cdedf.
Cargando: yellow_tripdata_2010-01.parquet en hdfs://hadoop-namenode:8020/data/nyc/raw/taxi-trips/2010...
26/01/12 01:57:45 INFO InMemoryFileIndex: It took 7 ms to list leaf files for 1 paths.
26/01/12 01:57:45 INFO SparkContext: Starting job: parquet at NativeMethodAccessorImpl.java:0
26/01/12 01:57:45 INFO DAGScheduler: Got job 24 (parquet at NativeMethodAccessorImpl.java:0) with 1 output partitions
26/01/12 01:57:45 INFO DAGScheduler: Final stage: ResultStage 24 (parquet at NativeMethodAccessorImpl.java:0)
26/01/12 01:57:45 INFO DAGScheduler: Parents of final stage: List()
26/01/12 01:57:45 INFO DAGScheduler: Missing parents: List()
26/01/12 01:57:45 INFO DAGScheduler: Submitting ResultStage 24 (MapPartitionsRDD[61] at parquet at NativeMethodAccessorImpl.java:0), which has no missing parents
26/01/12 01:57:45 INFO MemoryStore: Block broadcast_36 stored as values in memory (estimated size 102.6 KiB, free 365.5 MiB)
26/01/12 01:57:45 INFO MemoryStore: Block broadcast_36_piece0 stored as bytes in memory (estimated size 36.8 KiB, free 365.5 MiB)
26/01/12 01:57:45 INFO BlockManagerInfo: Added broadcast_36_piece0 in memory on 02926ee04bc9:45221 (size: 36.8 KiB, free: 366.2 MiB)
26/01/12 01:57:45 INFO SparkContext: Created broadcast 36 from broadcast at DAGScheduler.scala:1513
26/01/12 01:57:45 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 24 (MapPartitionsRDD[61] at parquet at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
26/01/12 01:57:45 INFO TaskSchedulerImpl: Adding task set 24.0 with 1 tasks resource profile 0
26/01/12 01:57:45 INFO TaskSetManager: Starting task 0.0 in stage 24.0 (TID 60) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4607 bytes) taskResourceAssignments Map()
26/01/12 01:57:45 INFO BlockManagerInfo: Added broadcast_36_piece0 in memory on 172.18.0.5:42453 (size: 36.8 KiB, free: 366.2 MiB)
26/01/12 01:57:45 INFO TaskSetManager: Finished task 0.0 in stage 24.0 (TID 60) in 52 ms on 172.18.0.5 (executor 0) (1/1)
26/01/12 01:57:45 INFO TaskSchedulerImpl: Removed TaskSet 24.0, whose tasks have all completed, from pool 
26/01/12 01:57:45 INFO DAGScheduler: ResultStage 24 (parquet at NativeMethodAccessorImpl.java:0) finished in 0.074 s
26/01/12 01:57:45 INFO DAGScheduler: Job 24 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 01:57:45 INFO TaskSchedulerImpl: Killing all running tasks in stage 24: Stage finished
26/01/12 01:57:45 INFO DAGScheduler: Job 24 finished: parquet at NativeMethodAccessorImpl.java:0, took 0.079003 s
26/01/12 01:57:45 INFO FileSourceStrategy: Pushed Filters: 
26/01/12 01:57:45 INFO FileSourceStrategy: Post-Scan Filters: 
26/01/12 01:57:45 INFO FileSourceStrategy: Output Data Schema: struct<vendor_id: string, pickup_datetime: string, dropoff_datetime: string, passenger_count: bigint, trip_distance: double ... 16 more fields>
26/01/12 01:57:45 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 01:57:45 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 01:57:45 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 01:57:45 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 01:57:45 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 01:57:45 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 01:57:45 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 01:57:45 INFO CodeGenerator: Code generated in 53.716882 ms
26/01/12 01:57:45 INFO MemoryStore: Block broadcast_37 stored as values in memory (estimated size 358.2 KiB, free 365.1 MiB)
26/01/12 01:57:45 INFO MemoryStore: Block broadcast_37_piece0 stored as bytes in memory (estimated size 35.2 KiB, free 365.1 MiB)
26/01/12 01:57:45 INFO BlockManagerInfo: Added broadcast_37_piece0 in memory on 02926ee04bc9:45221 (size: 35.2 KiB, free: 366.1 MiB)
26/01/12 01:57:45 INFO SparkContext: Created broadcast 37 from parquet at NativeMethodAccessorImpl.java:0
26/01/12 01:57:45 INFO FileSourceScanExec: Planning scan with bin packing, max size: 134217728 bytes, open cost is considered as scanning 4194304 bytes.
26/01/12 01:57:45 INFO SparkContext: Starting job: parquet at NativeMethodAccessorImpl.java:0
26/01/12 01:57:45 INFO DAGScheduler: Got job 25 (parquet at NativeMethodAccessorImpl.java:0) with 4 output partitions
26/01/12 01:57:45 INFO DAGScheduler: Final stage: ResultStage 25 (parquet at NativeMethodAccessorImpl.java:0)
26/01/12 01:57:45 INFO DAGScheduler: Parents of final stage: List()
26/01/12 01:57:45 INFO DAGScheduler: Missing parents: List()
26/01/12 01:57:45 INFO DAGScheduler: Submitting ResultStage 25 (MapPartitionsRDD[64] at parquet at NativeMethodAccessorImpl.java:0), which has no missing parents
26/01/12 01:57:45 INFO MemoryStore: Block broadcast_38 stored as values in memory (estimated size 224.4 KiB, free 364.9 MiB)
26/01/12 01:57:45 INFO MemoryStore: Block broadcast_38_piece0 stored as bytes in memory (estimated size 77.3 KiB, free 364.8 MiB)
26/01/12 01:57:45 INFO BlockManagerInfo: Added broadcast_38_piece0 in memory on 02926ee04bc9:45221 (size: 77.3 KiB, free: 366.0 MiB)
26/01/12 01:57:45 INFO SparkContext: Created broadcast 38 from broadcast at DAGScheduler.scala:1513
26/01/12 01:57:45 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 25 (MapPartitionsRDD[64] at parquet at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
26/01/12 01:57:45 INFO TaskSchedulerImpl: Adding task set 25.0 with 4 tasks resource profile 0
26/01/12 01:57:45 INFO TaskSetManager: Starting task 0.0 in stage 25.0 (TID 61) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 01:57:45 INFO TaskSetManager: Starting task 1.0 in stage 25.0 (TID 62) (172.18.0.5, executor 0, partition 1, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 01:57:45 INFO BlockManagerInfo: Added broadcast_38_piece0 in memory on 172.18.0.5:42453 (size: 77.3 KiB, free: 366.1 MiB)
26/01/12 01:57:45 INFO BlockManagerInfo: Added broadcast_37_piece0 in memory on 172.18.0.5:42453 (size: 35.2 KiB, free: 366.0 MiB)
26/01/12 01:57:46 INFO TaskSetManager: Starting task 2.0 in stage 25.0 (TID 63) (172.18.0.5, executor 0, partition 2, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 01:57:46 INFO TaskSetManager: Finished task 0.0 in stage 25.0 (TID 61) in 564 ms on 172.18.0.5 (executor 0) (1/4)
26/01/12 01:57:46 INFO TaskSetManager: Starting task 3.0 in stage 25.0 (TID 64) (172.18.0.5, executor 0, partition 3, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 01:57:46 INFO TaskSetManager: Finished task 2.0 in stage 25.0 (TID 63) in 39 ms on 172.18.0.5 (executor 0) (2/4)
26/01/12 01:57:46 INFO TaskSetManager: Finished task 3.0 in stage 25.0 (TID 64) in 46 ms on 172.18.0.5 (executor 0) (3/4)
26/01/12 01:58:39 INFO TaskSetManager: Finished task 1.0 in stage 25.0 (TID 62) in 53440 ms on 172.18.0.5 (executor 0) (4/4)
26/01/12 01:58:39 INFO TaskSchedulerImpl: Removed TaskSet 25.0, whose tasks have all completed, from pool 
26/01/12 01:58:39 INFO DAGScheduler: ResultStage 25 (parquet at NativeMethodAccessorImpl.java:0) finished in 53.464 s
26/01/12 01:58:39 INFO DAGScheduler: Job 25 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 01:58:39 INFO TaskSchedulerImpl: Killing all running tasks in stage 25: Stage finished
26/01/12 01:58:39 INFO DAGScheduler: Job 25 finished: parquet at NativeMethodAccessorImpl.java:0, took 53.476399 s
26/01/12 01:58:39 INFO FileFormatWriter: Start to commit write Job 5e5e6e90-4f02-4c8b-a18f-5345e9f45f09.
26/01/12 01:58:39 INFO FileFormatWriter: Write Job 5e5e6e90-4f02-4c8b-a18f-5345e9f45f09 committed. Elapsed time: 48 ms.
26/01/12 01:58:39 INFO FileFormatWriter: Finished processing stats for write job 5e5e6e90-4f02-4c8b-a18f-5345e9f45f09.
Cargando: yellow_tripdata_2010-02.parquet en hdfs://hadoop-namenode:8020/data/nyc/raw/taxi-trips/2010...
26/01/12 01:58:39 INFO InMemoryFileIndex: It took 6 ms to list leaf files for 1 paths.
26/01/12 01:58:39 INFO SparkContext: Starting job: parquet at NativeMethodAccessorImpl.java:0
26/01/12 01:58:39 INFO DAGScheduler: Got job 26 (parquet at NativeMethodAccessorImpl.java:0) with 1 output partitions
26/01/12 01:58:39 INFO DAGScheduler: Final stage: ResultStage 26 (parquet at NativeMethodAccessorImpl.java:0)
26/01/12 01:58:39 INFO DAGScheduler: Parents of final stage: List()
26/01/12 01:58:39 INFO DAGScheduler: Missing parents: List()
26/01/12 01:58:39 INFO DAGScheduler: Submitting ResultStage 26 (MapPartitionsRDD[66] at parquet at NativeMethodAccessorImpl.java:0), which has no missing parents
26/01/12 01:58:39 INFO MemoryStore: Block broadcast_39 stored as values in memory (estimated size 102.6 KiB, free 364.7 MiB)
26/01/12 01:58:39 INFO MemoryStore: Block broadcast_39_piece0 stored as bytes in memory (estimated size 36.8 KiB, free 364.7 MiB)
26/01/12 01:58:39 INFO BlockManagerInfo: Added broadcast_39_piece0 in memory on 02926ee04bc9:45221 (size: 36.8 KiB, free: 366.0 MiB)
26/01/12 01:58:39 INFO SparkContext: Created broadcast 39 from broadcast at DAGScheduler.scala:1513
26/01/12 01:58:39 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 26 (MapPartitionsRDD[66] at parquet at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
26/01/12 01:58:39 INFO TaskSchedulerImpl: Adding task set 26.0 with 1 tasks resource profile 0
26/01/12 01:58:39 INFO TaskSetManager: Starting task 0.0 in stage 26.0 (TID 65) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4607 bytes) taskResourceAssignments Map()
26/01/12 01:58:39 INFO BlockManagerInfo: Added broadcast_39_piece0 in memory on 172.18.0.5:42453 (size: 36.8 KiB, free: 366.0 MiB)
26/01/12 01:58:39 INFO TaskSetManager: Finished task 0.0 in stage 26.0 (TID 65) in 57 ms on 172.18.0.5 (executor 0) (1/1)
26/01/12 01:58:39 INFO TaskSchedulerImpl: Removed TaskSet 26.0, whose tasks have all completed, from pool 
26/01/12 01:58:39 INFO DAGScheduler: ResultStage 26 (parquet at NativeMethodAccessorImpl.java:0) finished in 0.070 s
26/01/12 01:58:39 INFO DAGScheduler: Job 26 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 01:58:39 INFO TaskSchedulerImpl: Killing all running tasks in stage 26: Stage finished
26/01/12 01:58:39 INFO DAGScheduler: Job 26 finished: parquet at NativeMethodAccessorImpl.java:0, took 0.076890 s
26/01/12 01:58:39 INFO FileSourceStrategy: Pushed Filters: 
26/01/12 01:58:39 INFO FileSourceStrategy: Post-Scan Filters: 
26/01/12 01:58:39 INFO FileSourceStrategy: Output Data Schema: struct<vendor_id: string, pickup_datetime: string, dropoff_datetime: string, passenger_count: bigint, trip_distance: double ... 17 more fields>
26/01/12 01:58:39 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 01:58:39 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 01:58:39 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 01:58:39 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 01:58:39 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 01:58:39 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 01:58:39 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 01:58:39 INFO CodeGenerator: Code generated in 24.453534 ms
26/01/12 01:58:39 INFO MemoryStore: Block broadcast_40 stored as values in memory (estimated size 358.4 KiB, free 364.3 MiB)
26/01/12 01:58:39 INFO MemoryStore: Block broadcast_40_piece0 stored as bytes in memory (estimated size 35.3 KiB, free 364.3 MiB)
26/01/12 01:58:39 INFO BlockManagerInfo: Added broadcast_40_piece0 in memory on 02926ee04bc9:45221 (size: 35.3 KiB, free: 366.0 MiB)
26/01/12 01:58:39 INFO SparkContext: Created broadcast 40 from parquet at NativeMethodAccessorImpl.java:0
26/01/12 01:58:39 INFO FileSourceScanExec: Planning scan with bin packing, max size: 134217728 bytes, open cost is considered as scanning 4194304 bytes.
26/01/12 01:58:39 INFO SparkContext: Starting job: parquet at NativeMethodAccessorImpl.java:0
26/01/12 01:58:39 INFO DAGScheduler: Got job 27 (parquet at NativeMethodAccessorImpl.java:0) with 3 output partitions
26/01/12 01:58:39 INFO DAGScheduler: Final stage: ResultStage 27 (parquet at NativeMethodAccessorImpl.java:0)
26/01/12 01:58:39 INFO DAGScheduler: Parents of final stage: List()
26/01/12 01:58:39 INFO DAGScheduler: Missing parents: List()
26/01/12 01:58:39 INFO DAGScheduler: Submitting ResultStage 27 (MapPartitionsRDD[69] at parquet at NativeMethodAccessorImpl.java:0), which has no missing parents
26/01/12 01:58:39 INFO MemoryStore: Block broadcast_41 stored as values in memory (estimated size 225.0 KiB, free 364.1 MiB)
26/01/12 01:58:39 INFO MemoryStore: Block broadcast_41_piece0 stored as bytes in memory (estimated size 77.2 KiB, free 364.0 MiB)
26/01/12 01:58:39 INFO BlockManagerInfo: Added broadcast_41_piece0 in memory on 02926ee04bc9:45221 (size: 77.2 KiB, free: 365.9 MiB)
26/01/12 01:58:39 INFO SparkContext: Created broadcast 41 from broadcast at DAGScheduler.scala:1513
26/01/12 01:58:39 INFO DAGScheduler: Submitting 3 missing tasks from ResultStage 27 (MapPartitionsRDD[69] at parquet at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2))
26/01/12 01:58:39 INFO TaskSchedulerImpl: Adding task set 27.0 with 3 tasks resource profile 0
26/01/12 01:58:39 INFO TaskSetManager: Starting task 0.0 in stage 27.0 (TID 66) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 01:58:39 INFO TaskSetManager: Starting task 1.0 in stage 27.0 (TID 67) (172.18.0.5, executor 0, partition 1, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 01:58:39 INFO BlockManagerInfo: Added broadcast_41_piece0 in memory on 172.18.0.5:42453 (size: 77.2 KiB, free: 365.9 MiB)
26/01/12 01:58:39 INFO BlockManagerInfo: Added broadcast_40_piece0 in memory on 172.18.0.5:42453 (size: 35.3 KiB, free: 365.9 MiB)
26/01/12 01:58:40 INFO TaskSetManager: Starting task 2.0 in stage 27.0 (TID 68) (172.18.0.5, executor 0, partition 2, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 01:58:40 INFO TaskSetManager: Finished task 0.0 in stage 27.0 (TID 66) in 521 ms on 172.18.0.5 (executor 0) (1/3)
26/01/12 01:58:40 INFO TaskSetManager: Finished task 2.0 in stage 27.0 (TID 68) in 72 ms on 172.18.0.5 (executor 0) (2/3)
26/01/12 01:59:23 INFO TaskSetManager: Finished task 1.0 in stage 27.0 (TID 67) in 44146 ms on 172.18.0.5 (executor 0) (3/3)
26/01/12 01:59:23 INFO TaskSchedulerImpl: Removed TaskSet 27.0, whose tasks have all completed, from pool 
26/01/12 01:59:23 INFO DAGScheduler: ResultStage 27 (parquet at NativeMethodAccessorImpl.java:0) finished in 44.168 s
26/01/12 01:59:23 INFO DAGScheduler: Job 27 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 01:59:23 INFO TaskSchedulerImpl: Killing all running tasks in stage 27: Stage finished
26/01/12 01:59:23 INFO DAGScheduler: Job 27 finished: parquet at NativeMethodAccessorImpl.java:0, took 44.176321 s
26/01/12 01:59:23 INFO FileFormatWriter: Start to commit write Job 3ad58b38-2d37-4ed2-ab42-86eed6ff8e46.
26/01/12 01:59:23 INFO FileFormatWriter: Write Job 3ad58b38-2d37-4ed2-ab42-86eed6ff8e46 committed. Elapsed time: 49 ms.
26/01/12 01:59:23 INFO FileFormatWriter: Finished processing stats for write job 3ad58b38-2d37-4ed2-ab42-86eed6ff8e46.
Cargando: yellow_tripdata_2010-03.parquet en hdfs://hadoop-namenode:8020/data/nyc/raw/taxi-trips/2010...
26/01/12 01:59:23 INFO InMemoryFileIndex: It took 6 ms to list leaf files for 1 paths.
26/01/12 01:59:23 INFO SparkContext: Starting job: parquet at NativeMethodAccessorImpl.java:0
26/01/12 01:59:23 INFO DAGScheduler: Got job 28 (parquet at NativeMethodAccessorImpl.java:0) with 1 output partitions
26/01/12 01:59:23 INFO DAGScheduler: Final stage: ResultStage 28 (parquet at NativeMethodAccessorImpl.java:0)
26/01/12 01:59:23 INFO DAGScheduler: Parents of final stage: List()
26/01/12 01:59:23 INFO DAGScheduler: Missing parents: List()
26/01/12 01:59:23 INFO DAGScheduler: Submitting ResultStage 28 (MapPartitionsRDD[71] at parquet at NativeMethodAccessorImpl.java:0), which has no missing parents
26/01/12 01:59:23 INFO MemoryStore: Block broadcast_42 stored as values in memory (estimated size 102.6 KiB, free 363.9 MiB)
26/01/12 01:59:23 INFO MemoryStore: Block broadcast_42_piece0 stored as bytes in memory (estimated size 36.8 KiB, free 363.9 MiB)
26/01/12 01:59:23 INFO BlockManagerInfo: Added broadcast_42_piece0 in memory on 02926ee04bc9:45221 (size: 36.8 KiB, free: 365.9 MiB)
26/01/12 01:59:23 INFO SparkContext: Created broadcast 42 from broadcast at DAGScheduler.scala:1513
26/01/12 01:59:23 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 28 (MapPartitionsRDD[71] at parquet at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
26/01/12 01:59:23 INFO TaskSchedulerImpl: Adding task set 28.0 with 1 tasks resource profile 0
26/01/12 01:59:23 INFO TaskSetManager: Starting task 0.0 in stage 28.0 (TID 69) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4607 bytes) taskResourceAssignments Map()
26/01/12 01:59:23 INFO BlockManagerInfo: Added broadcast_42_piece0 in memory on 172.18.0.5:42453 (size: 36.8 KiB, free: 365.9 MiB)
26/01/12 01:59:23 INFO TaskSetManager: Finished task 0.0 in stage 28.0 (TID 69) in 55 ms on 172.18.0.5 (executor 0) (1/1)
26/01/12 01:59:23 INFO TaskSchedulerImpl: Removed TaskSet 28.0, whose tasks have all completed, from pool 
26/01/12 01:59:23 INFO DAGScheduler: ResultStage 28 (parquet at NativeMethodAccessorImpl.java:0) finished in 0.067 s
26/01/12 01:59:23 INFO DAGScheduler: Job 28 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 01:59:23 INFO TaskSchedulerImpl: Killing all running tasks in stage 28: Stage finished
26/01/12 01:59:23 INFO DAGScheduler: Job 28 finished: parquet at NativeMethodAccessorImpl.java:0, took 0.071865 s
26/01/12 01:59:23 INFO FileSourceStrategy: Pushed Filters: 
26/01/12 01:59:23 INFO FileSourceStrategy: Post-Scan Filters: 
26/01/12 01:59:23 INFO FileSourceStrategy: Output Data Schema: struct<vendor_id: string, pickup_datetime: string, dropoff_datetime: string, passenger_count: bigint, trip_distance: double ... 17 more fields>
26/01/12 01:59:23 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 01:59:23 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 01:59:23 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 01:59:23 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 01:59:23 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 01:59:23 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 01:59:23 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 01:59:23 INFO MemoryStore: Block broadcast_43 stored as values in memory (estimated size 358.4 KiB, free 363.5 MiB)
26/01/12 01:59:23 INFO MemoryStore: Block broadcast_43_piece0 stored as bytes in memory (estimated size 35.3 KiB, free 363.5 MiB)
26/01/12 01:59:23 INFO BlockManagerInfo: Added broadcast_43_piece0 in memory on 02926ee04bc9:45221 (size: 35.3 KiB, free: 365.8 MiB)
26/01/12 01:59:23 INFO SparkContext: Created broadcast 43 from parquet at NativeMethodAccessorImpl.java:0
26/01/12 01:59:23 INFO FileSourceScanExec: Planning scan with bin packing, max size: 134217728 bytes, open cost is considered as scanning 4194304 bytes.
26/01/12 01:59:23 INFO SparkContext: Starting job: parquet at NativeMethodAccessorImpl.java:0
26/01/12 01:59:23 INFO DAGScheduler: Got job 29 (parquet at NativeMethodAccessorImpl.java:0) with 4 output partitions
26/01/12 01:59:23 INFO DAGScheduler: Final stage: ResultStage 29 (parquet at NativeMethodAccessorImpl.java:0)
26/01/12 01:59:23 INFO DAGScheduler: Parents of final stage: List()
26/01/12 01:59:23 INFO DAGScheduler: Missing parents: List()
26/01/12 01:59:23 INFO DAGScheduler: Submitting ResultStage 29 (MapPartitionsRDD[74] at parquet at NativeMethodAccessorImpl.java:0), which has no missing parents
26/01/12 01:59:23 INFO MemoryStore: Block broadcast_44 stored as values in memory (estimated size 225.0 KiB, free 363.3 MiB)
26/01/12 01:59:23 INFO MemoryStore: Block broadcast_44_piece0 stored as bytes in memory (estimated size 77.3 KiB, free 363.2 MiB)
26/01/12 01:59:23 INFO BlockManagerInfo: Added broadcast_44_piece0 in memory on 02926ee04bc9:45221 (size: 77.3 KiB, free: 365.8 MiB)
26/01/12 01:59:23 INFO SparkContext: Created broadcast 44 from broadcast at DAGScheduler.scala:1513
26/01/12 01:59:23 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 29 (MapPartitionsRDD[74] at parquet at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
26/01/12 01:59:23 INFO TaskSchedulerImpl: Adding task set 29.0 with 4 tasks resource profile 0
26/01/12 01:59:23 INFO TaskSetManager: Starting task 0.0 in stage 29.0 (TID 70) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 01:59:23 INFO TaskSetManager: Starting task 1.0 in stage 29.0 (TID 71) (172.18.0.5, executor 0, partition 1, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 01:59:23 INFO BlockManagerInfo: Added broadcast_44_piece0 in memory on 172.18.0.5:42453 (size: 77.3 KiB, free: 365.8 MiB)
26/01/12 01:59:23 INFO BlockManagerInfo: Added broadcast_43_piece0 in memory on 172.18.0.5:42453 (size: 35.3 KiB, free: 365.8 MiB)
26/01/12 01:59:24 INFO TaskSetManager: Starting task 2.0 in stage 29.0 (TID 72) (172.18.0.5, executor 0, partition 2, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 01:59:24 INFO TaskSetManager: Finished task 0.0 in stage 29.0 (TID 70) in 501 ms on 172.18.0.5 (executor 0) (1/4)
26/01/12 01:59:24 INFO TaskSetManager: Starting task 3.0 in stage 29.0 (TID 73) (172.18.0.5, executor 0, partition 3, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 01:59:24 INFO TaskSetManager: Finished task 2.0 in stage 29.0 (TID 72) in 33 ms on 172.18.0.5 (executor 0) (2/4)
26/01/12 01:59:24 INFO TaskSetManager: Finished task 3.0 in stage 29.0 (TID 73) in 32 ms on 172.18.0.5 (executor 0) (3/4)
26/01/12 02:03:39 INFO TaskSetManager: Finished task 1.0 in stage 29.0 (TID 71) in 255494 ms on 172.18.0.5 (executor 0) (4/4)
26/01/12 02:03:39 INFO TaskSchedulerImpl: Removed TaskSet 29.0, whose tasks have all completed, from pool 
26/01/12 02:03:39 INFO DAGScheduler: ResultStage 29 (parquet at NativeMethodAccessorImpl.java:0) finished in 255.523 s
26/01/12 02:03:39 INFO DAGScheduler: Job 29 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:03:39 INFO TaskSchedulerImpl: Killing all running tasks in stage 29: Stage finished
26/01/12 02:03:39 INFO DAGScheduler: Job 29 finished: parquet at NativeMethodAccessorImpl.java:0, took 47.767096 s
26/01/12 02:03:39 INFO FileFormatWriter: Start to commit write Job 6719b47b-93bf-4f55-a16b-0ff24588212f.
26/01/12 02:03:39 INFO FileFormatWriter: Write Job 6719b47b-93bf-4f55-a16b-0ff24588212f committed. Elapsed time: 88 ms.
26/01/12 02:03:39 INFO FileFormatWriter: Finished processing stats for write job 6719b47b-93bf-4f55-a16b-0ff24588212f.
Cargando: yellow_tripdata_2010-04.parquet en hdfs://hadoop-namenode:8020/data/nyc/raw/taxi-trips/2010...
26/01/12 02:03:39 INFO InMemoryFileIndex: It took 26 ms to list leaf files for 1 paths.
26/01/12 02:03:39 INFO SparkContext: Starting job: parquet at NativeMethodAccessorImpl.java:0
26/01/12 02:03:39 INFO DAGScheduler: Got job 30 (parquet at NativeMethodAccessorImpl.java:0) with 1 output partitions
26/01/12 02:03:39 INFO DAGScheduler: Final stage: ResultStage 30 (parquet at NativeMethodAccessorImpl.java:0)
26/01/12 02:03:39 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:03:39 INFO DAGScheduler: Missing parents: List()
26/01/12 02:03:39 INFO DAGScheduler: Submitting ResultStage 30 (MapPartitionsRDD[76] at parquet at NativeMethodAccessorImpl.java:0), which has no missing parents
26/01/12 02:03:39 INFO MemoryStore: Block broadcast_45 stored as values in memory (estimated size 102.6 KiB, free 363.1 MiB)
26/01/12 02:03:39 INFO MemoryStore: Block broadcast_45_piece0 stored as bytes in memory (estimated size 36.8 KiB, free 363.0 MiB)
26/01/12 02:03:39 INFO BlockManagerInfo: Added broadcast_45_piece0 in memory on 02926ee04bc9:45221 (size: 36.8 KiB, free: 365.7 MiB)
26/01/12 02:03:39 INFO SparkContext: Created broadcast 45 from broadcast at DAGScheduler.scala:1513
26/01/12 02:03:39 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 30 (MapPartitionsRDD[76] at parquet at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
26/01/12 02:03:39 INFO TaskSchedulerImpl: Adding task set 30.0 with 1 tasks resource profile 0
26/01/12 02:03:39 INFO TaskSetManager: Starting task 0.0 in stage 30.0 (TID 74) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4607 bytes) taskResourceAssignments Map()
26/01/12 02:03:40 INFO BlockManagerInfo: Added broadcast_45_piece0 in memory on 172.18.0.5:42453 (size: 36.8 KiB, free: 365.7 MiB)
26/01/12 02:03:40 INFO TaskSetManager: Finished task 0.0 in stage 30.0 (TID 74) in 92 ms on 172.18.0.5 (executor 0) (1/1)
26/01/12 02:03:40 INFO TaskSchedulerImpl: Removed TaskSet 30.0, whose tasks have all completed, from pool 
26/01/12 02:03:40 INFO DAGScheduler: ResultStage 30 (parquet at NativeMethodAccessorImpl.java:0) finished in 0.117 s
26/01/12 02:03:40 INFO DAGScheduler: Job 30 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:03:40 INFO TaskSchedulerImpl: Killing all running tasks in stage 30: Stage finished
26/01/12 02:03:40 INFO DAGScheduler: Job 30 finished: parquet at NativeMethodAccessorImpl.java:0, took 0.122858 s
26/01/12 02:03:40 INFO FileSourceStrategy: Pushed Filters: 
26/01/12 02:03:40 INFO FileSourceStrategy: Post-Scan Filters: 
26/01/12 02:03:40 INFO FileSourceStrategy: Output Data Schema: struct<vendor_id: string, pickup_datetime: string, dropoff_datetime: string, passenger_count: bigint, trip_distance: double ... 16 more fields>
26/01/12 02:03:40 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:03:40 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:03:40 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:03:40 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:03:40 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:03:40 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:03:40 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:03:40 INFO MemoryStore: Block broadcast_46 stored as values in memory (estimated size 358.2 KiB, free 362.7 MiB)
26/01/12 02:03:40 INFO MemoryStore: Block broadcast_46_piece0 stored as bytes in memory (estimated size 35.2 KiB, free 362.7 MiB)
26/01/12 02:03:40 INFO BlockManagerInfo: Added broadcast_46_piece0 in memory on 02926ee04bc9:45221 (size: 35.2 KiB, free: 365.7 MiB)
26/01/12 02:03:40 INFO SparkContext: Created broadcast 46 from parquet at NativeMethodAccessorImpl.java:0
26/01/12 02:03:40 INFO FileSourceScanExec: Planning scan with bin packing, max size: 134217728 bytes, open cost is considered as scanning 4194304 bytes.
26/01/12 02:03:40 INFO SparkContext: Starting job: parquet at NativeMethodAccessorImpl.java:0
26/01/12 02:03:40 INFO DAGScheduler: Got job 31 (parquet at NativeMethodAccessorImpl.java:0) with 4 output partitions
26/01/12 02:03:40 INFO DAGScheduler: Final stage: ResultStage 31 (parquet at NativeMethodAccessorImpl.java:0)
26/01/12 02:03:40 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:03:40 INFO DAGScheduler: Missing parents: List()
26/01/12 02:03:40 INFO DAGScheduler: Submitting ResultStage 31 (MapPartitionsRDD[79] at parquet at NativeMethodAccessorImpl.java:0), which has no missing parents
26/01/12 02:03:40 INFO MemoryStore: Block broadcast_47 stored as values in memory (estimated size 224.4 KiB, free 362.4 MiB)
26/01/12 02:03:40 INFO MemoryStore: Block broadcast_47_piece0 stored as bytes in memory (estimated size 77.3 KiB, free 362.4 MiB)
26/01/12 02:03:40 INFO BlockManagerInfo: Added broadcast_47_piece0 in memory on 02926ee04bc9:45221 (size: 77.3 KiB, free: 365.6 MiB)
26/01/12 02:03:40 INFO SparkContext: Created broadcast 47 from broadcast at DAGScheduler.scala:1513
26/01/12 02:03:40 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 31 (MapPartitionsRDD[79] at parquet at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
26/01/12 02:03:40 INFO TaskSchedulerImpl: Adding task set 31.0 with 4 tasks resource profile 0
26/01/12 02:03:40 INFO TaskSetManager: Starting task 0.0 in stage 31.0 (TID 75) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:03:40 INFO TaskSetManager: Starting task 1.0 in stage 31.0 (TID 76) (172.18.0.5, executor 0, partition 1, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:03:40 INFO BlockManagerInfo: Added broadcast_47_piece0 in memory on 172.18.0.5:42453 (size: 77.3 KiB, free: 365.6 MiB)
26/01/12 02:03:40 INFO BlockManagerInfo: Added broadcast_46_piece0 in memory on 172.18.0.5:42453 (size: 35.2 KiB, free: 365.6 MiB)
26/01/12 02:03:40 INFO TaskSetManager: Starting task 2.0 in stage 31.0 (TID 77) (172.18.0.5, executor 0, partition 2, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:03:40 INFO TaskSetManager: Finished task 0.0 in stage 31.0 (TID 75) in 594 ms on 172.18.0.5 (executor 0) (1/4)
26/01/12 02:03:41 INFO TaskSetManager: Starting task 3.0 in stage 31.0 (TID 78) (172.18.0.5, executor 0, partition 3, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:03:41 INFO TaskSetManager: Finished task 2.0 in stage 31.0 (TID 77) in 50 ms on 172.18.0.5 (executor 0) (2/4)
26/01/12 02:03:41 INFO TaskSetManager: Finished task 3.0 in stage 31.0 (TID 78) in 57 ms on 172.18.0.5 (executor 0) (3/4)
26/01/12 02:04:42 INFO TaskSetManager: Finished task 1.0 in stage 31.0 (TID 76) in 61651 ms on 172.18.0.5 (executor 0) (4/4)
26/01/12 02:04:42 INFO TaskSchedulerImpl: Removed TaskSet 31.0, whose tasks have all completed, from pool 
26/01/12 02:04:42 INFO DAGScheduler: ResultStage 31 (parquet at NativeMethodAccessorImpl.java:0) finished in 61.705 s
26/01/12 02:04:42 INFO DAGScheduler: Job 31 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:04:42 INFO TaskSchedulerImpl: Killing all running tasks in stage 31: Stage finished
26/01/12 02:04:42 INFO DAGScheduler: Job 31 finished: parquet at NativeMethodAccessorImpl.java:0, took 61.719118 s
26/01/12 02:04:42 INFO FileFormatWriter: Start to commit write Job 5d2346c3-f15c-4cdc-94ad-6ffb948eb183.
26/01/12 02:04:42 INFO FileFormatWriter: Write Job 5d2346c3-f15c-4cdc-94ad-6ffb948eb183 committed. Elapsed time: 50 ms.
26/01/12 02:04:42 INFO FileFormatWriter: Finished processing stats for write job 5d2346c3-f15c-4cdc-94ad-6ffb948eb183.
Cargando: yellow_tripdata_2010-05.parquet en hdfs://hadoop-namenode:8020/data/nyc/raw/taxi-trips/2010...
26/01/12 02:04:42 INFO InMemoryFileIndex: It took 6 ms to list leaf files for 1 paths.
26/01/12 02:04:42 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 02:04:42 INFO DAGScheduler: Got job 32 (parquet at <unknown>:0) with 1 output partitions
26/01/12 02:04:42 INFO DAGScheduler: Final stage: ResultStage 32 (parquet at <unknown>:0)
26/01/12 02:04:42 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:04:42 INFO DAGScheduler: Missing parents: List()
26/01/12 02:04:42 INFO DAGScheduler: Submitting ResultStage 32 (MapPartitionsRDD[81] at parquet at <unknown>:0), which has no missing parents
26/01/12 02:04:42 INFO MemoryStore: Block broadcast_48 stored as values in memory (estimated size 102.6 KiB, free 362.3 MiB)
26/01/12 02:04:42 INFO MemoryStore: Block broadcast_48_piece0 stored as bytes in memory (estimated size 36.8 KiB, free 362.2 MiB)
26/01/12 02:04:42 INFO BlockManagerInfo: Added broadcast_48_piece0 in memory on 02926ee04bc9:45221 (size: 36.8 KiB, free: 365.6 MiB)
26/01/12 02:04:42 INFO SparkContext: Created broadcast 48 from broadcast at DAGScheduler.scala:1513
26/01/12 02:04:42 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 32 (MapPartitionsRDD[81] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0))
26/01/12 02:04:42 INFO TaskSchedulerImpl: Adding task set 32.0 with 1 tasks resource profile 0
26/01/12 02:04:42 INFO TaskSetManager: Starting task 0.0 in stage 32.0 (TID 79) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4607 bytes) taskResourceAssignments Map()
26/01/12 02:04:42 INFO BlockManagerInfo: Added broadcast_48_piece0 in memory on 172.18.0.5:42453 (size: 36.8 KiB, free: 365.6 MiB)
26/01/12 02:04:42 INFO TaskSetManager: Finished task 0.0 in stage 32.0 (TID 79) in 54 ms on 172.18.0.5 (executor 0) (1/1)
26/01/12 02:04:42 INFO TaskSchedulerImpl: Removed TaskSet 32.0, whose tasks have all completed, from pool 
26/01/12 02:04:42 INFO DAGScheduler: ResultStage 32 (parquet at <unknown>:0) finished in 0.068 s
26/01/12 02:04:42 INFO DAGScheduler: Job 32 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:04:42 INFO TaskSchedulerImpl: Killing all running tasks in stage 32: Stage finished
26/01/12 02:04:42 INFO DAGScheduler: Job 32 finished: parquet at <unknown>:0, took 0.072736 s
26/01/12 02:04:42 INFO FileSourceStrategy: Pushed Filters: 
26/01/12 02:04:42 INFO FileSourceStrategy: Post-Scan Filters: 
26/01/12 02:04:42 INFO FileSourceStrategy: Output Data Schema: struct<vendor_id: string, pickup_datetime: string, dropoff_datetime: string, passenger_count: bigint, trip_distance: double ... 16 more fields>
26/01/12 02:04:42 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:04:42 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:04:42 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:04:42 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:04:42 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:04:42 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:04:42 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:04:42 INFO MemoryStore: Block broadcast_49 stored as values in memory (estimated size 358.2 KiB, free 361.9 MiB)
26/01/12 02:04:42 INFO MemoryStore: Block broadcast_49_piece0 stored as bytes in memory (estimated size 35.2 KiB, free 361.8 MiB)
26/01/12 02:04:42 INFO BlockManagerInfo: Added broadcast_49_piece0 in memory on 02926ee04bc9:45221 (size: 35.2 KiB, free: 365.5 MiB)
26/01/12 02:04:42 INFO SparkContext: Created broadcast 49 from parquet at <unknown>:0
26/01/12 02:04:42 INFO FileSourceScanExec: Planning scan with bin packing, max size: 134217728 bytes, open cost is considered as scanning 4194304 bytes.
26/01/12 02:04:42 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 02:04:42 INFO DAGScheduler: Got job 33 (parquet at <unknown>:0) with 5 output partitions
26/01/12 02:04:42 INFO DAGScheduler: Final stage: ResultStage 33 (parquet at <unknown>:0)
26/01/12 02:04:42 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:04:42 INFO DAGScheduler: Missing parents: List()
26/01/12 02:04:42 INFO DAGScheduler: Submitting ResultStage 33 (MapPartitionsRDD[84] at parquet at <unknown>:0), which has no missing parents
26/01/12 02:04:42 INFO MemoryStore: Block broadcast_50 stored as values in memory (estimated size 224.3 KiB, free 361.6 MiB)
26/01/12 02:04:42 INFO MemoryStore: Block broadcast_50_piece0 stored as bytes in memory (estimated size 77.3 KiB, free 361.5 MiB)
26/01/12 02:04:42 INFO BlockManagerInfo: Added broadcast_50_piece0 in memory on 02926ee04bc9:45221 (size: 77.3 KiB, free: 365.5 MiB)
26/01/12 02:04:42 INFO SparkContext: Created broadcast 50 from broadcast at DAGScheduler.scala:1513
26/01/12 02:04:42 INFO DAGScheduler: Submitting 5 missing tasks from ResultStage 33 (MapPartitionsRDD[84] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4))
26/01/12 02:04:42 INFO TaskSchedulerImpl: Adding task set 33.0 with 5 tasks resource profile 0
26/01/12 02:04:42 INFO TaskSetManager: Starting task 0.0 in stage 33.0 (TID 80) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:04:42 INFO TaskSetManager: Starting task 1.0 in stage 33.0 (TID 81) (172.18.0.5, executor 0, partition 1, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:04:42 INFO BlockManagerInfo: Added broadcast_50_piece0 in memory on 172.18.0.5:42453 (size: 77.3 KiB, free: 365.5 MiB)
26/01/12 02:04:42 INFO BlockManagerInfo: Added broadcast_49_piece0 in memory on 172.18.0.5:42453 (size: 35.2 KiB, free: 365.5 MiB)
26/01/12 02:04:42 INFO TaskSetManager: Starting task 2.0 in stage 33.0 (TID 82) (172.18.0.5, executor 0, partition 2, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:04:42 INFO TaskSetManager: Finished task 1.0 in stage 33.0 (TID 81) in 132 ms on 172.18.0.5 (executor 0) (1/5)
26/01/12 02:04:42 INFO TaskSetManager: Starting task 3.0 in stage 33.0 (TID 83) (172.18.0.5, executor 0, partition 3, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:04:42 INFO TaskSetManager: Finished task 0.0 in stage 33.0 (TID 80) in 563 ms on 172.18.0.5 (executor 0) (2/5)
26/01/12 02:04:42 INFO TaskSetManager: Starting task 4.0 in stage 33.0 (TID 84) (172.18.0.5, executor 0, partition 4, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:04:42 INFO TaskSetManager: Finished task 3.0 in stage 33.0 (TID 83) in 38 ms on 172.18.0.5 (executor 0) (3/5)
26/01/12 02:04:42 INFO TaskSetManager: Finished task 4.0 in stage 33.0 (TID 84) in 32 ms on 172.18.0.5 (executor 0) (4/5)
26/01/12 02:05:35 INFO TaskSetManager: Finished task 2.0 in stage 33.0 (TID 82) in 52988 ms on 172.18.0.5 (executor 0) (5/5)
26/01/12 02:05:35 INFO TaskSchedulerImpl: Removed TaskSet 33.0, whose tasks have all completed, from pool 
26/01/12 02:05:35 INFO DAGScheduler: ResultStage 33 (parquet at <unknown>:0) finished in 53.142 s
26/01/12 02:05:35 INFO DAGScheduler: Job 33 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:05:35 INFO TaskSchedulerImpl: Killing all running tasks in stage 33: Stage finished
26/01/12 02:05:35 INFO DAGScheduler: Job 33 finished: parquet at <unknown>:0, took 53.151956 s
26/01/12 02:05:35 INFO FileFormatWriter: Start to commit write Job afc9ff86-8090-4486-bb82-2471e41e2af9.
26/01/12 02:05:35 INFO FileFormatWriter: Write Job afc9ff86-8090-4486-bb82-2471e41e2af9 committed. Elapsed time: 45 ms.
26/01/12 02:05:35 INFO FileFormatWriter: Finished processing stats for write job afc9ff86-8090-4486-bb82-2471e41e2af9.
Cargando: yellow_tripdata_2010-06.parquet en hdfs://hadoop-namenode:8020/data/nyc/raw/taxi-trips/2010...
26/01/12 02:05:35 INFO BlockManagerInfo: Removed broadcast_45_piece0 on 02926ee04bc9:45221 in memory (size: 36.8 KiB, free: 365.5 MiB)
26/01/12 02:05:35 INFO BlockManagerInfo: Removed broadcast_45_piece0 on 172.18.0.5:42453 in memory (size: 36.8 KiB, free: 365.5 MiB)
26/01/12 02:05:35 INFO BlockManagerInfo: Removed broadcast_39_piece0 on 02926ee04bc9:45221 in memory (size: 36.8 KiB, free: 365.5 MiB)
26/01/12 02:05:35 INFO BlockManagerInfo: Removed broadcast_39_piece0 on 172.18.0.5:42453 in memory (size: 36.8 KiB, free: 365.5 MiB)
26/01/12 02:05:35 INFO BlockManagerInfo: Removed broadcast_36_piece0 on 02926ee04bc9:45221 in memory (size: 36.8 KiB, free: 365.6 MiB)
26/01/12 02:05:35 INFO BlockManagerInfo: Removed broadcast_36_piece0 on 172.18.0.5:42453 in memory (size: 36.8 KiB, free: 365.6 MiB)
26/01/12 02:05:35 INFO BlockManagerInfo: Removed broadcast_44_piece0 on 02926ee04bc9:45221 in memory (size: 77.3 KiB, free: 365.6 MiB)
26/01/12 02:05:35 INFO BlockManagerInfo: Removed broadcast_44_piece0 on 172.18.0.5:42453 in memory (size: 77.3 KiB, free: 365.6 MiB)
26/01/12 02:05:35 INFO InMemoryFileIndex: It took 27 ms to list leaf files for 1 paths.
26/01/12 02:05:35 INFO BlockManagerInfo: Removed broadcast_47_piece0 on 02926ee04bc9:45221 in memory (size: 77.3 KiB, free: 365.7 MiB)
26/01/12 02:05:35 INFO BlockManagerInfo: Removed broadcast_47_piece0 on 172.18.0.5:42453 in memory (size: 77.3 KiB, free: 365.7 MiB)
26/01/12 02:05:35 INFO BlockManagerInfo: Removed broadcast_43_piece0 on 02926ee04bc9:45221 in memory (size: 35.3 KiB, free: 365.8 MiB)
26/01/12 02:05:35 INFO BlockManagerInfo: Removed broadcast_43_piece0 on 172.18.0.5:42453 in memory (size: 35.3 KiB, free: 365.8 MiB)
26/01/12 02:05:35 INFO BlockManagerInfo: Removed broadcast_42_piece0 on 02926ee04bc9:45221 in memory (size: 36.8 KiB, free: 365.8 MiB)
26/01/12 02:05:35 INFO BlockManagerInfo: Removed broadcast_42_piece0 on 172.18.0.5:42453 in memory (size: 36.8 KiB, free: 365.8 MiB)
26/01/12 02:05:35 INFO BlockManagerInfo: Removed broadcast_48_piece0 on 02926ee04bc9:45221 in memory (size: 36.8 KiB, free: 365.8 MiB)
26/01/12 02:05:35 INFO BlockManagerInfo: Removed broadcast_48_piece0 on 172.18.0.5:42453 in memory (size: 36.8 KiB, free: 365.8 MiB)
26/01/12 02:05:35 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 02:05:35 INFO DAGScheduler: Got job 34 (parquet at <unknown>:0) with 1 output partitions
26/01/12 02:05:35 INFO DAGScheduler: Final stage: ResultStage 34 (parquet at <unknown>:0)
26/01/12 02:05:35 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:05:35 INFO DAGScheduler: Missing parents: List()
26/01/12 02:05:35 INFO DAGScheduler: Submitting ResultStage 34 (MapPartitionsRDD[86] at parquet at <unknown>:0), which has no missing parents
26/01/12 02:05:35 INFO BlockManagerInfo: Removed broadcast_35_piece0 on 02926ee04bc9:45221 in memory (size: 77.2 KiB, free: 365.9 MiB)
26/01/12 02:05:35 INFO BlockManagerInfo: Removed broadcast_35_piece0 on 172.18.0.5:42453 in memory (size: 77.2 KiB, free: 365.9 MiB)
26/01/12 02:05:35 INFO MemoryStore: Block broadcast_51 stored as values in memory (estimated size 102.6 KiB, free 363.4 MiB)
26/01/12 02:05:35 INFO MemoryStore: Block broadcast_51_piece0 stored as bytes in memory (estimated size 36.8 KiB, free 363.4 MiB)
26/01/12 02:05:35 INFO BlockManagerInfo: Removed broadcast_37_piece0 on 02926ee04bc9:45221 in memory (size: 35.2 KiB, free: 365.9 MiB)
26/01/12 02:05:35 INFO BlockManagerInfo: Added broadcast_51_piece0 in memory on 02926ee04bc9:45221 (size: 36.8 KiB, free: 365.9 MiB)
26/01/12 02:05:35 INFO SparkContext: Created broadcast 51 from broadcast at DAGScheduler.scala:1513
26/01/12 02:05:35 INFO BlockManagerInfo: Removed broadcast_37_piece0 on 172.18.0.5:42453 in memory (size: 35.2 KiB, free: 365.9 MiB)
26/01/12 02:05:35 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 34 (MapPartitionsRDD[86] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0))
26/01/12 02:05:35 INFO TaskSchedulerImpl: Adding task set 34.0 with 1 tasks resource profile 0
26/01/12 02:05:35 INFO TaskSetManager: Starting task 0.0 in stage 34.0 (TID 85) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4607 bytes) taskResourceAssignments Map()
26/01/12 02:05:35 INFO BlockManagerInfo: Removed broadcast_34_piece0 on 02926ee04bc9:45221 in memory (size: 35.2 KiB, free: 365.9 MiB)
26/01/12 02:05:35 INFO BlockManagerInfo: Removed broadcast_34_piece0 on 172.18.0.5:42453 in memory (size: 35.2 KiB, free: 366.0 MiB)
26/01/12 02:05:35 INFO BlockManagerInfo: Removed broadcast_46_piece0 on 02926ee04bc9:45221 in memory (size: 35.2 KiB, free: 366.0 MiB)
26/01/12 02:05:35 INFO BlockManagerInfo: Added broadcast_51_piece0 in memory on 172.18.0.5:42453 (size: 36.8 KiB, free: 365.9 MiB)
26/01/12 02:05:35 INFO BlockManagerInfo: Removed broadcast_46_piece0 on 172.18.0.5:42453 in memory (size: 35.2 KiB, free: 366.0 MiB)
26/01/12 02:05:35 INFO BlockManagerInfo: Removed broadcast_38_piece0 on 02926ee04bc9:45221 in memory (size: 77.3 KiB, free: 366.0 MiB)
26/01/12 02:05:35 INFO BlockManagerInfo: Removed broadcast_38_piece0 on 172.18.0.5:42453 in memory (size: 77.3 KiB, free: 366.0 MiB)
26/01/12 02:05:35 INFO BlockManagerInfo: Removed broadcast_40_piece0 on 02926ee04bc9:45221 in memory (size: 35.3 KiB, free: 366.1 MiB)
26/01/12 02:05:35 INFO BlockManagerInfo: Removed broadcast_40_piece0 on 172.18.0.5:42453 in memory (size: 35.3 KiB, free: 366.1 MiB)
26/01/12 02:05:35 INFO BlockManagerInfo: Removed broadcast_50_piece0 on 02926ee04bc9:45221 in memory (size: 77.3 KiB, free: 366.2 MiB)
26/01/12 02:05:35 INFO BlockManagerInfo: Removed broadcast_50_piece0 on 172.18.0.5:42453 in memory (size: 77.3 KiB, free: 366.2 MiB)
26/01/12 02:05:35 INFO BlockManagerInfo: Removed broadcast_41_piece0 on 02926ee04bc9:45221 in memory (size: 77.2 KiB, free: 366.2 MiB)
26/01/12 02:05:35 INFO BlockManagerInfo: Removed broadcast_41_piece0 on 172.18.0.5:42453 in memory (size: 77.2 KiB, free: 366.2 MiB)
26/01/12 02:05:35 INFO TaskSetManager: Finished task 0.0 in stage 34.0 (TID 85) in 74 ms on 172.18.0.5 (executor 0) (1/1)
26/01/12 02:05:35 INFO TaskSchedulerImpl: Removed TaskSet 34.0, whose tasks have all completed, from pool 
26/01/12 02:05:35 INFO DAGScheduler: ResultStage 34 (parquet at <unknown>:0) finished in 0.095 s
26/01/12 02:05:35 INFO DAGScheduler: Job 34 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:05:35 INFO TaskSchedulerImpl: Killing all running tasks in stage 34: Stage finished
26/01/12 02:05:35 INFO DAGScheduler: Job 34 finished: parquet at <unknown>:0, took 0.117997 s
26/01/12 02:05:35 INFO FileSourceStrategy: Pushed Filters: 
26/01/12 02:05:35 INFO FileSourceStrategy: Post-Scan Filters: 
26/01/12 02:05:35 INFO FileSourceStrategy: Output Data Schema: struct<vendor_id: string, pickup_datetime: string, dropoff_datetime: string, passenger_count: bigint, trip_distance: double ... 16 more fields>
26/01/12 02:05:35 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:05:35 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:05:35 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:05:35 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:05:35 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:05:35 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:05:35 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:05:35 INFO MemoryStore: Block broadcast_52 stored as values in memory (estimated size 358.2 KiB, free 365.4 MiB)
26/01/12 02:05:35 INFO MemoryStore: Block broadcast_52_piece0 stored as bytes in memory (estimated size 35.2 KiB, free 365.4 MiB)
26/01/12 02:05:35 INFO BlockManagerInfo: Added broadcast_52_piece0 in memory on 02926ee04bc9:45221 (size: 35.2 KiB, free: 366.2 MiB)
26/01/12 02:05:35 INFO SparkContext: Created broadcast 52 from parquet at <unknown>:0
26/01/12 02:05:35 INFO FileSourceScanExec: Planning scan with bin packing, max size: 134217728 bytes, open cost is considered as scanning 4194304 bytes.
26/01/12 02:05:35 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 02:05:35 INFO DAGScheduler: Got job 35 (parquet at <unknown>:0) with 4 output partitions
26/01/12 02:05:35 INFO DAGScheduler: Final stage: ResultStage 35 (parquet at <unknown>:0)
26/01/12 02:05:35 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:05:35 INFO DAGScheduler: Missing parents: List()
26/01/12 02:05:35 INFO DAGScheduler: Submitting ResultStage 35 (MapPartitionsRDD[89] at parquet at <unknown>:0), which has no missing parents
26/01/12 02:05:35 INFO MemoryStore: Block broadcast_53 stored as values in memory (estimated size 224.3 KiB, free 365.2 MiB)
26/01/12 02:05:35 INFO MemoryStore: Block broadcast_53_piece0 stored as bytes in memory (estimated size 77.3 KiB, free 365.1 MiB)
26/01/12 02:05:35 INFO BlockManagerInfo: Added broadcast_53_piece0 in memory on 02926ee04bc9:45221 (size: 77.3 KiB, free: 366.1 MiB)
26/01/12 02:05:35 INFO SparkContext: Created broadcast 53 from broadcast at DAGScheduler.scala:1513
26/01/12 02:05:35 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 35 (MapPartitionsRDD[89] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
26/01/12 02:05:35 INFO TaskSchedulerImpl: Adding task set 35.0 with 4 tasks resource profile 0
26/01/12 02:05:35 INFO TaskSetManager: Starting task 0.0 in stage 35.0 (TID 86) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:05:35 INFO TaskSetManager: Starting task 1.0 in stage 35.0 (TID 87) (172.18.0.5, executor 0, partition 1, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:05:35 INFO BlockManagerInfo: Added broadcast_53_piece0 in memory on 172.18.0.5:42453 (size: 77.3 KiB, free: 366.2 MiB)
26/01/12 02:05:35 INFO BlockManagerInfo: Added broadcast_52_piece0 in memory on 172.18.0.5:42453 (size: 35.2 KiB, free: 366.1 MiB)
26/01/12 02:05:36 INFO TaskSetManager: Starting task 2.0 in stage 35.0 (TID 88) (172.18.0.5, executor 0, partition 2, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:05:36 INFO TaskSetManager: Finished task 0.0 in stage 35.0 (TID 86) in 551 ms on 172.18.0.5 (executor 0) (1/4)
26/01/12 02:05:36 INFO TaskSetManager: Starting task 3.0 in stage 35.0 (TID 89) (172.18.0.5, executor 0, partition 3, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:05:36 INFO TaskSetManager: Finished task 2.0 in stage 35.0 (TID 88) in 33 ms on 172.18.0.5 (executor 0) (2/4)
26/01/12 02:05:36 INFO TaskSetManager: Finished task 3.0 in stage 35.0 (TID 89) in 31 ms on 172.18.0.5 (executor 0) (3/4)
26/01/12 02:06:28 INFO TaskSetManager: Finished task 1.0 in stage 35.0 (TID 87) in 52819 ms on 172.18.0.5 (executor 0) (4/4)
26/01/12 02:06:28 INFO TaskSchedulerImpl: Removed TaskSet 35.0, whose tasks have all completed, from pool 
26/01/12 02:06:28 INFO DAGScheduler: ResultStage 35 (parquet at <unknown>:0) finished in 52.843 s
26/01/12 02:06:28 INFO DAGScheduler: Job 35 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:06:28 INFO TaskSchedulerImpl: Killing all running tasks in stage 35: Stage finished
26/01/12 02:06:28 INFO DAGScheduler: Job 35 finished: parquet at <unknown>:0, took 52.850082 s
26/01/12 02:06:28 INFO FileFormatWriter: Start to commit write Job aedccdb9-0e85-475b-b2a5-55fe2f4e6793.
26/01/12 02:06:28 INFO FileFormatWriter: Write Job aedccdb9-0e85-475b-b2a5-55fe2f4e6793 committed. Elapsed time: 58 ms.
26/01/12 02:06:28 INFO FileFormatWriter: Finished processing stats for write job aedccdb9-0e85-475b-b2a5-55fe2f4e6793.
Cargando: yellow_tripdata_2010-07.parquet en hdfs://hadoop-namenode:8020/data/nyc/raw/taxi-trips/2010...
26/01/12 02:06:28 INFO InMemoryFileIndex: It took 7 ms to list leaf files for 1 paths.
26/01/12 02:06:28 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 02:06:28 INFO DAGScheduler: Got job 36 (parquet at <unknown>:0) with 1 output partitions
26/01/12 02:06:28 INFO DAGScheduler: Final stage: ResultStage 36 (parquet at <unknown>:0)
26/01/12 02:06:28 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:06:28 INFO DAGScheduler: Missing parents: List()
26/01/12 02:06:28 INFO DAGScheduler: Submitting ResultStage 36 (MapPartitionsRDD[91] at parquet at <unknown>:0), which has no missing parents
26/01/12 02:06:28 INFO MemoryStore: Block broadcast_54 stored as values in memory (estimated size 102.6 KiB, free 365.0 MiB)
26/01/12 02:06:28 INFO MemoryStore: Block broadcast_54_piece0 stored as bytes in memory (estimated size 36.8 KiB, free 365.0 MiB)
26/01/12 02:06:28 INFO BlockManagerInfo: Added broadcast_54_piece0 in memory on 02926ee04bc9:45221 (size: 36.8 KiB, free: 366.1 MiB)
26/01/12 02:06:28 INFO SparkContext: Created broadcast 54 from broadcast at DAGScheduler.scala:1513
26/01/12 02:06:28 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 36 (MapPartitionsRDD[91] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0))
26/01/12 02:06:28 INFO TaskSchedulerImpl: Adding task set 36.0 with 1 tasks resource profile 0
26/01/12 02:06:28 INFO TaskSetManager: Starting task 0.0 in stage 36.0 (TID 90) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4607 bytes) taskResourceAssignments Map()
26/01/12 02:06:28 INFO BlockManagerInfo: Added broadcast_54_piece0 in memory on 172.18.0.5:42453 (size: 36.8 KiB, free: 366.1 MiB)
26/01/12 02:06:28 INFO TaskSetManager: Finished task 0.0 in stage 36.0 (TID 90) in 53 ms on 172.18.0.5 (executor 0) (1/1)
26/01/12 02:06:28 INFO TaskSchedulerImpl: Removed TaskSet 36.0, whose tasks have all completed, from pool 
26/01/12 02:06:28 INFO DAGScheduler: ResultStage 36 (parquet at <unknown>:0) finished in 0.067 s
26/01/12 02:06:28 INFO DAGScheduler: Job 36 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:06:28 INFO TaskSchedulerImpl: Killing all running tasks in stage 36: Stage finished
26/01/12 02:06:28 INFO DAGScheduler: Job 36 finished: parquet at <unknown>:0, took 0.072837 s
26/01/12 02:06:28 INFO FileSourceStrategy: Pushed Filters: 
26/01/12 02:06:28 INFO FileSourceStrategy: Post-Scan Filters: 
26/01/12 02:06:28 INFO FileSourceStrategy: Output Data Schema: struct<vendor_id: string, pickup_datetime: string, dropoff_datetime: string, passenger_count: bigint, trip_distance: double ... 16 more fields>
26/01/12 02:06:28 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:06:28 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:06:28 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:06:28 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:06:28 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:06:28 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:06:28 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:06:28 INFO MemoryStore: Block broadcast_55 stored as values in memory (estimated size 358.2 KiB, free 364.6 MiB)
26/01/12 02:06:28 INFO MemoryStore: Block broadcast_55_piece0 stored as bytes in memory (estimated size 35.2 KiB, free 364.6 MiB)
26/01/12 02:06:28 INFO BlockManagerInfo: Added broadcast_55_piece0 in memory on 02926ee04bc9:45221 (size: 35.2 KiB, free: 366.0 MiB)
26/01/12 02:06:28 INFO SparkContext: Created broadcast 55 from parquet at <unknown>:0
26/01/12 02:06:28 INFO FileSourceScanExec: Planning scan with bin packing, max size: 134217728 bytes, open cost is considered as scanning 4194304 bytes.
26/01/12 02:06:28 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 02:06:28 INFO DAGScheduler: Got job 37 (parquet at <unknown>:0) with 4 output partitions
26/01/12 02:06:28 INFO DAGScheduler: Final stage: ResultStage 37 (parquet at <unknown>:0)
26/01/12 02:06:28 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:06:28 INFO DAGScheduler: Missing parents: List()
26/01/12 02:06:28 INFO DAGScheduler: Submitting ResultStage 37 (MapPartitionsRDD[94] at parquet at <unknown>:0), which has no missing parents
26/01/12 02:06:29 INFO MemoryStore: Block broadcast_56 stored as values in memory (estimated size 224.4 KiB, free 364.4 MiB)
26/01/12 02:06:29 INFO MemoryStore: Block broadcast_56_piece0 stored as bytes in memory (estimated size 77.3 KiB, free 364.3 MiB)
26/01/12 02:06:29 INFO BlockManagerInfo: Added broadcast_56_piece0 in memory on 02926ee04bc9:45221 (size: 77.3 KiB, free: 366.0 MiB)
26/01/12 02:06:29 INFO SparkContext: Created broadcast 56 from broadcast at DAGScheduler.scala:1513
26/01/12 02:06:29 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 37 (MapPartitionsRDD[94] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
26/01/12 02:06:29 INFO TaskSchedulerImpl: Adding task set 37.0 with 4 tasks resource profile 0
26/01/12 02:06:29 INFO TaskSetManager: Starting task 0.0 in stage 37.0 (TID 91) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:06:29 INFO TaskSetManager: Starting task 1.0 in stage 37.0 (TID 92) (172.18.0.5, executor 0, partition 1, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:06:29 INFO BlockManagerInfo: Added broadcast_56_piece0 in memory on 172.18.0.5:42453 (size: 77.3 KiB, free: 366.0 MiB)
26/01/12 02:06:29 INFO BlockManagerInfo: Added broadcast_55_piece0 in memory on 172.18.0.5:42453 (size: 35.2 KiB, free: 366.0 MiB)
26/01/12 02:06:29 INFO TaskSetManager: Starting task 2.0 in stage 37.0 (TID 93) (172.18.0.5, executor 0, partition 2, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:06:29 INFO TaskSetManager: Finished task 0.0 in stage 37.0 (TID 91) in 500 ms on 172.18.0.5 (executor 0) (1/4)
26/01/12 02:06:29 INFO TaskSetManager: Starting task 3.0 in stage 37.0 (TID 94) (172.18.0.5, executor 0, partition 3, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:06:29 INFO TaskSetManager: Finished task 2.0 in stage 37.0 (TID 93) in 37 ms on 172.18.0.5 (executor 0) (2/4)
26/01/12 02:06:29 INFO TaskSetManager: Finished task 3.0 in stage 37.0 (TID 94) in 35 ms on 172.18.0.5 (executor 0) (3/4)
26/01/12 02:07:20 INFO TaskSetManager: Finished task 1.0 in stage 37.0 (TID 92) in 51171 ms on 172.18.0.5 (executor 0) (4/4)
26/01/12 02:07:20 INFO TaskSchedulerImpl: Removed TaskSet 37.0, whose tasks have all completed, from pool 
26/01/12 02:07:20 INFO DAGScheduler: ResultStage 37 (parquet at <unknown>:0) finished in 51.197 s
26/01/12 02:07:20 INFO DAGScheduler: Job 37 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:07:20 INFO TaskSchedulerImpl: Killing all running tasks in stage 37: Stage finished
26/01/12 02:07:20 INFO DAGScheduler: Job 37 finished: parquet at <unknown>:0, took 51.206404 s
26/01/12 02:07:20 INFO FileFormatWriter: Start to commit write Job e7f2fc39-e21d-441d-8e02-8ea8c8daaa1e.
26/01/12 02:07:20 INFO FileFormatWriter: Write Job e7f2fc39-e21d-441d-8e02-8ea8c8daaa1e committed. Elapsed time: 43 ms.
26/01/12 02:07:20 INFO FileFormatWriter: Finished processing stats for write job e7f2fc39-e21d-441d-8e02-8ea8c8daaa1e.
Cargando: yellow_tripdata_2010-08.parquet en hdfs://hadoop-namenode:8020/data/nyc/raw/taxi-trips/2010...
26/01/12 02:07:20 INFO InMemoryFileIndex: It took 8 ms to list leaf files for 1 paths.
26/01/12 02:07:20 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 02:07:20 INFO DAGScheduler: Got job 38 (parquet at <unknown>:0) with 1 output partitions
26/01/12 02:07:20 INFO DAGScheduler: Final stage: ResultStage 38 (parquet at <unknown>:0)
26/01/12 02:07:20 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:07:20 INFO DAGScheduler: Missing parents: List()
26/01/12 02:07:20 INFO DAGScheduler: Submitting ResultStage 38 (MapPartitionsRDD[96] at parquet at <unknown>:0), which has no missing parents
26/01/12 02:07:20 INFO MemoryStore: Block broadcast_57 stored as values in memory (estimated size 102.6 KiB, free 364.2 MiB)
26/01/12 02:07:20 INFO MemoryStore: Block broadcast_57_piece0 stored as bytes in memory (estimated size 36.8 KiB, free 364.1 MiB)
26/01/12 02:07:20 INFO BlockManagerInfo: Added broadcast_57_piece0 in memory on 02926ee04bc9:45221 (size: 36.8 KiB, free: 365.9 MiB)
26/01/12 02:07:20 INFO SparkContext: Created broadcast 57 from broadcast at DAGScheduler.scala:1513
26/01/12 02:07:20 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 38 (MapPartitionsRDD[96] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0))
26/01/12 02:07:20 INFO TaskSchedulerImpl: Adding task set 38.0 with 1 tasks resource profile 0
26/01/12 02:07:20 INFO TaskSetManager: Starting task 0.0 in stage 38.0 (TID 95) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4607 bytes) taskResourceAssignments Map()
26/01/12 02:07:20 INFO BlockManagerInfo: Added broadcast_57_piece0 in memory on 172.18.0.5:42453 (size: 36.8 KiB, free: 365.9 MiB)
26/01/12 02:07:20 INFO TaskSetManager: Finished task 0.0 in stage 38.0 (TID 95) in 48 ms on 172.18.0.5 (executor 0) (1/1)
26/01/12 02:07:20 INFO TaskSchedulerImpl: Removed TaskSet 38.0, whose tasks have all completed, from pool 
26/01/12 02:07:20 INFO DAGScheduler: ResultStage 38 (parquet at <unknown>:0) finished in 0.064 s
26/01/12 02:07:20 INFO DAGScheduler: Job 38 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:07:20 INFO TaskSchedulerImpl: Killing all running tasks in stage 38: Stage finished
26/01/12 02:07:20 INFO DAGScheduler: Job 38 finished: parquet at <unknown>:0, took 0.068831 s
26/01/12 02:07:20 INFO FileSourceStrategy: Pushed Filters: 
26/01/12 02:07:20 INFO FileSourceStrategy: Post-Scan Filters: 
26/01/12 02:07:20 INFO FileSourceStrategy: Output Data Schema: struct<vendor_id: string, pickup_datetime: string, dropoff_datetime: string, passenger_count: bigint, trip_distance: double ... 16 more fields>
26/01/12 02:07:20 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:07:20 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:07:20 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:07:20 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:07:20 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:07:20 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:07:20 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:07:20 INFO MemoryStore: Block broadcast_58 stored as values in memory (estimated size 358.2 KiB, free 363.8 MiB)
26/01/12 02:07:20 INFO MemoryStore: Block broadcast_58_piece0 stored as bytes in memory (estimated size 35.2 KiB, free 363.8 MiB)
26/01/12 02:07:20 INFO BlockManagerInfo: Added broadcast_58_piece0 in memory on 02926ee04bc9:45221 (size: 35.2 KiB, free: 365.9 MiB)
26/01/12 02:07:20 INFO SparkContext: Created broadcast 58 from parquet at <unknown>:0
26/01/12 02:07:20 INFO FileSourceScanExec: Planning scan with bin packing, max size: 134217728 bytes, open cost is considered as scanning 4194304 bytes.
26/01/12 02:07:20 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 02:07:20 INFO DAGScheduler: Got job 39 (parquet at <unknown>:0) with 3 output partitions
26/01/12 02:07:20 INFO DAGScheduler: Final stage: ResultStage 39 (parquet at <unknown>:0)
26/01/12 02:07:20 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:07:20 INFO DAGScheduler: Missing parents: List()
26/01/12 02:07:20 INFO DAGScheduler: Submitting ResultStage 39 (MapPartitionsRDD[99] at parquet at <unknown>:0), which has no missing parents
26/01/12 02:07:20 INFO MemoryStore: Block broadcast_59 stored as values in memory (estimated size 224.4 KiB, free 363.5 MiB)
26/01/12 02:07:20 INFO MemoryStore: Block broadcast_59_piece0 stored as bytes in memory (estimated size 77.3 KiB, free 363.5 MiB)
26/01/12 02:07:20 INFO BlockManagerInfo: Added broadcast_59_piece0 in memory on 02926ee04bc9:45221 (size: 77.3 KiB, free: 365.8 MiB)
26/01/12 02:07:20 INFO SparkContext: Created broadcast 59 from broadcast at DAGScheduler.scala:1513
26/01/12 02:07:20 INFO DAGScheduler: Submitting 3 missing tasks from ResultStage 39 (MapPartitionsRDD[99] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1, 2))
26/01/12 02:07:20 INFO TaskSchedulerImpl: Adding task set 39.0 with 3 tasks resource profile 0
26/01/12 02:07:20 INFO TaskSetManager: Starting task 0.0 in stage 39.0 (TID 96) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:07:20 INFO TaskSetManager: Starting task 1.0 in stage 39.0 (TID 97) (172.18.0.5, executor 0, partition 1, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:07:20 INFO BlockManagerInfo: Added broadcast_59_piece0 in memory on 172.18.0.5:42453 (size: 77.3 KiB, free: 365.9 MiB)
26/01/12 02:07:20 INFO BlockManagerInfo: Added broadcast_58_piece0 in memory on 172.18.0.5:42453 (size: 35.2 KiB, free: 365.8 MiB)
26/01/12 02:07:20 INFO TaskSetManager: Starting task 2.0 in stage 39.0 (TID 98) (172.18.0.5, executor 0, partition 2, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:07:20 INFO TaskSetManager: Finished task 0.0 in stage 39.0 (TID 96) in 191 ms on 172.18.0.5 (executor 0) (1/3)
26/01/12 02:07:20 INFO TaskSetManager: Finished task 2.0 in stage 39.0 (TID 98) in 29 ms on 172.18.0.5 (executor 0) (2/3)
26/01/12 02:08:02 INFO TaskSetManager: Finished task 1.0 in stage 39.0 (TID 97) in 42005 ms on 172.18.0.5 (executor 0) (3/3)
26/01/12 02:08:02 INFO TaskSchedulerImpl: Removed TaskSet 39.0, whose tasks have all completed, from pool 
26/01/12 02:08:02 INFO DAGScheduler: ResultStage 39 (parquet at <unknown>:0) finished in 42.030 s
26/01/12 02:08:02 INFO DAGScheduler: Job 39 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:08:02 INFO TaskSchedulerImpl: Killing all running tasks in stage 39: Stage finished
26/01/12 02:08:02 INFO DAGScheduler: Job 39 finished: parquet at <unknown>:0, took 42.040952 s
26/01/12 02:08:02 INFO FileFormatWriter: Start to commit write Job 0b1ff9ae-47a3-414c-b413-3830d93d3b64.
26/01/12 02:08:02 INFO FileFormatWriter: Write Job 0b1ff9ae-47a3-414c-b413-3830d93d3b64 committed. Elapsed time: 43 ms.
26/01/12 02:08:02 INFO FileFormatWriter: Finished processing stats for write job 0b1ff9ae-47a3-414c-b413-3830d93d3b64.
Cargando: yellow_tripdata_2010-09.parquet en hdfs://hadoop-namenode:8020/data/nyc/raw/taxi-trips/2010...
26/01/12 02:08:02 INFO InMemoryFileIndex: It took 6 ms to list leaf files for 1 paths.
26/01/12 02:08:02 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 02:08:02 INFO DAGScheduler: Got job 40 (parquet at <unknown>:0) with 1 output partitions
26/01/12 02:08:02 INFO DAGScheduler: Final stage: ResultStage 40 (parquet at <unknown>:0)
26/01/12 02:08:02 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:08:02 INFO DAGScheduler: Missing parents: List()
26/01/12 02:08:02 INFO DAGScheduler: Submitting ResultStage 40 (MapPartitionsRDD[101] at parquet at <unknown>:0), which has no missing parents
26/01/12 02:08:02 INFO MemoryStore: Block broadcast_60 stored as values in memory (estimated size 102.6 KiB, free 363.4 MiB)
26/01/12 02:08:02 INFO MemoryStore: Block broadcast_60_piece0 stored as bytes in memory (estimated size 36.8 KiB, free 363.3 MiB)
26/01/12 02:08:02 INFO BlockManagerInfo: Added broadcast_60_piece0 in memory on 02926ee04bc9:45221 (size: 36.8 KiB, free: 365.8 MiB)
26/01/12 02:08:02 INFO SparkContext: Created broadcast 60 from broadcast at DAGScheduler.scala:1513
26/01/12 02:08:02 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 40 (MapPartitionsRDD[101] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0))
26/01/12 02:08:02 INFO TaskSchedulerImpl: Adding task set 40.0 with 1 tasks resource profile 0
26/01/12 02:08:02 INFO TaskSetManager: Starting task 0.0 in stage 40.0 (TID 99) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4607 bytes) taskResourceAssignments Map()
26/01/12 02:08:02 INFO BlockManagerInfo: Added broadcast_60_piece0 in memory on 172.18.0.5:42453 (size: 36.8 KiB, free: 365.8 MiB)
26/01/12 02:08:02 INFO TaskSetManager: Finished task 0.0 in stage 40.0 (TID 99) in 69 ms on 172.18.0.5 (executor 0) (1/1)
26/01/12 02:08:02 INFO TaskSchedulerImpl: Removed TaskSet 40.0, whose tasks have all completed, from pool 
26/01/12 02:08:02 INFO DAGScheduler: ResultStage 40 (parquet at <unknown>:0) finished in 0.084 s
26/01/12 02:08:02 INFO DAGScheduler: Job 40 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:08:02 INFO TaskSchedulerImpl: Killing all running tasks in stage 40: Stage finished
26/01/12 02:08:02 INFO DAGScheduler: Job 40 finished: parquet at <unknown>:0, took 0.089145 s
26/01/12 02:08:02 INFO FileSourceStrategy: Pushed Filters: 
26/01/12 02:08:02 INFO FileSourceStrategy: Post-Scan Filters: 
26/01/12 02:08:02 INFO FileSourceStrategy: Output Data Schema: struct<vendor_id: string, pickup_datetime: string, dropoff_datetime: string, passenger_count: bigint, trip_distance: double ... 16 more fields>
26/01/12 02:08:02 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:08:02 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:08:02 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:08:02 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:08:02 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:08:02 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:08:02 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:08:02 INFO MemoryStore: Block broadcast_61 stored as values in memory (estimated size 358.2 KiB, free 363.0 MiB)
26/01/12 02:08:02 INFO MemoryStore: Block broadcast_61_piece0 stored as bytes in memory (estimated size 35.2 KiB, free 363.0 MiB)
26/01/12 02:08:02 INFO BlockManagerInfo: Added broadcast_61_piece0 in memory on 02926ee04bc9:45221 (size: 35.2 KiB, free: 365.8 MiB)
26/01/12 02:08:02 INFO SparkContext: Created broadcast 61 from parquet at <unknown>:0
26/01/12 02:08:02 INFO FileSourceScanExec: Planning scan with bin packing, max size: 134217728 bytes, open cost is considered as scanning 4194304 bytes.
26/01/12 02:08:02 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 02:08:02 INFO DAGScheduler: Got job 41 (parquet at <unknown>:0) with 4 output partitions
26/01/12 02:08:02 INFO DAGScheduler: Final stage: ResultStage 41 (parquet at <unknown>:0)
26/01/12 02:08:02 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:08:02 INFO DAGScheduler: Missing parents: List()
26/01/12 02:08:02 INFO DAGScheduler: Submitting ResultStage 41 (MapPartitionsRDD[104] at parquet at <unknown>:0), which has no missing parents
26/01/12 02:08:02 INFO MemoryStore: Block broadcast_62 stored as values in memory (estimated size 224.4 KiB, free 362.7 MiB)
26/01/12 02:08:02 INFO MemoryStore: Block broadcast_62_piece0 stored as bytes in memory (estimated size 77.3 KiB, free 362.7 MiB)
26/01/12 02:08:02 INFO BlockManagerInfo: Added broadcast_62_piece0 in memory on 02926ee04bc9:45221 (size: 77.3 KiB, free: 365.7 MiB)
26/01/12 02:08:02 INFO SparkContext: Created broadcast 62 from broadcast at DAGScheduler.scala:1513
26/01/12 02:08:02 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 41 (MapPartitionsRDD[104] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
26/01/12 02:08:02 INFO TaskSchedulerImpl: Adding task set 41.0 with 4 tasks resource profile 0
26/01/12 02:08:02 INFO TaskSetManager: Starting task 0.0 in stage 41.0 (TID 100) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:08:02 INFO TaskSetManager: Starting task 1.0 in stage 41.0 (TID 101) (172.18.0.5, executor 0, partition 1, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:08:02 INFO BlockManagerInfo: Added broadcast_62_piece0 in memory on 172.18.0.5:42453 (size: 77.3 KiB, free: 365.7 MiB)
26/01/12 02:08:02 INFO BlockManagerInfo: Added broadcast_61_piece0 in memory on 172.18.0.5:42453 (size: 35.2 KiB, free: 365.7 MiB)
26/01/12 02:08:03 INFO TaskSetManager: Starting task 2.0 in stage 41.0 (TID 102) (172.18.0.5, executor 0, partition 2, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:08:03 INFO TaskSetManager: Finished task 0.0 in stage 41.0 (TID 100) in 510 ms on 172.18.0.5 (executor 0) (1/4)
26/01/12 02:08:03 INFO TaskSetManager: Starting task 3.0 in stage 41.0 (TID 103) (172.18.0.5, executor 0, partition 3, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:08:03 INFO TaskSetManager: Finished task 2.0 in stage 41.0 (TID 102) in 31 ms on 172.18.0.5 (executor 0) (2/4)
26/01/12 02:08:03 INFO TaskSetManager: Finished task 3.0 in stage 41.0 (TID 103) in 142 ms on 172.18.0.5 (executor 0) (3/4)
26/01/12 02:08:56 INFO TaskSetManager: Finished task 1.0 in stage 41.0 (TID 101) in 53686 ms on 172.18.0.5 (executor 0) (4/4)
26/01/12 02:08:56 INFO TaskSchedulerImpl: Removed TaskSet 41.0, whose tasks have all completed, from pool 
26/01/12 02:08:56 INFO DAGScheduler: ResultStage 41 (parquet at <unknown>:0) finished in 53.709 s
26/01/12 02:08:56 INFO DAGScheduler: Job 41 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:08:56 INFO TaskSchedulerImpl: Killing all running tasks in stage 41: Stage finished
26/01/12 02:08:56 INFO DAGScheduler: Job 41 finished: parquet at <unknown>:0, took 53.718397 s
26/01/12 02:08:56 INFO FileFormatWriter: Start to commit write Job 552aa9d8-793a-4263-95d4-a382a2fd260c.
26/01/12 02:08:56 INFO FileFormatWriter: Write Job 552aa9d8-793a-4263-95d4-a382a2fd260c committed. Elapsed time: 36 ms.
26/01/12 02:08:56 INFO FileFormatWriter: Finished processing stats for write job 552aa9d8-793a-4263-95d4-a382a2fd260c.
Cargando: yellow_tripdata_2010-10.parquet en hdfs://hadoop-namenode:8020/data/nyc/raw/taxi-trips/2010...
26/01/12 02:08:56 INFO InMemoryFileIndex: It took 7 ms to list leaf files for 1 paths.
26/01/12 02:08:56 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 02:08:56 INFO DAGScheduler: Got job 42 (parquet at <unknown>:0) with 1 output partitions
26/01/12 02:08:56 INFO DAGScheduler: Final stage: ResultStage 42 (parquet at <unknown>:0)
26/01/12 02:08:56 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:08:56 INFO DAGScheduler: Missing parents: List()
26/01/12 02:08:56 INFO DAGScheduler: Submitting ResultStage 42 (MapPartitionsRDD[106] at parquet at <unknown>:0), which has no missing parents
26/01/12 02:08:56 INFO MemoryStore: Block broadcast_63 stored as values in memory (estimated size 102.6 KiB, free 362.6 MiB)
26/01/12 02:08:56 INFO MemoryStore: Block broadcast_63_piece0 stored as bytes in memory (estimated size 36.8 KiB, free 362.5 MiB)
26/01/12 02:08:56 INFO BlockManagerInfo: Added broadcast_63_piece0 in memory on 02926ee04bc9:45221 (size: 36.8 KiB, free: 365.6 MiB)
26/01/12 02:08:56 INFO SparkContext: Created broadcast 63 from broadcast at DAGScheduler.scala:1513
26/01/12 02:08:56 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 42 (MapPartitionsRDD[106] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0))
26/01/12 02:08:56 INFO TaskSchedulerImpl: Adding task set 42.0 with 1 tasks resource profile 0
26/01/12 02:08:56 INFO TaskSetManager: Starting task 0.0 in stage 42.0 (TID 104) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4607 bytes) taskResourceAssignments Map()
26/01/12 02:08:56 INFO BlockManagerInfo: Added broadcast_63_piece0 in memory on 172.18.0.5:42453 (size: 36.8 KiB, free: 365.6 MiB)
26/01/12 02:08:56 INFO TaskSetManager: Finished task 0.0 in stage 42.0 (TID 104) in 57 ms on 172.18.0.5 (executor 0) (1/1)
26/01/12 02:08:56 INFO TaskSchedulerImpl: Removed TaskSet 42.0, whose tasks have all completed, from pool 
26/01/12 02:08:56 INFO DAGScheduler: ResultStage 42 (parquet at <unknown>:0) finished in 0.073 s
26/01/12 02:08:56 INFO DAGScheduler: Job 42 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:08:56 INFO TaskSchedulerImpl: Killing all running tasks in stage 42: Stage finished
26/01/12 02:08:56 INFO DAGScheduler: Job 42 finished: parquet at <unknown>:0, took 0.078879 s
26/01/12 02:08:56 INFO FileSourceStrategy: Pushed Filters: 
26/01/12 02:08:56 INFO FileSourceStrategy: Post-Scan Filters: 
26/01/12 02:08:56 INFO FileSourceStrategy: Output Data Schema: struct<vendor_id: string, pickup_datetime: string, dropoff_datetime: string, passenger_count: bigint, trip_distance: double ... 16 more fields>
26/01/12 02:08:56 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:08:56 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:08:56 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:08:56 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:08:56 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:08:56 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:08:56 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:08:56 INFO MemoryStore: Block broadcast_64 stored as values in memory (estimated size 358.2 KiB, free 362.2 MiB)
26/01/12 02:08:56 INFO MemoryStore: Block broadcast_64_piece0 stored as bytes in memory (estimated size 35.2 KiB, free 362.1 MiB)
26/01/12 02:08:56 INFO BlockManagerInfo: Added broadcast_64_piece0 in memory on 02926ee04bc9:45221 (size: 35.2 KiB, free: 365.6 MiB)
26/01/12 02:08:56 INFO SparkContext: Created broadcast 64 from parquet at <unknown>:0
26/01/12 02:08:56 INFO FileSourceScanExec: Planning scan with bin packing, max size: 134217728 bytes, open cost is considered as scanning 4194304 bytes.
26/01/12 02:08:56 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 02:08:56 INFO DAGScheduler: Got job 43 (parquet at <unknown>:0) with 4 output partitions
26/01/12 02:08:56 INFO DAGScheduler: Final stage: ResultStage 43 (parquet at <unknown>:0)
26/01/12 02:08:56 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:08:56 INFO DAGScheduler: Missing parents: List()
26/01/12 02:08:56 INFO DAGScheduler: Submitting ResultStage 43 (MapPartitionsRDD[109] at parquet at <unknown>:0), which has no missing parents
26/01/12 02:08:56 INFO MemoryStore: Block broadcast_65 stored as values in memory (estimated size 224.3 KiB, free 361.9 MiB)
26/01/12 02:08:56 INFO MemoryStore: Block broadcast_65_piece0 stored as bytes in memory (estimated size 77.2 KiB, free 361.8 MiB)
26/01/12 02:08:56 INFO BlockManagerInfo: Added broadcast_65_piece0 in memory on 02926ee04bc9:45221 (size: 77.2 KiB, free: 365.5 MiB)
26/01/12 02:08:56 INFO SparkContext: Created broadcast 65 from broadcast at DAGScheduler.scala:1513
26/01/12 02:08:56 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 43 (MapPartitionsRDD[109] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
26/01/12 02:08:56 INFO TaskSchedulerImpl: Adding task set 43.0 with 4 tasks resource profile 0
26/01/12 02:08:56 INFO TaskSetManager: Starting task 0.0 in stage 43.0 (TID 105) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:08:56 INFO TaskSetManager: Starting task 1.0 in stage 43.0 (TID 106) (172.18.0.5, executor 0, partition 1, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:08:56 INFO BlockManagerInfo: Added broadcast_65_piece0 in memory on 172.18.0.5:42453 (size: 77.2 KiB, free: 365.6 MiB)
26/01/12 02:08:56 INFO BlockManagerInfo: Added broadcast_64_piece0 in memory on 172.18.0.5:42453 (size: 35.2 KiB, free: 365.5 MiB)
26/01/12 02:08:57 INFO TaskSetManager: Starting task 2.0 in stage 43.0 (TID 107) (172.18.0.5, executor 0, partition 2, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:08:57 INFO TaskSetManager: Finished task 0.0 in stage 43.0 (TID 105) in 493 ms on 172.18.0.5 (executor 0) (1/4)
26/01/12 02:08:57 INFO TaskSetManager: Starting task 3.0 in stage 43.0 (TID 108) (172.18.0.5, executor 0, partition 3, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:08:57 INFO TaskSetManager: Finished task 2.0 in stage 43.0 (TID 107) in 34 ms on 172.18.0.5 (executor 0) (2/4)
26/01/12 02:08:57 INFO TaskSetManager: Finished task 3.0 in stage 43.0 (TID 108) in 33 ms on 172.18.0.5 (executor 0) (3/4)
26/01/12 02:09:44 INFO TaskSetManager: Finished task 1.0 in stage 43.0 (TID 106) in 47425 ms on 172.18.0.5 (executor 0) (4/4)
26/01/12 02:09:44 INFO TaskSchedulerImpl: Removed TaskSet 43.0, whose tasks have all completed, from pool 
26/01/12 02:09:44 INFO DAGScheduler: ResultStage 43 (parquet at <unknown>:0) finished in 47.447 s
26/01/12 02:09:44 INFO DAGScheduler: Job 43 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:09:44 INFO TaskSchedulerImpl: Killing all running tasks in stage 43: Stage finished
26/01/12 02:09:44 INFO DAGScheduler: Job 43 finished: parquet at <unknown>:0, took 47.456834 s
26/01/12 02:09:44 INFO FileFormatWriter: Start to commit write Job 9f7be9dd-3ad1-40b9-8c25-e75e8d196492.
26/01/12 02:09:44 INFO FileFormatWriter: Write Job 9f7be9dd-3ad1-40b9-8c25-e75e8d196492 committed. Elapsed time: 48 ms.
26/01/12 02:09:44 INFO FileFormatWriter: Finished processing stats for write job 9f7be9dd-3ad1-40b9-8c25-e75e8d196492.
Cargando: yellow_tripdata_2010-11.parquet en hdfs://hadoop-namenode:8020/data/nyc/raw/taxi-trips/2010...
26/01/12 02:09:44 INFO InMemoryFileIndex: It took 7 ms to list leaf files for 1 paths.
26/01/12 02:09:44 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 02:09:44 INFO DAGScheduler: Got job 44 (parquet at <unknown>:0) with 1 output partitions
26/01/12 02:09:44 INFO DAGScheduler: Final stage: ResultStage 44 (parquet at <unknown>:0)
26/01/12 02:09:44 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:09:44 INFO DAGScheduler: Missing parents: List()
26/01/12 02:09:44 INFO DAGScheduler: Submitting ResultStage 44 (MapPartitionsRDD[111] at parquet at <unknown>:0), which has no missing parents
26/01/12 02:09:44 INFO MemoryStore: Block broadcast_66 stored as values in memory (estimated size 102.6 KiB, free 361.7 MiB)
26/01/12 02:09:44 INFO MemoryStore: Block broadcast_66_piece0 stored as bytes in memory (estimated size 36.8 KiB, free 361.7 MiB)
26/01/12 02:09:44 INFO BlockManagerInfo: Added broadcast_66_piece0 in memory on 02926ee04bc9:45221 (size: 36.8 KiB, free: 365.5 MiB)
26/01/12 02:09:44 INFO SparkContext: Created broadcast 66 from broadcast at DAGScheduler.scala:1513
26/01/12 02:09:44 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 44 (MapPartitionsRDD[111] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0))
26/01/12 02:09:44 INFO TaskSchedulerImpl: Adding task set 44.0 with 1 tasks resource profile 0
26/01/12 02:09:44 INFO TaskSetManager: Starting task 0.0 in stage 44.0 (TID 109) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4607 bytes) taskResourceAssignments Map()
26/01/12 02:09:44 INFO BlockManagerInfo: Added broadcast_66_piece0 in memory on 172.18.0.5:42453 (size: 36.8 KiB, free: 365.5 MiB)
26/01/12 02:09:44 INFO TaskSetManager: Finished task 0.0 in stage 44.0 (TID 109) in 49 ms on 172.18.0.5 (executor 0) (1/1)
26/01/12 02:09:44 INFO TaskSchedulerImpl: Removed TaskSet 44.0, whose tasks have all completed, from pool 
26/01/12 02:09:44 INFO DAGScheduler: ResultStage 44 (parquet at <unknown>:0) finished in 0.063 s
26/01/12 02:09:44 INFO DAGScheduler: Job 44 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:09:44 INFO TaskSchedulerImpl: Killing all running tasks in stage 44: Stage finished
26/01/12 02:09:44 INFO DAGScheduler: Job 44 finished: parquet at <unknown>:0, took 0.067957 s
26/01/12 02:09:44 INFO FileSourceStrategy: Pushed Filters: 
26/01/12 02:09:44 INFO FileSourceStrategy: Post-Scan Filters: 
26/01/12 02:09:44 INFO FileSourceStrategy: Output Data Schema: struct<vendor_id: string, pickup_datetime: string, dropoff_datetime: string, passenger_count: bigint, trip_distance: double ... 16 more fields>
26/01/12 02:09:44 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:09:44 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:09:44 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:09:44 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:09:44 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:09:44 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:09:44 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:09:44 INFO MemoryStore: Block broadcast_67 stored as values in memory (estimated size 358.2 KiB, free 361.4 MiB)
26/01/12 02:09:44 INFO MemoryStore: Block broadcast_67_piece0 stored as bytes in memory (estimated size 35.2 KiB, free 361.3 MiB)
26/01/12 02:09:44 INFO BlockManagerInfo: Added broadcast_67_piece0 in memory on 02926ee04bc9:45221 (size: 35.2 KiB, free: 365.5 MiB)
26/01/12 02:09:44 INFO SparkContext: Created broadcast 67 from parquet at <unknown>:0
26/01/12 02:09:44 INFO FileSourceScanExec: Planning scan with bin packing, max size: 134217728 bytes, open cost is considered as scanning 4194304 bytes.
26/01/12 02:09:44 INFO BlockManagerInfo: Removed broadcast_64_piece0 on 02926ee04bc9:45221 in memory (size: 35.2 KiB, free: 365.5 MiB)
26/01/12 02:09:44 INFO BlockManagerInfo: Removed broadcast_64_piece0 on 172.18.0.5:42453 in memory (size: 35.2 KiB, free: 365.5 MiB)
26/01/12 02:09:44 INFO BlockManagerInfo: Removed broadcast_63_piece0 on 02926ee04bc9:45221 in memory (size: 36.8 KiB, free: 365.5 MiB)
26/01/12 02:09:44 INFO BlockManagerInfo: Removed broadcast_63_piece0 on 172.18.0.5:42453 in memory (size: 36.8 KiB, free: 365.6 MiB)
26/01/12 02:09:44 INFO BlockManagerInfo: Removed broadcast_57_piece0 on 02926ee04bc9:45221 in memory (size: 36.8 KiB, free: 365.6 MiB)
26/01/12 02:09:44 INFO BlockManagerInfo: Removed broadcast_57_piece0 on 172.18.0.5:42453 in memory (size: 36.8 KiB, free: 365.6 MiB)
26/01/12 02:09:44 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 02:09:44 INFO DAGScheduler: Got job 45 (parquet at <unknown>:0) with 4 output partitions
26/01/12 02:09:44 INFO DAGScheduler: Final stage: ResultStage 45 (parquet at <unknown>:0)
26/01/12 02:09:44 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:09:44 INFO DAGScheduler: Missing parents: List()
26/01/12 02:09:44 INFO BlockManagerInfo: Removed broadcast_51_piece0 on 02926ee04bc9:45221 in memory (size: 36.8 KiB, free: 365.6 MiB)
26/01/12 02:09:44 INFO DAGScheduler: Submitting ResultStage 45 (MapPartitionsRDD[114] at parquet at <unknown>:0), which has no missing parents
26/01/12 02:09:44 INFO BlockManagerInfo: Removed broadcast_51_piece0 on 172.18.0.5:42453 in memory (size: 36.8 KiB, free: 365.6 MiB)
26/01/12 02:09:44 INFO BlockManagerInfo: Removed broadcast_65_piece0 on 02926ee04bc9:45221 in memory (size: 77.2 KiB, free: 365.7 MiB)
26/01/12 02:09:44 INFO BlockManagerInfo: Removed broadcast_65_piece0 on 172.18.0.5:42453 in memory (size: 77.2 KiB, free: 365.7 MiB)
26/01/12 02:09:44 INFO BlockManagerInfo: Removed broadcast_60_piece0 on 02926ee04bc9:45221 in memory (size: 36.8 KiB, free: 365.7 MiB)
26/01/12 02:09:44 INFO MemoryStore: Block broadcast_68 stored as values in memory (estimated size 224.4 KiB, free 362.3 MiB)
26/01/12 02:09:44 INFO BlockManagerInfo: Removed broadcast_60_piece0 on 172.18.0.5:42453 in memory (size: 36.8 KiB, free: 365.8 MiB)
26/01/12 02:09:44 INFO MemoryStore: Block broadcast_68_piece0 stored as bytes in memory (estimated size 77.3 KiB, free 362.2 MiB)
26/01/12 02:09:44 INFO BlockManagerInfo: Added broadcast_68_piece0 in memory on 02926ee04bc9:45221 (size: 77.3 KiB, free: 365.6 MiB)
26/01/12 02:09:44 INFO BlockManagerInfo: Removed broadcast_49_piece0 on 02926ee04bc9:45221 in memory (size: 35.2 KiB, free: 365.7 MiB)
26/01/12 02:09:44 INFO SparkContext: Created broadcast 68 from broadcast at DAGScheduler.scala:1513
26/01/12 02:09:44 INFO BlockManagerInfo: Removed broadcast_49_piece0 on 172.18.0.5:42453 in memory (size: 35.2 KiB, free: 365.8 MiB)
26/01/12 02:09:44 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 45 (MapPartitionsRDD[114] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
26/01/12 02:09:44 INFO TaskSchedulerImpl: Adding task set 45.0 with 4 tasks resource profile 0
26/01/12 02:09:44 INFO TaskSetManager: Starting task 0.0 in stage 45.0 (TID 110) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:09:44 INFO TaskSetManager: Starting task 1.0 in stage 45.0 (TID 111) (172.18.0.5, executor 0, partition 1, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:09:44 INFO BlockManagerInfo: Removed broadcast_58_piece0 on 02926ee04bc9:45221 in memory (size: 35.2 KiB, free: 365.7 MiB)
26/01/12 02:09:44 INFO BlockManagerInfo: Removed broadcast_58_piece0 on 172.18.0.5:42453 in memory (size: 35.2 KiB, free: 365.8 MiB)
26/01/12 02:09:44 INFO BlockManagerInfo: Removed broadcast_56_piece0 on 02926ee04bc9:45221 in memory (size: 77.3 KiB, free: 365.8 MiB)
26/01/12 02:09:44 INFO BlockManagerInfo: Added broadcast_68_piece0 in memory on 172.18.0.5:42453 (size: 77.3 KiB, free: 365.7 MiB)
26/01/12 02:09:44 INFO BlockManagerInfo: Removed broadcast_56_piece0 on 172.18.0.5:42453 in memory (size: 77.3 KiB, free: 365.8 MiB)
26/01/12 02:09:44 INFO BlockManagerInfo: Removed broadcast_61_piece0 on 02926ee04bc9:45221 in memory (size: 35.2 KiB, free: 365.8 MiB)
26/01/12 02:09:44 INFO BlockManagerInfo: Removed broadcast_61_piece0 on 172.18.0.5:42453 in memory (size: 35.2 KiB, free: 365.9 MiB)
26/01/12 02:09:44 INFO BlockManagerInfo: Removed broadcast_52_piece0 on 02926ee04bc9:45221 in memory (size: 35.2 KiB, free: 365.9 MiB)
26/01/12 02:09:44 INFO BlockManagerInfo: Removed broadcast_52_piece0 on 172.18.0.5:42453 in memory (size: 35.2 KiB, free: 365.9 MiB)
26/01/12 02:09:44 INFO BlockManagerInfo: Removed broadcast_66_piece0 on 02926ee04bc9:45221 in memory (size: 36.8 KiB, free: 365.9 MiB)
26/01/12 02:09:44 INFO BlockManagerInfo: Added broadcast_67_piece0 in memory on 172.18.0.5:42453 (size: 35.2 KiB, free: 365.9 MiB)
26/01/12 02:09:44 INFO BlockManagerInfo: Removed broadcast_66_piece0 on 172.18.0.5:42453 in memory (size: 36.8 KiB, free: 365.9 MiB)
26/01/12 02:09:44 INFO BlockManagerInfo: Removed broadcast_53_piece0 on 02926ee04bc9:45221 in memory (size: 77.3 KiB, free: 366.0 MiB)
26/01/12 02:09:44 INFO BlockManagerInfo: Removed broadcast_53_piece0 on 172.18.0.5:42453 in memory (size: 77.3 KiB, free: 366.0 MiB)
26/01/12 02:09:44 INFO BlockManagerInfo: Removed broadcast_59_piece0 on 02926ee04bc9:45221 in memory (size: 77.3 KiB, free: 366.0 MiB)
26/01/12 02:09:44 INFO BlockManagerInfo: Removed broadcast_59_piece0 on 172.18.0.5:42453 in memory (size: 77.3 KiB, free: 366.0 MiB)
26/01/12 02:09:44 INFO BlockManagerInfo: Removed broadcast_54_piece0 on 02926ee04bc9:45221 in memory (size: 36.8 KiB, free: 366.1 MiB)
26/01/12 02:09:44 INFO BlockManagerInfo: Removed broadcast_54_piece0 on 172.18.0.5:42453 in memory (size: 36.8 KiB, free: 366.1 MiB)
26/01/12 02:09:44 INFO BlockManagerInfo: Removed broadcast_55_piece0 on 02926ee04bc9:45221 in memory (size: 35.2 KiB, free: 366.1 MiB)
26/01/12 02:09:44 INFO BlockManagerInfo: Removed broadcast_55_piece0 on 172.18.0.5:42453 in memory (size: 35.2 KiB, free: 366.1 MiB)
26/01/12 02:09:44 INFO BlockManagerInfo: Removed broadcast_62_piece0 on 02926ee04bc9:45221 in memory (size: 77.3 KiB, free: 366.2 MiB)
26/01/12 02:09:44 INFO BlockManagerInfo: Removed broadcast_62_piece0 on 172.18.0.5:42453 in memory (size: 77.3 KiB, free: 366.2 MiB)
26/01/12 02:09:44 INFO TaskSetManager: Starting task 2.0 in stage 45.0 (TID 112) (172.18.0.5, executor 0, partition 2, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:09:44 INFO TaskSetManager: Finished task 0.0 in stage 45.0 (TID 110) in 524 ms on 172.18.0.5 (executor 0) (1/4)
26/01/12 02:09:44 INFO TaskSetManager: Starting task 3.0 in stage 45.0 (TID 113) (172.18.0.5, executor 0, partition 3, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:09:44 INFO TaskSetManager: Finished task 2.0 in stage 45.0 (TID 112) in 31 ms on 172.18.0.5 (executor 0) (2/4)
26/01/12 02:09:45 INFO TaskSetManager: Finished task 3.0 in stage 45.0 (TID 113) in 32 ms on 172.18.0.5 (executor 0) (3/4)
26/01/12 02:10:30 INFO TaskSetManager: Finished task 1.0 in stage 45.0 (TID 111) in 45830 ms on 172.18.0.5 (executor 0) (4/4)
26/01/12 02:10:30 INFO TaskSchedulerImpl: Removed TaskSet 45.0, whose tasks have all completed, from pool 
26/01/12 02:10:30 INFO DAGScheduler: ResultStage 45 (parquet at <unknown>:0) finished in 45.857 s
26/01/12 02:10:30 INFO DAGScheduler: Job 45 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:10:30 INFO TaskSchedulerImpl: Killing all running tasks in stage 45: Stage finished
26/01/12 02:10:30 INFO DAGScheduler: Job 45 finished: parquet at <unknown>:0, took 45.866518 s
26/01/12 02:10:30 INFO FileFormatWriter: Start to commit write Job fddef23b-aeb8-43e4-a6a7-741524b6f769.
26/01/12 02:10:30 INFO FileFormatWriter: Write Job fddef23b-aeb8-43e4-a6a7-741524b6f769 committed. Elapsed time: 49 ms.
26/01/12 02:10:30 INFO FileFormatWriter: Finished processing stats for write job fddef23b-aeb8-43e4-a6a7-741524b6f769.
Cargando: yellow_tripdata_2010-12.parquet en hdfs://hadoop-namenode:8020/data/nyc/raw/taxi-trips/2010...
26/01/12 02:10:30 INFO InMemoryFileIndex: It took 8 ms to list leaf files for 1 paths.
26/01/12 02:10:30 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 02:10:30 INFO DAGScheduler: Got job 46 (parquet at <unknown>:0) with 1 output partitions
26/01/12 02:10:30 INFO DAGScheduler: Final stage: ResultStage 46 (parquet at <unknown>:0)
26/01/12 02:10:30 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:10:30 INFO DAGScheduler: Missing parents: List()
26/01/12 02:10:30 INFO DAGScheduler: Submitting ResultStage 46 (MapPartitionsRDD[116] at parquet at <unknown>:0), which has no missing parents
26/01/12 02:10:30 INFO MemoryStore: Block broadcast_69 stored as values in memory (estimated size 102.6 KiB, free 365.5 MiB)
26/01/12 02:10:30 INFO MemoryStore: Block broadcast_69_piece0 stored as bytes in memory (estimated size 36.8 KiB, free 365.5 MiB)
26/01/12 02:10:30 INFO BlockManagerInfo: Added broadcast_69_piece0 in memory on 02926ee04bc9:45221 (size: 36.8 KiB, free: 366.2 MiB)
26/01/12 02:10:30 INFO SparkContext: Created broadcast 69 from broadcast at DAGScheduler.scala:1513
26/01/12 02:10:30 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 46 (MapPartitionsRDD[116] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0))
26/01/12 02:10:30 INFO TaskSchedulerImpl: Adding task set 46.0 with 1 tasks resource profile 0
26/01/12 02:10:30 INFO TaskSetManager: Starting task 0.0 in stage 46.0 (TID 114) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4607 bytes) taskResourceAssignments Map()
26/01/12 02:10:30 INFO BlockManagerInfo: Added broadcast_69_piece0 in memory on 172.18.0.5:42453 (size: 36.8 KiB, free: 366.2 MiB)
26/01/12 02:10:30 INFO TaskSetManager: Finished task 0.0 in stage 46.0 (TID 114) in 70 ms on 172.18.0.5 (executor 0) (1/1)
26/01/12 02:10:30 INFO TaskSchedulerImpl: Removed TaskSet 46.0, whose tasks have all completed, from pool 
26/01/12 02:10:30 INFO DAGScheduler: ResultStage 46 (parquet at <unknown>:0) finished in 0.083 s
26/01/12 02:10:30 INFO DAGScheduler: Job 46 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:10:30 INFO TaskSchedulerImpl: Killing all running tasks in stage 46: Stage finished
26/01/12 02:10:30 INFO DAGScheduler: Job 46 finished: parquet at <unknown>:0, took 0.089079 s
26/01/12 02:10:30 INFO FileSourceStrategy: Pushed Filters: 
26/01/12 02:10:30 INFO FileSourceStrategy: Post-Scan Filters: 
26/01/12 02:10:30 INFO FileSourceStrategy: Output Data Schema: struct<vendor_id: string, pickup_datetime: string, dropoff_datetime: string, passenger_count: bigint, trip_distance: double ... 16 more fields>
26/01/12 02:10:30 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:10:30 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:10:30 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:10:30 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:10:30 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:10:30 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:10:30 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:10:30 INFO MemoryStore: Block broadcast_70 stored as values in memory (estimated size 358.2 KiB, free 365.1 MiB)
26/01/12 02:10:30 INFO MemoryStore: Block broadcast_70_piece0 stored as bytes in memory (estimated size 35.2 KiB, free 365.1 MiB)
26/01/12 02:10:30 INFO BlockManagerInfo: Added broadcast_70_piece0 in memory on 02926ee04bc9:45221 (size: 35.2 KiB, free: 366.1 MiB)
26/01/12 02:10:30 INFO SparkContext: Created broadcast 70 from parquet at <unknown>:0
26/01/12 02:10:30 INFO FileSourceScanExec: Planning scan with bin packing, max size: 134217728 bytes, open cost is considered as scanning 4194304 bytes.
26/01/12 02:10:30 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 02:10:30 INFO DAGScheduler: Got job 47 (parquet at <unknown>:0) with 4 output partitions
26/01/12 02:10:30 INFO DAGScheduler: Final stage: ResultStage 47 (parquet at <unknown>:0)
26/01/12 02:10:30 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:10:30 INFO DAGScheduler: Missing parents: List()
26/01/12 02:10:30 INFO DAGScheduler: Submitting ResultStage 47 (MapPartitionsRDD[119] at parquet at <unknown>:0), which has no missing parents
26/01/12 02:10:30 INFO MemoryStore: Block broadcast_71 stored as values in memory (estimated size 224.4 KiB, free 364.9 MiB)
26/01/12 02:10:30 INFO MemoryStore: Block broadcast_71_piece0 stored as bytes in memory (estimated size 77.3 KiB, free 364.8 MiB)
26/01/12 02:10:30 INFO BlockManagerInfo: Added broadcast_71_piece0 in memory on 02926ee04bc9:45221 (size: 77.3 KiB, free: 366.0 MiB)
26/01/12 02:10:30 INFO SparkContext: Created broadcast 71 from broadcast at DAGScheduler.scala:1513
26/01/12 02:10:30 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 47 (MapPartitionsRDD[119] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
26/01/12 02:10:30 INFO TaskSchedulerImpl: Adding task set 47.0 with 4 tasks resource profile 0
26/01/12 02:10:30 INFO TaskSetManager: Starting task 0.0 in stage 47.0 (TID 115) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:10:30 INFO TaskSetManager: Starting task 1.0 in stage 47.0 (TID 116) (172.18.0.5, executor 0, partition 1, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:10:30 INFO BlockManagerInfo: Added broadcast_71_piece0 in memory on 172.18.0.5:42453 (size: 77.3 KiB, free: 366.1 MiB)
26/01/12 02:10:30 INFO BlockManagerInfo: Added broadcast_70_piece0 in memory on 172.18.0.5:42453 (size: 35.2 KiB, free: 366.0 MiB)
26/01/12 02:10:31 INFO TaskSetManager: Starting task 2.0 in stage 47.0 (TID 117) (172.18.0.5, executor 0, partition 2, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:10:31 INFO TaskSetManager: Finished task 0.0 in stage 47.0 (TID 115) in 499 ms on 172.18.0.5 (executor 0) (1/4)
26/01/12 02:10:31 INFO TaskSetManager: Starting task 3.0 in stage 47.0 (TID 118) (172.18.0.5, executor 0, partition 3, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:10:31 INFO TaskSetManager: Finished task 2.0 in stage 47.0 (TID 117) in 31 ms on 172.18.0.5 (executor 0) (2/4)
26/01/12 02:10:31 INFO TaskSetManager: Finished task 3.0 in stage 47.0 (TID 118) in 33 ms on 172.18.0.5 (executor 0) (3/4)
26/01/12 02:11:14 INFO TaskSetManager: Finished task 1.0 in stage 47.0 (TID 116) in 43824 ms on 172.18.0.5 (executor 0) (4/4)
26/01/12 02:11:14 INFO TaskSchedulerImpl: Removed TaskSet 47.0, whose tasks have all completed, from pool 
26/01/12 02:11:14 INFO DAGScheduler: ResultStage 47 (parquet at <unknown>:0) finished in 43.848 s
26/01/12 02:11:14 INFO DAGScheduler: Job 47 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:11:14 INFO TaskSchedulerImpl: Killing all running tasks in stage 47: Stage finished
26/01/12 02:11:14 INFO DAGScheduler: Job 47 finished: parquet at <unknown>:0, took 43.858941 s
26/01/12 02:11:14 INFO FileFormatWriter: Start to commit write Job f7fb7e41-5361-4d40-ac9b-047e3f1dfb89.
26/01/12 02:11:14 INFO FileFormatWriter: Write Job f7fb7e41-5361-4d40-ac9b-047e3f1dfb89 committed. Elapsed time: 47 ms.
26/01/12 02:11:14 INFO FileFormatWriter: Finished processing stats for write job f7fb7e41-5361-4d40-ac9b-047e3f1dfb89.
Cargando: yellow_tripdata_2011-01.parquet en hdfs://hadoop-namenode:8020/data/nyc/raw/taxi-trips/2011...
26/01/12 02:11:14 INFO InMemoryFileIndex: It took 7 ms to list leaf files for 1 paths.
26/01/12 02:11:14 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 02:11:14 INFO DAGScheduler: Got job 48 (parquet at <unknown>:0) with 1 output partitions
26/01/12 02:11:14 INFO DAGScheduler: Final stage: ResultStage 48 (parquet at <unknown>:0)
26/01/12 02:11:14 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:11:14 INFO DAGScheduler: Missing parents: List()
26/01/12 02:11:14 INFO DAGScheduler: Submitting ResultStage 48 (MapPartitionsRDD[121] at parquet at <unknown>:0), which has no missing parents
26/01/12 02:11:14 INFO MemoryStore: Block broadcast_72 stored as values in memory (estimated size 102.6 KiB, free 364.7 MiB)
26/01/12 02:11:14 INFO MemoryStore: Block broadcast_72_piece0 stored as bytes in memory (estimated size 36.8 KiB, free 364.7 MiB)
26/01/12 02:11:14 INFO BlockManagerInfo: Added broadcast_72_piece0 in memory on 02926ee04bc9:45221 (size: 36.8 KiB, free: 366.0 MiB)
26/01/12 02:11:14 INFO SparkContext: Created broadcast 72 from broadcast at DAGScheduler.scala:1513
26/01/12 02:11:14 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 48 (MapPartitionsRDD[121] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0))
26/01/12 02:11:14 INFO TaskSchedulerImpl: Adding task set 48.0 with 1 tasks resource profile 0
26/01/12 02:11:14 INFO TaskSetManager: Starting task 0.0 in stage 48.0 (TID 119) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4607 bytes) taskResourceAssignments Map()
26/01/12 02:11:14 INFO BlockManagerInfo: Added broadcast_72_piece0 in memory on 172.18.0.5:42453 (size: 36.8 KiB, free: 366.0 MiB)
26/01/12 02:11:14 INFO TaskSetManager: Finished task 0.0 in stage 48.0 (TID 119) in 67 ms on 172.18.0.5 (executor 0) (1/1)
26/01/12 02:11:14 INFO TaskSchedulerImpl: Removed TaskSet 48.0, whose tasks have all completed, from pool 
26/01/12 02:11:14 INFO DAGScheduler: ResultStage 48 (parquet at <unknown>:0) finished in 0.078 s
26/01/12 02:11:14 INFO DAGScheduler: Job 48 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:11:14 INFO TaskSchedulerImpl: Killing all running tasks in stage 48: Stage finished
26/01/12 02:11:14 INFO DAGScheduler: Job 48 finished: parquet at <unknown>:0, took 0.082689 s
26/01/12 02:11:14 INFO FileSourceStrategy: Pushed Filters: 
26/01/12 02:11:14 INFO FileSourceStrategy: Post-Scan Filters: 
26/01/12 02:11:14 INFO FileSourceStrategy: Output Data Schema: struct<VendorID: bigint, tpep_pickup_datetime: timestamp, tpep_dropoff_datetime: timestamp, passenger_count: bigint, trip_distance: double ... 17 more fields>
26/01/12 02:11:14 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:11:14 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:11:14 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:11:14 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:11:14 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:11:14 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:11:14 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:11:14 INFO CodeGenerator: Code generated in 25.170123 ms
26/01/12 02:11:14 INFO MemoryStore: Block broadcast_73 stored as values in memory (estimated size 358.4 KiB, free 364.3 MiB)
26/01/12 02:11:14 INFO MemoryStore: Block broadcast_73_piece0 stored as bytes in memory (estimated size 35.3 KiB, free 364.3 MiB)
26/01/12 02:11:14 INFO BlockManagerInfo: Added broadcast_73_piece0 in memory on 02926ee04bc9:45221 (size: 35.3 KiB, free: 366.0 MiB)
26/01/12 02:11:14 INFO SparkContext: Created broadcast 73 from parquet at <unknown>:0
26/01/12 02:11:14 INFO FileSourceScanExec: Planning scan with bin packing, max size: 85687067 bytes, open cost is considered as scanning 4194304 bytes.
26/01/12 02:11:14 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 02:11:14 INFO DAGScheduler: Got job 49 (parquet at <unknown>:0) with 2 output partitions
26/01/12 02:11:14 INFO DAGScheduler: Final stage: ResultStage 49 (parquet at <unknown>:0)
26/01/12 02:11:14 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:11:14 INFO DAGScheduler: Missing parents: List()
26/01/12 02:11:14 INFO DAGScheduler: Submitting ResultStage 49 (MapPartitionsRDD[124] at parquet at <unknown>:0), which has no missing parents
26/01/12 02:11:14 INFO MemoryStore: Block broadcast_74 stored as values in memory (estimated size 225.0 KiB, free 364.1 MiB)
26/01/12 02:11:14 INFO MemoryStore: Block broadcast_74_piece0 stored as bytes in memory (estimated size 77.3 KiB, free 364.0 MiB)
26/01/12 02:11:14 INFO BlockManagerInfo: Added broadcast_74_piece0 in memory on 02926ee04bc9:45221 (size: 77.3 KiB, free: 365.9 MiB)
26/01/12 02:11:14 INFO SparkContext: Created broadcast 74 from broadcast at DAGScheduler.scala:1513
26/01/12 02:11:14 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 49 (MapPartitionsRDD[124] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1))
26/01/12 02:11:14 INFO TaskSchedulerImpl: Adding task set 49.0 with 2 tasks resource profile 0
26/01/12 02:11:14 INFO TaskSetManager: Starting task 0.0 in stage 49.0 (TID 120) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:11:14 INFO TaskSetManager: Starting task 1.0 in stage 49.0 (TID 121) (172.18.0.5, executor 0, partition 1, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:11:14 INFO BlockManagerInfo: Added broadcast_74_piece0 in memory on 172.18.0.5:42453 (size: 77.3 KiB, free: 365.9 MiB)
26/01/12 02:11:14 INFO BlockManagerInfo: Added broadcast_73_piece0 in memory on 172.18.0.5:42453 (size: 35.3 KiB, free: 365.9 MiB)
26/01/12 02:11:14 INFO TaskSetManager: Finished task 1.0 in stage 49.0 (TID 121) in 96 ms on 172.18.0.5 (executor 0) (1/2)
26/01/12 02:11:44 INFO TaskSetManager: Finished task 0.0 in stage 49.0 (TID 120) in 30034 ms on 172.18.0.5 (executor 0) (2/2)
26/01/12 02:11:44 INFO TaskSchedulerImpl: Removed TaskSet 49.0, whose tasks have all completed, from pool 
26/01/12 02:11:44 INFO DAGScheduler: ResultStage 49 (parquet at <unknown>:0) finished in 30.056 s
26/01/12 02:11:44 INFO DAGScheduler: Job 49 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:11:44 INFO TaskSchedulerImpl: Killing all running tasks in stage 49: Stage finished
26/01/12 02:11:44 INFO DAGScheduler: Job 49 finished: parquet at <unknown>:0, took 30.064182 s
26/01/12 02:11:44 INFO FileFormatWriter: Start to commit write Job 5db060f3-349a-435e-a599-66c97c7acd01.
26/01/12 02:11:44 INFO FileFormatWriter: Write Job 5db060f3-349a-435e-a599-66c97c7acd01 committed. Elapsed time: 37 ms.
26/01/12 02:11:44 INFO FileFormatWriter: Finished processing stats for write job 5db060f3-349a-435e-a599-66c97c7acd01.
Cargando: yellow_tripdata_2011-02.parquet en hdfs://hadoop-namenode:8020/data/nyc/raw/taxi-trips/2011...
26/01/12 02:11:44 INFO InMemoryFileIndex: It took 11 ms to list leaf files for 1 paths.
26/01/12 02:11:44 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 02:11:44 INFO DAGScheduler: Got job 50 (parquet at <unknown>:0) with 1 output partitions
26/01/12 02:11:44 INFO DAGScheduler: Final stage: ResultStage 50 (parquet at <unknown>:0)
26/01/12 02:11:44 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:11:44 INFO DAGScheduler: Missing parents: List()
26/01/12 02:11:44 INFO DAGScheduler: Submitting ResultStage 50 (MapPartitionsRDD[126] at parquet at <unknown>:0), which has no missing parents
26/01/12 02:11:44 INFO MemoryStore: Block broadcast_75 stored as values in memory (estimated size 102.6 KiB, free 363.9 MiB)
26/01/12 02:11:44 INFO MemoryStore: Block broadcast_75_piece0 stored as bytes in memory (estimated size 36.8 KiB, free 363.9 MiB)
26/01/12 02:11:44 INFO BlockManagerInfo: Added broadcast_75_piece0 in memory on 02926ee04bc9:45221 (size: 36.8 KiB, free: 365.9 MiB)
26/01/12 02:11:44 INFO SparkContext: Created broadcast 75 from broadcast at DAGScheduler.scala:1513
26/01/12 02:11:44 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 50 (MapPartitionsRDD[126] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0))
26/01/12 02:11:44 INFO TaskSchedulerImpl: Adding task set 50.0 with 1 tasks resource profile 0
26/01/12 02:11:44 INFO TaskSetManager: Starting task 0.0 in stage 50.0 (TID 122) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4607 bytes) taskResourceAssignments Map()
26/01/12 02:11:44 INFO BlockManagerInfo: Added broadcast_75_piece0 in memory on 172.18.0.5:42453 (size: 36.8 KiB, free: 365.9 MiB)
26/01/12 02:11:44 INFO TaskSetManager: Finished task 0.0 in stage 50.0 (TID 122) in 59 ms on 172.18.0.5 (executor 0) (1/1)
26/01/12 02:11:44 INFO TaskSchedulerImpl: Removed TaskSet 50.0, whose tasks have all completed, from pool 
26/01/12 02:11:44 INFO DAGScheduler: ResultStage 50 (parquet at <unknown>:0) finished in 0.073 s
26/01/12 02:11:44 INFO DAGScheduler: Job 50 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:11:44 INFO TaskSchedulerImpl: Killing all running tasks in stage 50: Stage finished
26/01/12 02:11:44 INFO DAGScheduler: Job 50 finished: parquet at <unknown>:0, took 0.079241 s
26/01/12 02:11:44 INFO FileSourceStrategy: Pushed Filters: 
26/01/12 02:11:44 INFO FileSourceStrategy: Post-Scan Filters: 
26/01/12 02:11:44 INFO FileSourceStrategy: Output Data Schema: struct<VendorID: bigint, tpep_pickup_datetime: timestamp, tpep_dropoff_datetime: timestamp, passenger_count: bigint, trip_distance: double ... 17 more fields>
26/01/12 02:11:44 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:11:44 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:11:44 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:11:44 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:11:44 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:11:44 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:11:44 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:11:45 INFO CodeGenerator: Code generated in 41.215176 ms
26/01/12 02:11:45 INFO MemoryStore: Block broadcast_76 stored as values in memory (estimated size 358.4 KiB, free 363.5 MiB)
26/01/12 02:11:45 INFO MemoryStore: Block broadcast_76_piece0 stored as bytes in memory (estimated size 35.4 KiB, free 363.5 MiB)
26/01/12 02:11:45 INFO BlockManagerInfo: Added broadcast_76_piece0 in memory on 02926ee04bc9:45221 (size: 35.4 KiB, free: 365.8 MiB)
26/01/12 02:11:45 INFO SparkContext: Created broadcast 76 from parquet at <unknown>:0
26/01/12 02:11:45 INFO FileSourceScanExec: Planning scan with bin packing, max size: 90087568 bytes, open cost is considered as scanning 4194304 bytes.
26/01/12 02:11:45 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 02:11:45 INFO DAGScheduler: Got job 51 (parquet at <unknown>:0) with 2 output partitions
26/01/12 02:11:45 INFO DAGScheduler: Final stage: ResultStage 51 (parquet at <unknown>:0)
26/01/12 02:11:45 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:11:45 INFO DAGScheduler: Missing parents: List()
26/01/12 02:11:45 INFO DAGScheduler: Submitting ResultStage 51 (MapPartitionsRDD[129] at parquet at <unknown>:0), which has no missing parents
26/01/12 02:11:45 INFO MemoryStore: Block broadcast_77 stored as values in memory (estimated size 225.1 KiB, free 363.2 MiB)
26/01/12 02:11:45 INFO MemoryStore: Block broadcast_77_piece0 stored as bytes in memory (estimated size 77.4 KiB, free 363.2 MiB)
26/01/12 02:11:45 INFO BlockManagerInfo: Added broadcast_77_piece0 in memory on 02926ee04bc9:45221 (size: 77.4 KiB, free: 365.8 MiB)
26/01/12 02:11:45 INFO SparkContext: Created broadcast 77 from broadcast at DAGScheduler.scala:1513
26/01/12 02:11:45 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 51 (MapPartitionsRDD[129] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1))
26/01/12 02:11:45 INFO TaskSchedulerImpl: Adding task set 51.0 with 2 tasks resource profile 0
26/01/12 02:11:45 INFO TaskSetManager: Starting task 0.0 in stage 51.0 (TID 123) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:11:45 INFO TaskSetManager: Starting task 1.0 in stage 51.0 (TID 124) (172.18.0.5, executor 0, partition 1, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:11:45 INFO BlockManagerInfo: Added broadcast_77_piece0 in memory on 172.18.0.5:42453 (size: 77.4 KiB, free: 365.8 MiB)
26/01/12 02:11:45 INFO BlockManagerInfo: Added broadcast_76_piece0 in memory on 172.18.0.5:42453 (size: 35.4 KiB, free: 365.8 MiB)
26/01/12 02:11:45 INFO TaskSetManager: Finished task 1.0 in stage 51.0 (TID 124) in 110 ms on 172.18.0.5 (executor 0) (1/2)
26/01/12 02:12:16 INFO TaskSetManager: Finished task 0.0 in stage 51.0 (TID 123) in 31081 ms on 172.18.0.5 (executor 0) (2/2)
26/01/12 02:12:16 INFO TaskSchedulerImpl: Removed TaskSet 51.0, whose tasks have all completed, from pool 
26/01/12 02:12:16 INFO DAGScheduler: ResultStage 51 (parquet at <unknown>:0) finished in 31.104 s
26/01/12 02:12:16 INFO DAGScheduler: Job 51 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:12:16 INFO TaskSchedulerImpl: Killing all running tasks in stage 51: Stage finished
26/01/12 02:12:16 INFO DAGScheduler: Job 51 finished: parquet at <unknown>:0, took 31.115534 s
26/01/12 02:12:16 INFO FileFormatWriter: Start to commit write Job cf7f5460-d508-4c29-a5cb-7439146ab7a3.
26/01/12 02:12:16 INFO FileFormatWriter: Write Job cf7f5460-d508-4c29-a5cb-7439146ab7a3 committed. Elapsed time: 37 ms.
26/01/12 02:12:16 INFO FileFormatWriter: Finished processing stats for write job cf7f5460-d508-4c29-a5cb-7439146ab7a3.
Cargando: yellow_tripdata_2011-03.parquet en hdfs://hadoop-namenode:8020/data/nyc/raw/taxi-trips/2011...
26/01/12 02:12:16 INFO InMemoryFileIndex: It took 13 ms to list leaf files for 1 paths.
26/01/12 02:12:16 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 02:12:16 INFO DAGScheduler: Got job 52 (parquet at <unknown>:0) with 1 output partitions
26/01/12 02:12:16 INFO DAGScheduler: Final stage: ResultStage 52 (parquet at <unknown>:0)
26/01/12 02:12:16 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:12:16 INFO DAGScheduler: Missing parents: List()
26/01/12 02:12:16 INFO DAGScheduler: Submitting ResultStage 52 (MapPartitionsRDD[131] at parquet at <unknown>:0), which has no missing parents
26/01/12 02:12:16 INFO MemoryStore: Block broadcast_78 stored as values in memory (estimated size 102.6 KiB, free 363.1 MiB)
26/01/12 02:12:16 INFO MemoryStore: Block broadcast_78_piece0 stored as bytes in memory (estimated size 36.8 KiB, free 363.0 MiB)
26/01/12 02:12:16 INFO BlockManagerInfo: Added broadcast_78_piece0 in memory on 02926ee04bc9:45221 (size: 36.8 KiB, free: 365.7 MiB)
26/01/12 02:12:16 INFO SparkContext: Created broadcast 78 from broadcast at DAGScheduler.scala:1513
26/01/12 02:12:16 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 52 (MapPartitionsRDD[131] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0))
26/01/12 02:12:16 INFO TaskSchedulerImpl: Adding task set 52.0 with 1 tasks resource profile 0
26/01/12 02:12:16 INFO TaskSetManager: Starting task 0.0 in stage 52.0 (TID 125) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4607 bytes) taskResourceAssignments Map()
26/01/12 02:12:16 INFO BlockManagerInfo: Added broadcast_78_piece0 in memory on 172.18.0.5:42453 (size: 36.8 KiB, free: 365.7 MiB)
26/01/12 02:12:16 INFO TaskSetManager: Finished task 0.0 in stage 52.0 (TID 125) in 60 ms on 172.18.0.5 (executor 0) (1/1)
26/01/12 02:12:16 INFO TaskSchedulerImpl: Removed TaskSet 52.0, whose tasks have all completed, from pool 
26/01/12 02:12:16 INFO DAGScheduler: ResultStage 52 (parquet at <unknown>:0) finished in 0.075 s
26/01/12 02:12:16 INFO DAGScheduler: Job 52 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:12:16 INFO TaskSchedulerImpl: Killing all running tasks in stage 52: Stage finished
26/01/12 02:12:16 INFO DAGScheduler: Job 52 finished: parquet at <unknown>:0, took 0.087111 s
26/01/12 02:12:16 INFO FileSourceStrategy: Pushed Filters: 
26/01/12 02:12:16 INFO FileSourceStrategy: Post-Scan Filters: 
26/01/12 02:12:16 INFO FileSourceStrategy: Output Data Schema: struct<VendorID: bigint, tpep_pickup_datetime: timestamp, tpep_dropoff_datetime: timestamp, passenger_count: bigint, trip_distance: double ... 17 more fields>
26/01/12 02:12:16 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:12:16 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:12:16 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:12:16 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:12:16 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:12:16 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:12:16 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:12:16 INFO CodeGenerator: Code generated in 42.918436 ms
26/01/12 02:12:16 INFO MemoryStore: Block broadcast_79 stored as values in memory (estimated size 358.4 KiB, free 362.7 MiB)
26/01/12 02:12:16 INFO MemoryStore: Block broadcast_79_piece0 stored as bytes in memory (estimated size 35.4 KiB, free 362.7 MiB)
26/01/12 02:12:16 INFO BlockManagerInfo: Added broadcast_79_piece0 in memory on 02926ee04bc9:45221 (size: 35.4 KiB, free: 365.7 MiB)
26/01/12 02:12:16 INFO SparkContext: Created broadcast 79 from parquet at <unknown>:0
26/01/12 02:12:16 INFO FileSourceScanExec: Planning scan with bin packing, max size: 102063587 bytes, open cost is considered as scanning 4194304 bytes.
26/01/12 02:12:16 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 02:12:16 INFO DAGScheduler: Got job 53 (parquet at <unknown>:0) with 2 output partitions
26/01/12 02:12:16 INFO DAGScheduler: Final stage: ResultStage 53 (parquet at <unknown>:0)
26/01/12 02:12:16 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:12:16 INFO DAGScheduler: Missing parents: List()
26/01/12 02:12:16 INFO DAGScheduler: Submitting ResultStage 53 (MapPartitionsRDD[134] at parquet at <unknown>:0), which has no missing parents
26/01/12 02:12:16 INFO MemoryStore: Block broadcast_80 stored as values in memory (estimated size 225.1 KiB, free 362.4 MiB)
26/01/12 02:12:16 INFO MemoryStore: Block broadcast_80_piece0 stored as bytes in memory (estimated size 77.4 KiB, free 362.4 MiB)
26/01/12 02:12:16 INFO BlockManagerInfo: Added broadcast_80_piece0 in memory on 02926ee04bc9:45221 (size: 77.4 KiB, free: 365.6 MiB)
26/01/12 02:12:16 INFO SparkContext: Created broadcast 80 from broadcast at DAGScheduler.scala:1513
26/01/12 02:12:16 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 53 (MapPartitionsRDD[134] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1))
26/01/12 02:12:16 INFO TaskSchedulerImpl: Adding task set 53.0 with 2 tasks resource profile 0
26/01/12 02:12:16 INFO TaskSetManager: Starting task 0.0 in stage 53.0 (TID 126) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:12:16 INFO TaskSetManager: Starting task 1.0 in stage 53.0 (TID 127) (172.18.0.5, executor 0, partition 1, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:12:16 INFO BlockManagerInfo: Added broadcast_80_piece0 in memory on 172.18.0.5:42453 (size: 77.4 KiB, free: 365.6 MiB)
26/01/12 02:12:16 INFO BlockManagerInfo: Added broadcast_79_piece0 in memory on 172.18.0.5:42453 (size: 35.4 KiB, free: 365.6 MiB)
26/01/12 02:12:16 INFO TaskSetManager: Finished task 1.0 in stage 53.0 (TID 127) in 151 ms on 172.18.0.5 (executor 0) (1/2)
26/01/12 02:12:56 INFO TaskSetManager: Finished task 0.0 in stage 53.0 (TID 126) in 39873 ms on 172.18.0.5 (executor 0) (2/2)
26/01/12 02:12:56 INFO TaskSchedulerImpl: Removed TaskSet 53.0, whose tasks have all completed, from pool 
26/01/12 02:12:56 INFO DAGScheduler: ResultStage 53 (parquet at <unknown>:0) finished in 39.909 s
26/01/12 02:12:56 INFO DAGScheduler: Job 53 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:12:56 INFO TaskSchedulerImpl: Killing all running tasks in stage 53: Stage finished
26/01/12 02:12:56 INFO DAGScheduler: Job 53 finished: parquet at <unknown>:0, took 39.932603 s
26/01/12 02:12:56 INFO FileFormatWriter: Start to commit write Job eb534f3e-55a1-421c-a3a6-ac60faca42be.
26/01/12 02:12:56 INFO FileFormatWriter: Write Job eb534f3e-55a1-421c-a3a6-ac60faca42be committed. Elapsed time: 34 ms.
26/01/12 02:12:56 INFO FileFormatWriter: Finished processing stats for write job eb534f3e-55a1-421c-a3a6-ac60faca42be.
Cargando: yellow_tripdata_2011-04.parquet en hdfs://hadoop-namenode:8020/data/nyc/raw/taxi-trips/2011...
26/01/12 02:12:56 INFO InMemoryFileIndex: It took 6 ms to list leaf files for 1 paths.
26/01/12 02:12:56 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 02:12:56 INFO DAGScheduler: Got job 54 (parquet at <unknown>:0) with 1 output partitions
26/01/12 02:12:56 INFO DAGScheduler: Final stage: ResultStage 54 (parquet at <unknown>:0)
26/01/12 02:12:56 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:12:56 INFO DAGScheduler: Missing parents: List()
26/01/12 02:12:56 INFO DAGScheduler: Submitting ResultStage 54 (MapPartitionsRDD[136] at parquet at <unknown>:0), which has no missing parents
26/01/12 02:12:56 INFO MemoryStore: Block broadcast_81 stored as values in memory (estimated size 102.6 KiB, free 362.3 MiB)
26/01/12 02:12:56 INFO MemoryStore: Block broadcast_81_piece0 stored as bytes in memory (estimated size 36.8 KiB, free 362.2 MiB)
26/01/12 02:12:56 INFO BlockManagerInfo: Added broadcast_81_piece0 in memory on 02926ee04bc9:45221 (size: 36.8 KiB, free: 365.6 MiB)
26/01/12 02:12:56 INFO SparkContext: Created broadcast 81 from broadcast at DAGScheduler.scala:1513
26/01/12 02:12:56 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 54 (MapPartitionsRDD[136] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0))
26/01/12 02:12:56 INFO TaskSchedulerImpl: Adding task set 54.0 with 1 tasks resource profile 0
26/01/12 02:12:56 INFO TaskSetManager: Starting task 0.0 in stage 54.0 (TID 128) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4607 bytes) taskResourceAssignments Map()
26/01/12 02:12:56 INFO BlockManagerInfo: Added broadcast_81_piece0 in memory on 172.18.0.5:42453 (size: 36.8 KiB, free: 365.6 MiB)
26/01/12 02:12:56 INFO TaskSetManager: Finished task 0.0 in stage 54.0 (TID 128) in 57 ms on 172.18.0.5 (executor 0) (1/1)
26/01/12 02:12:56 INFO TaskSchedulerImpl: Removed TaskSet 54.0, whose tasks have all completed, from pool 
26/01/12 02:12:56 INFO DAGScheduler: ResultStage 54 (parquet at <unknown>:0) finished in 0.074 s
26/01/12 02:12:56 INFO DAGScheduler: Job 54 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:12:56 INFO TaskSchedulerImpl: Killing all running tasks in stage 54: Stage finished
26/01/12 02:12:56 INFO DAGScheduler: Job 54 finished: parquet at <unknown>:0, took 0.078055 s
26/01/12 02:12:56 INFO FileSourceStrategy: Pushed Filters: 
26/01/12 02:12:56 INFO FileSourceStrategy: Post-Scan Filters: 
26/01/12 02:12:56 INFO FileSourceStrategy: Output Data Schema: struct<VendorID: bigint, tpep_pickup_datetime: timestamp, tpep_dropoff_datetime: timestamp, passenger_count: bigint, trip_distance: double ... 17 more fields>
26/01/12 02:12:56 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:12:56 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:12:56 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:12:56 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:12:56 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:12:56 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:12:56 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:12:56 INFO MemoryStore: Block broadcast_82 stored as values in memory (estimated size 358.4 KiB, free 361.9 MiB)
26/01/12 02:12:56 INFO MemoryStore: Block broadcast_82_piece0 stored as bytes in memory (estimated size 35.4 KiB, free 361.8 MiB)
26/01/12 02:12:56 INFO BlockManagerInfo: Added broadcast_82_piece0 in memory on 02926ee04bc9:45221 (size: 35.4 KiB, free: 365.5 MiB)
26/01/12 02:12:56 INFO SparkContext: Created broadcast 82 from parquet at <unknown>:0
26/01/12 02:12:56 INFO FileSourceScanExec: Planning scan with bin packing, max size: 94194769 bytes, open cost is considered as scanning 4194304 bytes.
26/01/12 02:12:56 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 02:12:56 INFO DAGScheduler: Got job 55 (parquet at <unknown>:0) with 2 output partitions
26/01/12 02:12:56 INFO DAGScheduler: Final stage: ResultStage 55 (parquet at <unknown>:0)
26/01/12 02:12:56 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:12:56 INFO DAGScheduler: Missing parents: List()
26/01/12 02:12:56 INFO DAGScheduler: Submitting ResultStage 55 (MapPartitionsRDD[139] at parquet at <unknown>:0), which has no missing parents
26/01/12 02:12:56 INFO BlockManagerInfo: Removed broadcast_73_piece0 on 02926ee04bc9:45221 in memory (size: 35.3 KiB, free: 365.6 MiB)
26/01/12 02:12:56 INFO BlockManagerInfo: Removed broadcast_73_piece0 on 172.18.0.5:42453 in memory (size: 35.3 KiB, free: 365.6 MiB)
26/01/12 02:12:56 INFO BlockManagerInfo: Removed broadcast_79_piece0 on 02926ee04bc9:45221 in memory (size: 35.4 KiB, free: 365.6 MiB)
26/01/12 02:12:56 INFO BlockManagerInfo: Removed broadcast_79_piece0 on 172.18.0.5:42453 in memory (size: 35.4 KiB, free: 365.6 MiB)
26/01/12 02:12:56 INFO BlockManagerInfo: Removed broadcast_77_piece0 on 02926ee04bc9:45221 in memory (size: 77.4 KiB, free: 365.7 MiB)
26/01/12 02:12:56 INFO MemoryStore: Block broadcast_83 stored as values in memory (estimated size 225.1 KiB, free 362.5 MiB)
26/01/12 02:12:56 INFO BlockManagerInfo: Removed broadcast_77_piece0 on 172.18.0.5:42453 in memory (size: 77.4 KiB, free: 365.7 MiB)
26/01/12 02:12:56 INFO MemoryStore: Block broadcast_83_piece0 stored as bytes in memory (estimated size 77.4 KiB, free 362.6 MiB)
26/01/12 02:12:56 INFO BlockManagerInfo: Added broadcast_83_piece0 in memory on 02926ee04bc9:45221 (size: 77.4 KiB, free: 365.6 MiB)
26/01/12 02:12:56 INFO SparkContext: Created broadcast 83 from broadcast at DAGScheduler.scala:1513
26/01/12 02:12:56 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 55 (MapPartitionsRDD[139] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1))
26/01/12 02:12:56 INFO TaskSchedulerImpl: Adding task set 55.0 with 2 tasks resource profile 0
26/01/12 02:12:56 INFO BlockManagerInfo: Removed broadcast_80_piece0 on 02926ee04bc9:45221 in memory (size: 77.4 KiB, free: 365.7 MiB)
26/01/12 02:12:56 INFO TaskSetManager: Starting task 0.0 in stage 55.0 (TID 129) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:12:56 INFO TaskSetManager: Starting task 1.0 in stage 55.0 (TID 130) (172.18.0.5, executor 0, partition 1, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:12:56 INFO BlockManagerInfo: Removed broadcast_80_piece0 on 172.18.0.5:42453 in memory (size: 77.4 KiB, free: 365.8 MiB)
26/01/12 02:12:56 INFO BlockManagerInfo: Removed broadcast_72_piece0 on 02926ee04bc9:45221 in memory (size: 36.8 KiB, free: 365.7 MiB)
26/01/12 02:12:56 INFO BlockManagerInfo: Removed broadcast_72_piece0 on 172.18.0.5:42453 in memory (size: 36.8 KiB, free: 365.8 MiB)
26/01/12 02:12:56 INFO BlockManagerInfo: Added broadcast_83_piece0 in memory on 172.18.0.5:42453 (size: 77.4 KiB, free: 365.8 MiB)
26/01/12 02:12:56 INFO BlockManagerInfo: Removed broadcast_78_piece0 on 02926ee04bc9:45221 in memory (size: 36.8 KiB, free: 365.8 MiB)
26/01/12 02:12:56 INFO BlockManagerInfo: Removed broadcast_78_piece0 on 172.18.0.5:42453 in memory (size: 36.8 KiB, free: 365.8 MiB)
26/01/12 02:12:56 INFO BlockManagerInfo: Removed broadcast_71_piece0 on 02926ee04bc9:45221 in memory (size: 77.3 KiB, free: 365.8 MiB)
26/01/12 02:12:56 INFO BlockManagerInfo: Removed broadcast_71_piece0 on 172.18.0.5:42453 in memory (size: 77.3 KiB, free: 365.9 MiB)
26/01/12 02:12:56 INFO BlockManagerInfo: Removed broadcast_70_piece0 on 02926ee04bc9:45221 in memory (size: 35.2 KiB, free: 365.9 MiB)
26/01/12 02:12:56 INFO BlockManagerInfo: Removed broadcast_70_piece0 on 172.18.0.5:42453 in memory (size: 35.2 KiB, free: 365.9 MiB)
26/01/12 02:12:56 INFO BlockManagerInfo: Added broadcast_82_piece0 in memory on 172.18.0.5:42453 (size: 35.4 KiB, free: 365.9 MiB)
26/01/12 02:12:56 INFO BlockManagerInfo: Removed broadcast_76_piece0 on 02926ee04bc9:45221 in memory (size: 35.4 KiB, free: 365.9 MiB)
26/01/12 02:12:56 INFO BlockManagerInfo: Removed broadcast_76_piece0 on 172.18.0.5:42453 in memory (size: 35.4 KiB, free: 365.9 MiB)
26/01/12 02:12:56 INFO BlockManagerInfo: Removed broadcast_67_piece0 on 02926ee04bc9:45221 in memory (size: 35.2 KiB, free: 365.9 MiB)
26/01/12 02:12:56 INFO BlockManagerInfo: Removed broadcast_67_piece0 on 172.18.0.5:42453 in memory (size: 35.2 KiB, free: 365.9 MiB)
26/01/12 02:12:56 INFO BlockManagerInfo: Removed broadcast_68_piece0 on 02926ee04bc9:45221 in memory (size: 77.3 KiB, free: 366.0 MiB)
26/01/12 02:12:56 INFO BlockManagerInfo: Removed broadcast_68_piece0 on 172.18.0.5:42453 in memory (size: 77.3 KiB, free: 366.0 MiB)
26/01/12 02:12:56 INFO BlockManagerInfo: Removed broadcast_81_piece0 on 02926ee04bc9:45221 in memory (size: 36.8 KiB, free: 366.0 MiB)
26/01/12 02:12:56 INFO BlockManagerInfo: Removed broadcast_81_piece0 on 172.18.0.5:42453 in memory (size: 36.8 KiB, free: 366.0 MiB)
26/01/12 02:12:56 INFO BlockManagerInfo: Removed broadcast_69_piece0 on 02926ee04bc9:45221 in memory (size: 36.8 KiB, free: 366.1 MiB)
26/01/12 02:12:56 INFO BlockManagerInfo: Removed broadcast_69_piece0 on 172.18.0.5:42453 in memory (size: 36.8 KiB, free: 366.1 MiB)
26/01/12 02:12:56 INFO BlockManagerInfo: Removed broadcast_74_piece0 on 02926ee04bc9:45221 in memory (size: 77.3 KiB, free: 366.2 MiB)
26/01/12 02:12:56 INFO TaskSetManager: Finished task 1.0 in stage 55.0 (TID 130) in 90 ms on 172.18.0.5 (executor 0) (1/2)
26/01/12 02:12:56 INFO BlockManagerInfo: Removed broadcast_74_piece0 on 172.18.0.5:42453 in memory (size: 77.3 KiB, free: 366.2 MiB)
26/01/12 02:12:56 INFO BlockManagerInfo: Removed broadcast_75_piece0 on 02926ee04bc9:45221 in memory (size: 36.8 KiB, free: 366.2 MiB)
26/01/12 02:12:56 INFO BlockManagerInfo: Removed broadcast_75_piece0 on 172.18.0.5:42453 in memory (size: 36.8 KiB, free: 366.2 MiB)
26/01/12 02:13:30 INFO TaskSetManager: Finished task 0.0 in stage 55.0 (TID 129) in 33958 ms on 172.18.0.5 (executor 0) (2/2)
26/01/12 02:13:30 INFO TaskSchedulerImpl: Removed TaskSet 55.0, whose tasks have all completed, from pool 
26/01/12 02:13:30 INFO DAGScheduler: ResultStage 55 (parquet at <unknown>:0) finished in 33.989 s
26/01/12 02:13:30 INFO DAGScheduler: Job 55 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:13:30 INFO TaskSchedulerImpl: Killing all running tasks in stage 55: Stage finished
26/01/12 02:13:30 INFO DAGScheduler: Job 55 finished: parquet at <unknown>:0, took 34.006881 s
26/01/12 02:13:30 INFO FileFormatWriter: Start to commit write Job 153c4821-bf56-4038-969f-5801ffc61d0d.
26/01/12 02:13:30 INFO FileFormatWriter: Write Job 153c4821-bf56-4038-969f-5801ffc61d0d committed. Elapsed time: 36 ms.
26/01/12 02:13:30 INFO FileFormatWriter: Finished processing stats for write job 153c4821-bf56-4038-969f-5801ffc61d0d.
Cargando: yellow_tripdata_2011-05.parquet en hdfs://hadoop-namenode:8020/data/nyc/raw/taxi-trips/2011...
26/01/12 02:13:30 INFO InMemoryFileIndex: It took 8 ms to list leaf files for 1 paths.
26/01/12 02:13:30 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 02:13:30 INFO DAGScheduler: Got job 56 (parquet at <unknown>:0) with 1 output partitions
26/01/12 02:13:30 INFO DAGScheduler: Final stage: ResultStage 56 (parquet at <unknown>:0)
26/01/12 02:13:30 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:13:30 INFO DAGScheduler: Missing parents: List()
26/01/12 02:13:30 INFO DAGScheduler: Submitting ResultStage 56 (MapPartitionsRDD[141] at parquet at <unknown>:0), which has no missing parents
26/01/12 02:13:30 INFO MemoryStore: Block broadcast_84 stored as values in memory (estimated size 102.6 KiB, free 365.5 MiB)
26/01/12 02:13:30 INFO MemoryStore: Block broadcast_84_piece0 stored as bytes in memory (estimated size 36.8 KiB, free 365.5 MiB)
26/01/12 02:13:30 INFO BlockManagerInfo: Added broadcast_84_piece0 in memory on 02926ee04bc9:45221 (size: 36.8 KiB, free: 366.2 MiB)
26/01/12 02:13:30 INFO SparkContext: Created broadcast 84 from broadcast at DAGScheduler.scala:1513
26/01/12 02:13:30 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 56 (MapPartitionsRDD[141] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0))
26/01/12 02:13:30 INFO TaskSchedulerImpl: Adding task set 56.0 with 1 tasks resource profile 0
26/01/12 02:13:30 INFO TaskSetManager: Starting task 0.0 in stage 56.0 (TID 131) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4607 bytes) taskResourceAssignments Map()
26/01/12 02:13:30 INFO BlockManagerInfo: Added broadcast_84_piece0 in memory on 172.18.0.5:42453 (size: 36.8 KiB, free: 366.2 MiB)
26/01/12 02:13:30 INFO TaskSetManager: Finished task 0.0 in stage 56.0 (TID 131) in 52 ms on 172.18.0.5 (executor 0) (1/1)
26/01/12 02:13:30 INFO TaskSchedulerImpl: Removed TaskSet 56.0, whose tasks have all completed, from pool 
26/01/12 02:13:30 INFO DAGScheduler: ResultStage 56 (parquet at <unknown>:0) finished in 0.066 s
26/01/12 02:13:30 INFO DAGScheduler: Job 56 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:13:30 INFO TaskSchedulerImpl: Killing all running tasks in stage 56: Stage finished
26/01/12 02:13:30 INFO DAGScheduler: Job 56 finished: parquet at <unknown>:0, took 0.072184 s
26/01/12 02:13:30 INFO FileSourceStrategy: Pushed Filters: 
26/01/12 02:13:30 INFO FileSourceStrategy: Post-Scan Filters: 
26/01/12 02:13:30 INFO FileSourceStrategy: Output Data Schema: struct<VendorID: bigint, tpep_pickup_datetime: timestamp, tpep_dropoff_datetime: timestamp, passenger_count: bigint, trip_distance: double ... 17 more fields>
26/01/12 02:13:30 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:13:30 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:13:30 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:13:30 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:13:30 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:13:30 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:13:30 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:13:30 INFO MemoryStore: Block broadcast_85 stored as values in memory (estimated size 358.4 KiB, free 365.1 MiB)
26/01/12 02:13:30 INFO MemoryStore: Block broadcast_85_piece0 stored as bytes in memory (estimated size 35.4 KiB, free 365.1 MiB)
26/01/12 02:13:30 INFO BlockManagerInfo: Added broadcast_85_piece0 in memory on 02926ee04bc9:45221 (size: 35.4 KiB, free: 366.1 MiB)
26/01/12 02:13:30 INFO SparkContext: Created broadcast 85 from parquet at <unknown>:0
26/01/12 02:13:30 INFO FileSourceScanExec: Planning scan with bin packing, max size: 98813477 bytes, open cost is considered as scanning 4194304 bytes.
26/01/12 02:13:30 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 02:13:31 INFO DAGScheduler: Got job 57 (parquet at <unknown>:0) with 2 output partitions
26/01/12 02:13:31 INFO DAGScheduler: Final stage: ResultStage 57 (parquet at <unknown>:0)
26/01/12 02:13:31 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:13:31 INFO DAGScheduler: Missing parents: List()
26/01/12 02:13:31 INFO DAGScheduler: Submitting ResultStage 57 (MapPartitionsRDD[144] at parquet at <unknown>:0), which has no missing parents
26/01/12 02:13:31 INFO MemoryStore: Block broadcast_86 stored as values in memory (estimated size 225.1 KiB, free 364.9 MiB)
26/01/12 02:13:31 INFO MemoryStore: Block broadcast_86_piece0 stored as bytes in memory (estimated size 77.4 KiB, free 364.8 MiB)
26/01/12 02:13:31 INFO BlockManagerInfo: Added broadcast_86_piece0 in memory on 02926ee04bc9:45221 (size: 77.4 KiB, free: 366.0 MiB)
26/01/12 02:13:31 INFO SparkContext: Created broadcast 86 from broadcast at DAGScheduler.scala:1513
26/01/12 02:13:31 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 57 (MapPartitionsRDD[144] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1))
26/01/12 02:13:31 INFO TaskSchedulerImpl: Adding task set 57.0 with 2 tasks resource profile 0
26/01/12 02:13:31 INFO TaskSetManager: Starting task 0.0 in stage 57.0 (TID 132) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:13:31 INFO TaskSetManager: Starting task 1.0 in stage 57.0 (TID 133) (172.18.0.5, executor 0, partition 1, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:13:31 INFO BlockManagerInfo: Added broadcast_86_piece0 in memory on 172.18.0.5:42453 (size: 77.4 KiB, free: 366.1 MiB)
26/01/12 02:13:31 INFO BlockManagerInfo: Added broadcast_85_piece0 in memory on 172.18.0.5:42453 (size: 35.4 KiB, free: 366.0 MiB)
26/01/12 02:13:31 INFO TaskSetManager: Finished task 1.0 in stage 57.0 (TID 133) in 65 ms on 172.18.0.5 (executor 0) (1/2)
26/01/12 02:14:06 INFO TaskSetManager: Finished task 0.0 in stage 57.0 (TID 132) in 35932 ms on 172.18.0.5 (executor 0) (2/2)
26/01/12 02:14:06 INFO TaskSchedulerImpl: Removed TaskSet 57.0, whose tasks have all completed, from pool 
26/01/12 02:14:06 INFO DAGScheduler: ResultStage 57 (parquet at <unknown>:0) finished in 35.981 s
26/01/12 02:14:06 INFO DAGScheduler: Job 57 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:14:06 INFO TaskSchedulerImpl: Killing all running tasks in stage 57: Stage finished
26/01/12 02:14:06 INFO DAGScheduler: Job 57 finished: parquet at <unknown>:0, took 35.989423 s
26/01/12 02:14:06 INFO FileFormatWriter: Start to commit write Job 32faea92-7f0c-4237-9cde-9fe85ed0d5e4.
26/01/12 02:14:07 INFO FileFormatWriter: Write Job 32faea92-7f0c-4237-9cde-9fe85ed0d5e4 committed. Elapsed time: 33 ms.
26/01/12 02:14:07 INFO FileFormatWriter: Finished processing stats for write job 32faea92-7f0c-4237-9cde-9fe85ed0d5e4.
Cargando: yellow_tripdata_2011-06.parquet en hdfs://hadoop-namenode:8020/data/nyc/raw/taxi-trips/2011...
26/01/12 02:14:07 INFO InMemoryFileIndex: It took 7 ms to list leaf files for 1 paths.
26/01/12 02:14:07 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 02:14:07 INFO DAGScheduler: Got job 58 (parquet at <unknown>:0) with 1 output partitions
26/01/12 02:14:07 INFO DAGScheduler: Final stage: ResultStage 58 (parquet at <unknown>:0)
26/01/12 02:14:07 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:14:07 INFO DAGScheduler: Missing parents: List()
26/01/12 02:14:07 INFO DAGScheduler: Submitting ResultStage 58 (MapPartitionsRDD[146] at parquet at <unknown>:0), which has no missing parents
26/01/12 02:14:07 INFO MemoryStore: Block broadcast_87 stored as values in memory (estimated size 102.6 KiB, free 364.7 MiB)
26/01/12 02:14:07 INFO MemoryStore: Block broadcast_87_piece0 stored as bytes in memory (estimated size 36.8 KiB, free 364.7 MiB)
26/01/12 02:14:07 INFO BlockManagerInfo: Added broadcast_87_piece0 in memory on 02926ee04bc9:45221 (size: 36.8 KiB, free: 366.0 MiB)
26/01/12 02:14:07 INFO SparkContext: Created broadcast 87 from broadcast at DAGScheduler.scala:1513
26/01/12 02:14:07 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 58 (MapPartitionsRDD[146] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0))
26/01/12 02:14:07 INFO TaskSchedulerImpl: Adding task set 58.0 with 1 tasks resource profile 0
26/01/12 02:14:07 INFO TaskSetManager: Starting task 0.0 in stage 58.0 (TID 134) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4607 bytes) taskResourceAssignments Map()
26/01/12 02:14:07 INFO BlockManagerInfo: Added broadcast_87_piece0 in memory on 172.18.0.5:42453 (size: 36.8 KiB, free: 366.0 MiB)
26/01/12 02:14:07 INFO TaskSetManager: Finished task 0.0 in stage 58.0 (TID 134) in 51 ms on 172.18.0.5 (executor 0) (1/1)
26/01/12 02:14:07 INFO TaskSchedulerImpl: Removed TaskSet 58.0, whose tasks have all completed, from pool 
26/01/12 02:14:07 INFO DAGScheduler: ResultStage 58 (parquet at <unknown>:0) finished in 0.064 s
26/01/12 02:14:07 INFO DAGScheduler: Job 58 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:14:07 INFO TaskSchedulerImpl: Killing all running tasks in stage 58: Stage finished
26/01/12 02:14:07 INFO DAGScheduler: Job 58 finished: parquet at <unknown>:0, took 0.069665 s
26/01/12 02:14:07 INFO FileSourceStrategy: Pushed Filters: 
26/01/12 02:14:07 INFO FileSourceStrategy: Post-Scan Filters: 
26/01/12 02:14:07 INFO FileSourceStrategy: Output Data Schema: struct<VendorID: bigint, tpep_pickup_datetime: timestamp, tpep_dropoff_datetime: timestamp, passenger_count: bigint, trip_distance: double ... 17 more fields>
26/01/12 02:14:07 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:14:07 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:14:07 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:14:07 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:14:07 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:14:07 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:14:07 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:14:07 INFO MemoryStore: Block broadcast_88 stored as values in memory (estimated size 358.4 KiB, free 364.3 MiB)
26/01/12 02:14:07 INFO MemoryStore: Block broadcast_88_piece0 stored as bytes in memory (estimated size 35.4 KiB, free 364.3 MiB)
26/01/12 02:14:07 INFO BlockManagerInfo: Added broadcast_88_piece0 in memory on 02926ee04bc9:45221 (size: 35.4 KiB, free: 366.0 MiB)
26/01/12 02:14:07 INFO SparkContext: Created broadcast 88 from parquet at <unknown>:0
26/01/12 02:14:07 INFO FileSourceScanExec: Planning scan with bin packing, max size: 96657113 bytes, open cost is considered as scanning 4194304 bytes.
26/01/12 02:14:07 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 02:14:07 INFO DAGScheduler: Got job 59 (parquet at <unknown>:0) with 2 output partitions
26/01/12 02:14:07 INFO DAGScheduler: Final stage: ResultStage 59 (parquet at <unknown>:0)
26/01/12 02:14:07 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:14:07 INFO DAGScheduler: Missing parents: List()
26/01/12 02:14:07 INFO DAGScheduler: Submitting ResultStage 59 (MapPartitionsRDD[149] at parquet at <unknown>:0), which has no missing parents
26/01/12 02:14:07 INFO MemoryStore: Block broadcast_89 stored as values in memory (estimated size 225.1 KiB, free 364.1 MiB)
26/01/12 02:14:07 INFO MemoryStore: Block broadcast_89_piece0 stored as bytes in memory (estimated size 77.4 KiB, free 364.0 MiB)
26/01/12 02:14:07 INFO BlockManagerInfo: Added broadcast_89_piece0 in memory on 02926ee04bc9:45221 (size: 77.4 KiB, free: 365.9 MiB)
26/01/12 02:14:07 INFO SparkContext: Created broadcast 89 from broadcast at DAGScheduler.scala:1513
26/01/12 02:14:07 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 59 (MapPartitionsRDD[149] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1))
26/01/12 02:14:07 INFO TaskSchedulerImpl: Adding task set 59.0 with 2 tasks resource profile 0
26/01/12 02:14:07 INFO TaskSetManager: Starting task 0.0 in stage 59.0 (TID 135) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:14:07 INFO TaskSetManager: Starting task 1.0 in stage 59.0 (TID 136) (172.18.0.5, executor 0, partition 1, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:14:07 INFO BlockManagerInfo: Added broadcast_89_piece0 in memory on 172.18.0.5:42453 (size: 77.4 KiB, free: 365.9 MiB)
26/01/12 02:14:07 INFO BlockManagerInfo: Added broadcast_88_piece0 in memory on 172.18.0.5:42453 (size: 35.4 KiB, free: 365.9 MiB)
26/01/12 02:14:07 INFO TaskSetManager: Finished task 1.0 in stage 59.0 (TID 136) in 63 ms on 172.18.0.5 (executor 0) (1/2)
26/01/12 02:14:40 INFO TaskSetManager: Finished task 0.0 in stage 59.0 (TID 135) in 32982 ms on 172.18.0.5 (executor 0) (2/2)
26/01/12 02:14:40 INFO TaskSchedulerImpl: Removed TaskSet 59.0, whose tasks have all completed, from pool 
26/01/12 02:14:40 INFO DAGScheduler: ResultStage 59 (parquet at <unknown>:0) finished in 33.004 s
26/01/12 02:14:40 INFO DAGScheduler: Job 59 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:14:40 INFO TaskSchedulerImpl: Killing all running tasks in stage 59: Stage finished
26/01/12 02:14:40 INFO DAGScheduler: Job 59 finished: parquet at <unknown>:0, took 33.011514 s
26/01/12 02:14:40 INFO FileFormatWriter: Start to commit write Job d531a0c9-5848-46a4-9dc6-1e1014f414d7.
26/01/12 02:14:40 INFO FileFormatWriter: Write Job d531a0c9-5848-46a4-9dc6-1e1014f414d7 committed. Elapsed time: 24 ms.
26/01/12 02:14:40 INFO FileFormatWriter: Finished processing stats for write job d531a0c9-5848-46a4-9dc6-1e1014f414d7.
Cargando: yellow_tripdata_2011-07.parquet en hdfs://hadoop-namenode:8020/data/nyc/raw/taxi-trips/2011...
26/01/12 02:14:40 INFO InMemoryFileIndex: It took 6 ms to list leaf files for 1 paths.
26/01/12 02:14:40 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 02:14:40 INFO DAGScheduler: Got job 60 (parquet at <unknown>:0) with 1 output partitions
26/01/12 02:14:40 INFO DAGScheduler: Final stage: ResultStage 60 (parquet at <unknown>:0)
26/01/12 02:14:40 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:14:40 INFO DAGScheduler: Missing parents: List()
26/01/12 02:14:40 INFO DAGScheduler: Submitting ResultStage 60 (MapPartitionsRDD[151] at parquet at <unknown>:0), which has no missing parents
26/01/12 02:14:40 INFO MemoryStore: Block broadcast_90 stored as values in memory (estimated size 102.6 KiB, free 363.9 MiB)
26/01/12 02:14:40 INFO MemoryStore: Block broadcast_90_piece0 stored as bytes in memory (estimated size 36.8 KiB, free 363.9 MiB)
26/01/12 02:14:40 INFO BlockManagerInfo: Added broadcast_90_piece0 in memory on 02926ee04bc9:45221 (size: 36.8 KiB, free: 365.9 MiB)
26/01/12 02:14:40 INFO SparkContext: Created broadcast 90 from broadcast at DAGScheduler.scala:1513
26/01/12 02:14:40 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 60 (MapPartitionsRDD[151] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0))
26/01/12 02:14:40 INFO TaskSchedulerImpl: Adding task set 60.0 with 1 tasks resource profile 0
26/01/12 02:14:40 INFO TaskSetManager: Starting task 0.0 in stage 60.0 (TID 137) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4607 bytes) taskResourceAssignments Map()
26/01/12 02:14:40 INFO BlockManagerInfo: Added broadcast_90_piece0 in memory on 172.18.0.5:42453 (size: 36.8 KiB, free: 365.9 MiB)
26/01/12 02:14:40 INFO TaskSetManager: Finished task 0.0 in stage 60.0 (TID 137) in 53 ms on 172.18.0.5 (executor 0) (1/1)
26/01/12 02:14:40 INFO TaskSchedulerImpl: Removed TaskSet 60.0, whose tasks have all completed, from pool 
26/01/12 02:14:40 INFO DAGScheduler: ResultStage 60 (parquet at <unknown>:0) finished in 0.068 s
26/01/12 02:14:40 INFO DAGScheduler: Job 60 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:14:40 INFO TaskSchedulerImpl: Killing all running tasks in stage 60: Stage finished
26/01/12 02:14:40 INFO DAGScheduler: Job 60 finished: parquet at <unknown>:0, took 0.072964 s
26/01/12 02:14:40 INFO FileSourceStrategy: Pushed Filters: 
26/01/12 02:14:40 INFO FileSourceStrategy: Post-Scan Filters: 
26/01/12 02:14:40 INFO FileSourceStrategy: Output Data Schema: struct<VendorID: bigint, tpep_pickup_datetime: timestamp, tpep_dropoff_datetime: timestamp, passenger_count: bigint, trip_distance: double ... 17 more fields>
26/01/12 02:14:40 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:14:40 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:14:40 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:14:40 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:14:40 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:14:40 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:14:40 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:14:40 INFO MemoryStore: Block broadcast_91 stored as values in memory (estimated size 358.4 KiB, free 363.5 MiB)
26/01/12 02:14:40 INFO MemoryStore: Block broadcast_91_piece0 stored as bytes in memory (estimated size 35.4 KiB, free 363.5 MiB)
26/01/12 02:14:40 INFO BlockManagerInfo: Added broadcast_91_piece0 in memory on 02926ee04bc9:45221 (size: 35.4 KiB, free: 365.8 MiB)
26/01/12 02:14:40 INFO SparkContext: Created broadcast 91 from parquet at <unknown>:0
26/01/12 02:14:40 INFO FileSourceScanExec: Planning scan with bin packing, max size: 94110977 bytes, open cost is considered as scanning 4194304 bytes.
26/01/12 02:14:40 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 02:14:40 INFO DAGScheduler: Got job 61 (parquet at <unknown>:0) with 2 output partitions
26/01/12 02:14:40 INFO DAGScheduler: Final stage: ResultStage 61 (parquet at <unknown>:0)
26/01/12 02:14:40 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:14:40 INFO DAGScheduler: Missing parents: List()
26/01/12 02:14:40 INFO DAGScheduler: Submitting ResultStage 61 (MapPartitionsRDD[154] at parquet at <unknown>:0), which has no missing parents
26/01/12 02:14:40 INFO MemoryStore: Block broadcast_92 stored as values in memory (estimated size 225.1 KiB, free 363.2 MiB)
26/01/12 02:14:40 INFO MemoryStore: Block broadcast_92_piece0 stored as bytes in memory (estimated size 77.5 KiB, free 363.2 MiB)
26/01/12 02:14:40 INFO BlockManagerInfo: Added broadcast_92_piece0 in memory on 02926ee04bc9:45221 (size: 77.5 KiB, free: 365.8 MiB)
26/01/12 02:14:40 INFO SparkContext: Created broadcast 92 from broadcast at DAGScheduler.scala:1513
26/01/12 02:14:40 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 61 (MapPartitionsRDD[154] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1))
26/01/12 02:14:40 INFO TaskSchedulerImpl: Adding task set 61.0 with 2 tasks resource profile 0
26/01/12 02:14:40 INFO TaskSetManager: Starting task 0.0 in stage 61.0 (TID 138) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:14:40 INFO TaskSetManager: Starting task 1.0 in stage 61.0 (TID 139) (172.18.0.5, executor 0, partition 1, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:14:40 INFO BlockManagerInfo: Added broadcast_92_piece0 in memory on 172.18.0.5:42453 (size: 77.5 KiB, free: 365.8 MiB)
26/01/12 02:14:40 INFO BlockManagerInfo: Added broadcast_91_piece0 in memory on 172.18.0.5:42453 (size: 35.4 KiB, free: 365.8 MiB)
26/01/12 02:14:40 INFO TaskSetManager: Finished task 1.0 in stage 61.0 (TID 139) in 62 ms on 172.18.0.5 (executor 0) (1/2)
26/01/12 02:15:12 INFO TaskSetManager: Finished task 0.0 in stage 61.0 (TID 138) in 31627 ms on 172.18.0.5 (executor 0) (2/2)
26/01/12 02:15:12 INFO TaskSchedulerImpl: Removed TaskSet 61.0, whose tasks have all completed, from pool 
26/01/12 02:15:12 INFO DAGScheduler: ResultStage 61 (parquet at <unknown>:0) finished in 31.648 s
26/01/12 02:15:12 INFO DAGScheduler: Job 61 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:15:12 INFO TaskSchedulerImpl: Killing all running tasks in stage 61: Stage finished
26/01/12 02:15:12 INFO DAGScheduler: Job 61 finished: parquet at <unknown>:0, took 31.655028 s
26/01/12 02:15:12 INFO FileFormatWriter: Start to commit write Job a58fb66f-dbfd-49e9-9435-4a6c8afc4b4b.
26/01/12 02:15:12 INFO FileFormatWriter: Write Job a58fb66f-dbfd-49e9-9435-4a6c8afc4b4b committed. Elapsed time: 25 ms.
26/01/12 02:15:12 INFO FileFormatWriter: Finished processing stats for write job a58fb66f-dbfd-49e9-9435-4a6c8afc4b4b.
Cargando: yellow_tripdata_2011-08.parquet en hdfs://hadoop-namenode:8020/data/nyc/raw/taxi-trips/2011...
26/01/12 02:15:12 INFO InMemoryFileIndex: It took 7 ms to list leaf files for 1 paths.
26/01/12 02:15:12 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 02:15:12 INFO DAGScheduler: Got job 62 (parquet at <unknown>:0) with 1 output partitions
26/01/12 02:15:12 INFO DAGScheduler: Final stage: ResultStage 62 (parquet at <unknown>:0)
26/01/12 02:15:12 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:15:12 INFO DAGScheduler: Missing parents: List()
26/01/12 02:15:12 INFO DAGScheduler: Submitting ResultStage 62 (MapPartitionsRDD[156] at parquet at <unknown>:0), which has no missing parents
26/01/12 02:15:12 INFO MemoryStore: Block broadcast_93 stored as values in memory (estimated size 102.6 KiB, free 363.1 MiB)
26/01/12 02:15:12 INFO MemoryStore: Block broadcast_93_piece0 stored as bytes in memory (estimated size 36.8 KiB, free 363.0 MiB)
26/01/12 02:15:12 INFO BlockManagerInfo: Added broadcast_93_piece0 in memory on 02926ee04bc9:45221 (size: 36.8 KiB, free: 365.7 MiB)
26/01/12 02:15:12 INFO SparkContext: Created broadcast 93 from broadcast at DAGScheduler.scala:1513
26/01/12 02:15:12 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 62 (MapPartitionsRDD[156] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0))
26/01/12 02:15:12 INFO TaskSchedulerImpl: Adding task set 62.0 with 1 tasks resource profile 0
26/01/12 02:15:12 INFO TaskSetManager: Starting task 0.0 in stage 62.0 (TID 140) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4607 bytes) taskResourceAssignments Map()
26/01/12 02:15:12 INFO BlockManagerInfo: Added broadcast_93_piece0 in memory on 172.18.0.5:42453 (size: 36.8 KiB, free: 365.7 MiB)
26/01/12 02:15:12 INFO TaskSetManager: Finished task 0.0 in stage 62.0 (TID 140) in 50 ms on 172.18.0.5 (executor 0) (1/1)
26/01/12 02:15:12 INFO TaskSchedulerImpl: Removed TaskSet 62.0, whose tasks have all completed, from pool 
26/01/12 02:15:12 INFO DAGScheduler: ResultStage 62 (parquet at <unknown>:0) finished in 0.063 s
26/01/12 02:15:12 INFO DAGScheduler: Job 62 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:15:12 INFO TaskSchedulerImpl: Killing all running tasks in stage 62: Stage finished
26/01/12 02:15:12 INFO DAGScheduler: Job 62 finished: parquet at <unknown>:0, took 0.067931 s
26/01/12 02:15:12 INFO FileSourceStrategy: Pushed Filters: 
26/01/12 02:15:12 INFO FileSourceStrategy: Post-Scan Filters: 
26/01/12 02:15:12 INFO FileSourceStrategy: Output Data Schema: struct<VendorID: bigint, tpep_pickup_datetime: timestamp, tpep_dropoff_datetime: timestamp, passenger_count: bigint, trip_distance: double ... 17 more fields>
26/01/12 02:15:12 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:15:12 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:15:12 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:15:12 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:15:12 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:15:12 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:15:12 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:15:12 INFO MemoryStore: Block broadcast_94 stored as values in memory (estimated size 358.4 KiB, free 362.7 MiB)
26/01/12 02:15:12 INFO MemoryStore: Block broadcast_94_piece0 stored as bytes in memory (estimated size 35.4 KiB, free 362.7 MiB)
26/01/12 02:15:12 INFO BlockManagerInfo: Added broadcast_94_piece0 in memory on 02926ee04bc9:45221 (size: 35.4 KiB, free: 365.7 MiB)
26/01/12 02:15:12 INFO SparkContext: Created broadcast 94 from parquet at <unknown>:0
26/01/12 02:15:12 INFO FileSourceScanExec: Planning scan with bin packing, max size: 85204576 bytes, open cost is considered as scanning 4194304 bytes.
26/01/12 02:15:12 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 02:15:12 INFO DAGScheduler: Got job 63 (parquet at <unknown>:0) with 2 output partitions
26/01/12 02:15:12 INFO DAGScheduler: Final stage: ResultStage 63 (parquet at <unknown>:0)
26/01/12 02:15:12 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:15:12 INFO DAGScheduler: Missing parents: List()
26/01/12 02:15:12 INFO DAGScheduler: Submitting ResultStage 63 (MapPartitionsRDD[159] at parquet at <unknown>:0), which has no missing parents
26/01/12 02:15:12 INFO MemoryStore: Block broadcast_95 stored as values in memory (estimated size 225.1 KiB, free 362.4 MiB)
26/01/12 02:15:12 INFO MemoryStore: Block broadcast_95_piece0 stored as bytes in memory (estimated size 77.4 KiB, free 362.4 MiB)
26/01/12 02:15:12 INFO BlockManagerInfo: Added broadcast_95_piece0 in memory on 02926ee04bc9:45221 (size: 77.4 KiB, free: 365.6 MiB)
26/01/12 02:15:12 INFO SparkContext: Created broadcast 95 from broadcast at DAGScheduler.scala:1513
26/01/12 02:15:12 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 63 (MapPartitionsRDD[159] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1))
26/01/12 02:15:12 INFO TaskSchedulerImpl: Adding task set 63.0 with 2 tasks resource profile 0
26/01/12 02:15:12 INFO TaskSetManager: Starting task 0.0 in stage 63.0 (TID 141) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:15:12 INFO TaskSetManager: Starting task 1.0 in stage 63.0 (TID 142) (172.18.0.5, executor 0, partition 1, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:15:12 INFO BlockManagerInfo: Added broadcast_95_piece0 in memory on 172.18.0.5:42453 (size: 77.4 KiB, free: 365.6 MiB)
26/01/12 02:15:12 INFO BlockManagerInfo: Added broadcast_94_piece0 in memory on 172.18.0.5:42453 (size: 35.4 KiB, free: 365.6 MiB)
26/01/12 02:15:12 INFO TaskSetManager: Finished task 1.0 in stage 63.0 (TID 142) in 61 ms on 172.18.0.5 (executor 0) (1/2)
26/01/12 02:15:40 INFO TaskSetManager: Finished task 0.0 in stage 63.0 (TID 141) in 27928 ms on 172.18.0.5 (executor 0) (2/2)
26/01/12 02:15:40 INFO TaskSchedulerImpl: Removed TaskSet 63.0, whose tasks have all completed, from pool 
26/01/12 02:15:40 INFO DAGScheduler: ResultStage 63 (parquet at <unknown>:0) finished in 27.953 s
26/01/12 02:15:40 INFO DAGScheduler: Job 63 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:15:40 INFO TaskSchedulerImpl: Killing all running tasks in stage 63: Stage finished
26/01/12 02:15:40 INFO DAGScheduler: Job 63 finished: parquet at <unknown>:0, took 27.960169 s
26/01/12 02:15:40 INFO FileFormatWriter: Start to commit write Job e8298e91-67c8-4c56-8d67-fed70ff0a637.
26/01/12 02:15:40 INFO FileFormatWriter: Write Job e8298e91-67c8-4c56-8d67-fed70ff0a637 committed. Elapsed time: 27 ms.
26/01/12 02:15:40 INFO FileFormatWriter: Finished processing stats for write job e8298e91-67c8-4c56-8d67-fed70ff0a637.
Cargando: yellow_tripdata_2011-09.parquet en hdfs://hadoop-namenode:8020/data/nyc/raw/taxi-trips/2011...
26/01/12 02:15:40 INFO InMemoryFileIndex: It took 6 ms to list leaf files for 1 paths.
26/01/12 02:15:40 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 02:15:40 INFO DAGScheduler: Got job 64 (parquet at <unknown>:0) with 1 output partitions
26/01/12 02:15:40 INFO DAGScheduler: Final stage: ResultStage 64 (parquet at <unknown>:0)
26/01/12 02:15:40 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:15:40 INFO DAGScheduler: Missing parents: List()
26/01/12 02:15:40 INFO DAGScheduler: Submitting ResultStage 64 (MapPartitionsRDD[161] at parquet at <unknown>:0), which has no missing parents
26/01/12 02:15:40 INFO MemoryStore: Block broadcast_96 stored as values in memory (estimated size 102.6 KiB, free 362.3 MiB)
26/01/12 02:15:40 INFO MemoryStore: Block broadcast_96_piece0 stored as bytes in memory (estimated size 36.8 KiB, free 362.2 MiB)
26/01/12 02:15:40 INFO BlockManagerInfo: Added broadcast_96_piece0 in memory on 02926ee04bc9:45221 (size: 36.8 KiB, free: 365.6 MiB)
26/01/12 02:15:40 INFO SparkContext: Created broadcast 96 from broadcast at DAGScheduler.scala:1513
26/01/12 02:15:40 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 64 (MapPartitionsRDD[161] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0))
26/01/12 02:15:40 INFO TaskSchedulerImpl: Adding task set 64.0 with 1 tasks resource profile 0
26/01/12 02:15:40 INFO TaskSetManager: Starting task 0.0 in stage 64.0 (TID 143) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4607 bytes) taskResourceAssignments Map()
26/01/12 02:15:40 INFO BlockManagerInfo: Added broadcast_96_piece0 in memory on 172.18.0.5:42453 (size: 36.8 KiB, free: 365.6 MiB)
26/01/12 02:15:40 INFO TaskSetManager: Finished task 0.0 in stage 64.0 (TID 143) in 51 ms on 172.18.0.5 (executor 0) (1/1)
26/01/12 02:15:40 INFO TaskSchedulerImpl: Removed TaskSet 64.0, whose tasks have all completed, from pool 
26/01/12 02:15:40 INFO DAGScheduler: ResultStage 64 (parquet at <unknown>:0) finished in 0.067 s
26/01/12 02:15:40 INFO DAGScheduler: Job 64 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:15:40 INFO TaskSchedulerImpl: Killing all running tasks in stage 64: Stage finished
26/01/12 02:15:40 INFO DAGScheduler: Job 64 finished: parquet at <unknown>:0, took 0.074138 s
26/01/12 02:15:40 INFO FileSourceStrategy: Pushed Filters: 
26/01/12 02:15:40 INFO FileSourceStrategy: Post-Scan Filters: 
26/01/12 02:15:40 INFO FileSourceStrategy: Output Data Schema: struct<VendorID: bigint, tpep_pickup_datetime: timestamp, tpep_dropoff_datetime: timestamp, passenger_count: bigint, trip_distance: double ... 17 more fields>
26/01/12 02:15:40 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:15:40 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:15:40 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:15:40 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:15:40 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:15:40 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:15:40 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:15:40 INFO MemoryStore: Block broadcast_97 stored as values in memory (estimated size 358.4 KiB, free 361.9 MiB)
26/01/12 02:15:40 INFO MemoryStore: Block broadcast_97_piece0 stored as bytes in memory (estimated size 35.4 KiB, free 361.8 MiB)
26/01/12 02:15:40 INFO BlockManagerInfo: Added broadcast_97_piece0 in memory on 02926ee04bc9:45221 (size: 35.4 KiB, free: 365.5 MiB)
26/01/12 02:15:40 INFO SparkContext: Created broadcast 97 from parquet at <unknown>:0
26/01/12 02:15:40 INFO FileSourceScanExec: Planning scan with bin packing, max size: 93843748 bytes, open cost is considered as scanning 4194304 bytes.
26/01/12 02:15:40 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 02:15:40 INFO DAGScheduler: Got job 65 (parquet at <unknown>:0) with 2 output partitions
26/01/12 02:15:40 INFO DAGScheduler: Final stage: ResultStage 65 (parquet at <unknown>:0)
26/01/12 02:15:40 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:15:40 INFO DAGScheduler: Missing parents: List()
26/01/12 02:15:40 INFO DAGScheduler: Submitting ResultStage 65 (MapPartitionsRDD[164] at parquet at <unknown>:0), which has no missing parents
26/01/12 02:15:40 INFO MemoryStore: Block broadcast_98 stored as values in memory (estimated size 225.1 KiB, free 361.6 MiB)
26/01/12 02:15:40 INFO MemoryStore: Block broadcast_98_piece0 stored as bytes in memory (estimated size 77.4 KiB, free 361.5 MiB)
26/01/12 02:15:40 INFO BlockManagerInfo: Added broadcast_98_piece0 in memory on 02926ee04bc9:45221 (size: 77.4 KiB, free: 365.5 MiB)
26/01/12 02:15:40 INFO SparkContext: Created broadcast 98 from broadcast at DAGScheduler.scala:1513
26/01/12 02:15:40 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 65 (MapPartitionsRDD[164] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1))
26/01/12 02:15:40 INFO TaskSchedulerImpl: Adding task set 65.0 with 2 tasks resource profile 0
26/01/12 02:15:40 INFO TaskSetManager: Starting task 0.0 in stage 65.0 (TID 144) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:15:40 INFO TaskSetManager: Starting task 1.0 in stage 65.0 (TID 145) (172.18.0.5, executor 0, partition 1, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:15:40 INFO BlockManagerInfo: Added broadcast_98_piece0 in memory on 172.18.0.5:42453 (size: 77.4 KiB, free: 365.5 MiB)
26/01/12 02:15:40 INFO BlockManagerInfo: Added broadcast_97_piece0 in memory on 172.18.0.5:42453 (size: 35.4 KiB, free: 365.5 MiB)
26/01/12 02:15:40 INFO TaskSetManager: Finished task 1.0 in stage 65.0 (TID 145) in 60 ms on 172.18.0.5 (executor 0) (1/2)
26/01/12 02:16:12 INFO TaskSetManager: Finished task 0.0 in stage 65.0 (TID 144) in 32297 ms on 172.18.0.5 (executor 0) (2/2)
26/01/12 02:16:12 INFO TaskSchedulerImpl: Removed TaskSet 65.0, whose tasks have all completed, from pool 
26/01/12 02:16:12 INFO DAGScheduler: ResultStage 65 (parquet at <unknown>:0) finished in 32.319 s
26/01/12 02:16:12 INFO DAGScheduler: Job 65 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:16:12 INFO TaskSchedulerImpl: Killing all running tasks in stage 65: Stage finished
26/01/12 02:16:12 INFO DAGScheduler: Job 65 finished: parquet at <unknown>:0, took 32.329587 s
26/01/12 02:16:12 INFO FileFormatWriter: Start to commit write Job 15d785b4-d56b-4c20-9dc4-70eb43efd75b.
26/01/12 02:16:12 INFO FileFormatWriter: Write Job 15d785b4-d56b-4c20-9dc4-70eb43efd75b committed. Elapsed time: 26 ms.
26/01/12 02:16:12 INFO FileFormatWriter: Finished processing stats for write job 15d785b4-d56b-4c20-9dc4-70eb43efd75b.
Cargando: yellow_tripdata_2011-10.parquet en hdfs://hadoop-namenode:8020/data/nyc/raw/taxi-trips/2011...
26/01/12 02:16:12 INFO InMemoryFileIndex: It took 5 ms to list leaf files for 1 paths.
26/01/12 02:16:12 INFO BlockManagerInfo: Removed broadcast_88_piece0 on 02926ee04bc9:45221 in memory (size: 35.4 KiB, free: 365.5 MiB)
26/01/12 02:16:12 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 02:16:12 INFO BlockManagerInfo: Removed broadcast_88_piece0 on 172.18.0.5:42453 in memory (size: 35.4 KiB, free: 365.5 MiB)
26/01/12 02:16:12 INFO DAGScheduler: Got job 66 (parquet at <unknown>:0) with 1 output partitions
26/01/12 02:16:12 INFO DAGScheduler: Final stage: ResultStage 66 (parquet at <unknown>:0)
26/01/12 02:16:12 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:16:12 INFO DAGScheduler: Missing parents: List()
26/01/12 02:16:12 INFO DAGScheduler: Submitting ResultStage 66 (MapPartitionsRDD[166] at parquet at <unknown>:0), which has no missing parents
26/01/12 02:16:12 INFO BlockManagerInfo: Removed broadcast_95_piece0 on 02926ee04bc9:45221 in memory (size: 77.4 KiB, free: 365.6 MiB)
26/01/12 02:16:12 INFO BlockManagerInfo: Removed broadcast_95_piece0 on 172.18.0.5:42453 in memory (size: 77.4 KiB, free: 365.6 MiB)
26/01/12 02:16:12 INFO MemoryStore: Block broadcast_99 stored as values in memory (estimated size 102.6 KiB, free 362.1 MiB)
26/01/12 02:16:12 INFO BlockManagerInfo: Removed broadcast_91_piece0 on 02926ee04bc9:45221 in memory (size: 35.4 KiB, free: 365.6 MiB)
26/01/12 02:16:12 INFO BlockManagerInfo: Removed broadcast_91_piece0 on 172.18.0.5:42453 in memory (size: 35.4 KiB, free: 365.6 MiB)
26/01/12 02:16:12 INFO MemoryStore: Block broadcast_99_piece0 stored as bytes in memory (estimated size 36.8 KiB, free 362.5 MiB)
26/01/12 02:16:12 INFO BlockManagerInfo: Added broadcast_99_piece0 in memory on 02926ee04bc9:45221 (size: 36.8 KiB, free: 365.6 MiB)
26/01/12 02:16:12 INFO SparkContext: Created broadcast 99 from broadcast at DAGScheduler.scala:1513
26/01/12 02:16:12 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 66 (MapPartitionsRDD[166] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0))
26/01/12 02:16:12 INFO TaskSchedulerImpl: Adding task set 66.0 with 1 tasks resource profile 0
26/01/12 02:16:12 INFO TaskSetManager: Starting task 0.0 in stage 66.0 (TID 146) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4607 bytes) taskResourceAssignments Map()
26/01/12 02:16:12 INFO BlockManagerInfo: Removed broadcast_86_piece0 on 02926ee04bc9:45221 in memory (size: 77.4 KiB, free: 365.6 MiB)
26/01/12 02:16:12 INFO BlockManagerInfo: Removed broadcast_86_piece0 on 172.18.0.5:42453 in memory (size: 77.4 KiB, free: 365.7 MiB)
26/01/12 02:16:12 INFO BlockManagerInfo: Removed broadcast_94_piece0 on 02926ee04bc9:45221 in memory (size: 35.4 KiB, free: 365.7 MiB)
26/01/12 02:16:12 INFO BlockManagerInfo: Removed broadcast_94_piece0 on 172.18.0.5:42453 in memory (size: 35.4 KiB, free: 365.7 MiB)
26/01/12 02:16:12 INFO BlockManagerInfo: Added broadcast_99_piece0 in memory on 172.18.0.5:42453 (size: 36.8 KiB, free: 365.7 MiB)
26/01/12 02:16:12 INFO BlockManagerInfo: Removed broadcast_87_piece0 on 02926ee04bc9:45221 in memory (size: 36.8 KiB, free: 365.7 MiB)
26/01/12 02:16:12 INFO BlockManagerInfo: Removed broadcast_87_piece0 on 172.18.0.5:42453 in memory (size: 36.8 KiB, free: 365.7 MiB)
26/01/12 02:16:12 INFO BlockManagerInfo: Removed broadcast_84_piece0 on 02926ee04bc9:45221 in memory (size: 36.8 KiB, free: 365.7 MiB)
26/01/12 02:16:12 INFO BlockManagerInfo: Removed broadcast_84_piece0 on 172.18.0.5:42453 in memory (size: 36.8 KiB, free: 365.7 MiB)
26/01/12 02:16:12 INFO BlockManagerInfo: Removed broadcast_96_piece0 on 02926ee04bc9:45221 in memory (size: 36.8 KiB, free: 365.8 MiB)
26/01/12 02:16:12 INFO BlockManagerInfo: Removed broadcast_96_piece0 on 172.18.0.5:42453 in memory (size: 36.8 KiB, free: 365.8 MiB)
26/01/12 02:16:12 INFO BlockManagerInfo: Removed broadcast_82_piece0 on 02926ee04bc9:45221 in memory (size: 35.4 KiB, free: 365.8 MiB)
26/01/12 02:16:12 INFO BlockManagerInfo: Removed broadcast_82_piece0 on 172.18.0.5:42453 in memory (size: 35.4 KiB, free: 365.8 MiB)
26/01/12 02:16:12 INFO BlockManagerInfo: Removed broadcast_93_piece0 on 02926ee04bc9:45221 in memory (size: 36.8 KiB, free: 365.9 MiB)
26/01/12 02:16:12 INFO BlockManagerInfo: Removed broadcast_93_piece0 on 172.18.0.5:42453 in memory (size: 36.8 KiB, free: 365.9 MiB)
26/01/12 02:16:12 INFO BlockManagerInfo: Removed broadcast_90_piece0 on 02926ee04bc9:45221 in memory (size: 36.8 KiB, free: 365.9 MiB)
26/01/12 02:16:12 INFO BlockManagerInfo: Removed broadcast_90_piece0 on 172.18.0.5:42453 in memory (size: 36.8 KiB, free: 365.9 MiB)
26/01/12 02:16:12 INFO BlockManagerInfo: Removed broadcast_89_piece0 on 02926ee04bc9:45221 in memory (size: 77.4 KiB, free: 366.0 MiB)
26/01/12 02:16:12 INFO BlockManagerInfo: Removed broadcast_89_piece0 on 172.18.0.5:42453 in memory (size: 77.4 KiB, free: 366.0 MiB)
26/01/12 02:16:13 INFO TaskSetManager: Finished task 0.0 in stage 66.0 (TID 146) in 71 ms on 172.18.0.5 (executor 0) (1/1)
26/01/12 02:16:13 INFO TaskSchedulerImpl: Removed TaskSet 66.0, whose tasks have all completed, from pool 
26/01/12 02:16:13 INFO DAGScheduler: ResultStage 66 (parquet at <unknown>:0) finished in 0.089 s
26/01/12 02:16:13 INFO DAGScheduler: Job 66 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:16:13 INFO BlockManagerInfo: Removed broadcast_83_piece0 on 02926ee04bc9:45221 in memory (size: 77.4 KiB, free: 366.0 MiB)
26/01/12 02:16:13 INFO TaskSchedulerImpl: Killing all running tasks in stage 66: Stage finished
26/01/12 02:16:13 INFO DAGScheduler: Job 66 finished: parquet at <unknown>:0, took 0.096773 s
26/01/12 02:16:13 INFO BlockManagerInfo: Removed broadcast_83_piece0 on 172.18.0.5:42453 in memory (size: 77.4 KiB, free: 366.0 MiB)
26/01/12 02:16:13 INFO BlockManagerInfo: Removed broadcast_98_piece0 on 02926ee04bc9:45221 in memory (size: 77.4 KiB, free: 366.1 MiB)
26/01/12 02:16:13 INFO BlockManagerInfo: Removed broadcast_98_piece0 on 172.18.0.5:42453 in memory (size: 77.4 KiB, free: 366.1 MiB)
26/01/12 02:16:13 INFO BlockManagerInfo: Removed broadcast_85_piece0 on 02926ee04bc9:45221 in memory (size: 35.4 KiB, free: 366.2 MiB)
26/01/12 02:16:13 INFO BlockManagerInfo: Removed broadcast_85_piece0 on 172.18.0.5:42453 in memory (size: 35.4 KiB, free: 366.2 MiB)
26/01/12 02:16:13 INFO FileSourceStrategy: Pushed Filters: 
26/01/12 02:16:13 INFO FileSourceStrategy: Post-Scan Filters: 
26/01/12 02:16:13 INFO FileSourceStrategy: Output Data Schema: struct<VendorID: bigint, tpep_pickup_datetime: timestamp, tpep_dropoff_datetime: timestamp, passenger_count: bigint, trip_distance: double ... 17 more fields>
26/01/12 02:16:13 INFO BlockManagerInfo: Removed broadcast_92_piece0 on 02926ee04bc9:45221 in memory (size: 77.5 KiB, free: 366.2 MiB)
26/01/12 02:16:13 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:16:13 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:16:13 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:16:13 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:16:13 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:16:13 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:16:13 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:16:13 INFO BlockManagerInfo: Removed broadcast_92_piece0 on 172.18.0.5:42453 in memory (size: 77.5 KiB, free: 366.2 MiB)
26/01/12 02:16:13 INFO MemoryStore: Block broadcast_100 stored as values in memory (estimated size 358.4 KiB, free 365.4 MiB)
26/01/12 02:16:13 INFO MemoryStore: Block broadcast_100_piece0 stored as bytes in memory (estimated size 35.4 KiB, free 365.4 MiB)
26/01/12 02:16:13 INFO BlockManagerInfo: Added broadcast_100_piece0 in memory on 02926ee04bc9:45221 (size: 35.4 KiB, free: 366.2 MiB)
26/01/12 02:16:13 INFO SparkContext: Created broadcast 100 from parquet at <unknown>:0
26/01/12 02:16:13 INFO FileSourceScanExec: Planning scan with bin packing, max size: 100233690 bytes, open cost is considered as scanning 4194304 bytes.
26/01/12 02:16:13 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 02:16:13 INFO DAGScheduler: Got job 67 (parquet at <unknown>:0) with 2 output partitions
26/01/12 02:16:13 INFO DAGScheduler: Final stage: ResultStage 67 (parquet at <unknown>:0)
26/01/12 02:16:13 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:16:13 INFO DAGScheduler: Missing parents: List()
26/01/12 02:16:13 INFO DAGScheduler: Submitting ResultStage 67 (MapPartitionsRDD[169] at parquet at <unknown>:0), which has no missing parents
26/01/12 02:16:13 INFO MemoryStore: Block broadcast_101 stored as values in memory (estimated size 225.1 KiB, free 365.2 MiB)
26/01/12 02:16:13 INFO MemoryStore: Block broadcast_101_piece0 stored as bytes in memory (estimated size 77.4 KiB, free 365.1 MiB)
26/01/12 02:16:13 INFO BlockManagerInfo: Added broadcast_101_piece0 in memory on 02926ee04bc9:45221 (size: 77.4 KiB, free: 366.1 MiB)
26/01/12 02:16:13 INFO SparkContext: Created broadcast 101 from broadcast at DAGScheduler.scala:1513
26/01/12 02:16:13 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 67 (MapPartitionsRDD[169] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1))
26/01/12 02:16:13 INFO TaskSchedulerImpl: Adding task set 67.0 with 2 tasks resource profile 0
26/01/12 02:16:13 INFO TaskSetManager: Starting task 0.0 in stage 67.0 (TID 147) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:16:13 INFO TaskSetManager: Starting task 1.0 in stage 67.0 (TID 148) (172.18.0.5, executor 0, partition 1, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:16:13 INFO BlockManagerInfo: Added broadcast_101_piece0 in memory on 172.18.0.5:42453 (size: 77.4 KiB, free: 366.2 MiB)
26/01/12 02:16:13 INFO BlockManagerInfo: Added broadcast_100_piece0 in memory on 172.18.0.5:42453 (size: 35.4 KiB, free: 366.1 MiB)
26/01/12 02:16:13 INFO TaskSetManager: Finished task 1.0 in stage 67.0 (TID 148) in 69 ms on 172.18.0.5 (executor 0) (1/2)
26/01/12 02:16:47 INFO TaskSetManager: Finished task 0.0 in stage 67.0 (TID 147) in 34886 ms on 172.18.0.5 (executor 0) (2/2)
26/01/12 02:16:47 INFO TaskSchedulerImpl: Removed TaskSet 67.0, whose tasks have all completed, from pool 
26/01/12 02:16:47 INFO DAGScheduler: ResultStage 67 (parquet at <unknown>:0) finished in 34.905 s
26/01/12 02:16:47 INFO DAGScheduler: Job 67 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:16:47 INFO TaskSchedulerImpl: Killing all running tasks in stage 67: Stage finished
26/01/12 02:16:47 INFO DAGScheduler: Job 67 finished: parquet at <unknown>:0, took 34.911020 s
26/01/12 02:16:47 INFO FileFormatWriter: Start to commit write Job e789e0cc-8f2a-4dbd-ab9e-f248a6b0bc07.
26/01/12 02:16:48 INFO FileFormatWriter: Write Job e789e0cc-8f2a-4dbd-ab9e-f248a6b0bc07 committed. Elapsed time: 33 ms.
26/01/12 02:16:48 INFO FileFormatWriter: Finished processing stats for write job e789e0cc-8f2a-4dbd-ab9e-f248a6b0bc07.
Cargando: yellow_tripdata_2011-11.parquet en hdfs://hadoop-namenode:8020/data/nyc/raw/taxi-trips/2011...
26/01/12 02:16:48 INFO InMemoryFileIndex: It took 7 ms to list leaf files for 1 paths.
26/01/12 02:16:48 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 02:16:48 INFO DAGScheduler: Got job 68 (parquet at <unknown>:0) with 1 output partitions
26/01/12 02:16:48 INFO DAGScheduler: Final stage: ResultStage 68 (parquet at <unknown>:0)
26/01/12 02:16:48 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:16:48 INFO DAGScheduler: Missing parents: List()
26/01/12 02:16:48 INFO DAGScheduler: Submitting ResultStage 68 (MapPartitionsRDD[171] at parquet at <unknown>:0), which has no missing parents
26/01/12 02:16:48 INFO MemoryStore: Block broadcast_102 stored as values in memory (estimated size 102.6 KiB, free 365.0 MiB)
26/01/12 02:16:48 INFO MemoryStore: Block broadcast_102_piece0 stored as bytes in memory (estimated size 36.8 KiB, free 365.0 MiB)
26/01/12 02:16:48 INFO BlockManagerInfo: Added broadcast_102_piece0 in memory on 02926ee04bc9:45221 (size: 36.8 KiB, free: 366.1 MiB)
26/01/12 02:16:48 INFO SparkContext: Created broadcast 102 from broadcast at DAGScheduler.scala:1513
26/01/12 02:16:48 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 68 (MapPartitionsRDD[171] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0))
26/01/12 02:16:48 INFO TaskSchedulerImpl: Adding task set 68.0 with 1 tasks resource profile 0
26/01/12 02:16:48 INFO TaskSetManager: Starting task 0.0 in stage 68.0 (TID 149) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4607 bytes) taskResourceAssignments Map()
26/01/12 02:16:48 INFO BlockManagerInfo: Added broadcast_102_piece0 in memory on 172.18.0.5:42453 (size: 36.8 KiB, free: 366.1 MiB)
26/01/12 02:16:48 INFO TaskSetManager: Finished task 0.0 in stage 68.0 (TID 149) in 69 ms on 172.18.0.5 (executor 0) (1/1)
26/01/12 02:16:48 INFO TaskSchedulerImpl: Removed TaskSet 68.0, whose tasks have all completed, from pool 
26/01/12 02:16:48 INFO DAGScheduler: ResultStage 68 (parquet at <unknown>:0) finished in 0.082 s
26/01/12 02:16:48 INFO DAGScheduler: Job 68 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:16:48 INFO TaskSchedulerImpl: Killing all running tasks in stage 68: Stage finished
26/01/12 02:16:48 INFO DAGScheduler: Job 68 finished: parquet at <unknown>:0, took 0.087001 s
26/01/12 02:16:48 INFO FileSourceStrategy: Pushed Filters: 
26/01/12 02:16:48 INFO FileSourceStrategy: Post-Scan Filters: 
26/01/12 02:16:48 INFO FileSourceStrategy: Output Data Schema: struct<VendorID: bigint, tpep_pickup_datetime: timestamp, tpep_dropoff_datetime: timestamp, passenger_count: bigint, trip_distance: double ... 17 more fields>
26/01/12 02:16:48 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:16:48 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:16:48 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:16:48 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:16:48 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:16:48 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:16:48 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:16:48 INFO MemoryStore: Block broadcast_103 stored as values in memory (estimated size 358.4 KiB, free 364.6 MiB)
26/01/12 02:16:48 INFO MemoryStore: Block broadcast_103_piece0 stored as bytes in memory (estimated size 35.4 KiB, free 364.6 MiB)
26/01/12 02:16:48 INFO BlockManagerInfo: Added broadcast_103_piece0 in memory on 02926ee04bc9:45221 (size: 35.4 KiB, free: 366.0 MiB)
26/01/12 02:16:48 INFO SparkContext: Created broadcast 103 from parquet at <unknown>:0
26/01/12 02:16:48 INFO FileSourceScanExec: Planning scan with bin packing, max size: 93028341 bytes, open cost is considered as scanning 4194304 bytes.
26/01/12 02:16:48 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 02:16:48 INFO DAGScheduler: Got job 69 (parquet at <unknown>:0) with 2 output partitions
26/01/12 02:16:48 INFO DAGScheduler: Final stage: ResultStage 69 (parquet at <unknown>:0)
26/01/12 02:16:48 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:16:48 INFO DAGScheduler: Missing parents: List()
26/01/12 02:16:48 INFO DAGScheduler: Submitting ResultStage 69 (MapPartitionsRDD[174] at parquet at <unknown>:0), which has no missing parents
26/01/12 02:16:48 INFO MemoryStore: Block broadcast_104 stored as values in memory (estimated size 225.1 KiB, free 364.4 MiB)
26/01/12 02:16:48 INFO MemoryStore: Block broadcast_104_piece0 stored as bytes in memory (estimated size 77.4 KiB, free 364.3 MiB)
26/01/12 02:16:48 INFO BlockManagerInfo: Added broadcast_104_piece0 in memory on 02926ee04bc9:45221 (size: 77.4 KiB, free: 366.0 MiB)
26/01/12 02:16:48 INFO SparkContext: Created broadcast 104 from broadcast at DAGScheduler.scala:1513
26/01/12 02:16:48 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 69 (MapPartitionsRDD[174] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1))
26/01/12 02:16:48 INFO TaskSchedulerImpl: Adding task set 69.0 with 2 tasks resource profile 0
26/01/12 02:16:48 INFO TaskSetManager: Starting task 0.0 in stage 69.0 (TID 150) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:16:48 INFO TaskSetManager: Starting task 1.0 in stage 69.0 (TID 151) (172.18.0.5, executor 0, partition 1, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:16:48 INFO BlockManagerInfo: Added broadcast_104_piece0 in memory on 172.18.0.5:42453 (size: 77.4 KiB, free: 366.0 MiB)
26/01/12 02:16:48 INFO BlockManagerInfo: Added broadcast_103_piece0 in memory on 172.18.0.5:42453 (size: 35.4 KiB, free: 366.0 MiB)
26/01/12 02:16:48 INFO TaskSetManager: Finished task 1.0 in stage 69.0 (TID 151) in 72 ms on 172.18.0.5 (executor 0) (1/2)
26/01/12 02:17:19 INFO TaskSetManager: Finished task 0.0 in stage 69.0 (TID 150) in 31467 ms on 172.18.0.5 (executor 0) (2/2)
26/01/12 02:17:19 INFO TaskSchedulerImpl: Removed TaskSet 69.0, whose tasks have all completed, from pool 
26/01/12 02:17:19 INFO DAGScheduler: ResultStage 69 (parquet at <unknown>:0) finished in 31.491 s
26/01/12 02:17:19 INFO DAGScheduler: Job 69 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:17:19 INFO TaskSchedulerImpl: Killing all running tasks in stage 69: Stage finished
26/01/12 02:17:19 INFO DAGScheduler: Job 69 finished: parquet at <unknown>:0, took 31.500135 s
26/01/12 02:17:19 INFO FileFormatWriter: Start to commit write Job 3bb817c2-e2f5-4f1b-902c-750aca738cc0.
26/01/12 02:17:19 INFO FileFormatWriter: Write Job 3bb817c2-e2f5-4f1b-902c-750aca738cc0 committed. Elapsed time: 37 ms.
26/01/12 02:17:19 INFO FileFormatWriter: Finished processing stats for write job 3bb817c2-e2f5-4f1b-902c-750aca738cc0.
Cargando: yellow_tripdata_2011-12.parquet en hdfs://hadoop-namenode:8020/data/nyc/raw/taxi-trips/2011...
26/01/12 02:17:19 INFO InMemoryFileIndex: It took 7 ms to list leaf files for 1 paths.
26/01/12 02:17:19 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 02:17:19 INFO DAGScheduler: Got job 70 (parquet at <unknown>:0) with 1 output partitions
26/01/12 02:17:19 INFO DAGScheduler: Final stage: ResultStage 70 (parquet at <unknown>:0)
26/01/12 02:17:19 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:17:19 INFO DAGScheduler: Missing parents: List()
26/01/12 02:17:19 INFO DAGScheduler: Submitting ResultStage 70 (MapPartitionsRDD[176] at parquet at <unknown>:0), which has no missing parents
26/01/12 02:17:19 INFO MemoryStore: Block broadcast_105 stored as values in memory (estimated size 102.6 KiB, free 364.2 MiB)
26/01/12 02:17:19 INFO MemoryStore: Block broadcast_105_piece0 stored as bytes in memory (estimated size 36.8 KiB, free 364.1 MiB)
26/01/12 02:17:19 INFO BlockManagerInfo: Added broadcast_105_piece0 in memory on 02926ee04bc9:45221 (size: 36.8 KiB, free: 365.9 MiB)
26/01/12 02:17:19 INFO SparkContext: Created broadcast 105 from broadcast at DAGScheduler.scala:1513
26/01/12 02:17:19 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 70 (MapPartitionsRDD[176] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0))
26/01/12 02:17:19 INFO TaskSchedulerImpl: Adding task set 70.0 with 1 tasks resource profile 0
26/01/12 02:17:19 INFO TaskSetManager: Starting task 0.0 in stage 70.0 (TID 152) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4607 bytes) taskResourceAssignments Map()
26/01/12 02:17:19 INFO BlockManagerInfo: Added broadcast_105_piece0 in memory on 172.18.0.5:42453 (size: 36.8 KiB, free: 365.9 MiB)
26/01/12 02:17:19 INFO TaskSetManager: Finished task 0.0 in stage 70.0 (TID 152) in 55 ms on 172.18.0.5 (executor 0) (1/1)
26/01/12 02:17:19 INFO TaskSchedulerImpl: Removed TaskSet 70.0, whose tasks have all completed, from pool 
26/01/12 02:17:19 INFO DAGScheduler: ResultStage 70 (parquet at <unknown>:0) finished in 0.068 s
26/01/12 02:17:19 INFO DAGScheduler: Job 70 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:17:19 INFO TaskSchedulerImpl: Killing all running tasks in stage 70: Stage finished
26/01/12 02:17:19 INFO DAGScheduler: Job 70 finished: parquet at <unknown>:0, took 0.074736 s
26/01/12 02:17:19 INFO FileSourceStrategy: Pushed Filters: 
26/01/12 02:17:19 INFO FileSourceStrategy: Post-Scan Filters: 
26/01/12 02:17:19 INFO FileSourceStrategy: Output Data Schema: struct<VendorID: bigint, tpep_pickup_datetime: timestamp, tpep_dropoff_datetime: timestamp, passenger_count: bigint, trip_distance: double ... 17 more fields>
26/01/12 02:17:19 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:17:19 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:17:19 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:17:19 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:17:19 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:17:19 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:17:19 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:17:19 INFO MemoryStore: Block broadcast_106 stored as values in memory (estimated size 358.4 KiB, free 363.8 MiB)
26/01/12 02:17:19 INFO MemoryStore: Block broadcast_106_piece0 stored as bytes in memory (estimated size 35.4 KiB, free 363.8 MiB)
26/01/12 02:17:19 INFO BlockManagerInfo: Added broadcast_106_piece0 in memory on 02926ee04bc9:45221 (size: 35.4 KiB, free: 365.9 MiB)
26/01/12 02:17:19 INFO SparkContext: Created broadcast 106 from parquet at <unknown>:0
26/01/12 02:17:19 INFO FileSourceScanExec: Planning scan with bin packing, max size: 95351520 bytes, open cost is considered as scanning 4194304 bytes.
26/01/12 02:17:19 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 02:17:19 INFO DAGScheduler: Got job 71 (parquet at <unknown>:0) with 2 output partitions
26/01/12 02:17:19 INFO DAGScheduler: Final stage: ResultStage 71 (parquet at <unknown>:0)
26/01/12 02:17:19 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:17:19 INFO DAGScheduler: Missing parents: List()
26/01/12 02:17:19 INFO DAGScheduler: Submitting ResultStage 71 (MapPartitionsRDD[179] at parquet at <unknown>:0), which has no missing parents
26/01/12 02:17:19 INFO MemoryStore: Block broadcast_107 stored as values in memory (estimated size 225.1 KiB, free 363.5 MiB)
26/01/12 02:17:19 INFO MemoryStore: Block broadcast_107_piece0 stored as bytes in memory (estimated size 77.4 KiB, free 363.5 MiB)
26/01/12 02:17:19 INFO BlockManagerInfo: Added broadcast_107_piece0 in memory on 02926ee04bc9:45221 (size: 77.4 KiB, free: 365.8 MiB)
26/01/12 02:17:19 INFO SparkContext: Created broadcast 107 from broadcast at DAGScheduler.scala:1513
26/01/12 02:17:19 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 71 (MapPartitionsRDD[179] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1))
26/01/12 02:17:19 INFO TaskSchedulerImpl: Adding task set 71.0 with 2 tasks resource profile 0
26/01/12 02:17:19 INFO TaskSetManager: Starting task 0.0 in stage 71.0 (TID 153) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:17:19 INFO TaskSetManager: Starting task 1.0 in stage 71.0 (TID 154) (172.18.0.5, executor 0, partition 1, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:17:19 INFO BlockManagerInfo: Added broadcast_107_piece0 in memory on 172.18.0.5:42453 (size: 77.4 KiB, free: 365.9 MiB)
26/01/12 02:17:20 INFO BlockManagerInfo: Added broadcast_106_piece0 in memory on 172.18.0.5:42453 (size: 35.4 KiB, free: 365.8 MiB)
26/01/12 02:17:20 INFO TaskSetManager: Finished task 1.0 in stage 71.0 (TID 154) in 68 ms on 172.18.0.5 (executor 0) (1/2)
26/01/12 02:17:52 INFO TaskSetManager: Finished task 0.0 in stage 71.0 (TID 153) in 32875 ms on 172.18.0.5 (executor 0) (2/2)
26/01/12 02:17:52 INFO TaskSchedulerImpl: Removed TaskSet 71.0, whose tasks have all completed, from pool 
26/01/12 02:17:52 INFO DAGScheduler: ResultStage 71 (parquet at <unknown>:0) finished in 32.897 s
26/01/12 02:17:52 INFO DAGScheduler: Job 71 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:17:52 INFO TaskSchedulerImpl: Killing all running tasks in stage 71: Stage finished
26/01/12 02:17:52 INFO DAGScheduler: Job 71 finished: parquet at <unknown>:0, took 32.905596 s
26/01/12 02:17:52 INFO FileFormatWriter: Start to commit write Job c3536b71-c62c-48f6-9919-96f4cc9f370f.
26/01/12 02:17:52 INFO FileFormatWriter: Write Job c3536b71-c62c-48f6-9919-96f4cc9f370f committed. Elapsed time: 29 ms.
26/01/12 02:17:52 INFO FileFormatWriter: Finished processing stats for write job c3536b71-c62c-48f6-9919-96f4cc9f370f.
Cargando: yellow_tripdata_2012-01.parquet en hdfs://hadoop-namenode:8020/data/nyc/raw/taxi-trips/2012...
26/01/12 02:17:52 INFO InMemoryFileIndex: It took 5 ms to list leaf files for 1 paths.
26/01/12 02:17:52 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 02:17:52 INFO DAGScheduler: Got job 72 (parquet at <unknown>:0) with 1 output partitions
26/01/12 02:17:52 INFO DAGScheduler: Final stage: ResultStage 72 (parquet at <unknown>:0)
26/01/12 02:17:52 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:17:52 INFO DAGScheduler: Missing parents: List()
26/01/12 02:17:52 INFO DAGScheduler: Submitting ResultStage 72 (MapPartitionsRDD[181] at parquet at <unknown>:0), which has no missing parents
26/01/12 02:17:52 INFO MemoryStore: Block broadcast_108 stored as values in memory (estimated size 102.6 KiB, free 363.4 MiB)
26/01/12 02:17:52 INFO MemoryStore: Block broadcast_108_piece0 stored as bytes in memory (estimated size 36.8 KiB, free 363.3 MiB)
26/01/12 02:17:52 INFO BlockManagerInfo: Added broadcast_108_piece0 in memory on 02926ee04bc9:45221 (size: 36.8 KiB, free: 365.8 MiB)
26/01/12 02:17:52 INFO SparkContext: Created broadcast 108 from broadcast at DAGScheduler.scala:1513
26/01/12 02:17:52 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 72 (MapPartitionsRDD[181] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0))
26/01/12 02:17:52 INFO TaskSchedulerImpl: Adding task set 72.0 with 1 tasks resource profile 0
26/01/12 02:17:52 INFO TaskSetManager: Starting task 0.0 in stage 72.0 (TID 155) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4607 bytes) taskResourceAssignments Map()
26/01/12 02:17:52 INFO BlockManagerInfo: Added broadcast_108_piece0 in memory on 172.18.0.5:42453 (size: 36.8 KiB, free: 365.8 MiB)
26/01/12 02:17:52 INFO TaskSetManager: Finished task 0.0 in stage 72.0 (TID 155) in 51 ms on 172.18.0.5 (executor 0) (1/1)
26/01/12 02:17:52 INFO TaskSchedulerImpl: Removed TaskSet 72.0, whose tasks have all completed, from pool 
26/01/12 02:17:53 INFO DAGScheduler: ResultStage 72 (parquet at <unknown>:0) finished in 0.064 s
26/01/12 02:17:53 INFO DAGScheduler: Job 72 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:17:53 INFO TaskSchedulerImpl: Killing all running tasks in stage 72: Stage finished
26/01/12 02:17:53 INFO DAGScheduler: Job 72 finished: parquet at <unknown>:0, took 0.069310 s
26/01/12 02:17:53 INFO FileSourceStrategy: Pushed Filters: 
26/01/12 02:17:53 INFO FileSourceStrategy: Post-Scan Filters: 
26/01/12 02:17:53 INFO FileSourceStrategy: Output Data Schema: struct<VendorID: bigint, tpep_pickup_datetime: timestamp, tpep_dropoff_datetime: timestamp, passenger_count: bigint, trip_distance: double ... 17 more fields>
26/01/12 02:17:53 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:17:53 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:17:53 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:17:53 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:17:53 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:17:53 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:17:53 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:17:53 INFO MemoryStore: Block broadcast_109 stored as values in memory (estimated size 358.4 KiB, free 363.0 MiB)
26/01/12 02:17:53 INFO MemoryStore: Block broadcast_109_piece0 stored as bytes in memory (estimated size 35.4 KiB, free 362.9 MiB)
26/01/12 02:17:53 INFO BlockManagerInfo: Added broadcast_109_piece0 in memory on 02926ee04bc9:45221 (size: 35.4 KiB, free: 365.8 MiB)
26/01/12 02:17:53 INFO SparkContext: Created broadcast 109 from parquet at <unknown>:0
26/01/12 02:17:53 INFO FileSourceScanExec: Planning scan with bin packing, max size: 85486503 bytes, open cost is considered as scanning 4194304 bytes.
26/01/12 02:17:53 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 02:17:53 INFO DAGScheduler: Got job 73 (parquet at <unknown>:0) with 2 output partitions
26/01/12 02:17:53 INFO DAGScheduler: Final stage: ResultStage 73 (parquet at <unknown>:0)
26/01/12 02:17:53 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:17:53 INFO DAGScheduler: Missing parents: List()
26/01/12 02:17:53 INFO DAGScheduler: Submitting ResultStage 73 (MapPartitionsRDD[184] at parquet at <unknown>:0), which has no missing parents
26/01/12 02:17:53 INFO MemoryStore: Block broadcast_110 stored as values in memory (estimated size 225.1 KiB, free 362.7 MiB)
26/01/12 02:17:53 INFO MemoryStore: Block broadcast_110_piece0 stored as bytes in memory (estimated size 77.4 KiB, free 362.7 MiB)
26/01/12 02:17:53 INFO BlockManagerInfo: Added broadcast_110_piece0 in memory on 02926ee04bc9:45221 (size: 77.4 KiB, free: 365.7 MiB)
26/01/12 02:17:53 INFO SparkContext: Created broadcast 110 from broadcast at DAGScheduler.scala:1513
26/01/12 02:17:53 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 73 (MapPartitionsRDD[184] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1))
26/01/12 02:17:53 INFO TaskSchedulerImpl: Adding task set 73.0 with 2 tasks resource profile 0
26/01/12 02:17:53 INFO TaskSetManager: Starting task 0.0 in stage 73.0 (TID 156) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:17:53 INFO TaskSetManager: Starting task 1.0 in stage 73.0 (TID 157) (172.18.0.5, executor 0, partition 1, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:17:53 INFO BlockManagerInfo: Added broadcast_110_piece0 in memory on 172.18.0.5:42453 (size: 77.4 KiB, free: 365.7 MiB)
26/01/12 02:17:53 INFO BlockManagerInfo: Added broadcast_109_piece0 in memory on 172.18.0.5:42453 (size: 35.4 KiB, free: 365.7 MiB)
26/01/12 02:17:53 INFO TaskSetManager: Finished task 1.0 in stage 73.0 (TID 157) in 61 ms on 172.18.0.5 (executor 0) (1/2)
26/01/12 02:18:22 INFO TaskSetManager: Finished task 0.0 in stage 73.0 (TID 156) in 29913 ms on 172.18.0.5 (executor 0) (2/2)
26/01/12 02:18:22 INFO TaskSchedulerImpl: Removed TaskSet 73.0, whose tasks have all completed, from pool 
26/01/12 02:18:22 INFO DAGScheduler: ResultStage 73 (parquet at <unknown>:0) finished in 29.935 s
26/01/12 02:18:22 INFO DAGScheduler: Job 73 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:18:22 INFO TaskSchedulerImpl: Killing all running tasks in stage 73: Stage finished
26/01/12 02:18:23 INFO DAGScheduler: Job 73 finished: parquet at <unknown>:0, took 29.943242 s
26/01/12 02:18:23 INFO FileFormatWriter: Start to commit write Job f7c54647-96ae-4274-9f66-a444250586c0.
26/01/12 02:18:23 INFO FileFormatWriter: Write Job f7c54647-96ae-4274-9f66-a444250586c0 committed. Elapsed time: 37 ms.
26/01/12 02:18:23 INFO FileFormatWriter: Finished processing stats for write job f7c54647-96ae-4274-9f66-a444250586c0.
Cargando: yellow_tripdata_2012-02.parquet en hdfs://hadoop-namenode:8020/data/nyc/raw/taxi-trips/2012...
26/01/12 02:18:23 INFO InMemoryFileIndex: It took 6 ms to list leaf files for 1 paths.
26/01/12 02:18:23 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 02:18:23 INFO DAGScheduler: Got job 74 (parquet at <unknown>:0) with 1 output partitions
26/01/12 02:18:23 INFO DAGScheduler: Final stage: ResultStage 74 (parquet at <unknown>:0)
26/01/12 02:18:23 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:18:23 INFO DAGScheduler: Missing parents: List()
26/01/12 02:18:23 INFO DAGScheduler: Submitting ResultStage 74 (MapPartitionsRDD[186] at parquet at <unknown>:0), which has no missing parents
26/01/12 02:18:23 INFO MemoryStore: Block broadcast_111 stored as values in memory (estimated size 102.6 KiB, free 362.6 MiB)
26/01/12 02:18:23 INFO MemoryStore: Block broadcast_111_piece0 stored as bytes in memory (estimated size 36.8 KiB, free 362.5 MiB)
26/01/12 02:18:23 INFO BlockManagerInfo: Added broadcast_111_piece0 in memory on 02926ee04bc9:45221 (size: 36.8 KiB, free: 365.6 MiB)
26/01/12 02:18:23 INFO SparkContext: Created broadcast 111 from broadcast at DAGScheduler.scala:1513
26/01/12 02:18:23 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 74 (MapPartitionsRDD[186] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0))
26/01/12 02:18:23 INFO TaskSchedulerImpl: Adding task set 74.0 with 1 tasks resource profile 0
26/01/12 02:18:23 INFO TaskSetManager: Starting task 0.0 in stage 74.0 (TID 158) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4607 bytes) taskResourceAssignments Map()
26/01/12 02:18:23 INFO BlockManagerInfo: Added broadcast_111_piece0 in memory on 172.18.0.5:42453 (size: 36.8 KiB, free: 365.6 MiB)
26/01/12 02:18:23 INFO TaskSetManager: Finished task 0.0 in stage 74.0 (TID 158) in 57 ms on 172.18.0.5 (executor 0) (1/1)
26/01/12 02:18:23 INFO TaskSchedulerImpl: Removed TaskSet 74.0, whose tasks have all completed, from pool 
26/01/12 02:18:23 INFO DAGScheduler: ResultStage 74 (parquet at <unknown>:0) finished in 0.070 s
26/01/12 02:18:23 INFO DAGScheduler: Job 74 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:18:23 INFO TaskSchedulerImpl: Killing all running tasks in stage 74: Stage finished
26/01/12 02:18:23 INFO DAGScheduler: Job 74 finished: parquet at <unknown>:0, took 0.074107 s
26/01/12 02:18:23 INFO FileSourceStrategy: Pushed Filters: 
26/01/12 02:18:23 INFO FileSourceStrategy: Post-Scan Filters: 
26/01/12 02:18:23 INFO FileSourceStrategy: Output Data Schema: struct<VendorID: bigint, tpep_pickup_datetime: timestamp, tpep_dropoff_datetime: timestamp, passenger_count: bigint, trip_distance: double ... 17 more fields>
26/01/12 02:18:23 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:18:23 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:18:23 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:18:23 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:18:23 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:18:23 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:18:23 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:18:23 INFO MemoryStore: Block broadcast_112 stored as values in memory (estimated size 358.4 KiB, free 362.2 MiB)
26/01/12 02:18:23 INFO MemoryStore: Block broadcast_112_piece0 stored as bytes in memory (estimated size 35.4 KiB, free 362.1 MiB)
26/01/12 02:18:23 INFO BlockManagerInfo: Added broadcast_112_piece0 in memory on 02926ee04bc9:45221 (size: 35.4 KiB, free: 365.6 MiB)
26/01/12 02:18:23 INFO SparkContext: Created broadcast 112 from parquet at <unknown>:0
26/01/12 02:18:23 INFO FileSourceScanExec: Planning scan with bin packing, max size: 87597059 bytes, open cost is considered as scanning 4194304 bytes.
26/01/12 02:18:23 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 02:18:23 INFO DAGScheduler: Got job 75 (parquet at <unknown>:0) with 2 output partitions
26/01/12 02:18:23 INFO DAGScheduler: Final stage: ResultStage 75 (parquet at <unknown>:0)
26/01/12 02:18:23 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:18:23 INFO DAGScheduler: Missing parents: List()
26/01/12 02:18:23 INFO DAGScheduler: Submitting ResultStage 75 (MapPartitionsRDD[189] at parquet at <unknown>:0), which has no missing parents
26/01/12 02:18:23 INFO MemoryStore: Block broadcast_113 stored as values in memory (estimated size 225.1 KiB, free 361.9 MiB)
26/01/12 02:18:23 INFO MemoryStore: Block broadcast_113_piece0 stored as bytes in memory (estimated size 77.4 KiB, free 361.8 MiB)
26/01/12 02:18:23 INFO BlockManagerInfo: Added broadcast_113_piece0 in memory on 02926ee04bc9:45221 (size: 77.4 KiB, free: 365.5 MiB)
26/01/12 02:18:23 INFO SparkContext: Created broadcast 113 from broadcast at DAGScheduler.scala:1513
26/01/12 02:18:23 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 75 (MapPartitionsRDD[189] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1))
26/01/12 02:18:23 INFO TaskSchedulerImpl: Adding task set 75.0 with 2 tasks resource profile 0
26/01/12 02:18:23 INFO TaskSetManager: Starting task 0.0 in stage 75.0 (TID 159) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:18:23 INFO TaskSetManager: Starting task 1.0 in stage 75.0 (TID 160) (172.18.0.5, executor 0, partition 1, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:18:23 INFO BlockManagerInfo: Added broadcast_113_piece0 in memory on 172.18.0.5:42453 (size: 77.4 KiB, free: 365.6 MiB)
26/01/12 02:18:23 INFO BlockManagerInfo: Added broadcast_112_piece0 in memory on 172.18.0.5:42453 (size: 35.4 KiB, free: 365.5 MiB)
26/01/12 02:18:23 INFO TaskSetManager: Finished task 1.0 in stage 75.0 (TID 160) in 70 ms on 172.18.0.5 (executor 0) (1/2)
26/01/12 02:18:52 INFO TaskSetManager: Finished task 0.0 in stage 75.0 (TID 159) in 28765 ms on 172.18.0.5 (executor 0) (2/2)
26/01/12 02:18:52 INFO TaskSchedulerImpl: Removed TaskSet 75.0, whose tasks have all completed, from pool 
26/01/12 02:18:52 INFO DAGScheduler: ResultStage 75 (parquet at <unknown>:0) finished in 28.788 s
26/01/12 02:18:52 INFO DAGScheduler: Job 75 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:18:52 INFO TaskSchedulerImpl: Killing all running tasks in stage 75: Stage finished
26/01/12 02:18:52 INFO DAGScheduler: Job 75 finished: parquet at <unknown>:0, took 28.795742 s
26/01/12 02:18:52 INFO FileFormatWriter: Start to commit write Job 68ba7c82-0ff9-44d2-85fc-641e39703073.
26/01/12 02:18:52 INFO FileFormatWriter: Write Job 68ba7c82-0ff9-44d2-85fc-641e39703073 committed. Elapsed time: 25 ms.
26/01/12 02:18:52 INFO FileFormatWriter: Finished processing stats for write job 68ba7c82-0ff9-44d2-85fc-641e39703073.
Cargando: yellow_tripdata_2012-03.parquet en hdfs://hadoop-namenode:8020/data/nyc/raw/taxi-trips/2012...
26/01/12 02:18:52 INFO InMemoryFileIndex: It took 7 ms to list leaf files for 1 paths.
26/01/12 02:18:52 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 02:18:52 INFO DAGScheduler: Got job 76 (parquet at <unknown>:0) with 1 output partitions
26/01/12 02:18:52 INFO DAGScheduler: Final stage: ResultStage 76 (parquet at <unknown>:0)
26/01/12 02:18:52 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:18:52 INFO DAGScheduler: Missing parents: List()
26/01/12 02:18:52 INFO DAGScheduler: Submitting ResultStage 76 (MapPartitionsRDD[191] at parquet at <unknown>:0), which has no missing parents
26/01/12 02:18:52 INFO MemoryStore: Block broadcast_114 stored as values in memory (estimated size 102.6 KiB, free 361.7 MiB)
26/01/12 02:18:52 INFO MemoryStore: Block broadcast_114_piece0 stored as bytes in memory (estimated size 36.8 KiB, free 361.7 MiB)
26/01/12 02:18:52 INFO BlockManagerInfo: Added broadcast_114_piece0 in memory on 02926ee04bc9:45221 (size: 36.8 KiB, free: 365.5 MiB)
26/01/12 02:18:52 INFO SparkContext: Created broadcast 114 from broadcast at DAGScheduler.scala:1513
26/01/12 02:18:52 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 76 (MapPartitionsRDD[191] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0))
26/01/12 02:18:52 INFO TaskSchedulerImpl: Adding task set 76.0 with 1 tasks resource profile 0
26/01/12 02:18:52 INFO TaskSetManager: Starting task 0.0 in stage 76.0 (TID 161) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4607 bytes) taskResourceAssignments Map()
26/01/12 02:18:52 INFO BlockManagerInfo: Removed broadcast_102_piece0 on 02926ee04bc9:45221 in memory (size: 36.8 KiB, free: 365.5 MiB)
26/01/12 02:18:52 INFO BlockManagerInfo: Added broadcast_114_piece0 in memory on 172.18.0.5:42453 (size: 36.8 KiB, free: 365.5 MiB)
26/01/12 02:18:52 INFO BlockManagerInfo: Removed broadcast_102_piece0 on 172.18.0.5:42453 in memory (size: 36.8 KiB, free: 365.5 MiB)
26/01/12 02:18:52 INFO BlockManagerInfo: Removed broadcast_110_piece0 on 02926ee04bc9:45221 in memory (size: 77.4 KiB, free: 365.6 MiB)
26/01/12 02:18:52 INFO BlockManagerInfo: Removed broadcast_110_piece0 on 172.18.0.5:42453 in memory (size: 77.4 KiB, free: 365.6 MiB)
26/01/12 02:18:52 INFO BlockManagerInfo: Removed broadcast_103_piece0 on 02926ee04bc9:45221 in memory (size: 35.4 KiB, free: 365.6 MiB)
26/01/12 02:18:52 INFO BlockManagerInfo: Removed broadcast_103_piece0 on 172.18.0.5:42453 in memory (size: 35.4 KiB, free: 365.6 MiB)
26/01/12 02:18:52 INFO BlockManagerInfo: Removed broadcast_100_piece0 on 02926ee04bc9:45221 in memory (size: 35.4 KiB, free: 365.7 MiB)
26/01/12 02:18:52 INFO BlockManagerInfo: Removed broadcast_100_piece0 on 172.18.0.5:42453 in memory (size: 35.4 KiB, free: 365.7 MiB)
26/01/12 02:18:52 INFO BlockManagerInfo: Removed broadcast_112_piece0 on 02926ee04bc9:45221 in memory (size: 35.4 KiB, free: 365.7 MiB)
26/01/12 02:18:52 INFO BlockManagerInfo: Removed broadcast_112_piece0 on 172.18.0.5:42453 in memory (size: 35.4 KiB, free: 365.7 MiB)
26/01/12 02:18:52 INFO BlockManagerInfo: Removed broadcast_104_piece0 on 02926ee04bc9:45221 in memory (size: 77.4 KiB, free: 365.8 MiB)
26/01/12 02:18:52 INFO BlockManagerInfo: Removed broadcast_104_piece0 on 172.18.0.5:42453 in memory (size: 77.4 KiB, free: 365.8 MiB)
26/01/12 02:18:52 INFO BlockManagerInfo: Removed broadcast_109_piece0 on 02926ee04bc9:45221 in memory (size: 35.4 KiB, free: 365.8 MiB)
26/01/12 02:18:52 INFO BlockManagerInfo: Removed broadcast_109_piece0 on 172.18.0.5:42453 in memory (size: 35.4 KiB, free: 365.8 MiB)
26/01/12 02:18:52 INFO BlockManagerInfo: Removed broadcast_105_piece0 on 02926ee04bc9:45221 in memory (size: 36.8 KiB, free: 365.9 MiB)
26/01/12 02:18:52 INFO BlockManagerInfo: Removed broadcast_105_piece0 on 172.18.0.5:42453 in memory (size: 36.8 KiB, free: 365.9 MiB)
26/01/12 02:18:52 INFO BlockManagerInfo: Removed broadcast_106_piece0 on 02926ee04bc9:45221 in memory (size: 35.4 KiB, free: 365.9 MiB)
26/01/12 02:18:52 INFO BlockManagerInfo: Removed broadcast_106_piece0 on 172.18.0.5:42453 in memory (size: 35.4 KiB, free: 365.9 MiB)
26/01/12 02:18:52 INFO BlockManagerInfo: Removed broadcast_111_piece0 on 02926ee04bc9:45221 in memory (size: 36.8 KiB, free: 365.9 MiB)
26/01/12 02:18:52 INFO BlockManagerInfo: Removed broadcast_111_piece0 on 172.18.0.5:42453 in memory (size: 36.8 KiB, free: 365.9 MiB)
26/01/12 02:18:52 INFO BlockManagerInfo: Removed broadcast_99_piece0 on 02926ee04bc9:45221 in memory (size: 36.8 KiB, free: 366.0 MiB)
26/01/12 02:18:52 INFO BlockManagerInfo: Removed broadcast_99_piece0 on 172.18.0.5:42453 in memory (size: 36.8 KiB, free: 366.0 MiB)
26/01/12 02:18:52 INFO TaskSetManager: Finished task 0.0 in stage 76.0 (TID 161) in 94 ms on 172.18.0.5 (executor 0) (1/1)
26/01/12 02:18:52 INFO TaskSchedulerImpl: Removed TaskSet 76.0, whose tasks have all completed, from pool 
26/01/12 02:18:52 INFO DAGScheduler: ResultStage 76 (parquet at <unknown>:0) finished in 0.143 s
26/01/12 02:18:52 INFO DAGScheduler: Job 76 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:18:52 INFO BlockManagerInfo: Removed broadcast_108_piece0 on 02926ee04bc9:45221 in memory (size: 36.8 KiB, free: 366.0 MiB)
26/01/12 02:18:52 INFO TaskSchedulerImpl: Killing all running tasks in stage 76: Stage finished
26/01/12 02:18:52 INFO DAGScheduler: Job 76 finished: parquet at <unknown>:0, took 0.149357 s
26/01/12 02:18:52 INFO BlockManagerInfo: Removed broadcast_108_piece0 on 172.18.0.5:42453 in memory (size: 36.8 KiB, free: 366.0 MiB)
26/01/12 02:18:52 INFO BlockManagerInfo: Removed broadcast_113_piece0 on 02926ee04bc9:45221 in memory (size: 77.4 KiB, free: 366.1 MiB)
26/01/12 02:18:52 INFO BlockManagerInfo: Removed broadcast_113_piece0 on 172.18.0.5:42453 in memory (size: 77.4 KiB, free: 366.1 MiB)
26/01/12 02:18:52 INFO BlockManagerInfo: Removed broadcast_107_piece0 on 02926ee04bc9:45221 in memory (size: 77.4 KiB, free: 366.2 MiB)
26/01/12 02:18:52 INFO BlockManagerInfo: Removed broadcast_107_piece0 on 172.18.0.5:42453 in memory (size: 77.4 KiB, free: 366.2 MiB)
26/01/12 02:18:52 INFO FileSourceStrategy: Pushed Filters: 
26/01/12 02:18:52 INFO FileSourceStrategy: Post-Scan Filters: 
26/01/12 02:18:52 INFO FileSourceStrategy: Output Data Schema: struct<VendorID: bigint, tpep_pickup_datetime: timestamp, tpep_dropoff_datetime: timestamp, passenger_count: bigint, trip_distance: double ... 17 more fields>
26/01/12 02:18:52 INFO BlockManagerInfo: Removed broadcast_101_piece0 on 02926ee04bc9:45221 in memory (size: 77.4 KiB, free: 366.2 MiB)
26/01/12 02:18:52 INFO BlockManagerInfo: Removed broadcast_101_piece0 on 172.18.0.5:42453 in memory (size: 77.4 KiB, free: 366.2 MiB)
26/01/12 02:18:52 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:18:52 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:18:52 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:18:52 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:18:52 INFO BlockManagerInfo: Removed broadcast_97_piece0 on 02926ee04bc9:45221 in memory (size: 35.4 KiB, free: 366.3 MiB)
26/01/12 02:18:52 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:18:52 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:18:52 INFO BlockManagerInfo: Removed broadcast_97_piece0 on 172.18.0.5:42453 in memory (size: 35.4 KiB, free: 366.3 MiB)
26/01/12 02:18:52 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:18:52 INFO MemoryStore: Block broadcast_115 stored as values in memory (estimated size 358.4 KiB, free 365.8 MiB)
26/01/12 02:18:52 INFO MemoryStore: Block broadcast_115_piece0 stored as bytes in memory (estimated size 35.4 KiB, free 365.8 MiB)
26/01/12 02:18:52 INFO BlockManagerInfo: Added broadcast_115_piece0 in memory on 02926ee04bc9:45221 (size: 35.4 KiB, free: 366.2 MiB)
26/01/12 02:18:52 INFO SparkContext: Created broadcast 115 from parquet at <unknown>:0
26/01/12 02:18:52 INFO FileSourceScanExec: Planning scan with bin packing, max size: 104586430 bytes, open cost is considered as scanning 4194304 bytes.
26/01/12 02:18:52 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 02:18:52 INFO DAGScheduler: Got job 77 (parquet at <unknown>:0) with 2 output partitions
26/01/12 02:18:52 INFO DAGScheduler: Final stage: ResultStage 77 (parquet at <unknown>:0)
26/01/12 02:18:52 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:18:52 INFO DAGScheduler: Missing parents: List()
26/01/12 02:18:52 INFO DAGScheduler: Submitting ResultStage 77 (MapPartitionsRDD[194] at parquet at <unknown>:0), which has no missing parents
26/01/12 02:18:52 INFO MemoryStore: Block broadcast_116 stored as values in memory (estimated size 225.1 KiB, free 365.6 MiB)
26/01/12 02:18:52 INFO MemoryStore: Block broadcast_116_piece0 stored as bytes in memory (estimated size 77.4 KiB, free 365.5 MiB)
26/01/12 02:18:52 INFO BlockManagerInfo: Added broadcast_116_piece0 in memory on 02926ee04bc9:45221 (size: 77.4 KiB, free: 366.2 MiB)
26/01/12 02:18:52 INFO SparkContext: Created broadcast 116 from broadcast at DAGScheduler.scala:1513
26/01/12 02:18:52 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 77 (MapPartitionsRDD[194] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1))
26/01/12 02:18:52 INFO TaskSchedulerImpl: Adding task set 77.0 with 2 tasks resource profile 0
26/01/12 02:18:52 INFO TaskSetManager: Starting task 0.0 in stage 77.0 (TID 162) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:18:52 INFO TaskSetManager: Starting task 1.0 in stage 77.0 (TID 163) (172.18.0.5, executor 0, partition 1, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:18:52 INFO BlockManagerInfo: Added broadcast_116_piece0 in memory on 172.18.0.5:42453 (size: 77.4 KiB, free: 366.2 MiB)
26/01/12 02:18:52 INFO BlockManagerInfo: Added broadcast_115_piece0 in memory on 172.18.0.5:42453 (size: 35.4 KiB, free: 366.2 MiB)
26/01/12 02:18:52 INFO TaskSetManager: Finished task 1.0 in stage 77.0 (TID 163) in 83 ms on 172.18.0.5 (executor 0) (1/2)
26/01/12 02:19:28 INFO TaskSetManager: Finished task 0.0 in stage 77.0 (TID 162) in 35910 ms on 172.18.0.5 (executor 0) (2/2)
26/01/12 02:19:28 INFO TaskSchedulerImpl: Removed TaskSet 77.0, whose tasks have all completed, from pool 
26/01/12 02:19:28 INFO DAGScheduler: ResultStage 77 (parquet at <unknown>:0) finished in 35.931 s
26/01/12 02:19:28 INFO DAGScheduler: Job 77 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:19:28 INFO TaskSchedulerImpl: Killing all running tasks in stage 77: Stage finished
26/01/12 02:19:28 INFO DAGScheduler: Job 77 finished: parquet at <unknown>:0, took 35.937126 s
26/01/12 02:19:28 INFO FileFormatWriter: Start to commit write Job 0c1ea25c-fc33-40ee-8f4b-4132a6175911.
26/01/12 02:19:28 INFO FileFormatWriter: Write Job 0c1ea25c-fc33-40ee-8f4b-4132a6175911 committed. Elapsed time: 39 ms.
26/01/12 02:19:28 INFO FileFormatWriter: Finished processing stats for write job 0c1ea25c-fc33-40ee-8f4b-4132a6175911.
Cargando: yellow_tripdata_2012-04.parquet en hdfs://hadoop-namenode:8020/data/nyc/raw/taxi-trips/2012...
26/01/12 02:19:28 INFO InMemoryFileIndex: It took 6 ms to list leaf files for 1 paths.
26/01/12 02:19:28 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 02:19:28 INFO DAGScheduler: Got job 78 (parquet at <unknown>:0) with 1 output partitions
26/01/12 02:19:28 INFO DAGScheduler: Final stage: ResultStage 78 (parquet at <unknown>:0)
26/01/12 02:19:28 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:19:28 INFO DAGScheduler: Missing parents: List()
26/01/12 02:19:28 INFO DAGScheduler: Submitting ResultStage 78 (MapPartitionsRDD[196] at parquet at <unknown>:0), which has no missing parents
26/01/12 02:19:28 INFO MemoryStore: Block broadcast_117 stored as values in memory (estimated size 102.6 KiB, free 365.4 MiB)
26/01/12 02:19:28 INFO MemoryStore: Block broadcast_117_piece0 stored as bytes in memory (estimated size 36.8 KiB, free 365.3 MiB)
26/01/12 02:19:28 INFO BlockManagerInfo: Added broadcast_117_piece0 in memory on 02926ee04bc9:45221 (size: 36.8 KiB, free: 366.1 MiB)
26/01/12 02:19:28 INFO SparkContext: Created broadcast 117 from broadcast at DAGScheduler.scala:1513
26/01/12 02:19:28 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 78 (MapPartitionsRDD[196] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0))
26/01/12 02:19:28 INFO TaskSchedulerImpl: Adding task set 78.0 with 1 tasks resource profile 0
26/01/12 02:19:28 INFO TaskSetManager: Starting task 0.0 in stage 78.0 (TID 164) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4607 bytes) taskResourceAssignments Map()
26/01/12 02:19:28 INFO BlockManagerInfo: Added broadcast_117_piece0 in memory on 172.18.0.5:42453 (size: 36.8 KiB, free: 366.1 MiB)
26/01/12 02:19:28 INFO TaskSetManager: Finished task 0.0 in stage 78.0 (TID 164) in 53 ms on 172.18.0.5 (executor 0) (1/1)
26/01/12 02:19:28 INFO TaskSchedulerImpl: Removed TaskSet 78.0, whose tasks have all completed, from pool 
26/01/12 02:19:28 INFO DAGScheduler: ResultStage 78 (parquet at <unknown>:0) finished in 0.066 s
26/01/12 02:19:28 INFO DAGScheduler: Job 78 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:19:28 INFO TaskSchedulerImpl: Killing all running tasks in stage 78: Stage finished
26/01/12 02:19:28 INFO DAGScheduler: Job 78 finished: parquet at <unknown>:0, took 0.071611 s
26/01/12 02:19:28 INFO FileSourceStrategy: Pushed Filters: 
26/01/12 02:19:28 INFO FileSourceStrategy: Post-Scan Filters: 
26/01/12 02:19:28 INFO FileSourceStrategy: Output Data Schema: struct<VendorID: bigint, tpep_pickup_datetime: timestamp, tpep_dropoff_datetime: timestamp, passenger_count: bigint, trip_distance: double ... 17 more fields>
26/01/12 02:19:28 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:19:28 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:19:28 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:19:28 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:19:28 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:19:28 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:19:28 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:19:28 INFO MemoryStore: Block broadcast_118 stored as values in memory (estimated size 358.4 KiB, free 365.0 MiB)
26/01/12 02:19:28 INFO MemoryStore: Block broadcast_118_piece0 stored as bytes in memory (estimated size 35.4 KiB, free 365.0 MiB)
26/01/12 02:19:28 INFO BlockManagerInfo: Added broadcast_118_piece0 in memory on 02926ee04bc9:45221 (size: 35.4 KiB, free: 366.1 MiB)
26/01/12 02:19:28 INFO SparkContext: Created broadcast 118 from parquet at <unknown>:0
26/01/12 02:19:28 INFO FileSourceScanExec: Planning scan with bin packing, max size: 89196023 bytes, open cost is considered as scanning 4194304 bytes.
26/01/12 02:19:28 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 02:19:28 INFO DAGScheduler: Got job 79 (parquet at <unknown>:0) with 2 output partitions
26/01/12 02:19:28 INFO DAGScheduler: Final stage: ResultStage 79 (parquet at <unknown>:0)
26/01/12 02:19:28 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:19:28 INFO DAGScheduler: Missing parents: List()
26/01/12 02:19:28 INFO DAGScheduler: Submitting ResultStage 79 (MapPartitionsRDD[199] at parquet at <unknown>:0), which has no missing parents
26/01/12 02:19:28 INFO MemoryStore: Block broadcast_119 stored as values in memory (estimated size 225.1 KiB, free 364.7 MiB)
26/01/12 02:19:28 INFO MemoryStore: Block broadcast_119_piece0 stored as bytes in memory (estimated size 77.5 KiB, free 364.7 MiB)
26/01/12 02:19:28 INFO BlockManagerInfo: Added broadcast_119_piece0 in memory on 02926ee04bc9:45221 (size: 77.5 KiB, free: 366.0 MiB)
26/01/12 02:19:28 INFO SparkContext: Created broadcast 119 from broadcast at DAGScheduler.scala:1513
26/01/12 02:19:28 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 79 (MapPartitionsRDD[199] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1))
26/01/12 02:19:28 INFO TaskSchedulerImpl: Adding task set 79.0 with 2 tasks resource profile 0
26/01/12 02:19:28 INFO TaskSetManager: Starting task 0.0 in stage 79.0 (TID 165) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:19:28 INFO TaskSetManager: Starting task 1.0 in stage 79.0 (TID 166) (172.18.0.5, executor 0, partition 1, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:19:28 INFO BlockManagerInfo: Added broadcast_119_piece0 in memory on 172.18.0.5:42453 (size: 77.5 KiB, free: 366.0 MiB)
26/01/12 02:19:28 INFO BlockManagerInfo: Added broadcast_118_piece0 in memory on 172.18.0.5:42453 (size: 35.4 KiB, free: 366.0 MiB)
26/01/12 02:19:28 INFO TaskSetManager: Finished task 1.0 in stage 79.0 (TID 166) in 63 ms on 172.18.0.5 (executor 0) (1/2)
26/01/12 02:19:58 INFO TaskSetManager: Finished task 0.0 in stage 79.0 (TID 165) in 30164 ms on 172.18.0.5 (executor 0) (2/2)
26/01/12 02:19:58 INFO TaskSchedulerImpl: Removed TaskSet 79.0, whose tasks have all completed, from pool 
26/01/12 02:19:58 INFO DAGScheduler: ResultStage 79 (parquet at <unknown>:0) finished in 30.190 s
26/01/12 02:19:58 INFO DAGScheduler: Job 79 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:19:58 INFO TaskSchedulerImpl: Killing all running tasks in stage 79: Stage finished
26/01/12 02:19:58 INFO DAGScheduler: Job 79 finished: parquet at <unknown>:0, took 30.198695 s
26/01/12 02:19:58 INFO FileFormatWriter: Start to commit write Job aec0f57a-76cb-457f-93bc-63e7924759b6.
26/01/12 02:19:58 INFO FileFormatWriter: Write Job aec0f57a-76cb-457f-93bc-63e7924759b6 committed. Elapsed time: 34 ms.
26/01/12 02:19:58 INFO FileFormatWriter: Finished processing stats for write job aec0f57a-76cb-457f-93bc-63e7924759b6.
Cargando: yellow_tripdata_2012-05.parquet en hdfs://hadoop-namenode:8020/data/nyc/raw/taxi-trips/2012...
26/01/12 02:19:58 INFO InMemoryFileIndex: It took 7 ms to list leaf files for 1 paths.
26/01/12 02:19:58 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 02:19:58 INFO DAGScheduler: Got job 80 (parquet at <unknown>:0) with 1 output partitions
26/01/12 02:19:58 INFO DAGScheduler: Final stage: ResultStage 80 (parquet at <unknown>:0)
26/01/12 02:19:58 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:19:58 INFO DAGScheduler: Missing parents: List()
26/01/12 02:19:58 INFO DAGScheduler: Submitting ResultStage 80 (MapPartitionsRDD[201] at parquet at <unknown>:0), which has no missing parents
26/01/12 02:19:58 INFO MemoryStore: Block broadcast_120 stored as values in memory (estimated size 102.6 KiB, free 364.6 MiB)
26/01/12 02:19:58 INFO MemoryStore: Block broadcast_120_piece0 stored as bytes in memory (estimated size 36.8 KiB, free 364.5 MiB)
26/01/12 02:19:58 INFO BlockManagerInfo: Added broadcast_120_piece0 in memory on 02926ee04bc9:45221 (size: 36.8 KiB, free: 366.0 MiB)
26/01/12 02:19:58 INFO SparkContext: Created broadcast 120 from broadcast at DAGScheduler.scala:1513
26/01/12 02:19:58 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 80 (MapPartitionsRDD[201] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0))
26/01/12 02:19:58 INFO TaskSchedulerImpl: Adding task set 80.0 with 1 tasks resource profile 0
26/01/12 02:19:58 INFO TaskSetManager: Starting task 0.0 in stage 80.0 (TID 167) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4607 bytes) taskResourceAssignments Map()
26/01/12 02:19:58 INFO BlockManagerInfo: Added broadcast_120_piece0 in memory on 172.18.0.5:42453 (size: 36.8 KiB, free: 366.0 MiB)
26/01/12 02:19:58 INFO TaskSetManager: Finished task 0.0 in stage 80.0 (TID 167) in 53 ms on 172.18.0.5 (executor 0) (1/1)
26/01/12 02:19:58 INFO TaskSchedulerImpl: Removed TaskSet 80.0, whose tasks have all completed, from pool 
26/01/12 02:19:58 INFO DAGScheduler: ResultStage 80 (parquet at <unknown>:0) finished in 0.068 s
26/01/12 02:19:58 INFO DAGScheduler: Job 80 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:19:58 INFO TaskSchedulerImpl: Killing all running tasks in stage 80: Stage finished
26/01/12 02:19:58 INFO DAGScheduler: Job 80 finished: parquet at <unknown>:0, took 0.073399 s
26/01/12 02:19:58 INFO FileSourceStrategy: Pushed Filters: 
26/01/12 02:19:58 INFO FileSourceStrategy: Post-Scan Filters: 
26/01/12 02:19:58 INFO FileSourceStrategy: Output Data Schema: struct<VendorID: bigint, tpep_pickup_datetime: timestamp, tpep_dropoff_datetime: timestamp, passenger_count: bigint, trip_distance: double ... 17 more fields>
26/01/12 02:19:58 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:19:58 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:19:58 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:19:58 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:19:58 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:19:58 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:19:58 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:19:58 INFO MemoryStore: Block broadcast_121 stored as values in memory (estimated size 358.4 KiB, free 364.2 MiB)
26/01/12 02:19:58 INFO MemoryStore: Block broadcast_121_piece0 stored as bytes in memory (estimated size 35.4 KiB, free 364.1 MiB)
26/01/12 02:19:58 INFO BlockManagerInfo: Added broadcast_121_piece0 in memory on 02926ee04bc9:45221 (size: 35.4 KiB, free: 365.9 MiB)
26/01/12 02:19:58 INFO SparkContext: Created broadcast 121 from parquet at <unknown>:0
26/01/12 02:19:58 INFO FileSourceScanExec: Planning scan with bin packing, max size: 92612469 bytes, open cost is considered as scanning 4194304 bytes.
26/01/12 02:19:58 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 02:19:58 INFO DAGScheduler: Got job 81 (parquet at <unknown>:0) with 2 output partitions
26/01/12 02:19:58 INFO DAGScheduler: Final stage: ResultStage 81 (parquet at <unknown>:0)
26/01/12 02:19:58 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:19:58 INFO DAGScheduler: Missing parents: List()
26/01/12 02:19:58 INFO DAGScheduler: Submitting ResultStage 81 (MapPartitionsRDD[204] at parquet at <unknown>:0), which has no missing parents
26/01/12 02:19:58 INFO MemoryStore: Block broadcast_122 stored as values in memory (estimated size 225.1 KiB, free 363.9 MiB)
26/01/12 02:19:58 INFO MemoryStore: Block broadcast_122_piece0 stored as bytes in memory (estimated size 77.4 KiB, free 363.9 MiB)
26/01/12 02:19:58 INFO BlockManagerInfo: Added broadcast_122_piece0 in memory on 02926ee04bc9:45221 (size: 77.4 KiB, free: 365.9 MiB)
26/01/12 02:19:58 INFO SparkContext: Created broadcast 122 from broadcast at DAGScheduler.scala:1513
26/01/12 02:19:58 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 81 (MapPartitionsRDD[204] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1))
26/01/12 02:19:58 INFO TaskSchedulerImpl: Adding task set 81.0 with 2 tasks resource profile 0
26/01/12 02:19:58 INFO TaskSetManager: Starting task 0.0 in stage 81.0 (TID 168) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:19:58 INFO TaskSetManager: Starting task 1.0 in stage 81.0 (TID 169) (172.18.0.5, executor 0, partition 1, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:19:58 INFO BlockManagerInfo: Added broadcast_122_piece0 in memory on 172.18.0.5:42453 (size: 77.4 KiB, free: 365.9 MiB)
26/01/12 02:19:58 INFO BlockManagerInfo: Added broadcast_121_piece0 in memory on 172.18.0.5:42453 (size: 35.4 KiB, free: 365.9 MiB)
26/01/12 02:19:58 INFO TaskSetManager: Finished task 1.0 in stage 81.0 (TID 169) in 59 ms on 172.18.0.5 (executor 0) (1/2)
26/01/12 02:20:30 INFO TaskSetManager: Finished task 0.0 in stage 81.0 (TID 168) in 31326 ms on 172.18.0.5 (executor 0) (2/2)
26/01/12 02:20:30 INFO TaskSchedulerImpl: Removed TaskSet 81.0, whose tasks have all completed, from pool 
26/01/12 02:20:30 INFO DAGScheduler: ResultStage 81 (parquet at <unknown>:0) finished in 31.348 s
26/01/12 02:20:30 INFO DAGScheduler: Job 81 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:20:30 INFO TaskSchedulerImpl: Killing all running tasks in stage 81: Stage finished
26/01/12 02:20:30 INFO DAGScheduler: Job 81 finished: parquet at <unknown>:0, took 31.357878 s
26/01/12 02:20:30 INFO FileFormatWriter: Start to commit write Job e1621ee1-a110-410e-86b6-c3e3f003e051.
26/01/12 02:20:30 INFO FileFormatWriter: Write Job e1621ee1-a110-410e-86b6-c3e3f003e051 committed. Elapsed time: 30 ms.
26/01/12 02:20:30 INFO FileFormatWriter: Finished processing stats for write job e1621ee1-a110-410e-86b6-c3e3f003e051.
Cargando: yellow_tripdata_2012-06.parquet en hdfs://hadoop-namenode:8020/data/nyc/raw/taxi-trips/2012...
26/01/12 02:20:30 INFO InMemoryFileIndex: It took 9 ms to list leaf files for 1 paths.
26/01/12 02:20:30 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 02:20:30 INFO DAGScheduler: Got job 82 (parquet at <unknown>:0) with 1 output partitions
26/01/12 02:20:30 INFO DAGScheduler: Final stage: ResultStage 82 (parquet at <unknown>:0)
26/01/12 02:20:30 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:20:30 INFO DAGScheduler: Missing parents: List()
26/01/12 02:20:30 INFO DAGScheduler: Submitting ResultStage 82 (MapPartitionsRDD[206] at parquet at <unknown>:0), which has no missing parents
26/01/12 02:20:30 INFO MemoryStore: Block broadcast_123 stored as values in memory (estimated size 102.6 KiB, free 363.8 MiB)
26/01/12 02:20:30 INFO MemoryStore: Block broadcast_123_piece0 stored as bytes in memory (estimated size 36.8 KiB, free 363.7 MiB)
26/01/12 02:20:30 INFO BlockManagerInfo: Added broadcast_123_piece0 in memory on 02926ee04bc9:45221 (size: 36.8 KiB, free: 365.8 MiB)
26/01/12 02:20:30 INFO SparkContext: Created broadcast 123 from broadcast at DAGScheduler.scala:1513
26/01/12 02:20:30 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 82 (MapPartitionsRDD[206] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0))
26/01/12 02:20:30 INFO TaskSchedulerImpl: Adding task set 82.0 with 1 tasks resource profile 0
26/01/12 02:20:30 INFO TaskSetManager: Starting task 0.0 in stage 82.0 (TID 170) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4607 bytes) taskResourceAssignments Map()
26/01/12 02:20:30 INFO BlockManagerInfo: Added broadcast_123_piece0 in memory on 172.18.0.5:42453 (size: 36.8 KiB, free: 365.8 MiB)
26/01/12 02:20:30 INFO TaskSetManager: Finished task 0.0 in stage 82.0 (TID 170) in 51 ms on 172.18.0.5 (executor 0) (1/1)
26/01/12 02:20:30 INFO TaskSchedulerImpl: Removed TaskSet 82.0, whose tasks have all completed, from pool 
26/01/12 02:20:30 INFO DAGScheduler: ResultStage 82 (parquet at <unknown>:0) finished in 0.064 s
26/01/12 02:20:30 INFO DAGScheduler: Job 82 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:20:30 INFO TaskSchedulerImpl: Killing all running tasks in stage 82: Stage finished
26/01/12 02:20:30 INFO DAGScheduler: Job 82 finished: parquet at <unknown>:0, took 0.068619 s
26/01/12 02:20:30 INFO FileSourceStrategy: Pushed Filters: 
26/01/12 02:20:30 INFO FileSourceStrategy: Post-Scan Filters: 
26/01/12 02:20:30 INFO FileSourceStrategy: Output Data Schema: struct<VendorID: bigint, tpep_pickup_datetime: timestamp, tpep_dropoff_datetime: timestamp, passenger_count: bigint, trip_distance: double ... 17 more fields>
26/01/12 02:20:30 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:20:30 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:20:30 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:20:30 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:20:30 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:20:30 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:20:30 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:20:30 INFO MemoryStore: Block broadcast_124 stored as values in memory (estimated size 358.4 KiB, free 363.4 MiB)
26/01/12 02:20:30 INFO MemoryStore: Block broadcast_124_piece0 stored as bytes in memory (estimated size 35.4 KiB, free 363.3 MiB)
26/01/12 02:20:30 INFO BlockManagerInfo: Added broadcast_124_piece0 in memory on 02926ee04bc9:45221 (size: 35.4 KiB, free: 365.8 MiB)
26/01/12 02:20:30 INFO SparkContext: Created broadcast 124 from parquet at <unknown>:0
26/01/12 02:20:30 INFO FileSourceScanExec: Planning scan with bin packing, max size: 98851906 bytes, open cost is considered as scanning 4194304 bytes.
26/01/12 02:20:30 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 02:20:30 INFO DAGScheduler: Got job 83 (parquet at <unknown>:0) with 2 output partitions
26/01/12 02:20:30 INFO DAGScheduler: Final stage: ResultStage 83 (parquet at <unknown>:0)
26/01/12 02:20:30 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:20:30 INFO DAGScheduler: Missing parents: List()
26/01/12 02:20:30 INFO DAGScheduler: Submitting ResultStage 83 (MapPartitionsRDD[209] at parquet at <unknown>:0), which has no missing parents
26/01/12 02:20:30 INFO MemoryStore: Block broadcast_125 stored as values in memory (estimated size 225.1 KiB, free 363.1 MiB)
26/01/12 02:20:30 INFO MemoryStore: Block broadcast_125_piece0 stored as bytes in memory (estimated size 77.4 KiB, free 363.0 MiB)
26/01/12 02:20:30 INFO BlockManagerInfo: Added broadcast_125_piece0 in memory on 02926ee04bc9:45221 (size: 77.4 KiB, free: 365.7 MiB)
26/01/12 02:20:30 INFO SparkContext: Created broadcast 125 from broadcast at DAGScheduler.scala:1513
26/01/12 02:20:30 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 83 (MapPartitionsRDD[209] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1))
26/01/12 02:20:30 INFO TaskSchedulerImpl: Adding task set 83.0 with 2 tasks resource profile 0
26/01/12 02:20:30 INFO TaskSetManager: Starting task 0.0 in stage 83.0 (TID 171) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:20:30 INFO TaskSetManager: Starting task 1.0 in stage 83.0 (TID 172) (172.18.0.5, executor 0, partition 1, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:20:30 INFO BlockManagerInfo: Added broadcast_125_piece0 in memory on 172.18.0.5:42453 (size: 77.4 KiB, free: 365.7 MiB)
26/01/12 02:20:30 INFO BlockManagerInfo: Added broadcast_124_piece0 in memory on 172.18.0.5:42453 (size: 35.4 KiB, free: 365.7 MiB)
26/01/12 02:20:30 INFO TaskSetManager: Finished task 1.0 in stage 83.0 (TID 172) in 60 ms on 172.18.0.5 (executor 0) (1/2)
26/01/12 02:21:03 INFO TaskSetManager: Finished task 0.0 in stage 83.0 (TID 171) in 32843 ms on 172.18.0.5 (executor 0) (2/2)
26/01/12 02:21:03 INFO TaskSchedulerImpl: Removed TaskSet 83.0, whose tasks have all completed, from pool 
26/01/12 02:21:03 INFO DAGScheduler: ResultStage 83 (parquet at <unknown>:0) finished in 32.863 s
26/01/12 02:21:03 INFO DAGScheduler: Job 83 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:21:03 INFO TaskSchedulerImpl: Killing all running tasks in stage 83: Stage finished
26/01/12 02:21:03 INFO DAGScheduler: Job 83 finished: parquet at <unknown>:0, took 32.869496 s
26/01/12 02:21:03 INFO FileFormatWriter: Start to commit write Job b4eaedb9-06e4-47b6-9e20-22b870cd92e7.
26/01/12 02:21:03 INFO FileFormatWriter: Write Job b4eaedb9-06e4-47b6-9e20-22b870cd92e7 committed. Elapsed time: 32 ms.
26/01/12 02:21:03 INFO FileFormatWriter: Finished processing stats for write job b4eaedb9-06e4-47b6-9e20-22b870cd92e7.
Cargando: yellow_tripdata_2012-07.parquet en hdfs://hadoop-namenode:8020/data/nyc/raw/taxi-trips/2012...
26/01/12 02:21:03 INFO InMemoryFileIndex: It took 6 ms to list leaf files for 1 paths.
26/01/12 02:21:03 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 02:21:03 INFO DAGScheduler: Got job 84 (parquet at <unknown>:0) with 1 output partitions
26/01/12 02:21:03 INFO DAGScheduler: Final stage: ResultStage 84 (parquet at <unknown>:0)
26/01/12 02:21:03 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:21:03 INFO DAGScheduler: Missing parents: List()
26/01/12 02:21:03 INFO DAGScheduler: Submitting ResultStage 84 (MapPartitionsRDD[211] at parquet at <unknown>:0), which has no missing parents
26/01/12 02:21:03 INFO MemoryStore: Block broadcast_126 stored as values in memory (estimated size 102.6 KiB, free 362.9 MiB)
26/01/12 02:21:03 INFO MemoryStore: Block broadcast_126_piece0 stored as bytes in memory (estimated size 36.8 KiB, free 362.9 MiB)
26/01/12 02:21:03 INFO BlockManagerInfo: Added broadcast_126_piece0 in memory on 02926ee04bc9:45221 (size: 36.8 KiB, free: 365.7 MiB)
26/01/12 02:21:03 INFO SparkContext: Created broadcast 126 from broadcast at DAGScheduler.scala:1513
26/01/12 02:21:03 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 84 (MapPartitionsRDD[211] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0))
26/01/12 02:21:03 INFO TaskSchedulerImpl: Adding task set 84.0 with 1 tasks resource profile 0
26/01/12 02:21:03 INFO TaskSetManager: Starting task 0.0 in stage 84.0 (TID 173) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4607 bytes) taskResourceAssignments Map()
26/01/12 02:21:03 INFO BlockManagerInfo: Added broadcast_126_piece0 in memory on 172.18.0.5:42453 (size: 36.8 KiB, free: 365.7 MiB)
26/01/12 02:21:03 INFO TaskSetManager: Finished task 0.0 in stage 84.0 (TID 173) in 50 ms on 172.18.0.5 (executor 0) (1/1)
26/01/12 02:21:03 INFO TaskSchedulerImpl: Removed TaskSet 84.0, whose tasks have all completed, from pool 
26/01/12 02:21:03 INFO DAGScheduler: ResultStage 84 (parquet at <unknown>:0) finished in 0.063 s
26/01/12 02:21:03 INFO DAGScheduler: Job 84 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:21:03 INFO TaskSchedulerImpl: Killing all running tasks in stage 84: Stage finished
26/01/12 02:21:03 INFO DAGScheduler: Job 84 finished: parquet at <unknown>:0, took 0.068384 s
26/01/12 02:21:03 INFO FileSourceStrategy: Pushed Filters: 
26/01/12 02:21:03 INFO FileSourceStrategy: Post-Scan Filters: 
26/01/12 02:21:03 INFO FileSourceStrategy: Output Data Schema: struct<VendorID: bigint, tpep_pickup_datetime: timestamp, tpep_dropoff_datetime: timestamp, passenger_count: bigint, trip_distance: double ... 17 more fields>
26/01/12 02:21:03 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:21:03 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:21:03 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:21:03 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:21:03 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:21:03 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:21:03 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:21:03 INFO MemoryStore: Block broadcast_127 stored as values in memory (estimated size 358.4 KiB, free 362.5 MiB)
26/01/12 02:21:03 INFO MemoryStore: Block broadcast_127_piece0 stored as bytes in memory (estimated size 35.4 KiB, free 362.5 MiB)
26/01/12 02:21:03 INFO BlockManagerInfo: Added broadcast_127_piece0 in memory on 02926ee04bc9:45221 (size: 35.4 KiB, free: 365.6 MiB)
26/01/12 02:21:03 INFO SparkContext: Created broadcast 127 from parquet at <unknown>:0
26/01/12 02:21:03 INFO FileSourceScanExec: Planning scan with bin packing, max size: 94064928 bytes, open cost is considered as scanning 4194304 bytes.
26/01/12 02:21:03 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 02:21:03 INFO DAGScheduler: Got job 85 (parquet at <unknown>:0) with 2 output partitions
26/01/12 02:21:03 INFO DAGScheduler: Final stage: ResultStage 85 (parquet at <unknown>:0)
26/01/12 02:21:03 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:21:03 INFO DAGScheduler: Missing parents: List()
26/01/12 02:21:03 INFO DAGScheduler: Submitting ResultStage 85 (MapPartitionsRDD[214] at parquet at <unknown>:0), which has no missing parents
26/01/12 02:21:03 INFO MemoryStore: Block broadcast_128 stored as values in memory (estimated size 225.1 KiB, free 362.3 MiB)
26/01/12 02:21:03 INFO MemoryStore: Block broadcast_128_piece0 stored as bytes in memory (estimated size 77.4 KiB, free 362.2 MiB)
26/01/12 02:21:03 INFO BlockManagerInfo: Added broadcast_128_piece0 in memory on 02926ee04bc9:45221 (size: 77.4 KiB, free: 365.6 MiB)
26/01/12 02:21:03 INFO SparkContext: Created broadcast 128 from broadcast at DAGScheduler.scala:1513
26/01/12 02:21:03 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 85 (MapPartitionsRDD[214] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1))
26/01/12 02:21:03 INFO TaskSchedulerImpl: Adding task set 85.0 with 2 tasks resource profile 0
26/01/12 02:21:03 INFO TaskSetManager: Starting task 0.0 in stage 85.0 (TID 174) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:21:03 INFO TaskSetManager: Starting task 1.0 in stage 85.0 (TID 175) (172.18.0.5, executor 0, partition 1, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:21:03 INFO BlockManagerInfo: Added broadcast_128_piece0 in memory on 172.18.0.5:42453 (size: 77.4 KiB, free: 365.6 MiB)
26/01/12 02:21:03 INFO BlockManagerInfo: Added broadcast_127_piece0 in memory on 172.18.0.5:42453 (size: 35.4 KiB, free: 365.6 MiB)
26/01/12 02:21:03 INFO TaskSetManager: Finished task 1.0 in stage 85.0 (TID 175) in 67 ms on 172.18.0.5 (executor 0) (1/2)
26/01/12 02:21:34 INFO TaskSetManager: Finished task 0.0 in stage 85.0 (TID 174) in 30776 ms on 172.18.0.5 (executor 0) (2/2)
26/01/12 02:21:34 INFO TaskSchedulerImpl: Removed TaskSet 85.0, whose tasks have all completed, from pool 
26/01/12 02:21:34 INFO DAGScheduler: ResultStage 85 (parquet at <unknown>:0) finished in 30.797 s
26/01/12 02:21:34 INFO DAGScheduler: Job 85 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:21:34 INFO TaskSchedulerImpl: Killing all running tasks in stage 85: Stage finished
26/01/12 02:21:34 INFO DAGScheduler: Job 85 finished: parquet at <unknown>:0, took 30.806307 s
26/01/12 02:21:34 INFO FileFormatWriter: Start to commit write Job 5b77450c-808c-4907-8723-6af3be45adc3.
26/01/12 02:21:34 INFO FileFormatWriter: Write Job 5b77450c-808c-4907-8723-6af3be45adc3 committed. Elapsed time: 35 ms.
26/01/12 02:21:34 INFO FileFormatWriter: Finished processing stats for write job 5b77450c-808c-4907-8723-6af3be45adc3.
Cargando: yellow_tripdata_2012-08.parquet en hdfs://hadoop-namenode:8020/data/nyc/raw/taxi-trips/2012...
26/01/12 02:21:34 INFO InMemoryFileIndex: It took 8 ms to list leaf files for 1 paths.
26/01/12 02:21:34 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 02:21:34 INFO DAGScheduler: Got job 86 (parquet at <unknown>:0) with 1 output partitions
26/01/12 02:21:34 INFO DAGScheduler: Final stage: ResultStage 86 (parquet at <unknown>:0)
26/01/12 02:21:34 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:21:34 INFO DAGScheduler: Missing parents: List()
26/01/12 02:21:34 INFO DAGScheduler: Submitting ResultStage 86 (MapPartitionsRDD[216] at parquet at <unknown>:0), which has no missing parents
26/01/12 02:21:34 INFO MemoryStore: Block broadcast_129 stored as values in memory (estimated size 102.6 KiB, free 362.1 MiB)
26/01/12 02:21:34 INFO MemoryStore: Block broadcast_129_piece0 stored as bytes in memory (estimated size 36.8 KiB, free 362.1 MiB)
26/01/12 02:21:34 INFO BlockManagerInfo: Added broadcast_129_piece0 in memory on 02926ee04bc9:45221 (size: 36.8 KiB, free: 365.5 MiB)
26/01/12 02:21:34 INFO SparkContext: Created broadcast 129 from broadcast at DAGScheduler.scala:1513
26/01/12 02:21:34 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 86 (MapPartitionsRDD[216] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0))
26/01/12 02:21:34 INFO TaskSchedulerImpl: Adding task set 86.0 with 1 tasks resource profile 0
26/01/12 02:21:34 INFO TaskSetManager: Starting task 0.0 in stage 86.0 (TID 176) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4607 bytes) taskResourceAssignments Map()
26/01/12 02:21:34 INFO BlockManagerInfo: Removed broadcast_121_piece0 on 02926ee04bc9:45221 in memory (size: 35.4 KiB, free: 365.6 MiB)
26/01/12 02:21:34 INFO BlockManagerInfo: Removed broadcast_121_piece0 on 172.18.0.5:42453 in memory (size: 35.4 KiB, free: 365.6 MiB)
26/01/12 02:21:34 INFO BlockManagerInfo: Added broadcast_129_piece0 in memory on 172.18.0.5:42453 (size: 36.8 KiB, free: 365.6 MiB)
26/01/12 02:21:34 INFO BlockManagerInfo: Removed broadcast_114_piece0 on 02926ee04bc9:45221 in memory (size: 36.8 KiB, free: 365.6 MiB)
26/01/12 02:21:34 INFO BlockManagerInfo: Removed broadcast_114_piece0 on 172.18.0.5:42453 in memory (size: 36.8 KiB, free: 365.6 MiB)
26/01/12 02:21:34 INFO BlockManagerInfo: Removed broadcast_118_piece0 on 02926ee04bc9:45221 in memory (size: 35.4 KiB, free: 365.6 MiB)
26/01/12 02:21:34 INFO BlockManagerInfo: Removed broadcast_118_piece0 on 172.18.0.5:42453 in memory (size: 35.4 KiB, free: 365.6 MiB)
26/01/12 02:21:34 INFO BlockManagerInfo: Removed broadcast_122_piece0 on 02926ee04bc9:45221 in memory (size: 77.4 KiB, free: 365.7 MiB)
26/01/12 02:21:34 INFO BlockManagerInfo: Removed broadcast_122_piece0 on 172.18.0.5:42453 in memory (size: 77.4 KiB, free: 365.7 MiB)
26/01/12 02:21:34 INFO BlockManagerInfo: Removed broadcast_117_piece0 on 02926ee04bc9:45221 in memory (size: 36.8 KiB, free: 365.7 MiB)
26/01/12 02:21:34 INFO BlockManagerInfo: Removed broadcast_117_piece0 on 172.18.0.5:42453 in memory (size: 36.8 KiB, free: 365.7 MiB)
26/01/12 02:21:34 INFO BlockManagerInfo: Removed broadcast_119_piece0 on 02926ee04bc9:45221 in memory (size: 77.5 KiB, free: 365.8 MiB)
26/01/12 02:21:34 INFO BlockManagerInfo: Removed broadcast_119_piece0 on 172.18.0.5:42453 in memory (size: 77.5 KiB, free: 365.8 MiB)
26/01/12 02:21:34 INFO BlockManagerInfo: Removed broadcast_128_piece0 on 02926ee04bc9:45221 in memory (size: 77.4 KiB, free: 365.9 MiB)
26/01/12 02:21:34 INFO BlockManagerInfo: Removed broadcast_128_piece0 on 172.18.0.5:42453 in memory (size: 77.4 KiB, free: 365.9 MiB)
26/01/12 02:21:34 INFO BlockManagerInfo: Removed broadcast_125_piece0 on 02926ee04bc9:45221 in memory (size: 77.4 KiB, free: 366.0 MiB)
26/01/12 02:21:34 INFO BlockManagerInfo: Removed broadcast_125_piece0 on 172.18.0.5:42453 in memory (size: 77.4 KiB, free: 366.0 MiB)
26/01/12 02:21:34 INFO BlockManagerInfo: Removed broadcast_115_piece0 on 02926ee04bc9:45221 in memory (size: 35.4 KiB, free: 366.0 MiB)
26/01/12 02:21:34 INFO BlockManagerInfo: Removed broadcast_115_piece0 on 172.18.0.5:42453 in memory (size: 35.4 KiB, free: 366.0 MiB)
26/01/12 02:21:34 INFO BlockManagerInfo: Removed broadcast_127_piece0 on 02926ee04bc9:45221 in memory (size: 35.4 KiB, free: 366.0 MiB)
26/01/12 02:21:34 INFO BlockManagerInfo: Removed broadcast_127_piece0 on 172.18.0.5:42453 in memory (size: 35.4 KiB, free: 366.0 MiB)
26/01/12 02:21:34 INFO TaskSetManager: Finished task 0.0 in stage 86.0 (TID 176) in 74 ms on 172.18.0.5 (executor 0) (1/1)
26/01/12 02:21:34 INFO TaskSchedulerImpl: Removed TaskSet 86.0, whose tasks have all completed, from pool 
26/01/12 02:21:34 INFO DAGScheduler: ResultStage 86 (parquet at <unknown>:0) finished in 0.123 s
26/01/12 02:21:34 INFO DAGScheduler: Job 86 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:21:34 INFO TaskSchedulerImpl: Killing all running tasks in stage 86: Stage finished
26/01/12 02:21:34 INFO BlockManagerInfo: Removed broadcast_124_piece0 on 02926ee04bc9:45221 in memory (size: 35.4 KiB, free: 366.1 MiB)
26/01/12 02:21:34 INFO DAGScheduler: Job 86 finished: parquet at <unknown>:0, took 0.128568 s
26/01/12 02:21:34 INFO BlockManagerInfo: Removed broadcast_124_piece0 on 172.18.0.5:42453 in memory (size: 35.4 KiB, free: 366.1 MiB)
26/01/12 02:21:34 INFO BlockManagerInfo: Removed broadcast_120_piece0 on 02926ee04bc9:45221 in memory (size: 36.8 KiB, free: 366.1 MiB)
26/01/12 02:21:34 INFO BlockManagerInfo: Removed broadcast_120_piece0 on 172.18.0.5:42453 in memory (size: 36.8 KiB, free: 366.1 MiB)
26/01/12 02:21:34 INFO BlockManagerInfo: Removed broadcast_116_piece0 on 02926ee04bc9:45221 in memory (size: 77.4 KiB, free: 366.2 MiB)
26/01/12 02:21:34 INFO FileSourceStrategy: Pushed Filters: 
26/01/12 02:21:34 INFO FileSourceStrategy: Post-Scan Filters: 
26/01/12 02:21:34 INFO BlockManagerInfo: Removed broadcast_116_piece0 on 172.18.0.5:42453 in memory (size: 77.4 KiB, free: 366.2 MiB)
26/01/12 02:21:34 INFO FileSourceStrategy: Output Data Schema: struct<VendorID: bigint, tpep_pickup_datetime: timestamp, tpep_dropoff_datetime: timestamp, passenger_count: bigint, trip_distance: double ... 17 more fields>
26/01/12 02:21:34 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:21:34 INFO BlockManagerInfo: Removed broadcast_126_piece0 on 02926ee04bc9:45221 in memory (size: 36.8 KiB, free: 366.2 MiB)
26/01/12 02:21:34 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:21:34 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:21:34 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:21:34 INFO BlockManagerInfo: Removed broadcast_126_piece0 on 172.18.0.5:42453 in memory (size: 36.8 KiB, free: 366.2 MiB)
26/01/12 02:21:34 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:21:34 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:21:34 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:21:34 INFO BlockManagerInfo: Removed broadcast_123_piece0 on 02926ee04bc9:45221 in memory (size: 36.8 KiB, free: 366.3 MiB)
26/01/12 02:21:34 INFO BlockManagerInfo: Removed broadcast_123_piece0 on 172.18.0.5:42453 in memory (size: 36.8 KiB, free: 366.3 MiB)
26/01/12 02:21:34 INFO MemoryStore: Block broadcast_130 stored as values in memory (estimated size 358.4 KiB, free 365.8 MiB)
26/01/12 02:21:34 INFO MemoryStore: Block broadcast_130_piece0 stored as bytes in memory (estimated size 35.4 KiB, free 365.8 MiB)
26/01/12 02:21:34 INFO BlockManagerInfo: Added broadcast_130_piece0 in memory on 02926ee04bc9:45221 (size: 35.4 KiB, free: 366.2 MiB)
26/01/12 02:21:34 INFO SparkContext: Created broadcast 130 from parquet at <unknown>:0
26/01/12 02:21:34 INFO FileSourceScanExec: Planning scan with bin packing, max size: 94350682 bytes, open cost is considered as scanning 4194304 bytes.
26/01/12 02:21:34 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 02:21:34 INFO DAGScheduler: Got job 87 (parquet at <unknown>:0) with 2 output partitions
26/01/12 02:21:34 INFO DAGScheduler: Final stage: ResultStage 87 (parquet at <unknown>:0)
26/01/12 02:21:34 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:21:34 INFO DAGScheduler: Missing parents: List()
26/01/12 02:21:34 INFO DAGScheduler: Submitting ResultStage 87 (MapPartitionsRDD[219] at parquet at <unknown>:0), which has no missing parents
26/01/12 02:21:34 INFO MemoryStore: Block broadcast_131 stored as values in memory (estimated size 225.1 KiB, free 365.6 MiB)
26/01/12 02:21:34 INFO MemoryStore: Block broadcast_131_piece0 stored as bytes in memory (estimated size 77.4 KiB, free 365.5 MiB)
26/01/12 02:21:34 INFO BlockManagerInfo: Added broadcast_131_piece0 in memory on 02926ee04bc9:45221 (size: 77.4 KiB, free: 366.2 MiB)
26/01/12 02:21:34 INFO SparkContext: Created broadcast 131 from broadcast at DAGScheduler.scala:1513
26/01/12 02:21:34 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 87 (MapPartitionsRDD[219] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1))
26/01/12 02:21:34 INFO TaskSchedulerImpl: Adding task set 87.0 with 2 tasks resource profile 0
26/01/12 02:21:34 INFO TaskSetManager: Starting task 0.0 in stage 87.0 (TID 177) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:21:34 INFO TaskSetManager: Starting task 1.0 in stage 87.0 (TID 178) (172.18.0.5, executor 0, partition 1, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:21:34 INFO BlockManagerInfo: Added broadcast_131_piece0 in memory on 172.18.0.5:42453 (size: 77.4 KiB, free: 366.2 MiB)
26/01/12 02:21:34 INFO BlockManagerInfo: Added broadcast_130_piece0 in memory on 172.18.0.5:42453 (size: 35.4 KiB, free: 366.2 MiB)
26/01/12 02:21:34 INFO TaskSetManager: Finished task 1.0 in stage 87.0 (TID 178) in 55 ms on 172.18.0.5 (executor 0) (1/2)
26/01/12 02:22:06 INFO TaskSetManager: Finished task 0.0 in stage 87.0 (TID 177) in 31999 ms on 172.18.0.5 (executor 0) (2/2)
26/01/12 02:22:06 INFO TaskSchedulerImpl: Removed TaskSet 87.0, whose tasks have all completed, from pool 
26/01/12 02:22:06 INFO DAGScheduler: ResultStage 87 (parquet at <unknown>:0) finished in 32.021 s
26/01/12 02:22:06 INFO DAGScheduler: Job 87 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:22:06 INFO TaskSchedulerImpl: Killing all running tasks in stage 87: Stage finished
26/01/12 02:22:06 INFO DAGScheduler: Job 87 finished: parquet at <unknown>:0, took 32.028533 s
26/01/12 02:22:06 INFO FileFormatWriter: Start to commit write Job 58758169-9994-40fe-8f5d-218685299011.
26/01/12 02:22:06 INFO FileFormatWriter: Write Job 58758169-9994-40fe-8f5d-218685299011 committed. Elapsed time: 30 ms.
26/01/12 02:22:06 INFO FileFormatWriter: Finished processing stats for write job 58758169-9994-40fe-8f5d-218685299011.
Cargando: yellow_tripdata_2012-09.parquet en hdfs://hadoop-namenode:8020/data/nyc/raw/taxi-trips/2012...
26/01/12 02:22:06 INFO InMemoryFileIndex: It took 7 ms to list leaf files for 1 paths.
26/01/12 02:22:06 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 02:22:06 INFO DAGScheduler: Got job 88 (parquet at <unknown>:0) with 1 output partitions
26/01/12 02:22:06 INFO DAGScheduler: Final stage: ResultStage 88 (parquet at <unknown>:0)
26/01/12 02:22:06 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:22:06 INFO DAGScheduler: Missing parents: List()
26/01/12 02:22:06 INFO DAGScheduler: Submitting ResultStage 88 (MapPartitionsRDD[221] at parquet at <unknown>:0), which has no missing parents
26/01/12 02:22:06 INFO MemoryStore: Block broadcast_132 stored as values in memory (estimated size 102.6 KiB, free 365.4 MiB)
26/01/12 02:22:06 INFO MemoryStore: Block broadcast_132_piece0 stored as bytes in memory (estimated size 36.8 KiB, free 365.3 MiB)
26/01/12 02:22:06 INFO BlockManagerInfo: Added broadcast_132_piece0 in memory on 02926ee04bc9:45221 (size: 36.8 KiB, free: 366.1 MiB)
26/01/12 02:22:06 INFO SparkContext: Created broadcast 132 from broadcast at DAGScheduler.scala:1513
26/01/12 02:22:06 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 88 (MapPartitionsRDD[221] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0))
26/01/12 02:22:06 INFO TaskSchedulerImpl: Adding task set 88.0 with 1 tasks resource profile 0
26/01/12 02:22:06 INFO TaskSetManager: Starting task 0.0 in stage 88.0 (TID 179) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4607 bytes) taskResourceAssignments Map()
26/01/12 02:22:06 INFO BlockManagerInfo: Added broadcast_132_piece0 in memory on 172.18.0.5:42453 (size: 36.8 KiB, free: 366.1 MiB)
26/01/12 02:22:06 INFO TaskSetManager: Finished task 0.0 in stage 88.0 (TID 179) in 50 ms on 172.18.0.5 (executor 0) (1/1)
26/01/12 02:22:06 INFO TaskSchedulerImpl: Removed TaskSet 88.0, whose tasks have all completed, from pool 
26/01/12 02:22:06 INFO DAGScheduler: ResultStage 88 (parquet at <unknown>:0) finished in 0.063 s
26/01/12 02:22:06 INFO DAGScheduler: Job 88 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:22:06 INFO TaskSchedulerImpl: Killing all running tasks in stage 88: Stage finished
26/01/12 02:22:06 INFO DAGScheduler: Job 88 finished: parquet at <unknown>:0, took 0.068284 s
26/01/12 02:22:06 INFO FileSourceStrategy: Pushed Filters: 
26/01/12 02:22:06 INFO FileSourceStrategy: Post-Scan Filters: 
26/01/12 02:22:06 INFO FileSourceStrategy: Output Data Schema: struct<VendorID: bigint, tpep_pickup_datetime: timestamp, tpep_dropoff_datetime: timestamp, passenger_count: bigint, trip_distance: double ... 17 more fields>
26/01/12 02:22:06 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:22:06 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:22:06 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:22:06 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:22:06 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:22:06 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:22:06 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:22:06 INFO MemoryStore: Block broadcast_133 stored as values in memory (estimated size 358.4 KiB, free 365.0 MiB)
26/01/12 02:22:06 INFO MemoryStore: Block broadcast_133_piece0 stored as bytes in memory (estimated size 35.4 KiB, free 365.0 MiB)
26/01/12 02:22:06 INFO BlockManagerInfo: Added broadcast_133_piece0 in memory on 02926ee04bc9:45221 (size: 35.4 KiB, free: 366.1 MiB)
26/01/12 02:22:06 INFO SparkContext: Created broadcast 133 from parquet at <unknown>:0
26/01/12 02:22:06 INFO FileSourceScanExec: Planning scan with bin packing, max size: 95719793 bytes, open cost is considered as scanning 4194304 bytes.
26/01/12 02:22:06 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 02:22:06 INFO DAGScheduler: Got job 89 (parquet at <unknown>:0) with 2 output partitions
26/01/12 02:22:06 INFO DAGScheduler: Final stage: ResultStage 89 (parquet at <unknown>:0)
26/01/12 02:22:06 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:22:06 INFO DAGScheduler: Missing parents: List()
26/01/12 02:22:06 INFO DAGScheduler: Submitting ResultStage 89 (MapPartitionsRDD[224] at parquet at <unknown>:0), which has no missing parents
26/01/12 02:22:06 INFO MemoryStore: Block broadcast_134 stored as values in memory (estimated size 225.1 KiB, free 364.7 MiB)
26/01/12 02:22:06 INFO MemoryStore: Block broadcast_134_piece0 stored as bytes in memory (estimated size 77.4 KiB, free 364.7 MiB)
26/01/12 02:22:06 INFO BlockManagerInfo: Added broadcast_134_piece0 in memory on 02926ee04bc9:45221 (size: 77.4 KiB, free: 366.0 MiB)
26/01/12 02:22:06 INFO SparkContext: Created broadcast 134 from broadcast at DAGScheduler.scala:1513
26/01/12 02:22:06 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 89 (MapPartitionsRDD[224] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1))
26/01/12 02:22:06 INFO TaskSchedulerImpl: Adding task set 89.0 with 2 tasks resource profile 0
26/01/12 02:22:06 INFO TaskSetManager: Starting task 0.0 in stage 89.0 (TID 180) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:22:06 INFO TaskSetManager: Starting task 1.0 in stage 89.0 (TID 181) (172.18.0.5, executor 0, partition 1, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:22:06 INFO BlockManagerInfo: Added broadcast_134_piece0 in memory on 172.18.0.5:42453 (size: 77.4 KiB, free: 366.0 MiB)
26/01/12 02:22:06 INFO BlockManagerInfo: Added broadcast_133_piece0 in memory on 172.18.0.5:42453 (size: 35.4 KiB, free: 366.0 MiB)
26/01/12 02:22:06 INFO TaskSetManager: Finished task 1.0 in stage 89.0 (TID 181) in 60 ms on 172.18.0.5 (executor 0) (1/2)
26/01/12 02:22:37 INFO TaskSetManager: Finished task 0.0 in stage 89.0 (TID 180) in 30861 ms on 172.18.0.5 (executor 0) (2/2)
26/01/12 02:22:37 INFO TaskSchedulerImpl: Removed TaskSet 89.0, whose tasks have all completed, from pool 
26/01/12 02:22:37 INFO DAGScheduler: ResultStage 89 (parquet at <unknown>:0) finished in 30.882 s
26/01/12 02:22:37 INFO DAGScheduler: Job 89 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:22:37 INFO TaskSchedulerImpl: Killing all running tasks in stage 89: Stage finished
26/01/12 02:22:37 INFO DAGScheduler: Job 89 finished: parquet at <unknown>:0, took 30.888656 s
26/01/12 02:22:37 INFO FileFormatWriter: Start to commit write Job 158330ed-6198-4f10-9e7d-acf14770c5a6.
26/01/12 02:22:37 INFO FileFormatWriter: Write Job 158330ed-6198-4f10-9e7d-acf14770c5a6 committed. Elapsed time: 31 ms.
26/01/12 02:22:37 INFO FileFormatWriter: Finished processing stats for write job 158330ed-6198-4f10-9e7d-acf14770c5a6.
Cargando: yellow_tripdata_2012-10.parquet en hdfs://hadoop-namenode:8020/data/nyc/raw/taxi-trips/2012...
26/01/12 02:22:37 INFO InMemoryFileIndex: It took 7 ms to list leaf files for 1 paths.
26/01/12 02:22:37 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 02:22:37 INFO DAGScheduler: Got job 90 (parquet at <unknown>:0) with 1 output partitions
26/01/12 02:22:37 INFO DAGScheduler: Final stage: ResultStage 90 (parquet at <unknown>:0)
26/01/12 02:22:37 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:22:37 INFO DAGScheduler: Missing parents: List()
26/01/12 02:22:37 INFO DAGScheduler: Submitting ResultStage 90 (MapPartitionsRDD[226] at parquet at <unknown>:0), which has no missing parents
26/01/12 02:22:37 INFO MemoryStore: Block broadcast_135 stored as values in memory (estimated size 102.6 KiB, free 364.6 MiB)
26/01/12 02:22:37 INFO MemoryStore: Block broadcast_135_piece0 stored as bytes in memory (estimated size 36.8 KiB, free 364.5 MiB)
26/01/12 02:22:37 INFO BlockManagerInfo: Added broadcast_135_piece0 in memory on 02926ee04bc9:45221 (size: 36.8 KiB, free: 366.0 MiB)
26/01/12 02:22:37 INFO SparkContext: Created broadcast 135 from broadcast at DAGScheduler.scala:1513
26/01/12 02:22:37 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 90 (MapPartitionsRDD[226] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0))
26/01/12 02:22:37 INFO TaskSchedulerImpl: Adding task set 90.0 with 1 tasks resource profile 0
26/01/12 02:22:37 INFO TaskSetManager: Starting task 0.0 in stage 90.0 (TID 182) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4607 bytes) taskResourceAssignments Map()
26/01/12 02:22:37 INFO BlockManagerInfo: Added broadcast_135_piece0 in memory on 172.18.0.5:42453 (size: 36.8 KiB, free: 366.0 MiB)
26/01/12 02:22:37 INFO TaskSetManager: Finished task 0.0 in stage 90.0 (TID 182) in 51 ms on 172.18.0.5 (executor 0) (1/1)
26/01/12 02:22:37 INFO TaskSchedulerImpl: Removed TaskSet 90.0, whose tasks have all completed, from pool 
26/01/12 02:22:37 INFO DAGScheduler: ResultStage 90 (parquet at <unknown>:0) finished in 0.063 s
26/01/12 02:22:37 INFO DAGScheduler: Job 90 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:22:37 INFO TaskSchedulerImpl: Killing all running tasks in stage 90: Stage finished
26/01/12 02:22:37 INFO DAGScheduler: Job 90 finished: parquet at <unknown>:0, took 0.068567 s
26/01/12 02:22:37 INFO FileSourceStrategy: Pushed Filters: 
26/01/12 02:22:37 INFO FileSourceStrategy: Post-Scan Filters: 
26/01/12 02:22:37 INFO FileSourceStrategy: Output Data Schema: struct<VendorID: bigint, tpep_pickup_datetime: timestamp, tpep_dropoff_datetime: timestamp, passenger_count: bigint, trip_distance: double ... 17 more fields>
26/01/12 02:22:37 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:22:37 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:22:37 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:22:37 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:22:37 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:22:37 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:22:37 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:22:37 INFO MemoryStore: Block broadcast_136 stored as values in memory (estimated size 358.4 KiB, free 364.2 MiB)
26/01/12 02:22:37 INFO MemoryStore: Block broadcast_136_piece0 stored as bytes in memory (estimated size 35.4 KiB, free 364.1 MiB)
26/01/12 02:22:37 INFO BlockManagerInfo: Added broadcast_136_piece0 in memory on 02926ee04bc9:45221 (size: 35.4 KiB, free: 365.9 MiB)
26/01/12 02:22:37 INFO SparkContext: Created broadcast 136 from parquet at <unknown>:0
26/01/12 02:22:37 INFO FileSourceScanExec: Planning scan with bin packing, max size: 92850410 bytes, open cost is considered as scanning 4194304 bytes.
26/01/12 02:22:37 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 02:22:37 INFO DAGScheduler: Got job 91 (parquet at <unknown>:0) with 2 output partitions
26/01/12 02:22:37 INFO DAGScheduler: Final stage: ResultStage 91 (parquet at <unknown>:0)
26/01/12 02:22:37 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:22:37 INFO DAGScheduler: Missing parents: List()
26/01/12 02:22:37 INFO DAGScheduler: Submitting ResultStage 91 (MapPartitionsRDD[229] at parquet at <unknown>:0), which has no missing parents
26/01/12 02:22:37 INFO MemoryStore: Block broadcast_137 stored as values in memory (estimated size 225.1 KiB, free 363.9 MiB)
26/01/12 02:22:37 INFO MemoryStore: Block broadcast_137_piece0 stored as bytes in memory (estimated size 77.4 KiB, free 363.9 MiB)
26/01/12 02:22:37 INFO BlockManagerInfo: Added broadcast_137_piece0 in memory on 02926ee04bc9:45221 (size: 77.4 KiB, free: 365.9 MiB)
26/01/12 02:22:37 INFO SparkContext: Created broadcast 137 from broadcast at DAGScheduler.scala:1513
26/01/12 02:22:37 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 91 (MapPartitionsRDD[229] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1))
26/01/12 02:22:37 INFO TaskSchedulerImpl: Adding task set 91.0 with 2 tasks resource profile 0
26/01/12 02:22:37 INFO TaskSetManager: Starting task 0.0 in stage 91.0 (TID 183) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:22:37 INFO TaskSetManager: Starting task 1.0 in stage 91.0 (TID 184) (172.18.0.5, executor 0, partition 1, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:22:37 INFO BlockManagerInfo: Added broadcast_137_piece0 in memory on 172.18.0.5:42453 (size: 77.4 KiB, free: 365.9 MiB)
26/01/12 02:22:37 INFO BlockManagerInfo: Added broadcast_136_piece0 in memory on 172.18.0.5:42453 (size: 35.4 KiB, free: 365.9 MiB)
26/01/12 02:22:38 INFO TaskSetManager: Finished task 1.0 in stage 91.0 (TID 184) in 58 ms on 172.18.0.5 (executor 0) (1/2)
26/01/12 02:23:09 INFO TaskSetManager: Finished task 0.0 in stage 91.0 (TID 183) in 31183 ms on 172.18.0.5 (executor 0) (2/2)
26/01/12 02:23:09 INFO TaskSchedulerImpl: Removed TaskSet 91.0, whose tasks have all completed, from pool 
26/01/12 02:23:09 INFO DAGScheduler: ResultStage 91 (parquet at <unknown>:0) finished in 31.204 s
26/01/12 02:23:09 INFO DAGScheduler: Job 91 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:23:09 INFO TaskSchedulerImpl: Killing all running tasks in stage 91: Stage finished
26/01/12 02:23:09 INFO DAGScheduler: Job 91 finished: parquet at <unknown>:0, took 31.212637 s
26/01/12 02:23:09 INFO FileFormatWriter: Start to commit write Job 386db21f-973e-4c19-b3b0-21621f5ead0b.
26/01/12 02:23:09 INFO FileFormatWriter: Write Job 386db21f-973e-4c19-b3b0-21621f5ead0b committed. Elapsed time: 25 ms.
26/01/12 02:23:09 INFO FileFormatWriter: Finished processing stats for write job 386db21f-973e-4c19-b3b0-21621f5ead0b.
Cargando: yellow_tripdata_2012-11.parquet en hdfs://hadoop-namenode:8020/data/nyc/raw/taxi-trips/2012...
26/01/12 02:23:09 INFO InMemoryFileIndex: It took 8 ms to list leaf files for 1 paths.
26/01/12 02:23:09 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 02:23:09 INFO DAGScheduler: Got job 92 (parquet at <unknown>:0) with 1 output partitions
26/01/12 02:23:09 INFO DAGScheduler: Final stage: ResultStage 92 (parquet at <unknown>:0)
26/01/12 02:23:09 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:23:09 INFO DAGScheduler: Missing parents: List()
26/01/12 02:23:09 INFO DAGScheduler: Submitting ResultStage 92 (MapPartitionsRDD[231] at parquet at <unknown>:0), which has no missing parents
26/01/12 02:23:09 INFO MemoryStore: Block broadcast_138 stored as values in memory (estimated size 102.6 KiB, free 363.8 MiB)
26/01/12 02:23:09 INFO MemoryStore: Block broadcast_138_piece0 stored as bytes in memory (estimated size 36.8 KiB, free 363.7 MiB)
26/01/12 02:23:09 INFO BlockManagerInfo: Added broadcast_138_piece0 in memory on 02926ee04bc9:45221 (size: 36.8 KiB, free: 365.8 MiB)
26/01/12 02:23:09 INFO SparkContext: Created broadcast 138 from broadcast at DAGScheduler.scala:1513
26/01/12 02:23:09 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 92 (MapPartitionsRDD[231] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0))
26/01/12 02:23:09 INFO TaskSchedulerImpl: Adding task set 92.0 with 1 tasks resource profile 0
26/01/12 02:23:09 INFO TaskSetManager: Starting task 0.0 in stage 92.0 (TID 185) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4607 bytes) taskResourceAssignments Map()
26/01/12 02:23:09 INFO BlockManagerInfo: Added broadcast_138_piece0 in memory on 172.18.0.5:42453 (size: 36.8 KiB, free: 365.8 MiB)
26/01/12 02:23:09 INFO TaskSetManager: Finished task 0.0 in stage 92.0 (TID 185) in 48 ms on 172.18.0.5 (executor 0) (1/1)
26/01/12 02:23:09 INFO TaskSchedulerImpl: Removed TaskSet 92.0, whose tasks have all completed, from pool 
26/01/12 02:23:09 INFO DAGScheduler: ResultStage 92 (parquet at <unknown>:0) finished in 0.059 s
26/01/12 02:23:09 INFO DAGScheduler: Job 92 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:23:09 INFO TaskSchedulerImpl: Killing all running tasks in stage 92: Stage finished
26/01/12 02:23:09 INFO DAGScheduler: Job 92 finished: parquet at <unknown>:0, took 0.068920 s
26/01/12 02:23:09 INFO FileSourceStrategy: Pushed Filters: 
26/01/12 02:23:09 INFO FileSourceStrategy: Post-Scan Filters: 
26/01/12 02:23:09 INFO FileSourceStrategy: Output Data Schema: struct<VendorID: bigint, tpep_pickup_datetime: timestamp, tpep_dropoff_datetime: timestamp, passenger_count: bigint, trip_distance: double ... 17 more fields>
26/01/12 02:23:09 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:23:09 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:23:09 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:23:09 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:23:09 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:23:09 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:23:09 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:23:09 INFO MemoryStore: Block broadcast_139 stored as values in memory (estimated size 358.4 KiB, free 363.4 MiB)
26/01/12 02:23:09 INFO MemoryStore: Block broadcast_139_piece0 stored as bytes in memory (estimated size 35.4 KiB, free 363.3 MiB)
26/01/12 02:23:09 INFO BlockManagerInfo: Added broadcast_139_piece0 in memory on 02926ee04bc9:45221 (size: 35.4 KiB, free: 365.8 MiB)
26/01/12 02:23:09 INFO SparkContext: Created broadcast 139 from parquet at <unknown>:0
26/01/12 02:23:09 INFO FileSourceScanExec: Planning scan with bin packing, max size: 88342049 bytes, open cost is considered as scanning 4194304 bytes.
26/01/12 02:23:09 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 02:23:09 INFO DAGScheduler: Got job 93 (parquet at <unknown>:0) with 2 output partitions
26/01/12 02:23:09 INFO DAGScheduler: Final stage: ResultStage 93 (parquet at <unknown>:0)
26/01/12 02:23:09 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:23:09 INFO DAGScheduler: Missing parents: List()
26/01/12 02:23:09 INFO DAGScheduler: Submitting ResultStage 93 (MapPartitionsRDD[234] at parquet at <unknown>:0), which has no missing parents
26/01/12 02:23:09 INFO MemoryStore: Block broadcast_140 stored as values in memory (estimated size 225.1 KiB, free 363.1 MiB)
26/01/12 02:23:09 INFO MemoryStore: Block broadcast_140_piece0 stored as bytes in memory (estimated size 77.4 KiB, free 363.0 MiB)
26/01/12 02:23:09 INFO BlockManagerInfo: Added broadcast_140_piece0 in memory on 02926ee04bc9:45221 (size: 77.4 KiB, free: 365.7 MiB)
26/01/12 02:23:09 INFO SparkContext: Created broadcast 140 from broadcast at DAGScheduler.scala:1513
26/01/12 02:23:09 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 93 (MapPartitionsRDD[234] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1))
26/01/12 02:23:09 INFO TaskSchedulerImpl: Adding task set 93.0 with 2 tasks resource profile 0
26/01/12 02:23:09 INFO TaskSetManager: Starting task 0.0 in stage 93.0 (TID 186) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:23:09 INFO TaskSetManager: Starting task 1.0 in stage 93.0 (TID 187) (172.18.0.5, executor 0, partition 1, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:23:09 INFO BlockManagerInfo: Added broadcast_140_piece0 in memory on 172.18.0.5:42453 (size: 77.4 KiB, free: 365.8 MiB)
26/01/12 02:23:09 INFO BlockManagerInfo: Added broadcast_139_piece0 in memory on 172.18.0.5:42453 (size: 35.4 KiB, free: 365.7 MiB)
26/01/12 02:23:09 INFO TaskSetManager: Finished task 1.0 in stage 93.0 (TID 187) in 56 ms on 172.18.0.5 (executor 0) (1/2)
26/01/12 02:23:10 INFO BlockManagerInfo: Removed broadcast_136_piece0 on 02926ee04bc9:45221 in memory (size: 35.4 KiB, free: 365.8 MiB)
26/01/12 02:23:10 INFO BlockManagerInfo: Removed broadcast_136_piece0 on 172.18.0.5:42453 in memory (size: 35.4 KiB, free: 365.8 MiB)
26/01/12 02:23:10 INFO BlockManagerInfo: Removed broadcast_134_piece0 on 02926ee04bc9:45221 in memory (size: 77.4 KiB, free: 365.8 MiB)
26/01/12 02:23:10 INFO BlockManagerInfo: Removed broadcast_134_piece0 on 172.18.0.5:42453 in memory (size: 77.4 KiB, free: 365.8 MiB)
26/01/12 02:23:10 INFO BlockManagerInfo: Removed broadcast_130_piece0 on 02926ee04bc9:45221 in memory (size: 35.4 KiB, free: 365.9 MiB)
26/01/12 02:23:10 INFO BlockManagerInfo: Removed broadcast_130_piece0 on 172.18.0.5:42453 in memory (size: 35.4 KiB, free: 365.9 MiB)
26/01/12 02:23:10 INFO BlockManagerInfo: Removed broadcast_129_piece0 on 02926ee04bc9:45221 in memory (size: 36.8 KiB, free: 365.9 MiB)
26/01/12 02:23:10 INFO BlockManagerInfo: Removed broadcast_129_piece0 on 172.18.0.5:42453 in memory (size: 36.8 KiB, free: 365.9 MiB)
26/01/12 02:23:10 INFO BlockManagerInfo: Removed broadcast_137_piece0 on 02926ee04bc9:45221 in memory (size: 77.4 KiB, free: 366.0 MiB)
26/01/12 02:23:10 INFO BlockManagerInfo: Removed broadcast_137_piece0 on 172.18.0.5:42453 in memory (size: 77.4 KiB, free: 366.0 MiB)
26/01/12 02:23:10 INFO BlockManagerInfo: Removed broadcast_133_piece0 on 02926ee04bc9:45221 in memory (size: 35.4 KiB, free: 366.0 MiB)
26/01/12 02:23:10 INFO BlockManagerInfo: Removed broadcast_133_piece0 on 172.18.0.5:42453 in memory (size: 35.4 KiB, free: 366.0 MiB)
26/01/12 02:23:10 INFO BlockManagerInfo: Removed broadcast_132_piece0 on 02926ee04bc9:45221 in memory (size: 36.8 KiB, free: 366.0 MiB)
26/01/12 02:23:10 INFO BlockManagerInfo: Removed broadcast_132_piece0 on 172.18.0.5:42453 in memory (size: 36.8 KiB, free: 366.0 MiB)
26/01/12 02:23:10 INFO BlockManagerInfo: Removed broadcast_138_piece0 on 02926ee04bc9:45221 in memory (size: 36.8 KiB, free: 366.1 MiB)
26/01/12 02:23:10 INFO BlockManagerInfo: Removed broadcast_138_piece0 on 172.18.0.5:42453 in memory (size: 36.8 KiB, free: 366.1 MiB)
26/01/12 02:23:10 INFO BlockManagerInfo: Removed broadcast_135_piece0 on 02926ee04bc9:45221 in memory (size: 36.8 KiB, free: 366.1 MiB)
26/01/12 02:23:10 INFO BlockManagerInfo: Removed broadcast_135_piece0 on 172.18.0.5:42453 in memory (size: 36.8 KiB, free: 366.1 MiB)
26/01/12 02:23:10 INFO BlockManagerInfo: Removed broadcast_131_piece0 on 02926ee04bc9:45221 in memory (size: 77.4 KiB, free: 366.2 MiB)
26/01/12 02:23:10 INFO BlockManagerInfo: Removed broadcast_131_piece0 on 172.18.0.5:42453 in memory (size: 77.4 KiB, free: 366.2 MiB)
26/01/12 02:23:38 INFO TaskSetManager: Finished task 0.0 in stage 93.0 (TID 186) in 28954 ms on 172.18.0.5 (executor 0) (2/2)
26/01/12 02:23:38 INFO TaskSchedulerImpl: Removed TaskSet 93.0, whose tasks have all completed, from pool 
26/01/12 02:23:38 INFO DAGScheduler: ResultStage 93 (parquet at <unknown>:0) finished in 28.974 s
26/01/12 02:23:38 INFO DAGScheduler: Job 93 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:23:38 INFO TaskSchedulerImpl: Killing all running tasks in stage 93: Stage finished
26/01/12 02:23:38 INFO DAGScheduler: Job 93 finished: parquet at <unknown>:0, took 28.979940 s
26/01/12 02:23:38 INFO FileFormatWriter: Start to commit write Job cf7a2e28-4fef-49d9-a2d6-bef20a0df73c.
26/01/12 02:23:38 INFO FileFormatWriter: Write Job cf7a2e28-4fef-49d9-a2d6-bef20a0df73c committed. Elapsed time: 27 ms.
26/01/12 02:23:38 INFO FileFormatWriter: Finished processing stats for write job cf7a2e28-4fef-49d9-a2d6-bef20a0df73c.
Cargando: yellow_tripdata_2012-12.parquet en hdfs://hadoop-namenode:8020/data/nyc/raw/taxi-trips/2012...
26/01/12 02:23:38 INFO InMemoryFileIndex: It took 7 ms to list leaf files for 1 paths.
26/01/12 02:23:38 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 02:23:38 INFO DAGScheduler: Got job 94 (parquet at <unknown>:0) with 1 output partitions
26/01/12 02:23:38 INFO DAGScheduler: Final stage: ResultStage 94 (parquet at <unknown>:0)
26/01/12 02:23:38 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:23:38 INFO DAGScheduler: Missing parents: List()
26/01/12 02:23:38 INFO DAGScheduler: Submitting ResultStage 94 (MapPartitionsRDD[236] at parquet at <unknown>:0), which has no missing parents
26/01/12 02:23:38 INFO MemoryStore: Block broadcast_141 stored as values in memory (estimated size 102.6 KiB, free 365.5 MiB)
26/01/12 02:23:38 INFO MemoryStore: Block broadcast_141_piece0 stored as bytes in memory (estimated size 36.8 KiB, free 365.5 MiB)
26/01/12 02:23:38 INFO BlockManagerInfo: Added broadcast_141_piece0 in memory on 02926ee04bc9:45221 (size: 36.8 KiB, free: 366.2 MiB)
26/01/12 02:23:38 INFO SparkContext: Created broadcast 141 from broadcast at DAGScheduler.scala:1513
26/01/12 02:23:38 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 94 (MapPartitionsRDD[236] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0))
26/01/12 02:23:38 INFO TaskSchedulerImpl: Adding task set 94.0 with 1 tasks resource profile 0
26/01/12 02:23:38 INFO TaskSetManager: Starting task 0.0 in stage 94.0 (TID 188) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4607 bytes) taskResourceAssignments Map()
26/01/12 02:23:38 INFO BlockManagerInfo: Added broadcast_141_piece0 in memory on 172.18.0.5:42453 (size: 36.8 KiB, free: 366.2 MiB)
26/01/12 02:23:38 INFO TaskSetManager: Finished task 0.0 in stage 94.0 (TID 188) in 52 ms on 172.18.0.5 (executor 0) (1/1)
26/01/12 02:23:38 INFO TaskSchedulerImpl: Removed TaskSet 94.0, whose tasks have all completed, from pool 
26/01/12 02:23:38 INFO DAGScheduler: ResultStage 94 (parquet at <unknown>:0) finished in 0.065 s
26/01/12 02:23:38 INFO DAGScheduler: Job 94 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:23:38 INFO TaskSchedulerImpl: Killing all running tasks in stage 94: Stage finished
26/01/12 02:23:38 INFO DAGScheduler: Job 94 finished: parquet at <unknown>:0, took 0.071269 s
26/01/12 02:23:38 INFO FileSourceStrategy: Pushed Filters: 
26/01/12 02:23:38 INFO FileSourceStrategy: Post-Scan Filters: 
26/01/12 02:23:38 INFO FileSourceStrategy: Output Data Schema: struct<VendorID: bigint, tpep_pickup_datetime: timestamp, tpep_dropoff_datetime: timestamp, passenger_count: bigint, trip_distance: double ... 17 more fields>
26/01/12 02:23:38 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:23:38 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:23:38 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:23:38 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:23:38 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:23:38 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:23:38 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:23:38 INFO MemoryStore: Block broadcast_142 stored as values in memory (estimated size 358.4 KiB, free 365.1 MiB)
26/01/12 02:23:38 INFO MemoryStore: Block broadcast_142_piece0 stored as bytes in memory (estimated size 35.4 KiB, free 365.1 MiB)
26/01/12 02:23:38 INFO BlockManagerInfo: Added broadcast_142_piece0 in memory on 02926ee04bc9:45221 (size: 35.4 KiB, free: 366.1 MiB)
26/01/12 02:23:38 INFO SparkContext: Created broadcast 142 from parquet at <unknown>:0
26/01/12 02:23:38 INFO FileSourceScanExec: Planning scan with bin packing, max size: 93397587 bytes, open cost is considered as scanning 4194304 bytes.
26/01/12 02:23:38 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 02:23:38 INFO DAGScheduler: Got job 95 (parquet at <unknown>:0) with 2 output partitions
26/01/12 02:23:38 INFO DAGScheduler: Final stage: ResultStage 95 (parquet at <unknown>:0)
26/01/12 02:23:38 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:23:38 INFO DAGScheduler: Missing parents: List()
26/01/12 02:23:38 INFO DAGScheduler: Submitting ResultStage 95 (MapPartitionsRDD[239] at parquet at <unknown>:0), which has no missing parents
26/01/12 02:23:38 INFO MemoryStore: Block broadcast_143 stored as values in memory (estimated size 225.1 KiB, free 364.9 MiB)
26/01/12 02:23:38 INFO MemoryStore: Block broadcast_143_piece0 stored as bytes in memory (estimated size 77.4 KiB, free 364.8 MiB)
26/01/12 02:23:38 INFO BlockManagerInfo: Added broadcast_143_piece0 in memory on 02926ee04bc9:45221 (size: 77.4 KiB, free: 366.0 MiB)
26/01/12 02:23:38 INFO SparkContext: Created broadcast 143 from broadcast at DAGScheduler.scala:1513
26/01/12 02:23:38 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 95 (MapPartitionsRDD[239] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1))
26/01/12 02:23:38 INFO TaskSchedulerImpl: Adding task set 95.0 with 2 tasks resource profile 0
26/01/12 02:23:38 INFO TaskSetManager: Starting task 0.0 in stage 95.0 (TID 189) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:23:38 INFO TaskSetManager: Starting task 1.0 in stage 95.0 (TID 190) (172.18.0.5, executor 0, partition 1, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:23:38 INFO BlockManagerInfo: Added broadcast_143_piece0 in memory on 172.18.0.5:42453 (size: 77.4 KiB, free: 366.1 MiB)
26/01/12 02:23:38 INFO BlockManagerInfo: Added broadcast_142_piece0 in memory on 172.18.0.5:42453 (size: 35.4 KiB, free: 366.0 MiB)
26/01/12 02:23:38 INFO TaskSetManager: Finished task 1.0 in stage 95.0 (TID 190) in 63 ms on 172.18.0.5 (executor 0) (1/2)
26/01/12 02:24:11 INFO TaskSetManager: Finished task 0.0 in stage 95.0 (TID 189) in 32597 ms on 172.18.0.5 (executor 0) (2/2)
26/01/12 02:24:11 INFO TaskSchedulerImpl: Removed TaskSet 95.0, whose tasks have all completed, from pool 
26/01/12 02:24:11 INFO DAGScheduler: ResultStage 95 (parquet at <unknown>:0) finished in 32.620 s
26/01/12 02:24:11 INFO DAGScheduler: Job 95 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:24:11 INFO TaskSchedulerImpl: Killing all running tasks in stage 95: Stage finished
26/01/12 02:24:11 INFO DAGScheduler: Job 95 finished: parquet at <unknown>:0, took 32.631572 s
26/01/12 02:24:11 INFO FileFormatWriter: Start to commit write Job 181abba6-8830-469c-8b34-4412ee8e8647.
26/01/12 02:24:11 INFO FileFormatWriter: Write Job 181abba6-8830-469c-8b34-4412ee8e8647 committed. Elapsed time: 32 ms.
26/01/12 02:24:11 INFO FileFormatWriter: Finished processing stats for write job 181abba6-8830-469c-8b34-4412ee8e8647.
Cargando: yellow_tripdata_2013-01.parquet en hdfs://hadoop-namenode:8020/data/nyc/raw/taxi-trips/2013...
26/01/12 02:24:11 INFO InMemoryFileIndex: It took 7 ms to list leaf files for 1 paths.
26/01/12 02:24:11 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 02:24:11 INFO DAGScheduler: Got job 96 (parquet at <unknown>:0) with 1 output partitions
26/01/12 02:24:11 INFO DAGScheduler: Final stage: ResultStage 96 (parquet at <unknown>:0)
26/01/12 02:24:11 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:24:11 INFO DAGScheduler: Missing parents: List()
26/01/12 02:24:11 INFO DAGScheduler: Submitting ResultStage 96 (MapPartitionsRDD[241] at parquet at <unknown>:0), which has no missing parents
26/01/12 02:24:11 INFO MemoryStore: Block broadcast_144 stored as values in memory (estimated size 102.6 KiB, free 364.7 MiB)
26/01/12 02:24:11 INFO MemoryStore: Block broadcast_144_piece0 stored as bytes in memory (estimated size 36.8 KiB, free 364.7 MiB)
26/01/12 02:24:11 INFO BlockManagerInfo: Added broadcast_144_piece0 in memory on 02926ee04bc9:45221 (size: 36.8 KiB, free: 366.0 MiB)
26/01/12 02:24:11 INFO SparkContext: Created broadcast 144 from broadcast at DAGScheduler.scala:1513
26/01/12 02:24:11 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 96 (MapPartitionsRDD[241] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0))
26/01/12 02:24:11 INFO TaskSchedulerImpl: Adding task set 96.0 with 1 tasks resource profile 0
26/01/12 02:24:11 INFO TaskSetManager: Starting task 0.0 in stage 96.0 (TID 191) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4607 bytes) taskResourceAssignments Map()
26/01/12 02:24:11 INFO BlockManagerInfo: Added broadcast_144_piece0 in memory on 172.18.0.5:42453 (size: 36.8 KiB, free: 366.0 MiB)
26/01/12 02:24:11 INFO TaskSetManager: Finished task 0.0 in stage 96.0 (TID 191) in 55 ms on 172.18.0.5 (executor 0) (1/1)
26/01/12 02:24:11 INFO TaskSchedulerImpl: Removed TaskSet 96.0, whose tasks have all completed, from pool 
26/01/12 02:24:11 INFO DAGScheduler: ResultStage 96 (parquet at <unknown>:0) finished in 0.070 s
26/01/12 02:24:11 INFO DAGScheduler: Job 96 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:24:11 INFO TaskSchedulerImpl: Killing all running tasks in stage 96: Stage finished
26/01/12 02:24:11 INFO DAGScheduler: Job 96 finished: parquet at <unknown>:0, took 0.074901 s
26/01/12 02:24:11 INFO FileSourceStrategy: Pushed Filters: 
26/01/12 02:24:11 INFO FileSourceStrategy: Post-Scan Filters: 
26/01/12 02:24:11 INFO FileSourceStrategy: Output Data Schema: struct<VendorID: bigint, tpep_pickup_datetime: timestamp, tpep_dropoff_datetime: timestamp, passenger_count: bigint, trip_distance: double ... 17 more fields>
26/01/12 02:24:11 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:24:11 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:24:11 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:24:11 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:24:11 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:24:11 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:24:11 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:24:11 INFO MemoryStore: Block broadcast_145 stored as values in memory (estimated size 358.4 KiB, free 364.3 MiB)
26/01/12 02:24:11 INFO MemoryStore: Block broadcast_145_piece0 stored as bytes in memory (estimated size 35.4 KiB, free 364.3 MiB)
26/01/12 02:24:11 INFO BlockManagerInfo: Added broadcast_145_piece0 in memory on 02926ee04bc9:45221 (size: 35.4 KiB, free: 366.0 MiB)
26/01/12 02:24:11 INFO SparkContext: Created broadcast 145 from parquet at <unknown>:0
26/01/12 02:24:11 INFO FileSourceScanExec: Planning scan with bin packing, max size: 94465477 bytes, open cost is considered as scanning 4194304 bytes.
26/01/12 02:24:11 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 02:24:11 INFO DAGScheduler: Got job 97 (parquet at <unknown>:0) with 2 output partitions
26/01/12 02:24:11 INFO DAGScheduler: Final stage: ResultStage 97 (parquet at <unknown>:0)
26/01/12 02:24:11 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:24:11 INFO DAGScheduler: Missing parents: List()
26/01/12 02:24:11 INFO DAGScheduler: Submitting ResultStage 97 (MapPartitionsRDD[244] at parquet at <unknown>:0), which has no missing parents
26/01/12 02:24:11 INFO MemoryStore: Block broadcast_146 stored as values in memory (estimated size 225.1 KiB, free 364.1 MiB)
26/01/12 02:24:11 INFO MemoryStore: Block broadcast_146_piece0 stored as bytes in memory (estimated size 77.4 KiB, free 364.0 MiB)
26/01/12 02:24:11 INFO BlockManagerInfo: Added broadcast_146_piece0 in memory on 02926ee04bc9:45221 (size: 77.4 KiB, free: 365.9 MiB)
26/01/12 02:24:11 INFO SparkContext: Created broadcast 146 from broadcast at DAGScheduler.scala:1513
26/01/12 02:24:11 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 97 (MapPartitionsRDD[244] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1))
26/01/12 02:24:11 INFO TaskSchedulerImpl: Adding task set 97.0 with 2 tasks resource profile 0
26/01/12 02:24:11 INFO TaskSetManager: Starting task 0.0 in stage 97.0 (TID 192) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:24:11 INFO TaskSetManager: Starting task 1.0 in stage 97.0 (TID 193) (172.18.0.5, executor 0, partition 1, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:24:11 INFO BlockManagerInfo: Added broadcast_146_piece0 in memory on 172.18.0.5:42453 (size: 77.4 KiB, free: 365.9 MiB)
26/01/12 02:24:11 INFO BlockManagerInfo: Added broadcast_145_piece0 in memory on 172.18.0.5:42453 (size: 35.4 KiB, free: 365.9 MiB)
26/01/12 02:24:11 INFO TaskSetManager: Finished task 1.0 in stage 97.0 (TID 193) in 56 ms on 172.18.0.5 (executor 0) (1/2)
26/01/12 02:24:42 INFO TaskSetManager: Finished task 0.0 in stage 97.0 (TID 192) in 31508 ms on 172.18.0.5 (executor 0) (2/2)
26/01/12 02:24:42 INFO TaskSchedulerImpl: Removed TaskSet 97.0, whose tasks have all completed, from pool 
26/01/12 02:24:42 INFO DAGScheduler: ResultStage 97 (parquet at <unknown>:0) finished in 31.528 s
26/01/12 02:24:42 INFO DAGScheduler: Job 97 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:24:42 INFO TaskSchedulerImpl: Killing all running tasks in stage 97: Stage finished
26/01/12 02:24:42 INFO DAGScheduler: Job 97 finished: parquet at <unknown>:0, took 31.533837 s
26/01/12 02:24:42 INFO FileFormatWriter: Start to commit write Job de2586ee-ae04-4c43-93ab-827fe6acbf2b.
26/01/12 02:24:42 INFO FileFormatWriter: Write Job de2586ee-ae04-4c43-93ab-827fe6acbf2b committed. Elapsed time: 28 ms.
26/01/12 02:24:42 INFO FileFormatWriter: Finished processing stats for write job de2586ee-ae04-4c43-93ab-827fe6acbf2b.
Cargando: yellow_tripdata_2013-02.parquet en hdfs://hadoop-namenode:8020/data/nyc/raw/taxi-trips/2013...
26/01/12 02:24:42 INFO InMemoryFileIndex: It took 6 ms to list leaf files for 1 paths.
26/01/12 02:24:43 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 02:24:43 INFO DAGScheduler: Got job 98 (parquet at <unknown>:0) with 1 output partitions
26/01/12 02:24:43 INFO DAGScheduler: Final stage: ResultStage 98 (parquet at <unknown>:0)
26/01/12 02:24:43 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:24:43 INFO DAGScheduler: Missing parents: List()
26/01/12 02:24:43 INFO DAGScheduler: Submitting ResultStage 98 (MapPartitionsRDD[246] at parquet at <unknown>:0), which has no missing parents
26/01/12 02:24:43 INFO MemoryStore: Block broadcast_147 stored as values in memory (estimated size 102.6 KiB, free 363.9 MiB)
26/01/12 02:24:43 INFO MemoryStore: Block broadcast_147_piece0 stored as bytes in memory (estimated size 36.8 KiB, free 363.9 MiB)
26/01/12 02:24:43 INFO BlockManagerInfo: Added broadcast_147_piece0 in memory on 02926ee04bc9:45221 (size: 36.8 KiB, free: 365.9 MiB)
26/01/12 02:24:43 INFO SparkContext: Created broadcast 147 from broadcast at DAGScheduler.scala:1513
26/01/12 02:24:43 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 98 (MapPartitionsRDD[246] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0))
26/01/12 02:24:43 INFO TaskSchedulerImpl: Adding task set 98.0 with 1 tasks resource profile 0
26/01/12 02:24:43 INFO TaskSetManager: Starting task 0.0 in stage 98.0 (TID 194) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4607 bytes) taskResourceAssignments Map()
26/01/12 02:24:43 INFO BlockManagerInfo: Added broadcast_147_piece0 in memory on 172.18.0.5:42453 (size: 36.8 KiB, free: 365.9 MiB)
26/01/12 02:24:43 INFO TaskSetManager: Finished task 0.0 in stage 98.0 (TID 194) in 45 ms on 172.18.0.5 (executor 0) (1/1)
26/01/12 02:24:43 INFO TaskSchedulerImpl: Removed TaskSet 98.0, whose tasks have all completed, from pool 
26/01/12 02:24:43 INFO DAGScheduler: ResultStage 98 (parquet at <unknown>:0) finished in 0.058 s
26/01/12 02:24:43 INFO DAGScheduler: Job 98 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:24:43 INFO TaskSchedulerImpl: Killing all running tasks in stage 98: Stage finished
26/01/12 02:24:43 INFO DAGScheduler: Job 98 finished: parquet at <unknown>:0, took 0.062115 s
26/01/12 02:24:43 INFO FileSourceStrategy: Pushed Filters: 
26/01/12 02:24:43 INFO FileSourceStrategy: Post-Scan Filters: 
26/01/12 02:24:43 INFO FileSourceStrategy: Output Data Schema: struct<VendorID: bigint, tpep_pickup_datetime: timestamp, tpep_dropoff_datetime: timestamp, passenger_count: bigint, trip_distance: double ... 17 more fields>
26/01/12 02:24:43 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:24:43 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:24:43 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:24:43 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:24:43 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:24:43 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:24:43 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:24:43 INFO MemoryStore: Block broadcast_148 stored as values in memory (estimated size 358.4 KiB, free 363.5 MiB)
26/01/12 02:24:43 INFO MemoryStore: Block broadcast_148_piece0 stored as bytes in memory (estimated size 35.4 KiB, free 363.5 MiB)
26/01/12 02:24:43 INFO BlockManagerInfo: Added broadcast_148_piece0 in memory on 02926ee04bc9:45221 (size: 35.4 KiB, free: 365.8 MiB)
26/01/12 02:24:43 INFO SparkContext: Created broadcast 148 from parquet at <unknown>:0
26/01/12 02:24:43 INFO FileSourceScanExec: Planning scan with bin packing, max size: 88349883 bytes, open cost is considered as scanning 4194304 bytes.
26/01/12 02:24:43 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 02:24:43 INFO DAGScheduler: Got job 99 (parquet at <unknown>:0) with 2 output partitions
26/01/12 02:24:43 INFO DAGScheduler: Final stage: ResultStage 99 (parquet at <unknown>:0)
26/01/12 02:24:43 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:24:43 INFO DAGScheduler: Missing parents: List()
26/01/12 02:24:43 INFO DAGScheduler: Submitting ResultStage 99 (MapPartitionsRDD[249] at parquet at <unknown>:0), which has no missing parents
26/01/12 02:24:43 INFO MemoryStore: Block broadcast_149 stored as values in memory (estimated size 225.1 KiB, free 363.2 MiB)
26/01/12 02:24:43 INFO MemoryStore: Block broadcast_149_piece0 stored as bytes in memory (estimated size 77.4 KiB, free 363.2 MiB)
26/01/12 02:24:43 INFO BlockManagerInfo: Added broadcast_149_piece0 in memory on 02926ee04bc9:45221 (size: 77.4 KiB, free: 365.8 MiB)
26/01/12 02:24:43 INFO SparkContext: Created broadcast 149 from broadcast at DAGScheduler.scala:1513
26/01/12 02:24:43 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 99 (MapPartitionsRDD[249] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1))
26/01/12 02:24:43 INFO TaskSchedulerImpl: Adding task set 99.0 with 2 tasks resource profile 0
26/01/12 02:24:43 INFO TaskSetManager: Starting task 0.0 in stage 99.0 (TID 195) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:24:43 INFO TaskSetManager: Starting task 1.0 in stage 99.0 (TID 196) (172.18.0.5, executor 0, partition 1, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:24:43 INFO BlockManagerInfo: Added broadcast_149_piece0 in memory on 172.18.0.5:42453 (size: 77.4 KiB, free: 365.8 MiB)
26/01/12 02:24:43 INFO BlockManagerInfo: Added broadcast_148_piece0 in memory on 172.18.0.5:42453 (size: 35.4 KiB, free: 365.8 MiB)
26/01/12 02:24:43 INFO TaskSetManager: Finished task 1.0 in stage 99.0 (TID 196) in 60 ms on 172.18.0.5 (executor 0) (1/2)
26/01/12 02:25:13 INFO TaskSetManager: Finished task 0.0 in stage 99.0 (TID 195) in 29993 ms on 172.18.0.5 (executor 0) (2/2)
26/01/12 02:25:13 INFO TaskSchedulerImpl: Removed TaskSet 99.0, whose tasks have all completed, from pool 
26/01/12 02:25:13 INFO DAGScheduler: ResultStage 99 (parquet at <unknown>:0) finished in 30.014 s
26/01/12 02:25:13 INFO DAGScheduler: Job 99 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:25:13 INFO TaskSchedulerImpl: Killing all running tasks in stage 99: Stage finished
26/01/12 02:25:13 INFO DAGScheduler: Job 99 finished: parquet at <unknown>:0, took 30.020480 s
26/01/12 02:25:13 INFO FileFormatWriter: Start to commit write Job 7f94a400-6fa0-4448-9bcf-3c878a2a429f.
26/01/12 02:25:13 INFO FileFormatWriter: Write Job 7f94a400-6fa0-4448-9bcf-3c878a2a429f committed. Elapsed time: 25 ms.
26/01/12 02:25:13 INFO FileFormatWriter: Finished processing stats for write job 7f94a400-6fa0-4448-9bcf-3c878a2a429f.
Cargando: yellow_tripdata_2013-03.parquet en hdfs://hadoop-namenode:8020/data/nyc/raw/taxi-trips/2013...
26/01/12 02:25:13 INFO InMemoryFileIndex: It took 7 ms to list leaf files for 1 paths.
26/01/12 02:25:13 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 02:25:13 INFO DAGScheduler: Got job 100 (parquet at <unknown>:0) with 1 output partitions
26/01/12 02:25:13 INFO DAGScheduler: Final stage: ResultStage 100 (parquet at <unknown>:0)
26/01/12 02:25:13 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:25:13 INFO DAGScheduler: Missing parents: List()
26/01/12 02:25:13 INFO DAGScheduler: Submitting ResultStage 100 (MapPartitionsRDD[251] at parquet at <unknown>:0), which has no missing parents
26/01/12 02:25:13 INFO MemoryStore: Block broadcast_150 stored as values in memory (estimated size 102.6 KiB, free 363.1 MiB)
26/01/12 02:25:13 INFO MemoryStore: Block broadcast_150_piece0 stored as bytes in memory (estimated size 36.8 KiB, free 363.0 MiB)
26/01/12 02:25:13 INFO BlockManagerInfo: Added broadcast_150_piece0 in memory on 02926ee04bc9:45221 (size: 36.8 KiB, free: 365.7 MiB)
26/01/12 02:25:13 INFO SparkContext: Created broadcast 150 from broadcast at DAGScheduler.scala:1513
26/01/12 02:25:13 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 100 (MapPartitionsRDD[251] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0))
26/01/12 02:25:13 INFO TaskSchedulerImpl: Adding task set 100.0 with 1 tasks resource profile 0
26/01/12 02:25:13 INFO TaskSetManager: Starting task 0.0 in stage 100.0 (TID 197) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4607 bytes) taskResourceAssignments Map()
26/01/12 02:25:13 INFO BlockManagerInfo: Added broadcast_150_piece0 in memory on 172.18.0.5:42453 (size: 36.8 KiB, free: 365.7 MiB)
26/01/12 02:25:13 INFO TaskSetManager: Finished task 0.0 in stage 100.0 (TID 197) in 49 ms on 172.18.0.5 (executor 0) (1/1)
26/01/12 02:25:13 INFO TaskSchedulerImpl: Removed TaskSet 100.0, whose tasks have all completed, from pool 
26/01/12 02:25:13 INFO DAGScheduler: ResultStage 100 (parquet at <unknown>:0) finished in 0.060 s
26/01/12 02:25:13 INFO DAGScheduler: Job 100 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:25:13 INFO TaskSchedulerImpl: Killing all running tasks in stage 100: Stage finished
26/01/12 02:25:13 INFO DAGScheduler: Job 100 finished: parquet at <unknown>:0, took 0.064104 s
26/01/12 02:25:13 INFO FileSourceStrategy: Pushed Filters: 
26/01/12 02:25:13 INFO FileSourceStrategy: Post-Scan Filters: 
26/01/12 02:25:13 INFO FileSourceStrategy: Output Data Schema: struct<VendorID: bigint, tpep_pickup_datetime: timestamp, tpep_dropoff_datetime: timestamp, passenger_count: bigint, trip_distance: double ... 17 more fields>
26/01/12 02:25:13 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:25:13 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:25:13 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:25:13 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:25:13 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:25:13 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:25:13 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:25:13 INFO MemoryStore: Block broadcast_151 stored as values in memory (estimated size 358.4 KiB, free 362.7 MiB)
26/01/12 02:25:13 INFO MemoryStore: Block broadcast_151_piece0 stored as bytes in memory (estimated size 35.4 KiB, free 362.7 MiB)
26/01/12 02:25:13 INFO BlockManagerInfo: Added broadcast_151_piece0 in memory on 02926ee04bc9:45221 (size: 35.4 KiB, free: 365.7 MiB)
26/01/12 02:25:13 INFO SparkContext: Created broadcast 151 from parquet at <unknown>:0
26/01/12 02:25:13 INFO FileSourceScanExec: Planning scan with bin packing, max size: 99753753 bytes, open cost is considered as scanning 4194304 bytes.
26/01/12 02:25:13 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 02:25:13 INFO DAGScheduler: Got job 101 (parquet at <unknown>:0) with 2 output partitions
26/01/12 02:25:13 INFO DAGScheduler: Final stage: ResultStage 101 (parquet at <unknown>:0)
26/01/12 02:25:13 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:25:13 INFO DAGScheduler: Missing parents: List()
26/01/12 02:25:13 INFO DAGScheduler: Submitting ResultStage 101 (MapPartitionsRDD[254] at parquet at <unknown>:0), which has no missing parents
26/01/12 02:25:13 INFO MemoryStore: Block broadcast_152 stored as values in memory (estimated size 225.1 KiB, free 362.4 MiB)
26/01/12 02:25:13 INFO MemoryStore: Block broadcast_152_piece0 stored as bytes in memory (estimated size 77.4 KiB, free 362.4 MiB)
26/01/12 02:25:13 INFO BlockManagerInfo: Added broadcast_152_piece0 in memory on 02926ee04bc9:45221 (size: 77.4 KiB, free: 365.6 MiB)
26/01/12 02:25:13 INFO SparkContext: Created broadcast 152 from broadcast at DAGScheduler.scala:1513
26/01/12 02:25:13 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 101 (MapPartitionsRDD[254] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1))
26/01/12 02:25:13 INFO TaskSchedulerImpl: Adding task set 101.0 with 2 tasks resource profile 0
26/01/12 02:25:13 INFO TaskSetManager: Starting task 0.0 in stage 101.0 (TID 198) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:25:13 INFO TaskSetManager: Starting task 1.0 in stage 101.0 (TID 199) (172.18.0.5, executor 0, partition 1, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:25:13 INFO BlockManagerInfo: Added broadcast_152_piece0 in memory on 172.18.0.5:42453 (size: 77.4 KiB, free: 365.6 MiB)
26/01/12 02:25:13 INFO BlockManagerInfo: Added broadcast_151_piece0 in memory on 172.18.0.5:42453 (size: 35.4 KiB, free: 365.6 MiB)
26/01/12 02:25:13 INFO TaskSetManager: Finished task 1.0 in stage 101.0 (TID 199) in 63 ms on 172.18.0.5 (executor 0) (1/2)
26/01/12 02:25:47 INFO TaskSetManager: Finished task 0.0 in stage 101.0 (TID 198) in 33823 ms on 172.18.0.5 (executor 0) (2/2)
26/01/12 02:25:47 INFO TaskSchedulerImpl: Removed TaskSet 101.0, whose tasks have all completed, from pool 
26/01/12 02:25:47 INFO DAGScheduler: ResultStage 101 (parquet at <unknown>:0) finished in 33.844 s
26/01/12 02:25:47 INFO DAGScheduler: Job 101 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:25:47 INFO TaskSchedulerImpl: Killing all running tasks in stage 101: Stage finished
26/01/12 02:25:47 INFO DAGScheduler: Job 101 finished: parquet at <unknown>:0, took 33.850741 s
26/01/12 02:25:47 INFO FileFormatWriter: Start to commit write Job c28357d7-b66c-4b4b-9ead-d062f7801f79.
26/01/12 02:25:47 INFO FileFormatWriter: Write Job c28357d7-b66c-4b4b-9ead-d062f7801f79 committed. Elapsed time: 25 ms.
26/01/12 02:25:47 INFO FileFormatWriter: Finished processing stats for write job c28357d7-b66c-4b4b-9ead-d062f7801f79.
Cargando: yellow_tripdata_2013-04.parquet en hdfs://hadoop-namenode:8020/data/nyc/raw/taxi-trips/2013...
26/01/12 02:25:47 INFO InMemoryFileIndex: It took 5 ms to list leaf files for 1 paths.
26/01/12 02:25:47 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 02:25:47 INFO DAGScheduler: Got job 102 (parquet at <unknown>:0) with 1 output partitions
26/01/12 02:25:47 INFO DAGScheduler: Final stage: ResultStage 102 (parquet at <unknown>:0)
26/01/12 02:25:47 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:25:47 INFO DAGScheduler: Missing parents: List()
26/01/12 02:25:47 INFO DAGScheduler: Submitting ResultStage 102 (MapPartitionsRDD[256] at parquet at <unknown>:0), which has no missing parents
26/01/12 02:25:47 INFO MemoryStore: Block broadcast_153 stored as values in memory (estimated size 102.6 KiB, free 362.3 MiB)
26/01/12 02:25:47 INFO MemoryStore: Block broadcast_153_piece0 stored as bytes in memory (estimated size 36.8 KiB, free 362.2 MiB)
26/01/12 02:25:47 INFO BlockManagerInfo: Added broadcast_153_piece0 in memory on 02926ee04bc9:45221 (size: 36.8 KiB, free: 365.6 MiB)
26/01/12 02:25:47 INFO SparkContext: Created broadcast 153 from broadcast at DAGScheduler.scala:1513
26/01/12 02:25:47 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 102 (MapPartitionsRDD[256] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0))
26/01/12 02:25:47 INFO TaskSchedulerImpl: Adding task set 102.0 with 1 tasks resource profile 0
26/01/12 02:25:47 INFO TaskSetManager: Starting task 0.0 in stage 102.0 (TID 200) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4607 bytes) taskResourceAssignments Map()
26/01/12 02:25:47 INFO BlockManagerInfo: Added broadcast_153_piece0 in memory on 172.18.0.5:42453 (size: 36.8 KiB, free: 365.6 MiB)
26/01/12 02:25:47 INFO TaskSetManager: Finished task 0.0 in stage 102.0 (TID 200) in 50 ms on 172.18.0.5 (executor 0) (1/1)
26/01/12 02:25:47 INFO TaskSchedulerImpl: Removed TaskSet 102.0, whose tasks have all completed, from pool 
26/01/12 02:25:47 INFO DAGScheduler: ResultStage 102 (parquet at <unknown>:0) finished in 0.063 s
26/01/12 02:25:47 INFO DAGScheduler: Job 102 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:25:47 INFO TaskSchedulerImpl: Killing all running tasks in stage 102: Stage finished
26/01/12 02:25:47 INFO DAGScheduler: Job 102 finished: parquet at <unknown>:0, took 0.067156 s
26/01/12 02:25:47 INFO FileSourceStrategy: Pushed Filters: 
26/01/12 02:25:47 INFO FileSourceStrategy: Post-Scan Filters: 
26/01/12 02:25:47 INFO FileSourceStrategy: Output Data Schema: struct<VendorID: bigint, tpep_pickup_datetime: timestamp, tpep_dropoff_datetime: timestamp, passenger_count: bigint, trip_distance: double ... 17 more fields>
26/01/12 02:25:47 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:25:47 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:25:47 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:25:47 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:25:47 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:25:47 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:25:47 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:25:47 INFO MemoryStore: Block broadcast_154 stored as values in memory (estimated size 358.4 KiB, free 361.9 MiB)
26/01/12 02:25:47 INFO MemoryStore: Block broadcast_154_piece0 stored as bytes in memory (estimated size 35.4 KiB, free 361.8 MiB)
26/01/12 02:25:47 INFO BlockManagerInfo: Added broadcast_154_piece0 in memory on 02926ee04bc9:45221 (size: 35.4 KiB, free: 365.5 MiB)
26/01/12 02:25:47 INFO SparkContext: Created broadcast 154 from parquet at <unknown>:0
26/01/12 02:25:47 INFO FileSourceScanExec: Planning scan with bin packing, max size: 92207679 bytes, open cost is considered as scanning 4194304 bytes.
26/01/12 02:25:47 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 02:25:47 INFO DAGScheduler: Got job 103 (parquet at <unknown>:0) with 2 output partitions
26/01/12 02:25:47 INFO DAGScheduler: Final stage: ResultStage 103 (parquet at <unknown>:0)
26/01/12 02:25:47 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:25:47 INFO DAGScheduler: Missing parents: List()
26/01/12 02:25:47 INFO DAGScheduler: Submitting ResultStage 103 (MapPartitionsRDD[259] at parquet at <unknown>:0), which has no missing parents
26/01/12 02:25:47 INFO MemoryStore: Block broadcast_155 stored as values in memory (estimated size 225.1 KiB, free 361.6 MiB)
26/01/12 02:25:47 INFO MemoryStore: Block broadcast_155_piece0 stored as bytes in memory (estimated size 77.4 KiB, free 361.5 MiB)
26/01/12 02:25:47 INFO BlockManagerInfo: Added broadcast_155_piece0 in memory on 02926ee04bc9:45221 (size: 77.4 KiB, free: 365.5 MiB)
26/01/12 02:25:47 INFO SparkContext: Created broadcast 155 from broadcast at DAGScheduler.scala:1513
26/01/12 02:25:47 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 103 (MapPartitionsRDD[259] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1))
26/01/12 02:25:47 INFO TaskSchedulerImpl: Adding task set 103.0 with 2 tasks resource profile 0
26/01/12 02:25:47 INFO TaskSetManager: Starting task 0.0 in stage 103.0 (TID 201) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:25:47 INFO TaskSetManager: Starting task 1.0 in stage 103.0 (TID 202) (172.18.0.5, executor 0, partition 1, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:25:47 INFO BlockManagerInfo: Added broadcast_155_piece0 in memory on 172.18.0.5:42453 (size: 77.4 KiB, free: 365.5 MiB)
26/01/12 02:25:47 INFO BlockManagerInfo: Added broadcast_154_piece0 in memory on 172.18.0.5:42453 (size: 35.4 KiB, free: 365.5 MiB)
26/01/12 02:25:47 INFO TaskSetManager: Finished task 1.0 in stage 103.0 (TID 202) in 137 ms on 172.18.0.5 (executor 0) (1/2)
26/01/12 02:26:19 INFO TaskSetManager: Finished task 0.0 in stage 103.0 (TID 201) in 31653 ms on 172.18.0.5 (executor 0) (2/2)
26/01/12 02:26:19 INFO TaskSchedulerImpl: Removed TaskSet 103.0, whose tasks have all completed, from pool 
26/01/12 02:26:19 INFO DAGScheduler: ResultStage 103 (parquet at <unknown>:0) finished in 31.674 s
26/01/12 02:26:19 INFO DAGScheduler: Job 103 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:26:19 INFO TaskSchedulerImpl: Killing all running tasks in stage 103: Stage finished
26/01/12 02:26:19 INFO DAGScheduler: Job 103 finished: parquet at <unknown>:0, took 31.680250 s
26/01/12 02:26:19 INFO FileFormatWriter: Start to commit write Job 50fa4283-b429-4852-9649-b598d7c0abc5.
26/01/12 02:26:19 INFO FileFormatWriter: Write Job 50fa4283-b429-4852-9649-b598d7c0abc5 committed. Elapsed time: 33 ms.
26/01/12 02:26:19 INFO FileFormatWriter: Finished processing stats for write job 50fa4283-b429-4852-9649-b598d7c0abc5.
Cargando: yellow_tripdata_2013-05.parquet en hdfs://hadoop-namenode:8020/data/nyc/raw/taxi-trips/2013...
26/01/12 02:26:19 INFO InMemoryFileIndex: It took 8 ms to list leaf files for 1 paths.
26/01/12 02:26:19 INFO BlockManagerInfo: Removed broadcast_141_piece0 on 02926ee04bc9:45221 in memory (size: 36.8 KiB, free: 365.5 MiB)
26/01/12 02:26:19 INFO BlockManagerInfo: Removed broadcast_141_piece0 on 172.18.0.5:42453 in memory (size: 36.8 KiB, free: 365.5 MiB)
26/01/12 02:26:19 INFO BlockManagerInfo: Removed broadcast_146_piece0 on 02926ee04bc9:45221 in memory (size: 77.4 KiB, free: 365.6 MiB)
26/01/12 02:26:19 INFO BlockManagerInfo: Removed broadcast_146_piece0 on 172.18.0.5:42453 in memory (size: 77.4 KiB, free: 365.6 MiB)
26/01/12 02:26:19 INFO BlockManagerInfo: Removed broadcast_149_piece0 on 02926ee04bc9:45221 in memory (size: 77.4 KiB, free: 365.6 MiB)
26/01/12 02:26:19 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 02:26:19 INFO BlockManagerInfo: Removed broadcast_149_piece0 on 172.18.0.5:42453 in memory (size: 77.4 KiB, free: 365.6 MiB)
26/01/12 02:26:19 INFO DAGScheduler: Got job 104 (parquet at <unknown>:0) with 1 output partitions
26/01/12 02:26:19 INFO DAGScheduler: Final stage: ResultStage 104 (parquet at <unknown>:0)
26/01/12 02:26:19 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:26:19 INFO DAGScheduler: Missing parents: List()
26/01/12 02:26:19 INFO DAGScheduler: Submitting ResultStage 104 (MapPartitionsRDD[261] at parquet at <unknown>:0), which has no missing parents
26/01/12 02:26:19 INFO BlockManagerInfo: Removed broadcast_155_piece0 on 02926ee04bc9:45221 in memory (size: 77.4 KiB, free: 365.7 MiB)
26/01/12 02:26:19 INFO BlockManagerInfo: Removed broadcast_155_piece0 on 172.18.0.5:42453 in memory (size: 77.4 KiB, free: 365.7 MiB)
26/01/12 02:26:19 INFO MemoryStore: Block broadcast_156 stored as values in memory (estimated size 102.6 KiB, free 362.5 MiB)
26/01/12 02:26:19 INFO BlockManagerInfo: Removed broadcast_150_piece0 on 02926ee04bc9:45221 in memory (size: 36.8 KiB, free: 365.8 MiB)
26/01/12 02:26:19 INFO MemoryStore: Block broadcast_156_piece0 stored as bytes in memory (estimated size 36.8 KiB, free 362.5 MiB)
26/01/12 02:26:19 INFO BlockManagerInfo: Removed broadcast_150_piece0 on 172.18.0.5:42453 in memory (size: 36.8 KiB, free: 365.8 MiB)
26/01/12 02:26:19 INFO BlockManagerInfo: Added broadcast_156_piece0 in memory on 02926ee04bc9:45221 (size: 36.8 KiB, free: 365.7 MiB)
26/01/12 02:26:19 INFO SparkContext: Created broadcast 156 from broadcast at DAGScheduler.scala:1513
26/01/12 02:26:19 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 104 (MapPartitionsRDD[261] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0))
26/01/12 02:26:19 INFO TaskSchedulerImpl: Adding task set 104.0 with 1 tasks resource profile 0
26/01/12 02:26:19 INFO TaskSetManager: Starting task 0.0 in stage 104.0 (TID 203) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4607 bytes) taskResourceAssignments Map()
26/01/12 02:26:19 INFO BlockManagerInfo: Removed broadcast_145_piece0 on 02926ee04bc9:45221 in memory (size: 35.4 KiB, free: 365.8 MiB)
26/01/12 02:26:19 INFO BlockManagerInfo: Removed broadcast_145_piece0 on 172.18.0.5:42453 in memory (size: 35.4 KiB, free: 365.8 MiB)
26/01/12 02:26:19 INFO BlockManagerInfo: Removed broadcast_152_piece0 on 02926ee04bc9:45221 in memory (size: 77.4 KiB, free: 365.8 MiB)
26/01/12 02:26:19 INFO BlockManagerInfo: Added broadcast_156_piece0 in memory on 172.18.0.5:42453 (size: 36.8 KiB, free: 365.8 MiB)
26/01/12 02:26:19 INFO BlockManagerInfo: Removed broadcast_152_piece0 on 172.18.0.5:42453 in memory (size: 77.4 KiB, free: 365.8 MiB)
26/01/12 02:26:19 INFO BlockManagerInfo: Removed broadcast_143_piece0 on 02926ee04bc9:45221 in memory (size: 77.4 KiB, free: 365.9 MiB)
26/01/12 02:26:19 INFO BlockManagerInfo: Removed broadcast_143_piece0 on 172.18.0.5:42453 in memory (size: 77.4 KiB, free: 365.9 MiB)
26/01/12 02:26:19 INFO BlockManagerInfo: Removed broadcast_142_piece0 on 02926ee04bc9:45221 in memory (size: 35.4 KiB, free: 365.9 MiB)
26/01/12 02:26:19 INFO BlockManagerInfo: Removed broadcast_142_piece0 on 172.18.0.5:42453 in memory (size: 35.4 KiB, free: 365.9 MiB)
26/01/12 02:26:19 INFO BlockManagerInfo: Removed broadcast_153_piece0 on 02926ee04bc9:45221 in memory (size: 36.8 KiB, free: 366.0 MiB)
26/01/12 02:26:19 INFO BlockManagerInfo: Removed broadcast_153_piece0 on 172.18.0.5:42453 in memory (size: 36.8 KiB, free: 366.0 MiB)
26/01/12 02:26:19 INFO BlockManagerInfo: Removed broadcast_148_piece0 on 02926ee04bc9:45221 in memory (size: 35.4 KiB, free: 366.0 MiB)
26/01/12 02:26:19 INFO BlockManagerInfo: Removed broadcast_148_piece0 on 172.18.0.5:42453 in memory (size: 35.4 KiB, free: 366.0 MiB)
26/01/12 02:26:19 INFO BlockManagerInfo: Removed broadcast_144_piece0 on 02926ee04bc9:45221 in memory (size: 36.8 KiB, free: 366.0 MiB)
26/01/12 02:26:19 INFO BlockManagerInfo: Removed broadcast_144_piece0 on 172.18.0.5:42453 in memory (size: 36.8 KiB, free: 366.0 MiB)
26/01/12 02:26:19 INFO BlockManagerInfo: Removed broadcast_151_piece0 on 02926ee04bc9:45221 in memory (size: 35.4 KiB, free: 366.1 MiB)
26/01/12 02:26:19 INFO BlockManagerInfo: Removed broadcast_151_piece0 on 172.18.0.5:42453 in memory (size: 35.4 KiB, free: 366.1 MiB)
26/01/12 02:26:19 INFO BlockManagerInfo: Removed broadcast_147_piece0 on 02926ee04bc9:45221 in memory (size: 36.8 KiB, free: 366.1 MiB)
26/01/12 02:26:19 INFO BlockManagerInfo: Removed broadcast_147_piece0 on 172.18.0.5:42453 in memory (size: 36.8 KiB, free: 366.1 MiB)
26/01/12 02:26:19 INFO TaskSetManager: Finished task 0.0 in stage 104.0 (TID 203) in 66 ms on 172.18.0.5 (executor 0) (1/1)
26/01/12 02:26:19 INFO TaskSchedulerImpl: Removed TaskSet 104.0, whose tasks have all completed, from pool 
26/01/12 02:26:19 INFO DAGScheduler: ResultStage 104 (parquet at <unknown>:0) finished in 0.081 s
26/01/12 02:26:19 INFO DAGScheduler: Job 104 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:26:19 INFO TaskSchedulerImpl: Killing all running tasks in stage 104: Stage finished
26/01/12 02:26:19 INFO DAGScheduler: Job 104 finished: parquet at <unknown>:0, took 0.085177 s
26/01/12 02:26:19 INFO FileSourceStrategy: Pushed Filters: 
26/01/12 02:26:19 INFO FileSourceStrategy: Post-Scan Filters: 
26/01/12 02:26:19 INFO FileSourceStrategy: Output Data Schema: struct<VendorID: bigint, tpep_pickup_datetime: timestamp, tpep_dropoff_datetime: timestamp, passenger_count: bigint, trip_distance: double ... 17 more fields>
26/01/12 02:26:19 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:26:19 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:26:19 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:26:19 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:26:19 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:26:19 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:26:19 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:26:19 INFO MemoryStore: Block broadcast_157 stored as values in memory (estimated size 358.4 KiB, free 364.7 MiB)
26/01/12 02:26:19 INFO MemoryStore: Block broadcast_157_piece0 stored as bytes in memory (estimated size 35.4 KiB, free 364.7 MiB)
26/01/12 02:26:19 INFO BlockManagerInfo: Added broadcast_157_piece0 in memory on 02926ee04bc9:45221 (size: 35.4 KiB, free: 366.1 MiB)
26/01/12 02:26:19 INFO SparkContext: Created broadcast 157 from parquet at <unknown>:0
26/01/12 02:26:19 INFO FileSourceScanExec: Planning scan with bin packing, max size: 97438167 bytes, open cost is considered as scanning 4194304 bytes.
26/01/12 02:26:19 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 02:26:19 INFO DAGScheduler: Got job 105 (parquet at <unknown>:0) with 2 output partitions
26/01/12 02:26:19 INFO DAGScheduler: Final stage: ResultStage 105 (parquet at <unknown>:0)
26/01/12 02:26:19 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:26:19 INFO DAGScheduler: Missing parents: List()
26/01/12 02:26:19 INFO DAGScheduler: Submitting ResultStage 105 (MapPartitionsRDD[264] at parquet at <unknown>:0), which has no missing parents
26/01/12 02:26:19 INFO MemoryStore: Block broadcast_158 stored as values in memory (estimated size 225.1 KiB, free 364.5 MiB)
26/01/12 02:26:19 INFO MemoryStore: Block broadcast_158_piece0 stored as bytes in memory (estimated size 77.4 KiB, free 364.4 MiB)
26/01/12 02:26:19 INFO BlockManagerInfo: Added broadcast_158_piece0 in memory on 02926ee04bc9:45221 (size: 77.4 KiB, free: 366.0 MiB)
26/01/12 02:26:19 INFO SparkContext: Created broadcast 158 from broadcast at DAGScheduler.scala:1513
26/01/12 02:26:19 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 105 (MapPartitionsRDD[264] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1))
26/01/12 02:26:19 INFO TaskSchedulerImpl: Adding task set 105.0 with 2 tasks resource profile 0
26/01/12 02:26:19 INFO TaskSetManager: Starting task 0.0 in stage 105.0 (TID 204) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:26:19 INFO TaskSetManager: Starting task 1.0 in stage 105.0 (TID 205) (172.18.0.5, executor 0, partition 1, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:26:19 INFO BlockManagerInfo: Added broadcast_158_piece0 in memory on 172.18.0.5:42453 (size: 77.4 KiB, free: 366.0 MiB)
26/01/12 02:26:19 INFO BlockManagerInfo: Added broadcast_157_piece0 in memory on 172.18.0.5:42453 (size: 35.4 KiB, free: 366.0 MiB)
26/01/12 02:26:19 INFO TaskSetManager: Finished task 1.0 in stage 105.0 (TID 205) in 59 ms on 172.18.0.5 (executor 0) (1/2)
26/01/12 02:26:52 INFO TaskSetManager: Finished task 0.0 in stage 105.0 (TID 204) in 32890 ms on 172.18.0.5 (executor 0) (2/2)
26/01/12 02:26:52 INFO TaskSchedulerImpl: Removed TaskSet 105.0, whose tasks have all completed, from pool 
26/01/12 02:26:52 INFO DAGScheduler: ResultStage 105 (parquet at <unknown>:0) finished in 32.910 s
26/01/12 02:26:52 INFO DAGScheduler: Job 105 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:26:52 INFO TaskSchedulerImpl: Killing all running tasks in stage 105: Stage finished
26/01/12 02:26:52 INFO DAGScheduler: Job 105 finished: parquet at <unknown>:0, took 32.919412 s
26/01/12 02:26:52 INFO FileFormatWriter: Start to commit write Job 9d58dc5b-99c9-41c9-ab81-c2cf50501684.
26/01/12 02:26:52 INFO FileFormatWriter: Write Job 9d58dc5b-99c9-41c9-ab81-c2cf50501684 committed. Elapsed time: 35 ms.
26/01/12 02:26:52 INFO FileFormatWriter: Finished processing stats for write job 9d58dc5b-99c9-41c9-ab81-c2cf50501684.
Cargando: yellow_tripdata_2013-06.parquet en hdfs://hadoop-namenode:8020/data/nyc/raw/taxi-trips/2013...
26/01/12 02:26:52 INFO InMemoryFileIndex: It took 7 ms to list leaf files for 1 paths.
26/01/12 02:26:52 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 02:26:52 INFO DAGScheduler: Got job 106 (parquet at <unknown>:0) with 1 output partitions
26/01/12 02:26:52 INFO DAGScheduler: Final stage: ResultStage 106 (parquet at <unknown>:0)
26/01/12 02:26:52 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:26:52 INFO DAGScheduler: Missing parents: List()
26/01/12 02:26:52 INFO DAGScheduler: Submitting ResultStage 106 (MapPartitionsRDD[266] at parquet at <unknown>:0), which has no missing parents
26/01/12 02:26:52 INFO MemoryStore: Block broadcast_159 stored as values in memory (estimated size 102.6 KiB, free 364.3 MiB)
26/01/12 02:26:52 INFO MemoryStore: Block broadcast_159_piece0 stored as bytes in memory (estimated size 36.8 KiB, free 364.3 MiB)
26/01/12 02:26:52 INFO BlockManagerInfo: Added broadcast_159_piece0 in memory on 02926ee04bc9:45221 (size: 36.8 KiB, free: 366.0 MiB)
26/01/12 02:26:52 INFO SparkContext: Created broadcast 159 from broadcast at DAGScheduler.scala:1513
26/01/12 02:26:52 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 106 (MapPartitionsRDD[266] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0))
26/01/12 02:26:52 INFO TaskSchedulerImpl: Adding task set 106.0 with 1 tasks resource profile 0
26/01/12 02:26:52 INFO TaskSetManager: Starting task 0.0 in stage 106.0 (TID 206) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4607 bytes) taskResourceAssignments Map()
26/01/12 02:26:52 INFO BlockManagerInfo: Added broadcast_159_piece0 in memory on 172.18.0.5:42453 (size: 36.8 KiB, free: 366.0 MiB)
26/01/12 02:26:52 INFO TaskSetManager: Finished task 0.0 in stage 106.0 (TID 206) in 49 ms on 172.18.0.5 (executor 0) (1/1)
26/01/12 02:26:52 INFO TaskSchedulerImpl: Removed TaskSet 106.0, whose tasks have all completed, from pool 
26/01/12 02:26:52 INFO DAGScheduler: ResultStage 106 (parquet at <unknown>:0) finished in 0.061 s
26/01/12 02:26:52 INFO DAGScheduler: Job 106 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:26:52 INFO TaskSchedulerImpl: Killing all running tasks in stage 106: Stage finished
26/01/12 02:26:52 INFO DAGScheduler: Job 106 finished: parquet at <unknown>:0, took 0.065430 s
26/01/12 02:26:52 INFO FileSourceStrategy: Pushed Filters: 
26/01/12 02:26:52 INFO FileSourceStrategy: Post-Scan Filters: 
26/01/12 02:26:52 INFO FileSourceStrategy: Output Data Schema: struct<VendorID: bigint, tpep_pickup_datetime: timestamp, tpep_dropoff_datetime: timestamp, passenger_count: bigint, trip_distance: double ... 17 more fields>
26/01/12 02:26:52 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:26:52 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:26:52 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:26:52 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:26:52 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:26:52 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:26:52 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:26:52 INFO MemoryStore: Block broadcast_160 stored as values in memory (estimated size 358.4 KiB, free 363.9 MiB)
26/01/12 02:26:52 INFO MemoryStore: Block broadcast_160_piece0 stored as bytes in memory (estimated size 35.4 KiB, free 363.9 MiB)
26/01/12 02:26:52 INFO BlockManagerInfo: Added broadcast_160_piece0 in memory on 02926ee04bc9:45221 (size: 35.4 KiB, free: 365.9 MiB)
26/01/12 02:26:52 INFO SparkContext: Created broadcast 160 from parquet at <unknown>:0
26/01/12 02:26:52 INFO FileSourceScanExec: Planning scan with bin packing, max size: 91869198 bytes, open cost is considered as scanning 4194304 bytes.
26/01/12 02:26:52 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 02:26:52 INFO DAGScheduler: Got job 107 (parquet at <unknown>:0) with 2 output partitions
26/01/12 02:26:52 INFO DAGScheduler: Final stage: ResultStage 107 (parquet at <unknown>:0)
26/01/12 02:26:52 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:26:52 INFO DAGScheduler: Missing parents: List()
26/01/12 02:26:52 INFO DAGScheduler: Submitting ResultStage 107 (MapPartitionsRDD[269] at parquet at <unknown>:0), which has no missing parents
26/01/12 02:26:52 INFO MemoryStore: Block broadcast_161 stored as values in memory (estimated size 225.1 KiB, free 363.7 MiB)
26/01/12 02:26:52 INFO MemoryStore: Block broadcast_161_piece0 stored as bytes in memory (estimated size 77.4 KiB, free 363.6 MiB)
26/01/12 02:26:52 INFO BlockManagerInfo: Added broadcast_161_piece0 in memory on 02926ee04bc9:45221 (size: 77.4 KiB, free: 365.9 MiB)
26/01/12 02:26:52 INFO SparkContext: Created broadcast 161 from broadcast at DAGScheduler.scala:1513
26/01/12 02:26:52 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 107 (MapPartitionsRDD[269] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1))
26/01/12 02:26:52 INFO TaskSchedulerImpl: Adding task set 107.0 with 2 tasks resource profile 0
26/01/12 02:26:52 INFO TaskSetManager: Starting task 0.0 in stage 107.0 (TID 207) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:26:52 INFO TaskSetManager: Starting task 1.0 in stage 107.0 (TID 208) (172.18.0.5, executor 0, partition 1, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:26:52 INFO BlockManagerInfo: Added broadcast_161_piece0 in memory on 172.18.0.5:42453 (size: 77.4 KiB, free: 365.9 MiB)
26/01/12 02:26:52 INFO BlockManagerInfo: Added broadcast_160_piece0 in memory on 172.18.0.5:42453 (size: 35.4 KiB, free: 365.9 MiB)
26/01/12 02:26:52 INFO TaskSetManager: Finished task 1.0 in stage 107.0 (TID 208) in 59 ms on 172.18.0.5 (executor 0) (1/2)
26/01/12 02:27:24 INFO TaskSetManager: Finished task 0.0 in stage 107.0 (TID 207) in 31955 ms on 172.18.0.5 (executor 0) (2/2)
26/01/12 02:27:24 INFO TaskSchedulerImpl: Removed TaskSet 107.0, whose tasks have all completed, from pool 
26/01/12 02:27:24 INFO DAGScheduler: ResultStage 107 (parquet at <unknown>:0) finished in 31.974 s
26/01/12 02:27:24 INFO DAGScheduler: Job 107 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:27:24 INFO TaskSchedulerImpl: Killing all running tasks in stage 107: Stage finished
26/01/12 02:27:24 INFO DAGScheduler: Job 107 finished: parquet at <unknown>:0, took 31.980134 s
26/01/12 02:27:24 INFO FileFormatWriter: Start to commit write Job 9a29b489-8f9c-4317-a2d0-74f37df8c7b7.
26/01/12 02:27:24 INFO FileFormatWriter: Write Job 9a29b489-8f9c-4317-a2d0-74f37df8c7b7 committed. Elapsed time: 32 ms.
26/01/12 02:27:24 INFO FileFormatWriter: Finished processing stats for write job 9a29b489-8f9c-4317-a2d0-74f37df8c7b7.
Cargando: yellow_tripdata_2013-07.parquet en hdfs://hadoop-namenode:8020/data/nyc/raw/taxi-trips/2013...
26/01/12 02:27:24 INFO InMemoryFileIndex: It took 7 ms to list leaf files for 1 paths.
26/01/12 02:27:24 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 02:27:24 INFO DAGScheduler: Got job 108 (parquet at <unknown>:0) with 1 output partitions
26/01/12 02:27:24 INFO DAGScheduler: Final stage: ResultStage 108 (parquet at <unknown>:0)
26/01/12 02:27:24 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:27:24 INFO DAGScheduler: Missing parents: List()
26/01/12 02:27:24 INFO DAGScheduler: Submitting ResultStage 108 (MapPartitionsRDD[271] at parquet at <unknown>:0), which has no missing parents
26/01/12 02:27:24 INFO MemoryStore: Block broadcast_162 stored as values in memory (estimated size 102.6 KiB, free 363.5 MiB)
26/01/12 02:27:24 INFO MemoryStore: Block broadcast_162_piece0 stored as bytes in memory (estimated size 36.8 KiB, free 363.5 MiB)
26/01/12 02:27:24 INFO BlockManagerInfo: Added broadcast_162_piece0 in memory on 02926ee04bc9:45221 (size: 36.8 KiB, free: 365.8 MiB)
26/01/12 02:27:24 INFO SparkContext: Created broadcast 162 from broadcast at DAGScheduler.scala:1513
26/01/12 02:27:24 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 108 (MapPartitionsRDD[271] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0))
26/01/12 02:27:24 INFO TaskSchedulerImpl: Adding task set 108.0 with 1 tasks resource profile 0
26/01/12 02:27:24 INFO TaskSetManager: Starting task 0.0 in stage 108.0 (TID 209) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4607 bytes) taskResourceAssignments Map()
26/01/12 02:27:24 INFO BlockManagerInfo: Added broadcast_162_piece0 in memory on 172.18.0.5:42453 (size: 36.8 KiB, free: 365.8 MiB)
26/01/12 02:27:24 INFO TaskSetManager: Finished task 0.0 in stage 108.0 (TID 209) in 48 ms on 172.18.0.5 (executor 0) (1/1)
26/01/12 02:27:24 INFO TaskSchedulerImpl: Removed TaskSet 108.0, whose tasks have all completed, from pool 
26/01/12 02:27:24 INFO DAGScheduler: ResultStage 108 (parquet at <unknown>:0) finished in 0.062 s
26/01/12 02:27:24 INFO DAGScheduler: Job 108 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:27:24 INFO TaskSchedulerImpl: Killing all running tasks in stage 108: Stage finished
26/01/12 02:27:24 INFO DAGScheduler: Job 108 finished: parquet at <unknown>:0, took 0.066895 s
26/01/12 02:27:24 INFO FileSourceStrategy: Pushed Filters: 
26/01/12 02:27:24 INFO FileSourceStrategy: Post-Scan Filters: 
26/01/12 02:27:24 INFO FileSourceStrategy: Output Data Schema: struct<VendorID: bigint, tpep_pickup_datetime: timestamp, tpep_dropoff_datetime: timestamp, passenger_count: bigint, trip_distance: double ... 17 more fields>
26/01/12 02:27:24 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:27:24 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:27:24 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:27:24 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:27:24 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:27:24 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:27:24 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:27:24 INFO MemoryStore: Block broadcast_163 stored as values in memory (estimated size 358.4 KiB, free 363.1 MiB)
26/01/12 02:27:24 INFO MemoryStore: Block broadcast_163_piece0 stored as bytes in memory (estimated size 35.4 KiB, free 363.1 MiB)
26/01/12 02:27:24 INFO BlockManagerInfo: Added broadcast_163_piece0 in memory on 02926ee04bc9:45221 (size: 35.4 KiB, free: 365.8 MiB)
26/01/12 02:27:24 INFO SparkContext: Created broadcast 163 from parquet at <unknown>:0
26/01/12 02:27:24 INFO FileSourceScanExec: Planning scan with bin packing, max size: 88863086 bytes, open cost is considered as scanning 4194304 bytes.
26/01/12 02:27:24 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 02:27:24 INFO DAGScheduler: Got job 109 (parquet at <unknown>:0) with 2 output partitions
26/01/12 02:27:24 INFO DAGScheduler: Final stage: ResultStage 109 (parquet at <unknown>:0)
26/01/12 02:27:24 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:27:24 INFO DAGScheduler: Missing parents: List()
26/01/12 02:27:24 INFO DAGScheduler: Submitting ResultStage 109 (MapPartitionsRDD[274] at parquet at <unknown>:0), which has no missing parents
26/01/12 02:27:24 INFO MemoryStore: Block broadcast_164 stored as values in memory (estimated size 225.1 KiB, free 362.9 MiB)
26/01/12 02:27:24 INFO MemoryStore: Block broadcast_164_piece0 stored as bytes in memory (estimated size 77.4 KiB, free 362.8 MiB)
26/01/12 02:27:24 INFO BlockManagerInfo: Added broadcast_164_piece0 in memory on 02926ee04bc9:45221 (size: 77.4 KiB, free: 365.7 MiB)
26/01/12 02:27:24 INFO SparkContext: Created broadcast 164 from broadcast at DAGScheduler.scala:1513
26/01/12 02:27:24 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 109 (MapPartitionsRDD[274] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1))
26/01/12 02:27:24 INFO TaskSchedulerImpl: Adding task set 109.0 with 2 tasks resource profile 0
26/01/12 02:27:24 INFO TaskSetManager: Starting task 0.0 in stage 109.0 (TID 210) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:27:24 INFO TaskSetManager: Starting task 1.0 in stage 109.0 (TID 211) (172.18.0.5, executor 0, partition 1, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:27:24 INFO BlockManagerInfo: Added broadcast_164_piece0 in memory on 172.18.0.5:42453 (size: 77.4 KiB, free: 365.8 MiB)
26/01/12 02:27:24 INFO BlockManagerInfo: Added broadcast_163_piece0 in memory on 172.18.0.5:42453 (size: 35.4 KiB, free: 365.7 MiB)
26/01/12 02:27:24 INFO TaskSetManager: Finished task 1.0 in stage 109.0 (TID 211) in 60 ms on 172.18.0.5 (executor 0) (1/2)
26/01/12 02:27:54 INFO TaskSetManager: Finished task 0.0 in stage 109.0 (TID 210) in 29677 ms on 172.18.0.5 (executor 0) (2/2)
26/01/12 02:27:54 INFO TaskSchedulerImpl: Removed TaskSet 109.0, whose tasks have all completed, from pool 
26/01/12 02:27:54 INFO DAGScheduler: ResultStage 109 (parquet at <unknown>:0) finished in 29.698 s
26/01/12 02:27:54 INFO DAGScheduler: Job 109 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:27:54 INFO TaskSchedulerImpl: Killing all running tasks in stage 109: Stage finished
26/01/12 02:27:54 INFO DAGScheduler: Job 109 finished: parquet at <unknown>:0, took 29.705415 s
26/01/12 02:27:54 INFO FileFormatWriter: Start to commit write Job a1b1298a-52fb-432e-aaa8-911fbbcc423c.
26/01/12 02:27:54 INFO FileFormatWriter: Write Job a1b1298a-52fb-432e-aaa8-911fbbcc423c committed. Elapsed time: 29 ms.
26/01/12 02:27:54 INFO FileFormatWriter: Finished processing stats for write job a1b1298a-52fb-432e-aaa8-911fbbcc423c.
Cargando: yellow_tripdata_2013-08.parquet en hdfs://hadoop-namenode:8020/data/nyc/raw/taxi-trips/2013...
26/01/12 02:27:54 INFO InMemoryFileIndex: It took 6 ms to list leaf files for 1 paths.
26/01/12 02:27:54 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 02:27:54 INFO DAGScheduler: Got job 110 (parquet at <unknown>:0) with 1 output partitions
26/01/12 02:27:54 INFO DAGScheduler: Final stage: ResultStage 110 (parquet at <unknown>:0)
26/01/12 02:27:54 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:27:54 INFO DAGScheduler: Missing parents: List()
26/01/12 02:27:54 INFO DAGScheduler: Submitting ResultStage 110 (MapPartitionsRDD[276] at parquet at <unknown>:0), which has no missing parents
26/01/12 02:27:54 INFO MemoryStore: Block broadcast_165 stored as values in memory (estimated size 102.6 KiB, free 362.7 MiB)
26/01/12 02:27:54 INFO MemoryStore: Block broadcast_165_piece0 stored as bytes in memory (estimated size 36.8 KiB, free 362.7 MiB)
26/01/12 02:27:54 INFO BlockManagerInfo: Added broadcast_165_piece0 in memory on 02926ee04bc9:45221 (size: 36.8 KiB, free: 365.7 MiB)
26/01/12 02:27:54 INFO SparkContext: Created broadcast 165 from broadcast at DAGScheduler.scala:1513
26/01/12 02:27:54 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 110 (MapPartitionsRDD[276] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0))
26/01/12 02:27:54 INFO TaskSchedulerImpl: Adding task set 110.0 with 1 tasks resource profile 0
26/01/12 02:27:54 INFO TaskSetManager: Starting task 0.0 in stage 110.0 (TID 212) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4607 bytes) taskResourceAssignments Map()
26/01/12 02:27:54 INFO BlockManagerInfo: Added broadcast_165_piece0 in memory on 172.18.0.5:42453 (size: 36.8 KiB, free: 365.7 MiB)
26/01/12 02:27:54 INFO TaskSetManager: Finished task 0.0 in stage 110.0 (TID 212) in 48 ms on 172.18.0.5 (executor 0) (1/1)
26/01/12 02:27:54 INFO TaskSchedulerImpl: Removed TaskSet 110.0, whose tasks have all completed, from pool 
26/01/12 02:27:54 INFO DAGScheduler: ResultStage 110 (parquet at <unknown>:0) finished in 0.061 s
26/01/12 02:27:54 INFO DAGScheduler: Job 110 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:27:54 INFO TaskSchedulerImpl: Killing all running tasks in stage 110: Stage finished
26/01/12 02:27:54 INFO DAGScheduler: Job 110 finished: parquet at <unknown>:0, took 0.065028 s
26/01/12 02:27:54 INFO FileSourceStrategy: Pushed Filters: 
26/01/12 02:27:54 INFO FileSourceStrategy: Post-Scan Filters: 
26/01/12 02:27:54 INFO FileSourceStrategy: Output Data Schema: struct<VendorID: bigint, tpep_pickup_datetime: timestamp, tpep_dropoff_datetime: timestamp, passenger_count: bigint, trip_distance: double ... 17 more fields>
26/01/12 02:27:54 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:27:54 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:27:54 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:27:54 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:27:54 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:27:54 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:27:54 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:27:54 INFO MemoryStore: Block broadcast_166 stored as values in memory (estimated size 358.4 KiB, free 362.3 MiB)
26/01/12 02:27:54 INFO MemoryStore: Block broadcast_166_piece0 stored as bytes in memory (estimated size 35.4 KiB, free 362.3 MiB)
26/01/12 02:27:54 INFO BlockManagerInfo: Added broadcast_166_piece0 in memory on 02926ee04bc9:45221 (size: 35.4 KiB, free: 365.6 MiB)
26/01/12 02:27:54 INFO SparkContext: Created broadcast 166 from parquet at <unknown>:0
26/01/12 02:27:54 INFO FileSourceScanExec: Planning scan with bin packing, max size: 76183424 bytes, open cost is considered as scanning 4194304 bytes.
26/01/12 02:27:54 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 02:27:54 INFO DAGScheduler: Got job 111 (parquet at <unknown>:0) with 2 output partitions
26/01/12 02:27:54 INFO DAGScheduler: Final stage: ResultStage 111 (parquet at <unknown>:0)
26/01/12 02:27:54 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:27:54 INFO DAGScheduler: Missing parents: List()
26/01/12 02:27:54 INFO DAGScheduler: Submitting ResultStage 111 (MapPartitionsRDD[279] at parquet at <unknown>:0), which has no missing parents
26/01/12 02:27:54 INFO MemoryStore: Block broadcast_167 stored as values in memory (estimated size 225.1 KiB, free 362.0 MiB)
26/01/12 02:27:54 INFO MemoryStore: Block broadcast_167_piece0 stored as bytes in memory (estimated size 77.4 KiB, free 362.0 MiB)
26/01/12 02:27:54 INFO BlockManagerInfo: Added broadcast_167_piece0 in memory on 02926ee04bc9:45221 (size: 77.4 KiB, free: 365.6 MiB)
26/01/12 02:27:54 INFO SparkContext: Created broadcast 167 from broadcast at DAGScheduler.scala:1513
26/01/12 02:27:54 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 111 (MapPartitionsRDD[279] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1))
26/01/12 02:27:54 INFO TaskSchedulerImpl: Adding task set 111.0 with 2 tasks resource profile 0
26/01/12 02:27:54 INFO TaskSetManager: Starting task 0.0 in stage 111.0 (TID 213) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:27:54 INFO TaskSetManager: Starting task 1.0 in stage 111.0 (TID 214) (172.18.0.5, executor 0, partition 1, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:27:54 INFO BlockManagerInfo: Added broadcast_167_piece0 in memory on 172.18.0.5:42453 (size: 77.4 KiB, free: 365.6 MiB)
26/01/12 02:27:54 INFO BlockManagerInfo: Added broadcast_166_piece0 in memory on 172.18.0.5:42453 (size: 35.4 KiB, free: 365.6 MiB)
26/01/12 02:27:54 INFO TaskSetManager: Finished task 1.0 in stage 111.0 (TID 214) in 59 ms on 172.18.0.5 (executor 0) (1/2)
26/01/12 02:28:20 INFO TaskSetManager: Finished task 0.0 in stage 111.0 (TID 213) in 25526 ms on 172.18.0.5 (executor 0) (2/2)
26/01/12 02:28:20 INFO TaskSchedulerImpl: Removed TaskSet 111.0, whose tasks have all completed, from pool 
26/01/12 02:28:20 INFO DAGScheduler: ResultStage 111 (parquet at <unknown>:0) finished in 25.546 s
26/01/12 02:28:20 INFO DAGScheduler: Job 111 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:28:20 INFO TaskSchedulerImpl: Killing all running tasks in stage 111: Stage finished
26/01/12 02:28:20 INFO DAGScheduler: Job 111 finished: parquet at <unknown>:0, took 25.555094 s
26/01/12 02:28:20 INFO FileFormatWriter: Start to commit write Job 23a002a9-044c-472a-8d23-65005e191ed0.
26/01/12 02:28:20 INFO FileFormatWriter: Write Job 23a002a9-044c-472a-8d23-65005e191ed0 committed. Elapsed time: 37 ms.
26/01/12 02:28:20 INFO FileFormatWriter: Finished processing stats for write job 23a002a9-044c-472a-8d23-65005e191ed0.
Cargando: yellow_tripdata_2013-09.parquet en hdfs://hadoop-namenode:8020/data/nyc/raw/taxi-trips/2013...
26/01/12 02:28:20 INFO InMemoryFileIndex: It took 7 ms to list leaf files for 1 paths.
26/01/12 02:28:20 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 02:28:20 INFO DAGScheduler: Got job 112 (parquet at <unknown>:0) with 1 output partitions
26/01/12 02:28:20 INFO DAGScheduler: Final stage: ResultStage 112 (parquet at <unknown>:0)
26/01/12 02:28:20 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:28:20 INFO DAGScheduler: Missing parents: List()
26/01/12 02:28:20 INFO DAGScheduler: Submitting ResultStage 112 (MapPartitionsRDD[281] at parquet at <unknown>:0), which has no missing parents
26/01/12 02:28:20 INFO MemoryStore: Block broadcast_168 stored as values in memory (estimated size 102.6 KiB, free 361.9 MiB)
26/01/12 02:28:20 INFO MemoryStore: Block broadcast_168_piece0 stored as bytes in memory (estimated size 36.8 KiB, free 361.8 MiB)
26/01/12 02:28:20 INFO BlockManagerInfo: Added broadcast_168_piece0 in memory on 02926ee04bc9:45221 (size: 36.8 KiB, free: 365.5 MiB)
26/01/12 02:28:20 INFO SparkContext: Created broadcast 168 from broadcast at DAGScheduler.scala:1513
26/01/12 02:28:20 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 112 (MapPartitionsRDD[281] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0))
26/01/12 02:28:20 INFO TaskSchedulerImpl: Adding task set 112.0 with 1 tasks resource profile 0
26/01/12 02:28:20 INFO TaskSetManager: Starting task 0.0 in stage 112.0 (TID 215) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4607 bytes) taskResourceAssignments Map()
26/01/12 02:28:20 INFO BlockManagerInfo: Added broadcast_168_piece0 in memory on 172.18.0.5:42453 (size: 36.8 KiB, free: 365.5 MiB)
26/01/12 02:28:20 INFO TaskSetManager: Finished task 0.0 in stage 112.0 (TID 215) in 49 ms on 172.18.0.5 (executor 0) (1/1)
26/01/12 02:28:20 INFO TaskSchedulerImpl: Removed TaskSet 112.0, whose tasks have all completed, from pool 
26/01/12 02:28:20 INFO DAGScheduler: ResultStage 112 (parquet at <unknown>:0) finished in 0.062 s
26/01/12 02:28:20 INFO DAGScheduler: Job 112 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:28:20 INFO TaskSchedulerImpl: Killing all running tasks in stage 112: Stage finished
26/01/12 02:28:20 INFO DAGScheduler: Job 112 finished: parquet at <unknown>:0, took 0.065985 s
26/01/12 02:28:20 INFO FileSourceStrategy: Pushed Filters: 
26/01/12 02:28:20 INFO FileSourceStrategy: Post-Scan Filters: 
26/01/12 02:28:20 INFO FileSourceStrategy: Output Data Schema: struct<VendorID: bigint, tpep_pickup_datetime: timestamp, tpep_dropoff_datetime: timestamp, passenger_count: bigint, trip_distance: double ... 17 more fields>
26/01/12 02:28:20 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:28:20 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:28:20 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:28:20 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:28:20 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:28:20 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:28:20 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:28:20 INFO MemoryStore: Block broadcast_169 stored as values in memory (estimated size 358.4 KiB, free 361.5 MiB)
26/01/12 02:28:20 INFO MemoryStore: Block broadcast_169_piece0 stored as bytes in memory (estimated size 35.4 KiB, free 361.5 MiB)
26/01/12 02:28:20 INFO BlockManagerInfo: Added broadcast_169_piece0 in memory on 02926ee04bc9:45221 (size: 35.4 KiB, free: 365.5 MiB)
26/01/12 02:28:20 INFO SparkContext: Created broadcast 169 from parquet at <unknown>:0
26/01/12 02:28:20 INFO FileSourceScanExec: Planning scan with bin packing, max size: 90516914 bytes, open cost is considered as scanning 4194304 bytes.
26/01/12 02:28:20 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 02:28:20 INFO DAGScheduler: Got job 113 (parquet at <unknown>:0) with 2 output partitions
26/01/12 02:28:20 INFO DAGScheduler: Final stage: ResultStage 113 (parquet at <unknown>:0)
26/01/12 02:28:20 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:28:20 INFO DAGScheduler: Missing parents: List()
26/01/12 02:28:20 INFO DAGScheduler: Submitting ResultStage 113 (MapPartitionsRDD[284] at parquet at <unknown>:0), which has no missing parents
26/01/12 02:28:20 INFO MemoryStore: Block broadcast_170 stored as values in memory (estimated size 225.1 KiB, free 361.2 MiB)
26/01/12 02:28:20 INFO MemoryStore: Block broadcast_170_piece0 stored as bytes in memory (estimated size 77.4 KiB, free 361.2 MiB)
26/01/12 02:28:20 INFO BlockManagerInfo: Added broadcast_170_piece0 in memory on 02926ee04bc9:45221 (size: 77.4 KiB, free: 365.4 MiB)
26/01/12 02:28:20 INFO SparkContext: Created broadcast 170 from broadcast at DAGScheduler.scala:1513
26/01/12 02:28:20 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 113 (MapPartitionsRDD[284] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1))
26/01/12 02:28:20 INFO TaskSchedulerImpl: Adding task set 113.0 with 2 tasks resource profile 0
26/01/12 02:28:20 INFO TaskSetManager: Starting task 0.0 in stage 113.0 (TID 216) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:28:20 INFO TaskSetManager: Starting task 1.0 in stage 113.0 (TID 217) (172.18.0.5, executor 0, partition 1, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:28:20 INFO BlockManagerInfo: Removed broadcast_154_piece0 on 02926ee04bc9:45221 in memory (size: 35.4 KiB, free: 365.5 MiB)
26/01/12 02:28:20 INFO BlockManagerInfo: Added broadcast_170_piece0 in memory on 172.18.0.5:42453 (size: 77.4 KiB, free: 365.5 MiB)
26/01/12 02:28:20 INFO BlockManagerInfo: Removed broadcast_154_piece0 on 172.18.0.5:42453 in memory (size: 35.4 KiB, free: 365.5 MiB)
26/01/12 02:28:20 INFO BlockManagerInfo: Removed broadcast_167_piece0 on 02926ee04bc9:45221 in memory (size: 77.4 KiB, free: 365.5 MiB)
26/01/12 02:28:20 INFO BlockManagerInfo: Removed broadcast_167_piece0 on 172.18.0.5:42453 in memory (size: 77.4 KiB, free: 365.6 MiB)
26/01/12 02:28:20 INFO BlockManagerInfo: Removed broadcast_158_piece0 on 02926ee04bc9:45221 in memory (size: 77.4 KiB, free: 365.6 MiB)
26/01/12 02:28:20 INFO BlockManagerInfo: Removed broadcast_158_piece0 on 172.18.0.5:42453 in memory (size: 77.4 KiB, free: 365.6 MiB)
26/01/12 02:28:20 INFO BlockManagerInfo: Removed broadcast_156_piece0 on 02926ee04bc9:45221 in memory (size: 36.8 KiB, free: 365.6 MiB)
26/01/12 02:28:20 INFO BlockManagerInfo: Added broadcast_169_piece0 in memory on 172.18.0.5:42453 (size: 35.4 KiB, free: 365.6 MiB)
26/01/12 02:28:20 INFO BlockManagerInfo: Removed broadcast_156_piece0 on 172.18.0.5:42453 in memory (size: 36.8 KiB, free: 365.6 MiB)
26/01/12 02:28:20 INFO BlockManagerInfo: Removed broadcast_165_piece0 on 02926ee04bc9:45221 in memory (size: 36.8 KiB, free: 365.7 MiB)
26/01/12 02:28:20 INFO BlockManagerInfo: Removed broadcast_165_piece0 on 172.18.0.5:42453 in memory (size: 36.8 KiB, free: 365.7 MiB)
26/01/12 02:28:20 INFO BlockManagerInfo: Removed broadcast_166_piece0 on 02926ee04bc9:45221 in memory (size: 35.4 KiB, free: 365.7 MiB)
26/01/12 02:28:20 INFO BlockManagerInfo: Removed broadcast_166_piece0 on 172.18.0.5:42453 in memory (size: 35.4 KiB, free: 365.7 MiB)
26/01/12 02:28:20 INFO BlockManagerInfo: Removed broadcast_157_piece0 on 02926ee04bc9:45221 in memory (size: 35.4 KiB, free: 365.8 MiB)
26/01/12 02:28:20 INFO BlockManagerInfo: Removed broadcast_157_piece0 on 172.18.0.5:42453 in memory (size: 35.4 KiB, free: 365.8 MiB)
26/01/12 02:28:20 INFO BlockManagerInfo: Removed broadcast_163_piece0 on 02926ee04bc9:45221 in memory (size: 35.4 KiB, free: 365.8 MiB)
26/01/12 02:28:20 INFO BlockManagerInfo: Removed broadcast_163_piece0 on 172.18.0.5:42453 in memory (size: 35.4 KiB, free: 365.8 MiB)
26/01/12 02:28:20 INFO BlockManagerInfo: Removed broadcast_162_piece0 on 02926ee04bc9:45221 in memory (size: 36.8 KiB, free: 365.8 MiB)
26/01/12 02:28:20 INFO BlockManagerInfo: Removed broadcast_162_piece0 on 172.18.0.5:42453 in memory (size: 36.8 KiB, free: 365.8 MiB)
26/01/12 02:28:20 INFO BlockManagerInfo: Removed broadcast_168_piece0 on 02926ee04bc9:45221 in memory (size: 36.8 KiB, free: 365.9 MiB)
26/01/12 02:28:20 INFO TaskSetManager: Finished task 1.0 in stage 113.0 (TID 217) in 89 ms on 172.18.0.5 (executor 0) (1/2)
26/01/12 02:28:20 INFO BlockManagerInfo: Removed broadcast_168_piece0 on 172.18.0.5:42453 in memory (size: 36.8 KiB, free: 365.9 MiB)
26/01/12 02:28:20 INFO BlockManagerInfo: Removed broadcast_161_piece0 on 02926ee04bc9:45221 in memory (size: 77.4 KiB, free: 365.9 MiB)
26/01/12 02:28:20 INFO BlockManagerInfo: Removed broadcast_161_piece0 on 172.18.0.5:42453 in memory (size: 77.4 KiB, free: 365.9 MiB)
26/01/12 02:28:20 INFO BlockManagerInfo: Removed broadcast_164_piece0 on 02926ee04bc9:45221 in memory (size: 77.4 KiB, free: 366.0 MiB)
26/01/12 02:28:20 INFO BlockManagerInfo: Removed broadcast_164_piece0 on 172.18.0.5:42453 in memory (size: 77.4 KiB, free: 366.0 MiB)
26/01/12 02:28:20 INFO BlockManagerInfo: Removed broadcast_160_piece0 on 02926ee04bc9:45221 in memory (size: 35.4 KiB, free: 366.0 MiB)
26/01/12 02:28:20 INFO BlockManagerInfo: Removed broadcast_160_piece0 on 172.18.0.5:42453 in memory (size: 35.4 KiB, free: 366.0 MiB)
26/01/12 02:28:20 INFO BlockManagerInfo: Removed broadcast_159_piece0 on 02926ee04bc9:45221 in memory (size: 36.8 KiB, free: 366.1 MiB)
26/01/12 02:28:20 INFO BlockManagerInfo: Removed broadcast_159_piece0 on 172.18.0.5:42453 in memory (size: 36.8 KiB, free: 366.1 MiB)
26/01/12 02:28:51 INFO TaskSetManager: Finished task 0.0 in stage 113.0 (TID 216) in 30917 ms on 172.18.0.5 (executor 0) (2/2)
26/01/12 02:28:51 INFO TaskSchedulerImpl: Removed TaskSet 113.0, whose tasks have all completed, from pool 
26/01/12 02:28:51 INFO DAGScheduler: ResultStage 113 (parquet at <unknown>:0) finished in 30.970 s
26/01/12 02:28:51 INFO DAGScheduler: Job 113 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:28:51 INFO TaskSchedulerImpl: Killing all running tasks in stage 113: Stage finished
26/01/12 02:28:51 INFO DAGScheduler: Job 113 finished: parquet at <unknown>:0, took 30.983576 s
26/01/12 02:28:51 INFO FileFormatWriter: Start to commit write Job d65d19da-f915-40e8-b240-0c9d561ff2e8.
26/01/12 02:28:51 INFO FileFormatWriter: Write Job d65d19da-f915-40e8-b240-0c9d561ff2e8 committed. Elapsed time: 29 ms.
26/01/12 02:28:51 INFO FileFormatWriter: Finished processing stats for write job d65d19da-f915-40e8-b240-0c9d561ff2e8.
Cargando: yellow_tripdata_2013-10.parquet en hdfs://hadoop-namenode:8020/data/nyc/raw/taxi-trips/2013...
26/01/12 02:28:51 INFO InMemoryFileIndex: It took 7 ms to list leaf files for 1 paths.
26/01/12 02:28:51 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 02:28:51 INFO DAGScheduler: Got job 114 (parquet at <unknown>:0) with 1 output partitions
26/01/12 02:28:51 INFO DAGScheduler: Final stage: ResultStage 114 (parquet at <unknown>:0)
26/01/12 02:28:51 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:28:51 INFO DAGScheduler: Missing parents: List()
26/01/12 02:28:51 INFO DAGScheduler: Submitting ResultStage 114 (MapPartitionsRDD[286] at parquet at <unknown>:0), which has no missing parents
26/01/12 02:28:51 INFO MemoryStore: Block broadcast_171 stored as values in memory (estimated size 102.6 KiB, free 364.8 MiB)
26/01/12 02:28:51 INFO MemoryStore: Block broadcast_171_piece0 stored as bytes in memory (estimated size 36.8 KiB, free 364.8 MiB)
26/01/12 02:28:51 INFO BlockManagerInfo: Added broadcast_171_piece0 in memory on 02926ee04bc9:45221 (size: 36.8 KiB, free: 366.0 MiB)
26/01/12 02:28:51 INFO SparkContext: Created broadcast 171 from broadcast at DAGScheduler.scala:1513
26/01/12 02:28:51 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 114 (MapPartitionsRDD[286] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0))
26/01/12 02:28:51 INFO TaskSchedulerImpl: Adding task set 114.0 with 1 tasks resource profile 0
26/01/12 02:28:51 INFO TaskSetManager: Starting task 0.0 in stage 114.0 (TID 218) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4607 bytes) taskResourceAssignments Map()
26/01/12 02:28:51 INFO BlockManagerInfo: Added broadcast_171_piece0 in memory on 172.18.0.5:42453 (size: 36.8 KiB, free: 366.0 MiB)
26/01/12 02:28:51 INFO TaskSetManager: Finished task 0.0 in stage 114.0 (TID 218) in 60 ms on 172.18.0.5 (executor 0) (1/1)
26/01/12 02:28:51 INFO TaskSchedulerImpl: Removed TaskSet 114.0, whose tasks have all completed, from pool 
26/01/12 02:28:51 INFO DAGScheduler: ResultStage 114 (parquet at <unknown>:0) finished in 0.075 s
26/01/12 02:28:51 INFO DAGScheduler: Job 114 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:28:51 INFO TaskSchedulerImpl: Killing all running tasks in stage 114: Stage finished
26/01/12 02:28:51 INFO DAGScheduler: Job 114 finished: parquet at <unknown>:0, took 0.081612 s
26/01/12 02:28:51 INFO FileSourceStrategy: Pushed Filters: 
26/01/12 02:28:51 INFO FileSourceStrategy: Post-Scan Filters: 
26/01/12 02:28:51 INFO FileSourceStrategy: Output Data Schema: struct<VendorID: bigint, tpep_pickup_datetime: timestamp, tpep_dropoff_datetime: timestamp, passenger_count: bigint, trip_distance: double ... 17 more fields>
26/01/12 02:28:51 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:28:51 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:28:51 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:28:51 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:28:51 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:28:51 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:28:51 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:28:51 INFO MemoryStore: Block broadcast_172 stored as values in memory (estimated size 358.4 KiB, free 364.5 MiB)
26/01/12 02:28:51 INFO MemoryStore: Block broadcast_172_piece0 stored as bytes in memory (estimated size 35.4 KiB, free 364.4 MiB)
26/01/12 02:28:51 INFO BlockManagerInfo: Added broadcast_172_piece0 in memory on 02926ee04bc9:45221 (size: 35.4 KiB, free: 366.0 MiB)
26/01/12 02:28:51 INFO SparkContext: Created broadcast 172 from parquet at <unknown>:0
26/01/12 02:28:51 INFO FileSourceScanExec: Planning scan with bin packing, max size: 96217940 bytes, open cost is considered as scanning 4194304 bytes.
26/01/12 02:28:51 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 02:28:51 INFO DAGScheduler: Got job 115 (parquet at <unknown>:0) with 2 output partitions
26/01/12 02:28:51 INFO DAGScheduler: Final stage: ResultStage 115 (parquet at <unknown>:0)
26/01/12 02:28:51 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:28:51 INFO DAGScheduler: Missing parents: List()
26/01/12 02:28:51 INFO DAGScheduler: Submitting ResultStage 115 (MapPartitionsRDD[289] at parquet at <unknown>:0), which has no missing parents
26/01/12 02:28:51 INFO MemoryStore: Block broadcast_173 stored as values in memory (estimated size 225.1 KiB, free 364.2 MiB)
26/01/12 02:28:51 INFO MemoryStore: Block broadcast_173_piece0 stored as bytes in memory (estimated size 77.4 KiB, free 364.1 MiB)
26/01/12 02:28:51 INFO BlockManagerInfo: Added broadcast_173_piece0 in memory on 02926ee04bc9:45221 (size: 77.4 KiB, free: 365.9 MiB)
26/01/12 02:28:51 INFO SparkContext: Created broadcast 173 from broadcast at DAGScheduler.scala:1513
26/01/12 02:28:51 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 115 (MapPartitionsRDD[289] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1))
26/01/12 02:28:51 INFO TaskSchedulerImpl: Adding task set 115.0 with 2 tasks resource profile 0
26/01/12 02:28:51 INFO TaskSetManager: Starting task 0.0 in stage 115.0 (TID 219) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:28:51 INFO TaskSetManager: Starting task 1.0 in stage 115.0 (TID 220) (172.18.0.5, executor 0, partition 1, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:28:51 INFO BlockManagerInfo: Added broadcast_173_piece0 in memory on 172.18.0.5:42453 (size: 77.4 KiB, free: 366.0 MiB)
26/01/12 02:28:51 INFO BlockManagerInfo: Added broadcast_172_piece0 in memory on 172.18.0.5:42453 (size: 35.4 KiB, free: 365.9 MiB)
26/01/12 02:28:51 INFO TaskSetManager: Finished task 1.0 in stage 115.0 (TID 220) in 62 ms on 172.18.0.5 (executor 0) (1/2)
26/01/12 02:29:23 INFO TaskSetManager: Finished task 0.0 in stage 115.0 (TID 219) in 32304 ms on 172.18.0.5 (executor 0) (2/2)
26/01/12 02:29:23 INFO TaskSchedulerImpl: Removed TaskSet 115.0, whose tasks have all completed, from pool 
26/01/12 02:29:23 INFO DAGScheduler: ResultStage 115 (parquet at <unknown>:0) finished in 32.324 s
26/01/12 02:29:23 INFO DAGScheduler: Job 115 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:29:23 INFO TaskSchedulerImpl: Killing all running tasks in stage 115: Stage finished
26/01/12 02:29:23 INFO DAGScheduler: Job 115 finished: parquet at <unknown>:0, took 32.331384 s
26/01/12 02:29:23 INFO FileFormatWriter: Start to commit write Job 97b65f33-d7bc-424d-988c-8c3399b0dc14.
26/01/12 02:29:23 INFO FileFormatWriter: Write Job 97b65f33-d7bc-424d-988c-8c3399b0dc14 committed. Elapsed time: 31 ms.
26/01/12 02:29:23 INFO FileFormatWriter: Finished processing stats for write job 97b65f33-d7bc-424d-988c-8c3399b0dc14.
Cargando: yellow_tripdata_2013-11.parquet en hdfs://hadoop-namenode:8020/data/nyc/raw/taxi-trips/2013...
26/01/12 02:29:23 INFO InMemoryFileIndex: It took 7 ms to list leaf files for 1 paths.
26/01/12 02:29:23 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 02:29:23 INFO DAGScheduler: Got job 116 (parquet at <unknown>:0) with 1 output partitions
26/01/12 02:29:23 INFO DAGScheduler: Final stage: ResultStage 116 (parquet at <unknown>:0)
26/01/12 02:29:23 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:29:23 INFO DAGScheduler: Missing parents: List()
26/01/12 02:29:23 INFO DAGScheduler: Submitting ResultStage 116 (MapPartitionsRDD[291] at parquet at <unknown>:0), which has no missing parents
26/01/12 02:29:23 INFO MemoryStore: Block broadcast_174 stored as values in memory (estimated size 102.6 KiB, free 364.0 MiB)
26/01/12 02:29:23 INFO MemoryStore: Block broadcast_174_piece0 stored as bytes in memory (estimated size 36.8 KiB, free 364.0 MiB)
26/01/12 02:29:23 INFO BlockManagerInfo: Added broadcast_174_piece0 in memory on 02926ee04bc9:45221 (size: 36.8 KiB, free: 365.9 MiB)
26/01/12 02:29:23 INFO SparkContext: Created broadcast 174 from broadcast at DAGScheduler.scala:1513
26/01/12 02:29:23 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 116 (MapPartitionsRDD[291] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0))
26/01/12 02:29:23 INFO TaskSchedulerImpl: Adding task set 116.0 with 1 tasks resource profile 0
26/01/12 02:29:23 INFO TaskSetManager: Starting task 0.0 in stage 116.0 (TID 221) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4607 bytes) taskResourceAssignments Map()
26/01/12 02:29:23 INFO BlockManagerInfo: Added broadcast_174_piece0 in memory on 172.18.0.5:42453 (size: 36.8 KiB, free: 365.9 MiB)
26/01/12 02:29:23 INFO TaskSetManager: Finished task 0.0 in stage 116.0 (TID 221) in 52 ms on 172.18.0.5 (executor 0) (1/1)
26/01/12 02:29:23 INFO TaskSchedulerImpl: Removed TaskSet 116.0, whose tasks have all completed, from pool 
26/01/12 02:29:23 INFO DAGScheduler: ResultStage 116 (parquet at <unknown>:0) finished in 0.068 s
26/01/12 02:29:23 INFO DAGScheduler: Job 116 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:29:23 INFO TaskSchedulerImpl: Killing all running tasks in stage 116: Stage finished
26/01/12 02:29:23 INFO DAGScheduler: Job 116 finished: parquet at <unknown>:0, took 0.072353 s
26/01/12 02:29:24 INFO FileSourceStrategy: Pushed Filters: 
26/01/12 02:29:24 INFO FileSourceStrategy: Post-Scan Filters: 
26/01/12 02:29:24 INFO FileSourceStrategy: Output Data Schema: struct<VendorID: bigint, tpep_pickup_datetime: timestamp, tpep_dropoff_datetime: timestamp, passenger_count: bigint, trip_distance: double ... 17 more fields>
26/01/12 02:29:24 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:29:24 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:29:24 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:29:24 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:29:24 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:29:24 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:29:24 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:29:24 INFO MemoryStore: Block broadcast_175 stored as values in memory (estimated size 358.4 KiB, free 363.6 MiB)
26/01/12 02:29:24 INFO MemoryStore: Block broadcast_175_piece0 stored as bytes in memory (estimated size 35.4 KiB, free 363.6 MiB)
26/01/12 02:29:24 INFO BlockManagerInfo: Added broadcast_175_piece0 in memory on 02926ee04bc9:45221 (size: 35.4 KiB, free: 365.9 MiB)
26/01/12 02:29:24 INFO SparkContext: Created broadcast 175 from parquet at <unknown>:0
26/01/12 02:29:24 INFO FileSourceScanExec: Planning scan with bin packing, max size: 91714947 bytes, open cost is considered as scanning 4194304 bytes.
26/01/12 02:29:24 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 02:29:24 INFO DAGScheduler: Got job 117 (parquet at <unknown>:0) with 2 output partitions
26/01/12 02:29:24 INFO DAGScheduler: Final stage: ResultStage 117 (parquet at <unknown>:0)
26/01/12 02:29:24 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:29:24 INFO DAGScheduler: Missing parents: List()
26/01/12 02:29:24 INFO DAGScheduler: Submitting ResultStage 117 (MapPartitionsRDD[294] at parquet at <unknown>:0), which has no missing parents
26/01/12 02:29:24 INFO MemoryStore: Block broadcast_176 stored as values in memory (estimated size 225.1 KiB, free 363.4 MiB)
26/01/12 02:29:24 INFO MemoryStore: Block broadcast_176_piece0 stored as bytes in memory (estimated size 77.4 KiB, free 363.3 MiB)
26/01/12 02:29:24 INFO BlockManagerInfo: Added broadcast_176_piece0 in memory on 02926ee04bc9:45221 (size: 77.4 KiB, free: 365.8 MiB)
26/01/12 02:29:24 INFO SparkContext: Created broadcast 176 from broadcast at DAGScheduler.scala:1513
26/01/12 02:29:24 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 117 (MapPartitionsRDD[294] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1))
26/01/12 02:29:24 INFO TaskSchedulerImpl: Adding task set 117.0 with 2 tasks resource profile 0
26/01/12 02:29:24 INFO TaskSetManager: Starting task 0.0 in stage 117.0 (TID 222) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:29:24 INFO TaskSetManager: Starting task 1.0 in stage 117.0 (TID 223) (172.18.0.5, executor 0, partition 1, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:29:24 INFO BlockManagerInfo: Added broadcast_176_piece0 in memory on 172.18.0.5:42453 (size: 77.4 KiB, free: 365.8 MiB)
26/01/12 02:29:24 INFO BlockManagerInfo: Added broadcast_175_piece0 in memory on 172.18.0.5:42453 (size: 35.4 KiB, free: 365.8 MiB)
26/01/12 02:29:24 INFO TaskSetManager: Finished task 1.0 in stage 117.0 (TID 223) in 66 ms on 172.18.0.5 (executor 0) (1/2)
26/01/12 02:29:55 INFO TaskSetManager: Finished task 0.0 in stage 117.0 (TID 222) in 31872 ms on 172.18.0.5 (executor 0) (2/2)
26/01/12 02:29:55 INFO TaskSchedulerImpl: Removed TaskSet 117.0, whose tasks have all completed, from pool 
26/01/12 02:29:55 INFO DAGScheduler: ResultStage 117 (parquet at <unknown>:0) finished in 31.892 s
26/01/12 02:29:55 INFO DAGScheduler: Job 117 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:29:55 INFO TaskSchedulerImpl: Killing all running tasks in stage 117: Stage finished
26/01/12 02:29:55 INFO DAGScheduler: Job 117 finished: parquet at <unknown>:0, took 31.899257 s
26/01/12 02:29:55 INFO FileFormatWriter: Start to commit write Job 5b727128-30fa-4f6a-88b7-58d6f4d83259.
26/01/12 02:29:55 INFO FileFormatWriter: Write Job 5b727128-30fa-4f6a-88b7-58d6f4d83259 committed. Elapsed time: 31 ms.
26/01/12 02:29:55 INFO FileFormatWriter: Finished processing stats for write job 5b727128-30fa-4f6a-88b7-58d6f4d83259.
Cargando: yellow_tripdata_2013-12.parquet en hdfs://hadoop-namenode:8020/data/nyc/raw/taxi-trips/2013...
26/01/12 02:29:56 INFO InMemoryFileIndex: It took 7 ms to list leaf files for 1 paths.
26/01/12 02:29:56 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 02:29:56 INFO DAGScheduler: Got job 118 (parquet at <unknown>:0) with 1 output partitions
26/01/12 02:29:56 INFO DAGScheduler: Final stage: ResultStage 118 (parquet at <unknown>:0)
26/01/12 02:29:56 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:29:56 INFO DAGScheduler: Missing parents: List()
26/01/12 02:29:56 INFO DAGScheduler: Submitting ResultStage 118 (MapPartitionsRDD[296] at parquet at <unknown>:0), which has no missing parents
26/01/12 02:29:56 INFO MemoryStore: Block broadcast_177 stored as values in memory (estimated size 102.6 KiB, free 363.2 MiB)
26/01/12 02:29:56 INFO MemoryStore: Block broadcast_177_piece0 stored as bytes in memory (estimated size 36.8 KiB, free 363.2 MiB)
26/01/12 02:29:56 INFO BlockManagerInfo: Added broadcast_177_piece0 in memory on 02926ee04bc9:45221 (size: 36.8 KiB, free: 365.8 MiB)
26/01/12 02:29:56 INFO SparkContext: Created broadcast 177 from broadcast at DAGScheduler.scala:1513
26/01/12 02:29:56 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 118 (MapPartitionsRDD[296] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0))
26/01/12 02:29:56 INFO TaskSchedulerImpl: Adding task set 118.0 with 1 tasks resource profile 0
26/01/12 02:29:56 INFO TaskSetManager: Starting task 0.0 in stage 118.0 (TID 224) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4607 bytes) taskResourceAssignments Map()
26/01/12 02:29:56 INFO BlockManagerInfo: Added broadcast_177_piece0 in memory on 172.18.0.5:42453 (size: 36.8 KiB, free: 365.8 MiB)
26/01/12 02:29:56 INFO TaskSetManager: Finished task 0.0 in stage 118.0 (TID 224) in 48 ms on 172.18.0.5 (executor 0) (1/1)
26/01/12 02:29:56 INFO TaskSchedulerImpl: Removed TaskSet 118.0, whose tasks have all completed, from pool 
26/01/12 02:29:56 INFO DAGScheduler: ResultStage 118 (parquet at <unknown>:0) finished in 0.061 s
26/01/12 02:29:56 INFO DAGScheduler: Job 118 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:29:56 INFO TaskSchedulerImpl: Killing all running tasks in stage 118: Stage finished
26/01/12 02:29:56 INFO DAGScheduler: Job 118 finished: parquet at <unknown>:0, took 0.065267 s
26/01/12 02:29:56 INFO FileSourceStrategy: Pushed Filters: 
26/01/12 02:29:56 INFO FileSourceStrategy: Post-Scan Filters: 
26/01/12 02:29:56 INFO FileSourceStrategy: Output Data Schema: struct<VendorID: bigint, tpep_pickup_datetime: timestamp, tpep_dropoff_datetime: timestamp, passenger_count: bigint, trip_distance: double ... 17 more fields>
26/01/12 02:29:56 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:29:56 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:29:56 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:29:56 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:29:56 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:29:56 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:29:56 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:29:56 INFO MemoryStore: Block broadcast_178 stored as values in memory (estimated size 358.4 KiB, free 362.8 MiB)
26/01/12 02:29:56 INFO MemoryStore: Block broadcast_178_piece0 stored as bytes in memory (estimated size 35.4 KiB, free 362.8 MiB)
26/01/12 02:29:56 INFO BlockManagerInfo: Added broadcast_178_piece0 in memory on 02926ee04bc9:45221 (size: 35.4 KiB, free: 365.7 MiB)
26/01/12 02:29:56 INFO SparkContext: Created broadcast 178 from parquet at <unknown>:0
26/01/12 02:29:56 INFO FileSourceScanExec: Planning scan with bin packing, max size: 89542481 bytes, open cost is considered as scanning 4194304 bytes.
26/01/12 02:29:56 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 02:29:56 INFO DAGScheduler: Got job 119 (parquet at <unknown>:0) with 2 output partitions
26/01/12 02:29:56 INFO DAGScheduler: Final stage: ResultStage 119 (parquet at <unknown>:0)
26/01/12 02:29:56 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:29:56 INFO DAGScheduler: Missing parents: List()
26/01/12 02:29:56 INFO DAGScheduler: Submitting ResultStage 119 (MapPartitionsRDD[299] at parquet at <unknown>:0), which has no missing parents
26/01/12 02:29:56 INFO MemoryStore: Block broadcast_179 stored as values in memory (estimated size 225.1 KiB, free 362.6 MiB)
26/01/12 02:29:56 INFO MemoryStore: Block broadcast_179_piece0 stored as bytes in memory (estimated size 77.4 KiB, free 362.5 MiB)
26/01/12 02:29:56 INFO BlockManagerInfo: Added broadcast_179_piece0 in memory on 02926ee04bc9:45221 (size: 77.4 KiB, free: 365.6 MiB)
26/01/12 02:29:56 INFO SparkContext: Created broadcast 179 from broadcast at DAGScheduler.scala:1513
26/01/12 02:29:56 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 119 (MapPartitionsRDD[299] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1))
26/01/12 02:29:56 INFO TaskSchedulerImpl: Adding task set 119.0 with 2 tasks resource profile 0
26/01/12 02:29:56 INFO TaskSetManager: Starting task 0.0 in stage 119.0 (TID 225) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:29:56 INFO TaskSetManager: Starting task 1.0 in stage 119.0 (TID 226) (172.18.0.5, executor 0, partition 1, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:29:56 INFO BlockManagerInfo: Added broadcast_179_piece0 in memory on 172.18.0.5:42453 (size: 77.4 KiB, free: 365.7 MiB)
26/01/12 02:29:56 INFO BlockManagerInfo: Added broadcast_178_piece0 in memory on 172.18.0.5:42453 (size: 35.4 KiB, free: 365.6 MiB)
26/01/12 02:29:56 INFO TaskSetManager: Finished task 1.0 in stage 119.0 (TID 226) in 56 ms on 172.18.0.5 (executor 0) (1/2)
26/01/12 02:30:27 INFO TaskSetManager: Finished task 0.0 in stage 119.0 (TID 225) in 30845 ms on 172.18.0.5 (executor 0) (2/2)
26/01/12 02:30:27 INFO TaskSchedulerImpl: Removed TaskSet 119.0, whose tasks have all completed, from pool 
26/01/12 02:30:27 INFO DAGScheduler: ResultStage 119 (parquet at <unknown>:0) finished in 30.868 s
26/01/12 02:30:27 INFO DAGScheduler: Job 119 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:30:27 INFO TaskSchedulerImpl: Killing all running tasks in stage 119: Stage finished
26/01/12 02:30:27 INFO DAGScheduler: Job 119 finished: parquet at <unknown>:0, took 30.875386 s
26/01/12 02:30:27 INFO FileFormatWriter: Start to commit write Job c05b6e36-d5f5-479e-92a2-eb7466d89721.
26/01/12 02:30:27 INFO FileFormatWriter: Write Job c05b6e36-d5f5-479e-92a2-eb7466d89721 committed. Elapsed time: 36 ms.
26/01/12 02:30:27 INFO FileFormatWriter: Finished processing stats for write job c05b6e36-d5f5-479e-92a2-eb7466d89721.
Cargando: yellow_tripdata_2014-01.parquet en hdfs://hadoop-namenode:8020/data/nyc/raw/taxi-trips/2014...
26/01/12 02:30:27 INFO InMemoryFileIndex: It took 9 ms to list leaf files for 1 paths.
26/01/12 02:30:27 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 02:30:27 INFO DAGScheduler: Got job 120 (parquet at <unknown>:0) with 1 output partitions
26/01/12 02:30:27 INFO DAGScheduler: Final stage: ResultStage 120 (parquet at <unknown>:0)
26/01/12 02:30:27 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:30:27 INFO DAGScheduler: Missing parents: List()
26/01/12 02:30:27 INFO DAGScheduler: Submitting ResultStage 120 (MapPartitionsRDD[301] at parquet at <unknown>:0), which has no missing parents
26/01/12 02:30:27 INFO MemoryStore: Block broadcast_180 stored as values in memory (estimated size 102.6 KiB, free 362.4 MiB)
26/01/12 02:30:27 INFO MemoryStore: Block broadcast_180_piece0 stored as bytes in memory (estimated size 36.8 KiB, free 362.4 MiB)
26/01/12 02:30:27 INFO BlockManagerInfo: Added broadcast_180_piece0 in memory on 02926ee04bc9:45221 (size: 36.8 KiB, free: 365.6 MiB)
26/01/12 02:30:27 INFO SparkContext: Created broadcast 180 from broadcast at DAGScheduler.scala:1513
26/01/12 02:30:27 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 120 (MapPartitionsRDD[301] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0))
26/01/12 02:30:27 INFO TaskSchedulerImpl: Adding task set 120.0 with 1 tasks resource profile 0
26/01/12 02:30:27 INFO TaskSetManager: Starting task 0.0 in stage 120.0 (TID 227) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4607 bytes) taskResourceAssignments Map()
26/01/12 02:30:27 INFO BlockManagerInfo: Added broadcast_180_piece0 in memory on 172.18.0.5:42453 (size: 36.8 KiB, free: 365.6 MiB)
26/01/12 02:30:27 INFO TaskSetManager: Finished task 0.0 in stage 120.0 (TID 227) in 56 ms on 172.18.0.5 (executor 0) (1/1)
26/01/12 02:30:27 INFO TaskSchedulerImpl: Removed TaskSet 120.0, whose tasks have all completed, from pool 
26/01/12 02:30:27 INFO DAGScheduler: ResultStage 120 (parquet at <unknown>:0) finished in 0.069 s
26/01/12 02:30:27 INFO DAGScheduler: Job 120 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:30:27 INFO TaskSchedulerImpl: Killing all running tasks in stage 120: Stage finished
26/01/12 02:30:27 INFO DAGScheduler: Job 120 finished: parquet at <unknown>:0, took 0.073377 s
26/01/12 02:30:27 INFO FileSourceStrategy: Pushed Filters: 
26/01/12 02:30:27 INFO FileSourceStrategy: Post-Scan Filters: 
26/01/12 02:30:27 INFO FileSourceStrategy: Output Data Schema: struct<VendorID: bigint, tpep_pickup_datetime: timestamp, tpep_dropoff_datetime: timestamp, passenger_count: bigint, trip_distance: double ... 17 more fields>
26/01/12 02:30:27 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:30:27 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:30:27 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:30:27 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:30:27 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:30:27 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:30:27 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:30:27 INFO MemoryStore: Block broadcast_181 stored as values in memory (estimated size 358.4 KiB, free 362.0 MiB)
26/01/12 02:30:27 INFO MemoryStore: Block broadcast_181_piece0 stored as bytes in memory (estimated size 35.4 KiB, free 362.0 MiB)
26/01/12 02:30:27 INFO BlockManagerInfo: Added broadcast_181_piece0 in memory on 02926ee04bc9:45221 (size: 35.4 KiB, free: 365.6 MiB)
26/01/12 02:30:27 INFO SparkContext: Created broadcast 181 from parquet at <unknown>:0
26/01/12 02:30:27 INFO FileSourceScanExec: Planning scan with bin packing, max size: 88088201 bytes, open cost is considered as scanning 4194304 bytes.
26/01/12 02:30:27 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 02:30:27 INFO DAGScheduler: Got job 121 (parquet at <unknown>:0) with 2 output partitions
26/01/12 02:30:27 INFO DAGScheduler: Final stage: ResultStage 121 (parquet at <unknown>:0)
26/01/12 02:30:27 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:30:27 INFO DAGScheduler: Missing parents: List()
26/01/12 02:30:27 INFO DAGScheduler: Submitting ResultStage 121 (MapPartitionsRDD[304] at parquet at <unknown>:0), which has no missing parents
26/01/12 02:30:27 INFO MemoryStore: Block broadcast_182 stored as values in memory (estimated size 225.1 KiB, free 361.8 MiB)
26/01/12 02:30:27 INFO MemoryStore: Block broadcast_182_piece0 stored as bytes in memory (estimated size 77.4 KiB, free 361.7 MiB)
26/01/12 02:30:27 INFO BlockManagerInfo: Added broadcast_182_piece0 in memory on 02926ee04bc9:45221 (size: 77.4 KiB, free: 365.5 MiB)
26/01/12 02:30:27 INFO SparkContext: Created broadcast 182 from broadcast at DAGScheduler.scala:1513
26/01/12 02:30:27 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 121 (MapPartitionsRDD[304] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1))
26/01/12 02:30:27 INFO TaskSchedulerImpl: Adding task set 121.0 with 2 tasks resource profile 0
26/01/12 02:30:27 INFO TaskSetManager: Starting task 0.0 in stage 121.0 (TID 228) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:30:27 INFO TaskSetManager: Starting task 1.0 in stage 121.0 (TID 229) (172.18.0.5, executor 0, partition 1, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:30:27 INFO BlockManagerInfo: Added broadcast_182_piece0 in memory on 172.18.0.5:42453 (size: 77.4 KiB, free: 365.5 MiB)
26/01/12 02:30:27 INFO BlockManagerInfo: Added broadcast_181_piece0 in memory on 172.18.0.5:42453 (size: 35.4 KiB, free: 365.5 MiB)
26/01/12 02:30:27 INFO TaskSetManager: Finished task 1.0 in stage 121.0 (TID 229) in 61 ms on 172.18.0.5 (executor 0) (1/2)
26/01/12 02:30:57 INFO TaskSetManager: Finished task 0.0 in stage 121.0 (TID 228) in 29988 ms on 172.18.0.5 (executor 0) (2/2)
26/01/12 02:30:57 INFO TaskSchedulerImpl: Removed TaskSet 121.0, whose tasks have all completed, from pool 
26/01/12 02:30:57 INFO DAGScheduler: ResultStage 121 (parquet at <unknown>:0) finished in 30.009 s
26/01/12 02:30:57 INFO DAGScheduler: Job 121 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:30:57 INFO TaskSchedulerImpl: Killing all running tasks in stage 121: Stage finished
26/01/12 02:30:57 INFO DAGScheduler: Job 121 finished: parquet at <unknown>:0, took 30.016486 s
26/01/12 02:30:57 INFO FileFormatWriter: Start to commit write Job 4c6c2a48-2f82-4fff-9fb0-1e57d0961a47.
26/01/12 02:30:57 INFO FileFormatWriter: Write Job 4c6c2a48-2f82-4fff-9fb0-1e57d0961a47 committed. Elapsed time: 30 ms.
26/01/12 02:30:57 INFO FileFormatWriter: Finished processing stats for write job 4c6c2a48-2f82-4fff-9fb0-1e57d0961a47.
Cargando: yellow_tripdata_2014-02.parquet en hdfs://hadoop-namenode:8020/data/nyc/raw/taxi-trips/2014...
26/01/12 02:30:57 INFO InMemoryFileIndex: It took 6 ms to list leaf files for 1 paths.
26/01/12 02:30:57 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 02:30:57 INFO DAGScheduler: Got job 122 (parquet at <unknown>:0) with 1 output partitions
26/01/12 02:30:57 INFO DAGScheduler: Final stage: ResultStage 122 (parquet at <unknown>:0)
26/01/12 02:30:57 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:30:57 INFO DAGScheduler: Missing parents: List()
26/01/12 02:30:57 INFO DAGScheduler: Submitting ResultStage 122 (MapPartitionsRDD[306] at parquet at <unknown>:0), which has no missing parents
26/01/12 02:30:57 INFO MemoryStore: Block broadcast_183 stored as values in memory (estimated size 102.6 KiB, free 361.6 MiB)
26/01/12 02:30:57 INFO MemoryStore: Block broadcast_183_piece0 stored as bytes in memory (estimated size 36.8 KiB, free 361.5 MiB)
26/01/12 02:30:57 INFO BlockManagerInfo: Added broadcast_183_piece0 in memory on 02926ee04bc9:45221 (size: 36.8 KiB, free: 365.5 MiB)
26/01/12 02:30:57 INFO SparkContext: Created broadcast 183 from broadcast at DAGScheduler.scala:1513
26/01/12 02:30:57 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 122 (MapPartitionsRDD[306] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0))
26/01/12 02:30:57 INFO TaskSchedulerImpl: Adding task set 122.0 with 1 tasks resource profile 0
26/01/12 02:30:57 INFO TaskSetManager: Starting task 0.0 in stage 122.0 (TID 230) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4607 bytes) taskResourceAssignments Map()
26/01/12 02:30:57 INFO BlockManagerInfo: Added broadcast_183_piece0 in memory on 172.18.0.5:42453 (size: 36.8 KiB, free: 365.5 MiB)
26/01/12 02:30:57 INFO TaskSetManager: Finished task 0.0 in stage 122.0 (TID 230) in 47 ms on 172.18.0.5 (executor 0) (1/1)
26/01/12 02:30:57 INFO TaskSchedulerImpl: Removed TaskSet 122.0, whose tasks have all completed, from pool 
26/01/12 02:30:57 INFO DAGScheduler: ResultStage 122 (parquet at <unknown>:0) finished in 0.059 s
26/01/12 02:30:57 INFO DAGScheduler: Job 122 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:30:57 INFO TaskSchedulerImpl: Killing all running tasks in stage 122: Stage finished
26/01/12 02:30:57 INFO DAGScheduler: Job 122 finished: parquet at <unknown>:0, took 0.063270 s
26/01/12 02:30:57 INFO FileSourceStrategy: Pushed Filters: 
26/01/12 02:30:57 INFO FileSourceStrategy: Post-Scan Filters: 
26/01/12 02:30:57 INFO FileSourceStrategy: Output Data Schema: struct<VendorID: bigint, tpep_pickup_datetime: timestamp, tpep_dropoff_datetime: timestamp, passenger_count: bigint, trip_distance: double ... 17 more fields>
26/01/12 02:30:57 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:30:57 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:30:57 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:30:57 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:30:57 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:30:57 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:30:57 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:30:57 INFO MemoryStore: Block broadcast_184 stored as values in memory (estimated size 358.4 KiB, free 361.2 MiB)
26/01/12 02:30:57 INFO MemoryStore: Block broadcast_184_piece0 stored as bytes in memory (estimated size 35.4 KiB, free 361.2 MiB)
26/01/12 02:30:57 INFO BlockManagerInfo: Added broadcast_184_piece0 in memory on 02926ee04bc9:45221 (size: 35.4 KiB, free: 365.4 MiB)
26/01/12 02:30:57 INFO SparkContext: Created broadcast 184 from parquet at <unknown>:0
26/01/12 02:30:57 INFO FileSourceScanExec: Planning scan with bin packing, max size: 83198325 bytes, open cost is considered as scanning 4194304 bytes.
26/01/12 02:30:57 INFO BlockManagerInfo: Removed broadcast_176_piece0 on 02926ee04bc9:45221 in memory (size: 77.4 KiB, free: 365.5 MiB)
26/01/12 02:30:57 INFO BlockManagerInfo: Removed broadcast_176_piece0 on 172.18.0.5:42453 in memory (size: 77.4 KiB, free: 365.5 MiB)
26/01/12 02:30:57 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 02:30:57 INFO BlockManagerInfo: Removed broadcast_183_piece0 on 02926ee04bc9:45221 in memory (size: 36.8 KiB, free: 365.5 MiB)
26/01/12 02:30:57 INFO DAGScheduler: Got job 123 (parquet at <unknown>:0) with 2 output partitions
26/01/12 02:30:57 INFO DAGScheduler: Final stage: ResultStage 123 (parquet at <unknown>:0)
26/01/12 02:30:57 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:30:57 INFO BlockManagerInfo: Removed broadcast_183_piece0 on 172.18.0.5:42453 in memory (size: 36.8 KiB, free: 365.6 MiB)
26/01/12 02:30:57 INFO DAGScheduler: Missing parents: List()
26/01/12 02:30:57 INFO DAGScheduler: Submitting ResultStage 123 (MapPartitionsRDD[309] at parquet at <unknown>:0), which has no missing parents
26/01/12 02:30:57 INFO BlockManagerInfo: Removed broadcast_170_piece0 on 02926ee04bc9:45221 in memory (size: 77.4 KiB, free: 365.6 MiB)
26/01/12 02:30:57 INFO BlockManagerInfo: Removed broadcast_170_piece0 on 172.18.0.5:42453 in memory (size: 77.4 KiB, free: 365.6 MiB)
26/01/12 02:30:57 INFO BlockManagerInfo: Removed broadcast_172_piece0 on 02926ee04bc9:45221 in memory (size: 35.4 KiB, free: 365.6 MiB)
26/01/12 02:30:57 INFO BlockManagerInfo: Removed broadcast_172_piece0 on 172.18.0.5:42453 in memory (size: 35.4 KiB, free: 365.7 MiB)
26/01/12 02:30:57 INFO MemoryStore: Block broadcast_185 stored as values in memory (estimated size 225.1 KiB, free 362.0 MiB)
26/01/12 02:30:57 INFO BlockManagerInfo: Removed broadcast_171_piece0 on 02926ee04bc9:45221 in memory (size: 36.8 KiB, free: 365.7 MiB)
26/01/12 02:30:57 INFO BlockManagerInfo: Removed broadcast_171_piece0 on 172.18.0.5:42453 in memory (size: 36.8 KiB, free: 365.7 MiB)
26/01/12 02:30:57 INFO MemoryStore: Block broadcast_185_piece0 stored as bytes in memory (estimated size 77.4 KiB, free 362.1 MiB)
26/01/12 02:30:57 INFO BlockManagerInfo: Added broadcast_185_piece0 in memory on 02926ee04bc9:45221 (size: 77.4 KiB, free: 365.6 MiB)
26/01/12 02:30:57 INFO SparkContext: Created broadcast 185 from broadcast at DAGScheduler.scala:1513
26/01/12 02:30:57 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 123 (MapPartitionsRDD[309] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1))
26/01/12 02:30:57 INFO TaskSchedulerImpl: Adding task set 123.0 with 2 tasks resource profile 0
26/01/12 02:30:57 INFO TaskSetManager: Starting task 0.0 in stage 123.0 (TID 231) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:30:57 INFO BlockManagerInfo: Removed broadcast_181_piece0 on 02926ee04bc9:45221 in memory (size: 35.4 KiB, free: 365.6 MiB)
26/01/12 02:30:57 INFO TaskSetManager: Starting task 1.0 in stage 123.0 (TID 232) (172.18.0.5, executor 0, partition 1, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:30:57 INFO BlockManagerInfo: Removed broadcast_181_piece0 on 172.18.0.5:42453 in memory (size: 35.4 KiB, free: 365.8 MiB)
26/01/12 02:30:57 INFO BlockManagerInfo: Removed broadcast_174_piece0 on 02926ee04bc9:45221 in memory (size: 36.8 KiB, free: 365.7 MiB)
26/01/12 02:30:57 INFO BlockManagerInfo: Removed broadcast_174_piece0 on 172.18.0.5:42453 in memory (size: 36.8 KiB, free: 365.8 MiB)
26/01/12 02:30:57 INFO BlockManagerInfo: Added broadcast_185_piece0 in memory on 172.18.0.5:42453 (size: 77.4 KiB, free: 365.7 MiB)
26/01/12 02:30:57 INFO BlockManagerInfo: Removed broadcast_178_piece0 on 02926ee04bc9:45221 in memory (size: 35.4 KiB, free: 365.7 MiB)
26/01/12 02:30:57 INFO BlockManagerInfo: Removed broadcast_178_piece0 on 172.18.0.5:42453 in memory (size: 35.4 KiB, free: 365.7 MiB)
26/01/12 02:30:57 INFO BlockManagerInfo: Removed broadcast_180_piece0 on 02926ee04bc9:45221 in memory (size: 36.8 KiB, free: 365.7 MiB)
26/01/12 02:30:57 INFO BlockManagerInfo: Removed broadcast_180_piece0 on 172.18.0.5:42453 in memory (size: 36.8 KiB, free: 365.8 MiB)
26/01/12 02:30:57 INFO BlockManagerInfo: Removed broadcast_182_piece0 on 02926ee04bc9:45221 in memory (size: 77.4 KiB, free: 365.8 MiB)
26/01/12 02:30:57 INFO BlockManagerInfo: Removed broadcast_182_piece0 on 172.18.0.5:42453 in memory (size: 77.4 KiB, free: 365.9 MiB)
26/01/12 02:30:57 INFO BlockManagerInfo: Added broadcast_184_piece0 in memory on 172.18.0.5:42453 (size: 35.4 KiB, free: 365.8 MiB)
26/01/12 02:30:57 INFO BlockManagerInfo: Removed broadcast_169_piece0 on 02926ee04bc9:45221 in memory (size: 35.4 KiB, free: 365.9 MiB)
26/01/12 02:30:57 INFO BlockManagerInfo: Removed broadcast_169_piece0 on 172.18.0.5:42453 in memory (size: 35.4 KiB, free: 365.9 MiB)
26/01/12 02:30:57 INFO BlockManagerInfo: Removed broadcast_173_piece0 on 02926ee04bc9:45221 in memory (size: 77.4 KiB, free: 365.9 MiB)
26/01/12 02:30:57 INFO BlockManagerInfo: Removed broadcast_173_piece0 on 172.18.0.5:42453 in memory (size: 77.4 KiB, free: 365.9 MiB)
26/01/12 02:30:57 INFO BlockManagerInfo: Removed broadcast_177_piece0 on 02926ee04bc9:45221 in memory (size: 36.8 KiB, free: 366.0 MiB)
26/01/12 02:30:57 INFO BlockManagerInfo: Removed broadcast_177_piece0 on 172.18.0.5:42453 in memory (size: 36.8 KiB, free: 366.0 MiB)
26/01/12 02:30:57 INFO BlockManagerInfo: Removed broadcast_179_piece0 on 02926ee04bc9:45221 in memory (size: 77.4 KiB, free: 366.0 MiB)
26/01/12 02:30:57 INFO BlockManagerInfo: Removed broadcast_179_piece0 on 172.18.0.5:42453 in memory (size: 77.4 KiB, free: 366.0 MiB)
26/01/12 02:30:57 INFO BlockManagerInfo: Removed broadcast_175_piece0 on 02926ee04bc9:45221 in memory (size: 35.4 KiB, free: 366.1 MiB)
26/01/12 02:30:57 INFO BlockManagerInfo: Removed broadcast_175_piece0 on 172.18.0.5:42453 in memory (size: 35.4 KiB, free: 366.1 MiB)
26/01/12 02:30:57 INFO TaskSetManager: Finished task 1.0 in stage 123.0 (TID 232) in 77 ms on 172.18.0.5 (executor 0) (1/2)
26/01/12 02:31:26 INFO TaskSetManager: Finished task 0.0 in stage 123.0 (TID 231) in 29231 ms on 172.18.0.5 (executor 0) (2/2)
26/01/12 02:31:26 INFO TaskSchedulerImpl: Removed TaskSet 123.0, whose tasks have all completed, from pool 
26/01/12 02:31:26 INFO DAGScheduler: ResultStage 123 (parquet at <unknown>:0) finished in 29.256 s
26/01/12 02:31:26 INFO DAGScheduler: Job 123 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:31:26 INFO TaskSchedulerImpl: Killing all running tasks in stage 123: Stage finished
26/01/12 02:31:26 INFO DAGScheduler: Job 123 finished: parquet at <unknown>:0, took 29.266749 s
26/01/12 02:31:26 INFO FileFormatWriter: Start to commit write Job 19d36f7e-23d0-4907-947d-f48829886e81.
26/01/12 02:31:26 INFO FileFormatWriter: Write Job 19d36f7e-23d0-4907-947d-f48829886e81 committed. Elapsed time: 34 ms.
26/01/12 02:31:26 INFO FileFormatWriter: Finished processing stats for write job 19d36f7e-23d0-4907-947d-f48829886e81.
Cargando: yellow_tripdata_2014-03.parquet en hdfs://hadoop-namenode:8020/data/nyc/raw/taxi-trips/2014...
26/01/12 02:31:26 INFO InMemoryFileIndex: It took 7 ms to list leaf files for 1 paths.
26/01/12 02:31:26 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 02:31:26 INFO DAGScheduler: Got job 124 (parquet at <unknown>:0) with 1 output partitions
26/01/12 02:31:26 INFO DAGScheduler: Final stage: ResultStage 124 (parquet at <unknown>:0)
26/01/12 02:31:26 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:31:26 INFO DAGScheduler: Missing parents: List()
26/01/12 02:31:26 INFO DAGScheduler: Submitting ResultStage 124 (MapPartitionsRDD[311] at parquet at <unknown>:0), which has no missing parents
26/01/12 02:31:26 INFO MemoryStore: Block broadcast_186 stored as values in memory (estimated size 102.6 KiB, free 364.8 MiB)
26/01/12 02:31:26 INFO MemoryStore: Block broadcast_186_piece0 stored as bytes in memory (estimated size 36.8 KiB, free 364.8 MiB)
26/01/12 02:31:26 INFO BlockManagerInfo: Added broadcast_186_piece0 in memory on 02926ee04bc9:45221 (size: 36.8 KiB, free: 366.0 MiB)
26/01/12 02:31:26 INFO SparkContext: Created broadcast 186 from broadcast at DAGScheduler.scala:1513
26/01/12 02:31:26 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 124 (MapPartitionsRDD[311] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0))
26/01/12 02:31:26 INFO TaskSchedulerImpl: Adding task set 124.0 with 1 tasks resource profile 0
26/01/12 02:31:26 INFO TaskSetManager: Starting task 0.0 in stage 124.0 (TID 233) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4607 bytes) taskResourceAssignments Map()
26/01/12 02:31:26 INFO BlockManagerInfo: Added broadcast_186_piece0 in memory on 172.18.0.5:42453 (size: 36.8 KiB, free: 366.0 MiB)
26/01/12 02:31:26 INFO TaskSetManager: Finished task 0.0 in stage 124.0 (TID 233) in 48 ms on 172.18.0.5 (executor 0) (1/1)
26/01/12 02:31:26 INFO TaskSchedulerImpl: Removed TaskSet 124.0, whose tasks have all completed, from pool 
26/01/12 02:31:26 INFO DAGScheduler: ResultStage 124 (parquet at <unknown>:0) finished in 0.060 s
26/01/12 02:31:26 INFO DAGScheduler: Job 124 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:31:26 INFO TaskSchedulerImpl: Killing all running tasks in stage 124: Stage finished
26/01/12 02:31:26 INFO DAGScheduler: Job 124 finished: parquet at <unknown>:0, took 0.065052 s
26/01/12 02:31:26 INFO FileSourceStrategy: Pushed Filters: 
26/01/12 02:31:26 INFO FileSourceStrategy: Post-Scan Filters: 
26/01/12 02:31:26 INFO FileSourceStrategy: Output Data Schema: struct<VendorID: bigint, tpep_pickup_datetime: timestamp, tpep_dropoff_datetime: timestamp, passenger_count: bigint, trip_distance: double ... 17 more fields>
26/01/12 02:31:26 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:31:26 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:31:26 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:31:26 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:31:26 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:31:26 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:31:26 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:31:26 INFO MemoryStore: Block broadcast_187 stored as values in memory (estimated size 358.4 KiB, free 364.5 MiB)
26/01/12 02:31:26 INFO MemoryStore: Block broadcast_187_piece0 stored as bytes in memory (estimated size 35.4 KiB, free 364.4 MiB)
26/01/12 02:31:26 INFO BlockManagerInfo: Added broadcast_187_piece0 in memory on 02926ee04bc9:45221 (size: 35.4 KiB, free: 366.0 MiB)
26/01/12 02:31:26 INFO SparkContext: Created broadcast 187 from parquet at <unknown>:0
26/01/12 02:31:26 INFO FileSourceScanExec: Planning scan with bin packing, max size: 98314498 bytes, open cost is considered as scanning 4194304 bytes.
26/01/12 02:31:26 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 02:31:26 INFO DAGScheduler: Got job 125 (parquet at <unknown>:0) with 2 output partitions
26/01/12 02:31:26 INFO DAGScheduler: Final stage: ResultStage 125 (parquet at <unknown>:0)
26/01/12 02:31:26 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:31:26 INFO DAGScheduler: Missing parents: List()
26/01/12 02:31:26 INFO DAGScheduler: Submitting ResultStage 125 (MapPartitionsRDD[314] at parquet at <unknown>:0), which has no missing parents
26/01/12 02:31:26 INFO MemoryStore: Block broadcast_188 stored as values in memory (estimated size 225.1 KiB, free 364.2 MiB)
26/01/12 02:31:26 INFO MemoryStore: Block broadcast_188_piece0 stored as bytes in memory (estimated size 77.4 KiB, free 364.1 MiB)
26/01/12 02:31:26 INFO BlockManagerInfo: Added broadcast_188_piece0 in memory on 02926ee04bc9:45221 (size: 77.4 KiB, free: 365.9 MiB)
26/01/12 02:31:26 INFO SparkContext: Created broadcast 188 from broadcast at DAGScheduler.scala:1513
26/01/12 02:31:26 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 125 (MapPartitionsRDD[314] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1))
26/01/12 02:31:26 INFO TaskSchedulerImpl: Adding task set 125.0 with 2 tasks resource profile 0
26/01/12 02:31:26 INFO TaskSetManager: Starting task 0.0 in stage 125.0 (TID 234) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:31:26 INFO TaskSetManager: Starting task 1.0 in stage 125.0 (TID 235) (172.18.0.5, executor 0, partition 1, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:31:27 INFO BlockManagerInfo: Added broadcast_188_piece0 in memory on 172.18.0.5:42453 (size: 77.4 KiB, free: 366.0 MiB)
26/01/12 02:31:27 INFO BlockManagerInfo: Added broadcast_187_piece0 in memory on 172.18.0.5:42453 (size: 35.4 KiB, free: 365.9 MiB)
26/01/12 02:31:27 INFO TaskSetManager: Finished task 1.0 in stage 125.0 (TID 235) in 59 ms on 172.18.0.5 (executor 0) (1/2)
26/01/12 02:32:00 INFO TaskSetManager: Finished task 0.0 in stage 125.0 (TID 234) in 33240 ms on 172.18.0.5 (executor 0) (2/2)
26/01/12 02:32:00 INFO TaskSchedulerImpl: Removed TaskSet 125.0, whose tasks have all completed, from pool 
26/01/12 02:32:00 INFO DAGScheduler: ResultStage 125 (parquet at <unknown>:0) finished in 33.262 s
26/01/12 02:32:00 INFO DAGScheduler: Job 125 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:32:00 INFO TaskSchedulerImpl: Killing all running tasks in stage 125: Stage finished
26/01/12 02:32:00 INFO DAGScheduler: Job 125 finished: parquet at <unknown>:0, took 33.271807 s
26/01/12 02:32:00 INFO FileFormatWriter: Start to commit write Job 8c3b0074-2fcd-4b3f-93eb-a80c07d0f733.
26/01/12 02:32:00 INFO FileFormatWriter: Write Job 8c3b0074-2fcd-4b3f-93eb-a80c07d0f733 committed. Elapsed time: 35 ms.
26/01/12 02:32:00 INFO FileFormatWriter: Finished processing stats for write job 8c3b0074-2fcd-4b3f-93eb-a80c07d0f733.
Cargando: yellow_tripdata_2014-04.parquet en hdfs://hadoop-namenode:8020/data/nyc/raw/taxi-trips/2014...
26/01/12 02:32:00 INFO InMemoryFileIndex: It took 8 ms to list leaf files for 1 paths.
26/01/12 02:32:00 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 02:32:00 INFO DAGScheduler: Got job 126 (parquet at <unknown>:0) with 1 output partitions
26/01/12 02:32:00 INFO DAGScheduler: Final stage: ResultStage 126 (parquet at <unknown>:0)
26/01/12 02:32:00 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:32:00 INFO DAGScheduler: Missing parents: List()
26/01/12 02:32:00 INFO DAGScheduler: Submitting ResultStage 126 (MapPartitionsRDD[316] at parquet at <unknown>:0), which has no missing parents
26/01/12 02:32:00 INFO MemoryStore: Block broadcast_189 stored as values in memory (estimated size 102.6 KiB, free 364.0 MiB)
26/01/12 02:32:00 INFO MemoryStore: Block broadcast_189_piece0 stored as bytes in memory (estimated size 36.8 KiB, free 364.0 MiB)
26/01/12 02:32:00 INFO BlockManagerInfo: Added broadcast_189_piece0 in memory on 02926ee04bc9:45221 (size: 36.8 KiB, free: 365.9 MiB)
26/01/12 02:32:00 INFO SparkContext: Created broadcast 189 from broadcast at DAGScheduler.scala:1513
26/01/12 02:32:00 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 126 (MapPartitionsRDD[316] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0))
26/01/12 02:32:00 INFO TaskSchedulerImpl: Adding task set 126.0 with 1 tasks resource profile 0
26/01/12 02:32:00 INFO TaskSetManager: Starting task 0.0 in stage 126.0 (TID 236) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4607 bytes) taskResourceAssignments Map()
26/01/12 02:32:00 INFO BlockManagerInfo: Added broadcast_189_piece0 in memory on 172.18.0.5:42453 (size: 36.8 KiB, free: 365.9 MiB)
26/01/12 02:32:00 INFO TaskSetManager: Finished task 0.0 in stage 126.0 (TID 236) in 54 ms on 172.18.0.5 (executor 0) (1/1)
26/01/12 02:32:00 INFO TaskSchedulerImpl: Removed TaskSet 126.0, whose tasks have all completed, from pool 
26/01/12 02:32:00 INFO DAGScheduler: ResultStage 126 (parquet at <unknown>:0) finished in 0.066 s
26/01/12 02:32:00 INFO DAGScheduler: Job 126 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:32:00 INFO TaskSchedulerImpl: Killing all running tasks in stage 126: Stage finished
26/01/12 02:32:00 INFO DAGScheduler: Job 126 finished: parquet at <unknown>:0, took 0.072132 s
26/01/12 02:32:00 INFO FileSourceStrategy: Pushed Filters: 
26/01/12 02:32:00 INFO FileSourceStrategy: Post-Scan Filters: 
26/01/12 02:32:00 INFO FileSourceStrategy: Output Data Schema: struct<VendorID: bigint, tpep_pickup_datetime: timestamp, tpep_dropoff_datetime: timestamp, passenger_count: bigint, trip_distance: double ... 17 more fields>
26/01/12 02:32:00 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:32:00 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:32:00 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:32:00 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:32:00 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:32:00 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:32:00 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:32:00 INFO MemoryStore: Block broadcast_190 stored as values in memory (estimated size 358.4 KiB, free 363.6 MiB)
26/01/12 02:32:00 INFO MemoryStore: Block broadcast_190_piece0 stored as bytes in memory (estimated size 35.4 KiB, free 363.6 MiB)
26/01/12 02:32:00 INFO BlockManagerInfo: Added broadcast_190_piece0 in memory on 02926ee04bc9:45221 (size: 35.4 KiB, free: 365.9 MiB)
26/01/12 02:32:00 INFO SparkContext: Created broadcast 190 from parquet at <unknown>:0
26/01/12 02:32:00 INFO FileSourceScanExec: Planning scan with bin packing, max size: 93694660 bytes, open cost is considered as scanning 4194304 bytes.
26/01/12 02:32:00 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 02:32:00 INFO DAGScheduler: Got job 127 (parquet at <unknown>:0) with 2 output partitions
26/01/12 02:32:00 INFO DAGScheduler: Final stage: ResultStage 127 (parquet at <unknown>:0)
26/01/12 02:32:00 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:32:00 INFO DAGScheduler: Missing parents: List()
26/01/12 02:32:00 INFO DAGScheduler: Submitting ResultStage 127 (MapPartitionsRDD[319] at parquet at <unknown>:0), which has no missing parents
26/01/12 02:32:00 INFO MemoryStore: Block broadcast_191 stored as values in memory (estimated size 225.1 KiB, free 363.4 MiB)
26/01/12 02:32:00 INFO MemoryStore: Block broadcast_191_piece0 stored as bytes in memory (estimated size 77.4 KiB, free 363.3 MiB)
26/01/12 02:32:00 INFO BlockManagerInfo: Added broadcast_191_piece0 in memory on 02926ee04bc9:45221 (size: 77.4 KiB, free: 365.8 MiB)
26/01/12 02:32:00 INFO SparkContext: Created broadcast 191 from broadcast at DAGScheduler.scala:1513
26/01/12 02:32:00 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 127 (MapPartitionsRDD[319] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1))
26/01/12 02:32:00 INFO TaskSchedulerImpl: Adding task set 127.0 with 2 tasks resource profile 0
26/01/12 02:32:00 INFO TaskSetManager: Starting task 0.0 in stage 127.0 (TID 237) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:32:00 INFO TaskSetManager: Starting task 1.0 in stage 127.0 (TID 238) (172.18.0.5, executor 0, partition 1, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:32:00 INFO BlockManagerInfo: Added broadcast_191_piece0 in memory on 172.18.0.5:42453 (size: 77.4 KiB, free: 365.8 MiB)
26/01/12 02:32:00 INFO BlockManagerInfo: Added broadcast_190_piece0 in memory on 172.18.0.5:42453 (size: 35.4 KiB, free: 365.8 MiB)
26/01/12 02:32:00 INFO TaskSetManager: Finished task 1.0 in stage 127.0 (TID 238) in 60 ms on 172.18.0.5 (executor 0) (1/2)
26/01/12 02:32:33 INFO TaskSetManager: Finished task 0.0 in stage 127.0 (TID 237) in 32698 ms on 172.18.0.5 (executor 0) (2/2)
26/01/12 02:32:33 INFO TaskSchedulerImpl: Removed TaskSet 127.0, whose tasks have all completed, from pool 
26/01/12 02:32:33 INFO DAGScheduler: ResultStage 127 (parquet at <unknown>:0) finished in 32.721 s
26/01/12 02:32:33 INFO DAGScheduler: Job 127 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:32:33 INFO TaskSchedulerImpl: Killing all running tasks in stage 127: Stage finished
26/01/12 02:32:33 INFO DAGScheduler: Job 127 finished: parquet at <unknown>:0, took 32.729191 s
26/01/12 02:32:33 INFO FileFormatWriter: Start to commit write Job 6824f71e-5b3e-412e-9833-50a35797bf31.
26/01/12 02:32:33 INFO FileFormatWriter: Write Job 6824f71e-5b3e-412e-9833-50a35797bf31 committed. Elapsed time: 37 ms.
26/01/12 02:32:33 INFO FileFormatWriter: Finished processing stats for write job 6824f71e-5b3e-412e-9833-50a35797bf31.
Cargando: yellow_tripdata_2014-05.parquet en hdfs://hadoop-namenode:8020/data/nyc/raw/taxi-trips/2014...
26/01/12 02:32:33 INFO InMemoryFileIndex: It took 8 ms to list leaf files for 1 paths.
26/01/12 02:32:33 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 02:32:33 INFO DAGScheduler: Got job 128 (parquet at <unknown>:0) with 1 output partitions
26/01/12 02:32:33 INFO DAGScheduler: Final stage: ResultStage 128 (parquet at <unknown>:0)
26/01/12 02:32:33 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:32:33 INFO DAGScheduler: Missing parents: List()
26/01/12 02:32:33 INFO DAGScheduler: Submitting ResultStage 128 (MapPartitionsRDD[321] at parquet at <unknown>:0), which has no missing parents
26/01/12 02:32:33 INFO MemoryStore: Block broadcast_192 stored as values in memory (estimated size 102.6 KiB, free 363.2 MiB)
26/01/12 02:32:33 INFO MemoryStore: Block broadcast_192_piece0 stored as bytes in memory (estimated size 36.8 KiB, free 363.2 MiB)
26/01/12 02:32:33 INFO BlockManagerInfo: Added broadcast_192_piece0 in memory on 02926ee04bc9:45221 (size: 36.8 KiB, free: 365.8 MiB)
26/01/12 02:32:33 INFO SparkContext: Created broadcast 192 from broadcast at DAGScheduler.scala:1513
26/01/12 02:32:33 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 128 (MapPartitionsRDD[321] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0))
26/01/12 02:32:33 INFO TaskSchedulerImpl: Adding task set 128.0 with 1 tasks resource profile 0
26/01/12 02:32:33 INFO TaskSetManager: Starting task 0.0 in stage 128.0 (TID 239) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4607 bytes) taskResourceAssignments Map()
26/01/12 02:32:33 INFO BlockManagerInfo: Added broadcast_192_piece0 in memory on 172.18.0.5:42453 (size: 36.8 KiB, free: 365.8 MiB)
26/01/12 02:32:33 INFO TaskSetManager: Finished task 0.0 in stage 128.0 (TID 239) in 51 ms on 172.18.0.5 (executor 0) (1/1)
26/01/12 02:32:33 INFO TaskSchedulerImpl: Removed TaskSet 128.0, whose tasks have all completed, from pool 
26/01/12 02:32:33 INFO DAGScheduler: ResultStage 128 (parquet at <unknown>:0) finished in 0.067 s
26/01/12 02:32:33 INFO DAGScheduler: Job 128 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:32:33 INFO TaskSchedulerImpl: Killing all running tasks in stage 128: Stage finished
26/01/12 02:32:33 INFO DAGScheduler: Job 128 finished: parquet at <unknown>:0, took 0.071783 s
26/01/12 02:32:33 INFO FileSourceStrategy: Pushed Filters: 
26/01/12 02:32:33 INFO FileSourceStrategy: Post-Scan Filters: 
26/01/12 02:32:33 INFO FileSourceStrategy: Output Data Schema: struct<VendorID: bigint, tpep_pickup_datetime: timestamp, tpep_dropoff_datetime: timestamp, passenger_count: bigint, trip_distance: double ... 17 more fields>
26/01/12 02:32:33 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:32:33 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:32:33 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:32:33 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:32:33 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:32:33 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:32:33 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:32:33 INFO MemoryStore: Block broadcast_193 stored as values in memory (estimated size 358.4 KiB, free 362.8 MiB)
26/01/12 02:32:33 INFO MemoryStore: Block broadcast_193_piece0 stored as bytes in memory (estimated size 35.4 KiB, free 362.8 MiB)
26/01/12 02:32:33 INFO BlockManagerInfo: Added broadcast_193_piece0 in memory on 02926ee04bc9:45221 (size: 35.4 KiB, free: 365.7 MiB)
26/01/12 02:32:33 INFO SparkContext: Created broadcast 193 from parquet at <unknown>:0
26/01/12 02:32:33 INFO FileSourceScanExec: Planning scan with bin packing, max size: 95444363 bytes, open cost is considered as scanning 4194304 bytes.
26/01/12 02:32:33 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 02:32:33 INFO DAGScheduler: Got job 129 (parquet at <unknown>:0) with 2 output partitions
26/01/12 02:32:33 INFO DAGScheduler: Final stage: ResultStage 129 (parquet at <unknown>:0)
26/01/12 02:32:33 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:32:33 INFO DAGScheduler: Missing parents: List()
26/01/12 02:32:33 INFO DAGScheduler: Submitting ResultStage 129 (MapPartitionsRDD[324] at parquet at <unknown>:0), which has no missing parents
26/01/12 02:32:33 INFO MemoryStore: Block broadcast_194 stored as values in memory (estimated size 225.1 KiB, free 362.6 MiB)
26/01/12 02:32:33 INFO MemoryStore: Block broadcast_194_piece0 stored as bytes in memory (estimated size 77.4 KiB, free 362.5 MiB)
26/01/12 02:32:33 INFO BlockManagerInfo: Added broadcast_194_piece0 in memory on 02926ee04bc9:45221 (size: 77.4 KiB, free: 365.6 MiB)
26/01/12 02:32:33 INFO SparkContext: Created broadcast 194 from broadcast at DAGScheduler.scala:1513
26/01/12 02:32:33 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 129 (MapPartitionsRDD[324] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1))
26/01/12 02:32:33 INFO TaskSchedulerImpl: Adding task set 129.0 with 2 tasks resource profile 0
26/01/12 02:32:33 INFO TaskSetManager: Starting task 0.0 in stage 129.0 (TID 240) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:32:33 INFO TaskSetManager: Starting task 1.0 in stage 129.0 (TID 241) (172.18.0.5, executor 0, partition 1, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:32:33 INFO BlockManagerInfo: Added broadcast_194_piece0 in memory on 172.18.0.5:42453 (size: 77.4 KiB, free: 365.7 MiB)
26/01/12 02:32:33 INFO BlockManagerInfo: Added broadcast_193_piece0 in memory on 172.18.0.5:42453 (size: 35.4 KiB, free: 365.6 MiB)
26/01/12 02:32:33 INFO TaskSetManager: Finished task 1.0 in stage 129.0 (TID 241) in 55 ms on 172.18.0.5 (executor 0) (1/2)
26/01/12 02:33:06 INFO TaskSetManager: Finished task 0.0 in stage 129.0 (TID 240) in 32873 ms on 172.18.0.5 (executor 0) (2/2)
26/01/12 02:33:06 INFO TaskSchedulerImpl: Removed TaskSet 129.0, whose tasks have all completed, from pool 
26/01/12 02:33:06 INFO DAGScheduler: ResultStage 129 (parquet at <unknown>:0) finished in 32.893 s
26/01/12 02:33:06 INFO DAGScheduler: Job 129 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:33:06 INFO TaskSchedulerImpl: Killing all running tasks in stage 129: Stage finished
26/01/12 02:33:06 INFO DAGScheduler: Job 129 finished: parquet at <unknown>:0, took 32.899611 s
26/01/12 02:33:06 INFO FileFormatWriter: Start to commit write Job 8a1b98ab-6598-4aa3-9be1-2fcc51030603.
26/01/12 02:33:06 INFO FileFormatWriter: Write Job 8a1b98ab-6598-4aa3-9be1-2fcc51030603 committed. Elapsed time: 36 ms.
26/01/12 02:33:06 INFO FileFormatWriter: Finished processing stats for write job 8a1b98ab-6598-4aa3-9be1-2fcc51030603.
Cargando: yellow_tripdata_2014-06.parquet en hdfs://hadoop-namenode:8020/data/nyc/raw/taxi-trips/2014...
26/01/12 02:33:06 INFO InMemoryFileIndex: It took 10 ms to list leaf files for 1 paths.
26/01/12 02:33:06 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 02:33:06 INFO DAGScheduler: Got job 130 (parquet at <unknown>:0) with 1 output partitions
26/01/12 02:33:06 INFO DAGScheduler: Final stage: ResultStage 130 (parquet at <unknown>:0)
26/01/12 02:33:06 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:33:06 INFO DAGScheduler: Missing parents: List()
26/01/12 02:33:06 INFO DAGScheduler: Submitting ResultStage 130 (MapPartitionsRDD[326] at parquet at <unknown>:0), which has no missing parents
26/01/12 02:33:06 INFO MemoryStore: Block broadcast_195 stored as values in memory (estimated size 102.6 KiB, free 362.4 MiB)
26/01/12 02:33:06 INFO MemoryStore: Block broadcast_195_piece0 stored as bytes in memory (estimated size 36.8 KiB, free 362.4 MiB)
26/01/12 02:33:06 INFO BlockManagerInfo: Added broadcast_195_piece0 in memory on 02926ee04bc9:45221 (size: 36.8 KiB, free: 365.6 MiB)
26/01/12 02:33:06 INFO SparkContext: Created broadcast 195 from broadcast at DAGScheduler.scala:1513
26/01/12 02:33:06 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 130 (MapPartitionsRDD[326] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0))
26/01/12 02:33:06 INFO TaskSchedulerImpl: Adding task set 130.0 with 1 tasks resource profile 0
26/01/12 02:33:06 INFO TaskSetManager: Starting task 0.0 in stage 130.0 (TID 242) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4607 bytes) taskResourceAssignments Map()
26/01/12 02:33:06 INFO BlockManagerInfo: Added broadcast_195_piece0 in memory on 172.18.0.5:42453 (size: 36.8 KiB, free: 365.6 MiB)
26/01/12 02:33:06 INFO TaskSetManager: Finished task 0.0 in stage 130.0 (TID 242) in 62 ms on 172.18.0.5 (executor 0) (1/1)
26/01/12 02:33:06 INFO TaskSchedulerImpl: Removed TaskSet 130.0, whose tasks have all completed, from pool 
26/01/12 02:33:06 INFO DAGScheduler: ResultStage 130 (parquet at <unknown>:0) finished in 0.076 s
26/01/12 02:33:06 INFO DAGScheduler: Job 130 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:33:06 INFO TaskSchedulerImpl: Killing all running tasks in stage 130: Stage finished
26/01/12 02:33:06 INFO DAGScheduler: Job 130 finished: parquet at <unknown>:0, took 0.082040 s
26/01/12 02:33:06 INFO FileSourceStrategy: Pushed Filters: 
26/01/12 02:33:06 INFO FileSourceStrategy: Post-Scan Filters: 
26/01/12 02:33:06 INFO FileSourceStrategy: Output Data Schema: struct<VendorID: bigint, tpep_pickup_datetime: timestamp, tpep_dropoff_datetime: timestamp, passenger_count: bigint, trip_distance: double ... 17 more fields>
26/01/12 02:33:06 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:33:06 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:33:06 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:33:06 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:33:06 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:33:06 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:33:06 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:33:06 INFO MemoryStore: Block broadcast_196 stored as values in memory (estimated size 358.4 KiB, free 362.0 MiB)
26/01/12 02:33:06 INFO MemoryStore: Block broadcast_196_piece0 stored as bytes in memory (estimated size 35.4 KiB, free 362.0 MiB)
26/01/12 02:33:06 INFO BlockManagerInfo: Added broadcast_196_piece0 in memory on 02926ee04bc9:45221 (size: 35.4 KiB, free: 365.6 MiB)
26/01/12 02:33:06 INFO SparkContext: Created broadcast 196 from parquet at <unknown>:0
26/01/12 02:33:06 INFO FileSourceScanExec: Planning scan with bin packing, max size: 89014090 bytes, open cost is considered as scanning 4194304 bytes.
26/01/12 02:33:06 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 02:33:06 INFO DAGScheduler: Got job 131 (parquet at <unknown>:0) with 2 output partitions
26/01/12 02:33:06 INFO DAGScheduler: Final stage: ResultStage 131 (parquet at <unknown>:0)
26/01/12 02:33:06 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:33:06 INFO DAGScheduler: Missing parents: List()
26/01/12 02:33:06 INFO DAGScheduler: Submitting ResultStage 131 (MapPartitionsRDD[329] at parquet at <unknown>:0), which has no missing parents
26/01/12 02:33:06 INFO MemoryStore: Block broadcast_197 stored as values in memory (estimated size 225.1 KiB, free 361.8 MiB)
26/01/12 02:33:06 INFO MemoryStore: Block broadcast_197_piece0 stored as bytes in memory (estimated size 77.4 KiB, free 361.7 MiB)
26/01/12 02:33:06 INFO BlockManagerInfo: Added broadcast_197_piece0 in memory on 02926ee04bc9:45221 (size: 77.4 KiB, free: 365.5 MiB)
26/01/12 02:33:06 INFO SparkContext: Created broadcast 197 from broadcast at DAGScheduler.scala:1513
26/01/12 02:33:06 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 131 (MapPartitionsRDD[329] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1))
26/01/12 02:33:06 INFO TaskSchedulerImpl: Adding task set 131.0 with 2 tasks resource profile 0
26/01/12 02:33:06 INFO TaskSetManager: Starting task 0.0 in stage 131.0 (TID 243) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:33:06 INFO TaskSetManager: Starting task 1.0 in stage 131.0 (TID 244) (172.18.0.5, executor 0, partition 1, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:33:06 INFO BlockManagerInfo: Added broadcast_197_piece0 in memory on 172.18.0.5:42453 (size: 77.4 KiB, free: 365.5 MiB)
26/01/12 02:33:06 INFO BlockManagerInfo: Added broadcast_196_piece0 in memory on 172.18.0.5:42453 (size: 35.4 KiB, free: 365.5 MiB)
26/01/12 02:33:06 INFO TaskSetManager: Finished task 1.0 in stage 131.0 (TID 244) in 61 ms on 172.18.0.5 (executor 0) (1/2)
26/01/12 02:33:36 INFO TaskSetManager: Finished task 0.0 in stage 131.0 (TID 243) in 29478 ms on 172.18.0.5 (executor 0) (2/2)
26/01/12 02:33:36 INFO TaskSchedulerImpl: Removed TaskSet 131.0, whose tasks have all completed, from pool 
26/01/12 02:33:36 INFO DAGScheduler: ResultStage 131 (parquet at <unknown>:0) finished in 29.502 s
26/01/12 02:33:36 INFO DAGScheduler: Job 131 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:33:36 INFO TaskSchedulerImpl: Killing all running tasks in stage 131: Stage finished
26/01/12 02:33:36 INFO DAGScheduler: Job 131 finished: parquet at <unknown>:0, took 29.509636 s
26/01/12 02:33:36 INFO FileFormatWriter: Start to commit write Job d8440118-8fcd-4ba1-8b89-2d0d19b87eda.
26/01/12 02:33:36 INFO FileFormatWriter: Write Job d8440118-8fcd-4ba1-8b89-2d0d19b87eda committed. Elapsed time: 25 ms.
26/01/12 02:33:36 INFO FileFormatWriter: Finished processing stats for write job d8440118-8fcd-4ba1-8b89-2d0d19b87eda.
Cargando: yellow_tripdata_2014-07.parquet en hdfs://hadoop-namenode:8020/data/nyc/raw/taxi-trips/2014...
26/01/12 02:33:36 INFO InMemoryFileIndex: It took 7 ms to list leaf files for 1 paths.
26/01/12 02:33:36 INFO BlockManagerInfo: Removed broadcast_187_piece0 on 02926ee04bc9:45221 in memory (size: 35.4 KiB, free: 365.5 MiB)
26/01/12 02:33:36 INFO BlockManagerInfo: Removed broadcast_187_piece0 on 172.18.0.5:42453 in memory (size: 35.4 KiB, free: 365.5 MiB)
26/01/12 02:33:36 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 02:33:36 INFO DAGScheduler: Got job 132 (parquet at <unknown>:0) with 1 output partitions
26/01/12 02:33:36 INFO BlockManagerInfo: Removed broadcast_188_piece0 on 02926ee04bc9:45221 in memory (size: 77.4 KiB, free: 365.6 MiB)
26/01/12 02:33:36 INFO DAGScheduler: Final stage: ResultStage 132 (parquet at <unknown>:0)
26/01/12 02:33:36 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:33:36 INFO DAGScheduler: Missing parents: List()
26/01/12 02:33:36 INFO BlockManagerInfo: Removed broadcast_188_piece0 on 172.18.0.5:42453 in memory (size: 77.4 KiB, free: 365.6 MiB)
26/01/12 02:33:36 INFO DAGScheduler: Submitting ResultStage 132 (MapPartitionsRDD[331] at parquet at <unknown>:0), which has no missing parents
26/01/12 02:33:36 INFO MemoryStore: Block broadcast_198 stored as values in memory (estimated size 102.6 KiB, free 362.3 MiB)
26/01/12 02:33:36 INFO BlockManagerInfo: Removed broadcast_190_piece0 on 02926ee04bc9:45221 in memory (size: 35.4 KiB, free: 365.6 MiB)
26/01/12 02:33:36 INFO MemoryStore: Block broadcast_198_piece0 stored as bytes in memory (estimated size 36.8 KiB, free 362.6 MiB)
26/01/12 02:33:36 INFO BlockManagerInfo: Removed broadcast_190_piece0 on 172.18.0.5:42453 in memory (size: 35.4 KiB, free: 365.6 MiB)
26/01/12 02:33:36 INFO BlockManagerInfo: Added broadcast_198_piece0 in memory on 02926ee04bc9:45221 (size: 36.8 KiB, free: 365.6 MiB)
26/01/12 02:33:36 INFO SparkContext: Created broadcast 198 from broadcast at DAGScheduler.scala:1513
26/01/12 02:33:36 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 132 (MapPartitionsRDD[331] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0))
26/01/12 02:33:36 INFO TaskSchedulerImpl: Adding task set 132.0 with 1 tasks resource profile 0
26/01/12 02:33:36 INFO TaskSetManager: Starting task 0.0 in stage 132.0 (TID 245) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4607 bytes) taskResourceAssignments Map()
26/01/12 02:33:36 INFO BlockManagerInfo: Removed broadcast_194_piece0 on 02926ee04bc9:45221 in memory (size: 77.4 KiB, free: 365.7 MiB)
26/01/12 02:33:36 INFO BlockManagerInfo: Removed broadcast_194_piece0 on 172.18.0.5:42453 in memory (size: 77.4 KiB, free: 365.7 MiB)
26/01/12 02:33:36 INFO BlockManagerInfo: Removed broadcast_193_piece0 on 02926ee04bc9:45221 in memory (size: 35.4 KiB, free: 365.7 MiB)
26/01/12 02:33:36 INFO BlockManagerInfo: Added broadcast_198_piece0 in memory on 172.18.0.5:42453 (size: 36.8 KiB, free: 365.7 MiB)
26/01/12 02:33:36 INFO BlockManagerInfo: Removed broadcast_193_piece0 on 172.18.0.5:42453 in memory (size: 35.4 KiB, free: 365.7 MiB)
26/01/12 02:33:36 INFO BlockManagerInfo: Removed broadcast_191_piece0 on 02926ee04bc9:45221 in memory (size: 77.4 KiB, free: 365.8 MiB)
26/01/12 02:33:36 INFO BlockManagerInfo: Removed broadcast_191_piece0 on 172.18.0.5:42453 in memory (size: 77.4 KiB, free: 365.8 MiB)
26/01/12 02:33:36 INFO BlockManagerInfo: Removed broadcast_185_piece0 on 02926ee04bc9:45221 in memory (size: 77.4 KiB, free: 365.9 MiB)
26/01/12 02:33:36 INFO BlockManagerInfo: Removed broadcast_185_piece0 on 172.18.0.5:42453 in memory (size: 77.4 KiB, free: 365.9 MiB)
26/01/12 02:33:36 INFO BlockManagerInfo: Removed broadcast_189_piece0 on 02926ee04bc9:45221 in memory (size: 36.8 KiB, free: 365.9 MiB)
26/01/12 02:33:36 INFO BlockManagerInfo: Removed broadcast_189_piece0 on 172.18.0.5:42453 in memory (size: 36.8 KiB, free: 365.9 MiB)
26/01/12 02:33:36 INFO BlockManagerInfo: Removed broadcast_184_piece0 on 02926ee04bc9:45221 in memory (size: 35.4 KiB, free: 365.9 MiB)
26/01/12 02:33:36 INFO BlockManagerInfo: Removed broadcast_184_piece0 on 172.18.0.5:42453 in memory (size: 35.4 KiB, free: 365.9 MiB)
26/01/12 02:33:36 INFO BlockManagerInfo: Removed broadcast_186_piece0 on 02926ee04bc9:45221 in memory (size: 36.8 KiB, free: 366.0 MiB)
26/01/12 02:33:36 INFO BlockManagerInfo: Removed broadcast_186_piece0 on 172.18.0.5:42453 in memory (size: 36.8 KiB, free: 366.0 MiB)
26/01/12 02:33:36 INFO BlockManagerInfo: Removed broadcast_195_piece0 on 02926ee04bc9:45221 in memory (size: 36.8 KiB, free: 366.0 MiB)
26/01/12 02:33:36 INFO BlockManagerInfo: Removed broadcast_195_piece0 on 172.18.0.5:42453 in memory (size: 36.8 KiB, free: 366.0 MiB)
26/01/12 02:33:36 INFO BlockManagerInfo: Removed broadcast_192_piece0 on 02926ee04bc9:45221 in memory (size: 36.8 KiB, free: 366.0 MiB)
26/01/12 02:33:36 INFO BlockManagerInfo: Removed broadcast_192_piece0 on 172.18.0.5:42453 in memory (size: 36.8 KiB, free: 366.0 MiB)
26/01/12 02:33:36 INFO BlockManagerInfo: Removed broadcast_197_piece0 on 02926ee04bc9:45221 in memory (size: 77.4 KiB, free: 366.1 MiB)
26/01/12 02:33:36 INFO BlockManagerInfo: Removed broadcast_197_piece0 on 172.18.0.5:42453 in memory (size: 77.4 KiB, free: 366.1 MiB)
26/01/12 02:33:36 INFO TaskSetManager: Finished task 0.0 in stage 132.0 (TID 245) in 77 ms on 172.18.0.5 (executor 0) (1/1)
26/01/12 02:33:36 INFO TaskSchedulerImpl: Removed TaskSet 132.0, whose tasks have all completed, from pool 
26/01/12 02:33:36 INFO DAGScheduler: ResultStage 132 (parquet at <unknown>:0) finished in 0.092 s
26/01/12 02:33:36 INFO DAGScheduler: Job 132 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:33:36 INFO TaskSchedulerImpl: Killing all running tasks in stage 132: Stage finished
26/01/12 02:33:36 INFO DAGScheduler: Job 132 finished: parquet at <unknown>:0, took 0.097222 s
26/01/12 02:33:36 INFO FileSourceStrategy: Pushed Filters: 
26/01/12 02:33:36 INFO FileSourceStrategy: Post-Scan Filters: 
26/01/12 02:33:36 INFO FileSourceStrategy: Output Data Schema: struct<VendorID: bigint, tpep_pickup_datetime: timestamp, tpep_dropoff_datetime: timestamp, passenger_count: bigint, trip_distance: double ... 17 more fields>
26/01/12 02:33:36 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:33:36 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:33:36 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:33:36 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:33:36 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:33:36 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:33:36 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:33:36 INFO MemoryStore: Block broadcast_199 stored as values in memory (estimated size 358.4 KiB, free 364.7 MiB)
26/01/12 02:33:36 INFO MemoryStore: Block broadcast_199_piece0 stored as bytes in memory (estimated size 35.4 KiB, free 364.7 MiB)
26/01/12 02:33:36 INFO BlockManagerInfo: Added broadcast_199_piece0 in memory on 02926ee04bc9:45221 (size: 35.4 KiB, free: 366.1 MiB)
26/01/12 02:33:36 INFO SparkContext: Created broadcast 199 from parquet at <unknown>:0
26/01/12 02:33:36 INFO FileSourceScanExec: Planning scan with bin packing, max size: 84651452 bytes, open cost is considered as scanning 4194304 bytes.
26/01/12 02:33:36 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 02:33:36 INFO DAGScheduler: Got job 133 (parquet at <unknown>:0) with 2 output partitions
26/01/12 02:33:36 INFO DAGScheduler: Final stage: ResultStage 133 (parquet at <unknown>:0)
26/01/12 02:33:36 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:33:36 INFO DAGScheduler: Missing parents: List()
26/01/12 02:33:36 INFO DAGScheduler: Submitting ResultStage 133 (MapPartitionsRDD[334] at parquet at <unknown>:0), which has no missing parents
26/01/12 02:33:36 INFO MemoryStore: Block broadcast_200 stored as values in memory (estimated size 225.1 KiB, free 364.5 MiB)
26/01/12 02:33:36 INFO MemoryStore: Block broadcast_200_piece0 stored as bytes in memory (estimated size 77.4 KiB, free 364.4 MiB)
26/01/12 02:33:36 INFO BlockManagerInfo: Added broadcast_200_piece0 in memory on 02926ee04bc9:45221 (size: 77.4 KiB, free: 366.0 MiB)
26/01/12 02:33:36 INFO SparkContext: Created broadcast 200 from broadcast at DAGScheduler.scala:1513
26/01/12 02:33:36 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 133 (MapPartitionsRDD[334] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1))
26/01/12 02:33:36 INFO TaskSchedulerImpl: Adding task set 133.0 with 2 tasks resource profile 0
26/01/12 02:33:36 INFO TaskSetManager: Starting task 0.0 in stage 133.0 (TID 246) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:33:36 INFO TaskSetManager: Starting task 1.0 in stage 133.0 (TID 247) (172.18.0.5, executor 0, partition 1, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:33:36 INFO BlockManagerInfo: Added broadcast_200_piece0 in memory on 172.18.0.5:42453 (size: 77.4 KiB, free: 366.0 MiB)
26/01/12 02:33:36 INFO BlockManagerInfo: Added broadcast_199_piece0 in memory on 172.18.0.5:42453 (size: 35.4 KiB, free: 366.0 MiB)
26/01/12 02:33:36 INFO TaskSetManager: Finished task 1.0 in stage 133.0 (TID 247) in 59 ms on 172.18.0.5 (executor 0) (1/2)
26/01/12 02:34:04 INFO TaskSetManager: Finished task 0.0 in stage 133.0 (TID 246) in 28566 ms on 172.18.0.5 (executor 0) (2/2)
26/01/12 02:34:04 INFO TaskSchedulerImpl: Removed TaskSet 133.0, whose tasks have all completed, from pool 
26/01/12 02:34:04 INFO DAGScheduler: ResultStage 133 (parquet at <unknown>:0) finished in 28.585 s
26/01/12 02:34:04 INFO DAGScheduler: Job 133 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:34:04 INFO TaskSchedulerImpl: Killing all running tasks in stage 133: Stage finished
26/01/12 02:34:04 INFO DAGScheduler: Job 133 finished: parquet at <unknown>:0, took 28.590713 s
26/01/12 02:34:04 INFO FileFormatWriter: Start to commit write Job a4f1b834-bf6c-4dd0-be0e-90f1c8eb709f.
26/01/12 02:34:04 INFO FileFormatWriter: Write Job a4f1b834-bf6c-4dd0-be0e-90f1c8eb709f committed. Elapsed time: 29 ms.
26/01/12 02:34:04 INFO FileFormatWriter: Finished processing stats for write job a4f1b834-bf6c-4dd0-be0e-90f1c8eb709f.
Cargando: yellow_tripdata_2014-08.parquet en hdfs://hadoop-namenode:8020/data/nyc/raw/taxi-trips/2014...
26/01/12 02:34:04 INFO InMemoryFileIndex: It took 7 ms to list leaf files for 1 paths.
26/01/12 02:34:04 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 02:34:04 INFO DAGScheduler: Got job 134 (parquet at <unknown>:0) with 1 output partitions
26/01/12 02:34:04 INFO DAGScheduler: Final stage: ResultStage 134 (parquet at <unknown>:0)
26/01/12 02:34:04 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:34:04 INFO DAGScheduler: Missing parents: List()
26/01/12 02:34:04 INFO DAGScheduler: Submitting ResultStage 134 (MapPartitionsRDD[336] at parquet at <unknown>:0), which has no missing parents
26/01/12 02:34:04 INFO MemoryStore: Block broadcast_201 stored as values in memory (estimated size 102.6 KiB, free 364.3 MiB)
26/01/12 02:34:04 INFO MemoryStore: Block broadcast_201_piece0 stored as bytes in memory (estimated size 36.8 KiB, free 364.3 MiB)
26/01/12 02:34:05 INFO BlockManagerInfo: Added broadcast_201_piece0 in memory on 02926ee04bc9:45221 (size: 36.8 KiB, free: 366.0 MiB)
26/01/12 02:34:05 INFO SparkContext: Created broadcast 201 from broadcast at DAGScheduler.scala:1513
26/01/12 02:34:05 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 134 (MapPartitionsRDD[336] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0))
26/01/12 02:34:05 INFO TaskSchedulerImpl: Adding task set 134.0 with 1 tasks resource profile 0
26/01/12 02:34:05 INFO TaskSetManager: Starting task 0.0 in stage 134.0 (TID 248) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4607 bytes) taskResourceAssignments Map()
26/01/12 02:34:05 INFO BlockManagerInfo: Added broadcast_201_piece0 in memory on 172.18.0.5:42453 (size: 36.8 KiB, free: 366.0 MiB)
26/01/12 02:34:05 INFO TaskSetManager: Finished task 0.0 in stage 134.0 (TID 248) in 59 ms on 172.18.0.5 (executor 0) (1/1)
26/01/12 02:34:05 INFO TaskSchedulerImpl: Removed TaskSet 134.0, whose tasks have all completed, from pool 
26/01/12 02:34:05 INFO DAGScheduler: ResultStage 134 (parquet at <unknown>:0) finished in 0.073 s
26/01/12 02:34:05 INFO DAGScheduler: Job 134 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:34:05 INFO TaskSchedulerImpl: Killing all running tasks in stage 134: Stage finished
26/01/12 02:34:05 INFO DAGScheduler: Job 134 finished: parquet at <unknown>:0, took 0.077779 s
26/01/12 02:34:05 INFO FileSourceStrategy: Pushed Filters: 
26/01/12 02:34:05 INFO FileSourceStrategy: Post-Scan Filters: 
26/01/12 02:34:05 INFO FileSourceStrategy: Output Data Schema: struct<VendorID: bigint, tpep_pickup_datetime: timestamp, tpep_dropoff_datetime: timestamp, passenger_count: bigint, trip_distance: double ... 17 more fields>
26/01/12 02:34:05 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:34:05 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:34:05 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:34:05 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:34:05 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:34:05 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:34:05 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:34:05 INFO CodeGenerator: Code generated in 21.56767 ms
26/01/12 02:34:05 INFO MemoryStore: Block broadcast_202 stored as values in memory (estimated size 358.5 KiB, free 363.9 MiB)
26/01/12 02:34:05 INFO MemoryStore: Block broadcast_202_piece0 stored as bytes in memory (estimated size 35.4 KiB, free 363.9 MiB)
26/01/12 02:34:05 INFO BlockManagerInfo: Added broadcast_202_piece0 in memory on 02926ee04bc9:45221 (size: 35.4 KiB, free: 365.9 MiB)
26/01/12 02:34:05 INFO SparkContext: Created broadcast 202 from parquet at <unknown>:0
26/01/12 02:34:05 INFO FileSourceScanExec: Planning scan with bin packing, max size: 88693442 bytes, open cost is considered as scanning 4194304 bytes.
26/01/12 02:34:05 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 02:34:05 INFO DAGScheduler: Got job 135 (parquet at <unknown>:0) with 2 output partitions
26/01/12 02:34:05 INFO DAGScheduler: Final stage: ResultStage 135 (parquet at <unknown>:0)
26/01/12 02:34:05 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:34:05 INFO DAGScheduler: Missing parents: List()
26/01/12 02:34:05 INFO DAGScheduler: Submitting ResultStage 135 (MapPartitionsRDD[339] at parquet at <unknown>:0), which has no missing parents
26/01/12 02:34:05 INFO MemoryStore: Block broadcast_203 stored as values in memory (estimated size 225.1 KiB, free 363.7 MiB)
26/01/12 02:34:05 INFO MemoryStore: Block broadcast_203_piece0 stored as bytes in memory (estimated size 77.4 KiB, free 363.6 MiB)
26/01/12 02:34:05 INFO BlockManagerInfo: Added broadcast_203_piece0 in memory on 02926ee04bc9:45221 (size: 77.4 KiB, free: 365.9 MiB)
26/01/12 02:34:05 INFO SparkContext: Created broadcast 203 from broadcast at DAGScheduler.scala:1513
26/01/12 02:34:05 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 135 (MapPartitionsRDD[339] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1))
26/01/12 02:34:05 INFO TaskSchedulerImpl: Adding task set 135.0 with 2 tasks resource profile 0
26/01/12 02:34:05 INFO TaskSetManager: Starting task 0.0 in stage 135.0 (TID 249) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:34:05 INFO TaskSetManager: Starting task 1.0 in stage 135.0 (TID 250) (172.18.0.5, executor 0, partition 1, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:34:05 INFO BlockManagerInfo: Added broadcast_203_piece0 in memory on 172.18.0.5:42453 (size: 77.4 KiB, free: 365.9 MiB)
26/01/12 02:34:05 INFO BlockManagerInfo: Added broadcast_202_piece0 in memory on 172.18.0.5:42453 (size: 35.4 KiB, free: 365.9 MiB)
26/01/12 02:34:05 INFO TaskSetManager: Finished task 1.0 in stage 135.0 (TID 250) in 88 ms on 172.18.0.5 (executor 0) (1/2)
26/01/12 02:34:32 INFO TaskSetManager: Finished task 0.0 in stage 135.0 (TID 249) in 27610 ms on 172.18.0.5 (executor 0) (2/2)
26/01/12 02:34:32 INFO TaskSchedulerImpl: Removed TaskSet 135.0, whose tasks have all completed, from pool 
26/01/12 02:34:32 INFO DAGScheduler: ResultStage 135 (parquet at <unknown>:0) finished in 27.630 s
26/01/12 02:34:32 INFO DAGScheduler: Job 135 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:34:32 INFO TaskSchedulerImpl: Killing all running tasks in stage 135: Stage finished
26/01/12 02:34:32 INFO DAGScheduler: Job 135 finished: parquet at <unknown>:0, took 27.637494 s
26/01/12 02:34:32 INFO FileFormatWriter: Start to commit write Job ce92237f-9620-4dc9-827d-2021d5cbe11b.
26/01/12 02:34:32 INFO FileFormatWriter: Write Job ce92237f-9620-4dc9-827d-2021d5cbe11b committed. Elapsed time: 34 ms.
26/01/12 02:34:32 INFO FileFormatWriter: Finished processing stats for write job ce92237f-9620-4dc9-827d-2021d5cbe11b.
Cargando: yellow_tripdata_2014-09.parquet en hdfs://hadoop-namenode:8020/data/nyc/raw/taxi-trips/2014...
26/01/12 02:34:32 INFO InMemoryFileIndex: It took 7 ms to list leaf files for 1 paths.
26/01/12 02:34:32 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 02:34:32 INFO DAGScheduler: Got job 136 (parquet at <unknown>:0) with 1 output partitions
26/01/12 02:34:32 INFO DAGScheduler: Final stage: ResultStage 136 (parquet at <unknown>:0)
26/01/12 02:34:32 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:34:32 INFO DAGScheduler: Missing parents: List()
26/01/12 02:34:32 INFO DAGScheduler: Submitting ResultStage 136 (MapPartitionsRDD[341] at parquet at <unknown>:0), which has no missing parents
26/01/12 02:34:32 INFO MemoryStore: Block broadcast_204 stored as values in memory (estimated size 102.6 KiB, free 363.5 MiB)
26/01/12 02:34:32 INFO MemoryStore: Block broadcast_204_piece0 stored as bytes in memory (estimated size 36.8 KiB, free 363.5 MiB)
26/01/12 02:34:32 INFO BlockManagerInfo: Added broadcast_204_piece0 in memory on 02926ee04bc9:45221 (size: 36.8 KiB, free: 365.8 MiB)
26/01/12 02:34:32 INFO SparkContext: Created broadcast 204 from broadcast at DAGScheduler.scala:1513
26/01/12 02:34:32 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 136 (MapPartitionsRDD[341] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0))
26/01/12 02:34:32 INFO TaskSchedulerImpl: Adding task set 136.0 with 1 tasks resource profile 0
26/01/12 02:34:32 INFO TaskSetManager: Starting task 0.0 in stage 136.0 (TID 251) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4607 bytes) taskResourceAssignments Map()
26/01/12 02:34:32 INFO BlockManagerInfo: Added broadcast_204_piece0 in memory on 172.18.0.5:42453 (size: 36.8 KiB, free: 365.8 MiB)
26/01/12 02:34:32 INFO TaskSetManager: Finished task 0.0 in stage 136.0 (TID 251) in 45 ms on 172.18.0.5 (executor 0) (1/1)
26/01/12 02:34:32 INFO TaskSchedulerImpl: Removed TaskSet 136.0, whose tasks have all completed, from pool 
26/01/12 02:34:32 INFO DAGScheduler: ResultStage 136 (parquet at <unknown>:0) finished in 0.057 s
26/01/12 02:34:32 INFO DAGScheduler: Job 136 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:34:32 INFO TaskSchedulerImpl: Killing all running tasks in stage 136: Stage finished
26/01/12 02:34:32 INFO DAGScheduler: Job 136 finished: parquet at <unknown>:0, took 0.061988 s
26/01/12 02:34:32 INFO FileSourceStrategy: Pushed Filters: 
26/01/12 02:34:32 INFO FileSourceStrategy: Post-Scan Filters: 
26/01/12 02:34:32 INFO FileSourceStrategy: Output Data Schema: struct<VendorID: bigint, tpep_pickup_datetime: timestamp, tpep_dropoff_datetime: timestamp, passenger_count: bigint, trip_distance: double ... 17 more fields>
26/01/12 02:34:32 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:34:32 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:34:32 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:34:32 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:34:32 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:34:32 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:34:32 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:34:32 INFO MemoryStore: Block broadcast_205 stored as values in memory (estimated size 358.4 KiB, free 363.1 MiB)
26/01/12 02:34:32 INFO MemoryStore: Block broadcast_205_piece0 stored as bytes in memory (estimated size 35.4 KiB, free 363.1 MiB)
26/01/12 02:34:32 INFO BlockManagerInfo: Added broadcast_205_piece0 in memory on 02926ee04bc9:45221 (size: 35.4 KiB, free: 365.8 MiB)
26/01/12 02:34:32 INFO SparkContext: Created broadcast 205 from parquet at <unknown>:0
26/01/12 02:34:32 INFO FileSourceScanExec: Planning scan with bin packing, max size: 94023858 bytes, open cost is considered as scanning 4194304 bytes.
26/01/12 02:34:32 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 02:34:32 INFO DAGScheduler: Got job 137 (parquet at <unknown>:0) with 2 output partitions
26/01/12 02:34:32 INFO DAGScheduler: Final stage: ResultStage 137 (parquet at <unknown>:0)
26/01/12 02:34:32 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:34:32 INFO DAGScheduler: Missing parents: List()
26/01/12 02:34:32 INFO DAGScheduler: Submitting ResultStage 137 (MapPartitionsRDD[344] at parquet at <unknown>:0), which has no missing parents
26/01/12 02:34:33 INFO MemoryStore: Block broadcast_206 stored as values in memory (estimated size 225.1 KiB, free 362.9 MiB)
26/01/12 02:34:33 INFO MemoryStore: Block broadcast_206_piece0 stored as bytes in memory (estimated size 77.4 KiB, free 362.8 MiB)
26/01/12 02:34:33 INFO BlockManagerInfo: Added broadcast_206_piece0 in memory on 02926ee04bc9:45221 (size: 77.4 KiB, free: 365.7 MiB)
26/01/12 02:34:33 INFO SparkContext: Created broadcast 206 from broadcast at DAGScheduler.scala:1513
26/01/12 02:34:33 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 137 (MapPartitionsRDD[344] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1))
26/01/12 02:34:33 INFO TaskSchedulerImpl: Adding task set 137.0 with 2 tasks resource profile 0
26/01/12 02:34:33 INFO TaskSetManager: Starting task 0.0 in stage 137.0 (TID 252) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:34:33 INFO TaskSetManager: Starting task 1.0 in stage 137.0 (TID 253) (172.18.0.5, executor 0, partition 1, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:34:33 INFO BlockManagerInfo: Added broadcast_206_piece0 in memory on 172.18.0.5:42453 (size: 77.4 KiB, free: 365.8 MiB)
26/01/12 02:34:33 INFO BlockManagerInfo: Added broadcast_205_piece0 in memory on 172.18.0.5:42453 (size: 35.4 KiB, free: 365.7 MiB)
26/01/12 02:34:33 INFO TaskSetManager: Finished task 1.0 in stage 137.0 (TID 253) in 65 ms on 172.18.0.5 (executor 0) (1/2)
26/01/12 02:35:02 INFO TaskSetManager: Finished task 0.0 in stage 137.0 (TID 252) in 29359 ms on 172.18.0.5 (executor 0) (2/2)
26/01/12 02:35:02 INFO TaskSchedulerImpl: Removed TaskSet 137.0, whose tasks have all completed, from pool 
26/01/12 02:35:02 INFO DAGScheduler: ResultStage 137 (parquet at <unknown>:0) finished in 29.381 s
26/01/12 02:35:02 INFO DAGScheduler: Job 137 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:35:02 INFO TaskSchedulerImpl: Killing all running tasks in stage 137: Stage finished
26/01/12 02:35:02 INFO DAGScheduler: Job 137 finished: parquet at <unknown>:0, took 29.387132 s
26/01/12 02:35:02 INFO FileFormatWriter: Start to commit write Job bd8f8211-76ba-4de8-8626-eff3011d7d1a.
26/01/12 02:35:02 INFO FileFormatWriter: Write Job bd8f8211-76ba-4de8-8626-eff3011d7d1a committed. Elapsed time: 25 ms.
26/01/12 02:35:02 INFO FileFormatWriter: Finished processing stats for write job bd8f8211-76ba-4de8-8626-eff3011d7d1a.
Cargando: yellow_tripdata_2014-10.parquet en hdfs://hadoop-namenode:8020/data/nyc/raw/taxi-trips/2014...
26/01/12 02:35:02 INFO InMemoryFileIndex: It took 6 ms to list leaf files for 1 paths.
26/01/12 02:35:02 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 02:35:02 INFO DAGScheduler: Got job 138 (parquet at <unknown>:0) with 1 output partitions
26/01/12 02:35:02 INFO DAGScheduler: Final stage: ResultStage 138 (parquet at <unknown>:0)
26/01/12 02:35:02 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:35:02 INFO DAGScheduler: Missing parents: List()
26/01/12 02:35:02 INFO DAGScheduler: Submitting ResultStage 138 (MapPartitionsRDD[346] at parquet at <unknown>:0), which has no missing parents
26/01/12 02:35:02 INFO MemoryStore: Block broadcast_207 stored as values in memory (estimated size 102.6 KiB, free 362.7 MiB)
26/01/12 02:35:02 INFO MemoryStore: Block broadcast_207_piece0 stored as bytes in memory (estimated size 36.8 KiB, free 362.7 MiB)
26/01/12 02:35:02 INFO BlockManagerInfo: Added broadcast_207_piece0 in memory on 02926ee04bc9:45221 (size: 36.8 KiB, free: 365.7 MiB)
26/01/12 02:35:02 INFO SparkContext: Created broadcast 207 from broadcast at DAGScheduler.scala:1513
26/01/12 02:35:02 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 138 (MapPartitionsRDD[346] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0))
26/01/12 02:35:02 INFO TaskSchedulerImpl: Adding task set 138.0 with 1 tasks resource profile 0
26/01/12 02:35:02 INFO TaskSetManager: Starting task 0.0 in stage 138.0 (TID 254) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4607 bytes) taskResourceAssignments Map()
26/01/12 02:35:02 INFO BlockManagerInfo: Added broadcast_207_piece0 in memory on 172.18.0.5:42453 (size: 36.8 KiB, free: 365.7 MiB)
26/01/12 02:35:02 INFO TaskSetManager: Finished task 0.0 in stage 138.0 (TID 254) in 54 ms on 172.18.0.5 (executor 0) (1/1)
26/01/12 02:35:02 INFO TaskSchedulerImpl: Removed TaskSet 138.0, whose tasks have all completed, from pool 
26/01/12 02:35:02 INFO DAGScheduler: ResultStage 138 (parquet at <unknown>:0) finished in 0.066 s
26/01/12 02:35:02 INFO DAGScheduler: Job 138 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:35:02 INFO TaskSchedulerImpl: Killing all running tasks in stage 138: Stage finished
26/01/12 02:35:02 INFO DAGScheduler: Job 138 finished: parquet at <unknown>:0, took 0.069725 s
26/01/12 02:35:02 INFO FileSourceStrategy: Pushed Filters: 
26/01/12 02:35:02 INFO FileSourceStrategy: Post-Scan Filters: 
26/01/12 02:35:02 INFO FileSourceStrategy: Output Data Schema: struct<VendorID: bigint, tpep_pickup_datetime: timestamp, tpep_dropoff_datetime: timestamp, passenger_count: bigint, trip_distance: double ... 17 more fields>
26/01/12 02:35:02 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:35:02 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:35:02 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:35:02 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:35:02 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:35:02 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:35:02 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:35:02 INFO MemoryStore: Block broadcast_208 stored as values in memory (estimated size 358.4 KiB, free 362.3 MiB)
26/01/12 02:35:02 INFO MemoryStore: Block broadcast_208_piece0 stored as bytes in memory (estimated size 35.4 KiB, free 362.3 MiB)
26/01/12 02:35:02 INFO BlockManagerInfo: Added broadcast_208_piece0 in memory on 02926ee04bc9:45221 (size: 35.4 KiB, free: 365.6 MiB)
26/01/12 02:35:02 INFO SparkContext: Created broadcast 208 from parquet at <unknown>:0
26/01/12 02:35:02 INFO FileSourceScanExec: Planning scan with bin packing, max size: 99924501 bytes, open cost is considered as scanning 4194304 bytes.
26/01/12 02:35:02 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 02:35:02 INFO DAGScheduler: Got job 139 (parquet at <unknown>:0) with 2 output partitions
26/01/12 02:35:02 INFO DAGScheduler: Final stage: ResultStage 139 (parquet at <unknown>:0)
26/01/12 02:35:02 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:35:02 INFO DAGScheduler: Missing parents: List()
26/01/12 02:35:02 INFO DAGScheduler: Submitting ResultStage 139 (MapPartitionsRDD[349] at parquet at <unknown>:0), which has no missing parents
26/01/12 02:35:02 INFO MemoryStore: Block broadcast_209 stored as values in memory (estimated size 225.1 KiB, free 362.0 MiB)
26/01/12 02:35:02 INFO MemoryStore: Block broadcast_209_piece0 stored as bytes in memory (estimated size 77.4 KiB, free 362.0 MiB)
26/01/12 02:35:02 INFO BlockManagerInfo: Added broadcast_209_piece0 in memory on 02926ee04bc9:45221 (size: 77.4 KiB, free: 365.6 MiB)
26/01/12 02:35:02 INFO SparkContext: Created broadcast 209 from broadcast at DAGScheduler.scala:1513
26/01/12 02:35:02 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 139 (MapPartitionsRDD[349] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1))
26/01/12 02:35:02 INFO TaskSchedulerImpl: Adding task set 139.0 with 2 tasks resource profile 0
26/01/12 02:35:02 INFO TaskSetManager: Starting task 0.0 in stage 139.0 (TID 255) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:35:02 INFO TaskSetManager: Starting task 1.0 in stage 139.0 (TID 256) (172.18.0.5, executor 0, partition 1, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:35:02 INFO BlockManagerInfo: Added broadcast_209_piece0 in memory on 172.18.0.5:42453 (size: 77.4 KiB, free: 365.6 MiB)
26/01/12 02:35:02 INFO BlockManagerInfo: Added broadcast_208_piece0 in memory on 172.18.0.5:42453 (size: 35.4 KiB, free: 365.6 MiB)
26/01/12 02:35:02 INFO TaskSetManager: Finished task 1.0 in stage 139.0 (TID 256) in 61 ms on 172.18.0.5 (executor 0) (1/2)
26/01/12 02:35:34 INFO TaskSetManager: Finished task 0.0 in stage 139.0 (TID 255) in 32364 ms on 172.18.0.5 (executor 0) (2/2)
26/01/12 02:35:34 INFO TaskSchedulerImpl: Removed TaskSet 139.0, whose tasks have all completed, from pool 
26/01/12 02:35:34 INFO DAGScheduler: ResultStage 139 (parquet at <unknown>:0) finished in 32.386 s
26/01/12 02:35:34 INFO DAGScheduler: Job 139 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:35:34 INFO TaskSchedulerImpl: Killing all running tasks in stage 139: Stage finished
26/01/12 02:35:34 INFO DAGScheduler: Job 139 finished: parquet at <unknown>:0, took 32.394444 s
26/01/12 02:35:34 INFO FileFormatWriter: Start to commit write Job caae39b2-bbd8-4b13-8375-b7b7f0962455.
26/01/12 02:35:34 INFO FileFormatWriter: Write Job caae39b2-bbd8-4b13-8375-b7b7f0962455 committed. Elapsed time: 30 ms.
26/01/12 02:35:34 INFO FileFormatWriter: Finished processing stats for write job caae39b2-bbd8-4b13-8375-b7b7f0962455.
Cargando: yellow_tripdata_2014-11.parquet en hdfs://hadoop-namenode:8020/data/nyc/raw/taxi-trips/2014...
26/01/12 02:35:35 INFO InMemoryFileIndex: It took 6 ms to list leaf files for 1 paths.
26/01/12 02:35:35 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 02:35:35 INFO DAGScheduler: Got job 140 (parquet at <unknown>:0) with 1 output partitions
26/01/12 02:35:35 INFO DAGScheduler: Final stage: ResultStage 140 (parquet at <unknown>:0)
26/01/12 02:35:35 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:35:35 INFO DAGScheduler: Missing parents: List()
26/01/12 02:35:35 INFO DAGScheduler: Submitting ResultStage 140 (MapPartitionsRDD[351] at parquet at <unknown>:0), which has no missing parents
26/01/12 02:35:35 INFO MemoryStore: Block broadcast_210 stored as values in memory (estimated size 102.6 KiB, free 361.9 MiB)
26/01/12 02:35:35 INFO MemoryStore: Block broadcast_210_piece0 stored as bytes in memory (estimated size 36.8 KiB, free 361.8 MiB)
26/01/12 02:35:35 INFO BlockManagerInfo: Added broadcast_210_piece0 in memory on 02926ee04bc9:45221 (size: 36.8 KiB, free: 365.5 MiB)
26/01/12 02:35:35 INFO SparkContext: Created broadcast 210 from broadcast at DAGScheduler.scala:1513
26/01/12 02:35:35 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 140 (MapPartitionsRDD[351] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0))
26/01/12 02:35:35 INFO TaskSchedulerImpl: Adding task set 140.0 with 1 tasks resource profile 0
26/01/12 02:35:35 INFO TaskSetManager: Starting task 0.0 in stage 140.0 (TID 257) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4607 bytes) taskResourceAssignments Map()
26/01/12 02:35:35 INFO BlockManagerInfo: Added broadcast_210_piece0 in memory on 172.18.0.5:42453 (size: 36.8 KiB, free: 365.5 MiB)
26/01/12 02:35:35 INFO TaskSetManager: Finished task 0.0 in stage 140.0 (TID 257) in 49 ms on 172.18.0.5 (executor 0) (1/1)
26/01/12 02:35:35 INFO TaskSchedulerImpl: Removed TaskSet 140.0, whose tasks have all completed, from pool 
26/01/12 02:35:35 INFO DAGScheduler: ResultStage 140 (parquet at <unknown>:0) finished in 0.060 s
26/01/12 02:35:35 INFO DAGScheduler: Job 140 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:35:35 INFO TaskSchedulerImpl: Killing all running tasks in stage 140: Stage finished
26/01/12 02:35:35 INFO DAGScheduler: Job 140 finished: parquet at <unknown>:0, took 0.064479 s
26/01/12 02:35:35 INFO FileSourceStrategy: Pushed Filters: 
26/01/12 02:35:35 INFO FileSourceStrategy: Post-Scan Filters: 
26/01/12 02:35:35 INFO FileSourceStrategy: Output Data Schema: struct<VendorID: bigint, tpep_pickup_datetime: timestamp, tpep_dropoff_datetime: timestamp, passenger_count: bigint, trip_distance: double ... 17 more fields>
26/01/12 02:35:35 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:35:35 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:35:35 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:35:35 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:35:35 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:35:35 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:35:35 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:35:35 INFO BlockManagerInfo: Removed broadcast_196_piece0 on 02926ee04bc9:45221 in memory (size: 35.4 KiB, free: 365.6 MiB)
26/01/12 02:35:35 INFO BlockManagerInfo: Removed broadcast_196_piece0 on 172.18.0.5:42453 in memory (size: 35.4 KiB, free: 365.6 MiB)
26/01/12 02:35:35 INFO MemoryStore: Block broadcast_211 stored as values in memory (estimated size 358.4 KiB, free 361.9 MiB)
26/01/12 02:35:35 INFO BlockManagerInfo: Removed broadcast_198_piece0 on 02926ee04bc9:45221 in memory (size: 36.8 KiB, free: 365.6 MiB)
26/01/12 02:35:35 INFO BlockManagerInfo: Removed broadcast_198_piece0 on 172.18.0.5:42453 in memory (size: 36.8 KiB, free: 365.6 MiB)
26/01/12 02:35:35 INFO BlockManagerInfo: Removed broadcast_209_piece0 on 02926ee04bc9:45221 in memory (size: 77.4 KiB, free: 365.7 MiB)
26/01/12 02:35:35 INFO MemoryStore: Block broadcast_211_piece0 stored as bytes in memory (estimated size 35.4 KiB, free 362.3 MiB)
26/01/12 02:35:35 INFO BlockManagerInfo: Removed broadcast_209_piece0 on 172.18.0.5:42453 in memory (size: 77.4 KiB, free: 365.7 MiB)
26/01/12 02:35:35 INFO BlockManagerInfo: Added broadcast_211_piece0 in memory on 02926ee04bc9:45221 (size: 35.4 KiB, free: 365.6 MiB)
26/01/12 02:35:35 INFO SparkContext: Created broadcast 211 from parquet at <unknown>:0
26/01/12 02:35:35 INFO FileSourceScanExec: Planning scan with bin packing, max size: 92642822 bytes, open cost is considered as scanning 4194304 bytes.
26/01/12 02:35:35 INFO BlockManagerInfo: Removed broadcast_207_piece0 on 02926ee04bc9:45221 in memory (size: 36.8 KiB, free: 365.7 MiB)
26/01/12 02:35:35 INFO BlockManagerInfo: Removed broadcast_207_piece0 on 172.18.0.5:42453 in memory (size: 36.8 KiB, free: 365.7 MiB)
26/01/12 02:35:35 INFO BlockManagerInfo: Removed broadcast_201_piece0 on 02926ee04bc9:45221 in memory (size: 36.8 KiB, free: 365.7 MiB)
26/01/12 02:35:35 INFO BlockManagerInfo: Removed broadcast_201_piece0 on 172.18.0.5:42453 in memory (size: 36.8 KiB, free: 365.8 MiB)
26/01/12 02:35:35 INFO BlockManagerInfo: Removed broadcast_208_piece0 on 02926ee04bc9:45221 in memory (size: 35.4 KiB, free: 365.8 MiB)
26/01/12 02:35:35 INFO BlockManagerInfo: Removed broadcast_208_piece0 on 172.18.0.5:42453 in memory (size: 35.4 KiB, free: 365.8 MiB)
26/01/12 02:35:35 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 02:35:35 INFO DAGScheduler: Got job 141 (parquet at <unknown>:0) with 2 output partitions
26/01/12 02:35:35 INFO DAGScheduler: Final stage: ResultStage 141 (parquet at <unknown>:0)
26/01/12 02:35:35 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:35:35 INFO DAGScheduler: Missing parents: List()
26/01/12 02:35:35 INFO BlockManagerInfo: Removed broadcast_205_piece0 on 02926ee04bc9:45221 in memory (size: 35.4 KiB, free: 365.8 MiB)
26/01/12 02:35:35 INFO DAGScheduler: Submitting ResultStage 141 (MapPartitionsRDD[354] at parquet at <unknown>:0), which has no missing parents
26/01/12 02:35:35 INFO BlockManagerInfo: Removed broadcast_205_piece0 on 172.18.0.5:42453 in memory (size: 35.4 KiB, free: 365.8 MiB)
26/01/12 02:35:35 INFO BlockManagerInfo: Removed broadcast_204_piece0 on 02926ee04bc9:45221 in memory (size: 36.8 KiB, free: 365.8 MiB)
26/01/12 02:35:35 INFO BlockManagerInfo: Removed broadcast_204_piece0 on 172.18.0.5:42453 in memory (size: 36.8 KiB, free: 365.9 MiB)
26/01/12 02:35:35 INFO BlockManagerInfo: Removed broadcast_199_piece0 on 02926ee04bc9:45221 in memory (size: 35.4 KiB, free: 365.9 MiB)
26/01/12 02:35:35 INFO BlockManagerInfo: Removed broadcast_199_piece0 on 172.18.0.5:42453 in memory (size: 35.4 KiB, free: 365.9 MiB)
26/01/12 02:35:35 INFO MemoryStore: Block broadcast_212 stored as values in memory (estimated size 225.1 KiB, free 363.6 MiB)
26/01/12 02:35:35 INFO BlockManagerInfo: Removed broadcast_202_piece0 on 02926ee04bc9:45221 in memory (size: 35.4 KiB, free: 365.9 MiB)
26/01/12 02:35:35 INFO MemoryStore: Block broadcast_212_piece0 stored as bytes in memory (estimated size 77.4 KiB, free 363.9 MiB)
26/01/12 02:35:35 INFO BlockManagerInfo: Removed broadcast_202_piece0 on 172.18.0.5:42453 in memory (size: 35.4 KiB, free: 365.9 MiB)
26/01/12 02:35:35 INFO BlockManagerInfo: Added broadcast_212_piece0 in memory on 02926ee04bc9:45221 (size: 77.4 KiB, free: 365.8 MiB)
26/01/12 02:35:35 INFO SparkContext: Created broadcast 212 from broadcast at DAGScheduler.scala:1513
26/01/12 02:35:35 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 141 (MapPartitionsRDD[354] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1))
26/01/12 02:35:35 INFO TaskSchedulerImpl: Adding task set 141.0 with 2 tasks resource profile 0
26/01/12 02:35:35 INFO TaskSetManager: Starting task 0.0 in stage 141.0 (TID 258) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:35:35 INFO TaskSetManager: Starting task 1.0 in stage 141.0 (TID 259) (172.18.0.5, executor 0, partition 1, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:35:35 INFO BlockManagerInfo: Removed broadcast_203_piece0 on 02926ee04bc9:45221 in memory (size: 77.4 KiB, free: 365.9 MiB)
26/01/12 02:35:35 INFO BlockManagerInfo: Removed broadcast_203_piece0 on 172.18.0.5:42453 in memory (size: 77.4 KiB, free: 366.0 MiB)
26/01/12 02:35:35 INFO BlockManagerInfo: Removed broadcast_210_piece0 on 02926ee04bc9:45221 in memory (size: 36.8 KiB, free: 365.9 MiB)
26/01/12 02:35:35 INFO BlockManagerInfo: Added broadcast_212_piece0 in memory on 172.18.0.5:42453 (size: 77.4 KiB, free: 365.9 MiB)
26/01/12 02:35:35 INFO BlockManagerInfo: Removed broadcast_210_piece0 on 172.18.0.5:42453 in memory (size: 36.8 KiB, free: 366.0 MiB)
26/01/12 02:35:35 INFO BlockManagerInfo: Removed broadcast_200_piece0 on 02926ee04bc9:45221 in memory (size: 77.4 KiB, free: 366.0 MiB)
26/01/12 02:35:35 INFO BlockManagerInfo: Removed broadcast_200_piece0 on 172.18.0.5:42453 in memory (size: 77.4 KiB, free: 366.0 MiB)
26/01/12 02:35:35 INFO BlockManagerInfo: Removed broadcast_206_piece0 on 02926ee04bc9:45221 in memory (size: 77.4 KiB, free: 366.1 MiB)
26/01/12 02:35:35 INFO BlockManagerInfo: Removed broadcast_206_piece0 on 172.18.0.5:42453 in memory (size: 77.4 KiB, free: 366.1 MiB)
26/01/12 02:35:35 INFO BlockManagerInfo: Added broadcast_211_piece0 in memory on 172.18.0.5:42453 (size: 35.4 KiB, free: 366.1 MiB)
26/01/12 02:35:35 INFO TaskSetManager: Finished task 1.0 in stage 141.0 (TID 259) in 74 ms on 172.18.0.5 (executor 0) (1/2)
26/01/12 02:36:04 INFO TaskSetManager: Finished task 0.0 in stage 141.0 (TID 258) in 28824 ms on 172.18.0.5 (executor 0) (2/2)
26/01/12 02:36:04 INFO TaskSchedulerImpl: Removed TaskSet 141.0, whose tasks have all completed, from pool 
26/01/12 02:36:04 INFO DAGScheduler: ResultStage 141 (parquet at <unknown>:0) finished in 28.847 s
26/01/12 02:36:04 INFO DAGScheduler: Job 141 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:36:04 INFO TaskSchedulerImpl: Killing all running tasks in stage 141: Stage finished
26/01/12 02:36:04 INFO DAGScheduler: Job 141 finished: parquet at <unknown>:0, took 28.853948 s
26/01/12 02:36:04 INFO FileFormatWriter: Start to commit write Job 8b093fcc-fba5-4521-aae9-ee769688c155.
26/01/12 02:36:04 INFO FileFormatWriter: Write Job 8b093fcc-fba5-4521-aae9-ee769688c155 committed. Elapsed time: 32 ms.
26/01/12 02:36:04 INFO FileFormatWriter: Finished processing stats for write job 8b093fcc-fba5-4521-aae9-ee769688c155.
Cargando: yellow_tripdata_2014-12.parquet en hdfs://hadoop-namenode:8020/data/nyc/raw/taxi-trips/2014...
26/01/12 02:36:04 INFO InMemoryFileIndex: It took 6 ms to list leaf files for 1 paths.
26/01/12 02:36:04 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 02:36:04 INFO DAGScheduler: Got job 142 (parquet at <unknown>:0) with 1 output partitions
26/01/12 02:36:04 INFO DAGScheduler: Final stage: ResultStage 142 (parquet at <unknown>:0)
26/01/12 02:36:04 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:36:04 INFO DAGScheduler: Missing parents: List()
26/01/12 02:36:04 INFO DAGScheduler: Submitting ResultStage 142 (MapPartitionsRDD[356] at parquet at <unknown>:0), which has no missing parents
26/01/12 02:36:04 INFO MemoryStore: Block broadcast_213 stored as values in memory (estimated size 102.6 KiB, free 364.8 MiB)
26/01/12 02:36:04 INFO MemoryStore: Block broadcast_213_piece0 stored as bytes in memory (estimated size 36.8 KiB, free 364.8 MiB)
26/01/12 02:36:04 INFO BlockManagerInfo: Added broadcast_213_piece0 in memory on 02926ee04bc9:45221 (size: 36.8 KiB, free: 366.0 MiB)
26/01/12 02:36:04 INFO SparkContext: Created broadcast 213 from broadcast at DAGScheduler.scala:1513
26/01/12 02:36:04 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 142 (MapPartitionsRDD[356] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0))
26/01/12 02:36:04 INFO TaskSchedulerImpl: Adding task set 142.0 with 1 tasks resource profile 0
26/01/12 02:36:04 INFO TaskSetManager: Starting task 0.0 in stage 142.0 (TID 260) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4607 bytes) taskResourceAssignments Map()
26/01/12 02:36:04 INFO BlockManagerInfo: Added broadcast_213_piece0 in memory on 172.18.0.5:42453 (size: 36.8 KiB, free: 366.0 MiB)
26/01/12 02:36:04 INFO TaskSetManager: Finished task 0.0 in stage 142.0 (TID 260) in 49 ms on 172.18.0.5 (executor 0) (1/1)
26/01/12 02:36:04 INFO TaskSchedulerImpl: Removed TaskSet 142.0, whose tasks have all completed, from pool 
26/01/12 02:36:04 INFO DAGScheduler: ResultStage 142 (parquet at <unknown>:0) finished in 0.061 s
26/01/12 02:36:04 INFO DAGScheduler: Job 142 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:36:04 INFO TaskSchedulerImpl: Killing all running tasks in stage 142: Stage finished
26/01/12 02:36:04 INFO DAGScheduler: Job 142 finished: parquet at <unknown>:0, took 0.066034 s
26/01/12 02:36:04 INFO FileSourceStrategy: Pushed Filters: 
26/01/12 02:36:04 INFO FileSourceStrategy: Post-Scan Filters: 
26/01/12 02:36:04 INFO FileSourceStrategy: Output Data Schema: struct<VendorID: bigint, tpep_pickup_datetime: timestamp, tpep_dropoff_datetime: timestamp, passenger_count: bigint, trip_distance: double ... 17 more fields>
26/01/12 02:36:04 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:36:04 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:36:04 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:36:04 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:36:04 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:36:04 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:36:04 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:36:04 INFO MemoryStore: Block broadcast_214 stored as values in memory (estimated size 358.4 KiB, free 364.5 MiB)
26/01/12 02:36:04 INFO MemoryStore: Block broadcast_214_piece0 stored as bytes in memory (estimated size 35.4 KiB, free 364.4 MiB)
26/01/12 02:36:04 INFO BlockManagerInfo: Added broadcast_214_piece0 in memory on 02926ee04bc9:45221 (size: 35.4 KiB, free: 366.0 MiB)
26/01/12 02:36:04 INFO SparkContext: Created broadcast 214 from parquet at <unknown>:0
26/01/12 02:36:04 INFO FileSourceScanExec: Planning scan with bin packing, max size: 91599095 bytes, open cost is considered as scanning 4194304 bytes.
26/01/12 02:36:04 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 02:36:04 INFO DAGScheduler: Got job 143 (parquet at <unknown>:0) with 2 output partitions
26/01/12 02:36:04 INFO DAGScheduler: Final stage: ResultStage 143 (parquet at <unknown>:0)
26/01/12 02:36:04 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:36:04 INFO DAGScheduler: Missing parents: List()
26/01/12 02:36:04 INFO DAGScheduler: Submitting ResultStage 143 (MapPartitionsRDD[359] at parquet at <unknown>:0), which has no missing parents
26/01/12 02:36:04 INFO MemoryStore: Block broadcast_215 stored as values in memory (estimated size 225.1 KiB, free 364.2 MiB)
26/01/12 02:36:04 INFO MemoryStore: Block broadcast_215_piece0 stored as bytes in memory (estimated size 77.4 KiB, free 364.1 MiB)
26/01/12 02:36:04 INFO BlockManagerInfo: Added broadcast_215_piece0 in memory on 02926ee04bc9:45221 (size: 77.4 KiB, free: 365.9 MiB)
26/01/12 02:36:04 INFO SparkContext: Created broadcast 215 from broadcast at DAGScheduler.scala:1513
26/01/12 02:36:04 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 143 (MapPartitionsRDD[359] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1))
26/01/12 02:36:04 INFO TaskSchedulerImpl: Adding task set 143.0 with 2 tasks resource profile 0
26/01/12 02:36:04 INFO TaskSetManager: Starting task 0.0 in stage 143.0 (TID 261) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:36:04 INFO TaskSetManager: Starting task 1.0 in stage 143.0 (TID 262) (172.18.0.5, executor 0, partition 1, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:36:04 INFO BlockManagerInfo: Added broadcast_215_piece0 in memory on 172.18.0.5:42453 (size: 77.4 KiB, free: 366.0 MiB)
26/01/12 02:36:04 INFO BlockManagerInfo: Added broadcast_214_piece0 in memory on 172.18.0.5:42453 (size: 35.4 KiB, free: 365.9 MiB)
26/01/12 02:36:04 INFO TaskSetManager: Finished task 1.0 in stage 143.0 (TID 262) in 60 ms on 172.18.0.5 (executor 0) (1/2)
26/01/12 02:36:33 INFO TaskSetManager: Finished task 0.0 in stage 143.0 (TID 261) in 29556 ms on 172.18.0.5 (executor 0) (2/2)
26/01/12 02:36:33 INFO TaskSchedulerImpl: Removed TaskSet 143.0, whose tasks have all completed, from pool 
26/01/12 02:36:33 INFO DAGScheduler: ResultStage 143 (parquet at <unknown>:0) finished in 29.578 s
26/01/12 02:36:33 INFO DAGScheduler: Job 143 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:36:33 INFO TaskSchedulerImpl: Killing all running tasks in stage 143: Stage finished
26/01/12 02:36:33 INFO DAGScheduler: Job 143 finished: parquet at <unknown>:0, took 29.584795 s
26/01/12 02:36:33 INFO FileFormatWriter: Start to commit write Job 20507fbf-fa48-4ed4-bdc2-ff433266be0d.
26/01/12 02:36:33 INFO FileFormatWriter: Write Job 20507fbf-fa48-4ed4-bdc2-ff433266be0d committed. Elapsed time: 33 ms.
26/01/12 02:36:33 INFO FileFormatWriter: Finished processing stats for write job 20507fbf-fa48-4ed4-bdc2-ff433266be0d.
Cargando: yellow_tripdata_2015-01.parquet en hdfs://hadoop-namenode:8020/data/nyc/raw/taxi-trips/2015...
26/01/12 02:36:33 INFO InMemoryFileIndex: It took 6 ms to list leaf files for 1 paths.
26/01/12 02:36:33 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 02:36:33 INFO DAGScheduler: Got job 144 (parquet at <unknown>:0) with 1 output partitions
26/01/12 02:36:33 INFO DAGScheduler: Final stage: ResultStage 144 (parquet at <unknown>:0)
26/01/12 02:36:33 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:36:33 INFO DAGScheduler: Missing parents: List()
26/01/12 02:36:33 INFO DAGScheduler: Submitting ResultStage 144 (MapPartitionsRDD[361] at parquet at <unknown>:0), which has no missing parents
26/01/12 02:36:33 INFO MemoryStore: Block broadcast_216 stored as values in memory (estimated size 102.6 KiB, free 364.0 MiB)
26/01/12 02:36:33 INFO MemoryStore: Block broadcast_216_piece0 stored as bytes in memory (estimated size 36.8 KiB, free 364.0 MiB)
26/01/12 02:36:33 INFO BlockManagerInfo: Added broadcast_216_piece0 in memory on 02926ee04bc9:45221 (size: 36.8 KiB, free: 365.9 MiB)
26/01/12 02:36:33 INFO SparkContext: Created broadcast 216 from broadcast at DAGScheduler.scala:1513
26/01/12 02:36:33 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 144 (MapPartitionsRDD[361] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0))
26/01/12 02:36:33 INFO TaskSchedulerImpl: Adding task set 144.0 with 1 tasks resource profile 0
26/01/12 02:36:33 INFO TaskSetManager: Starting task 0.0 in stage 144.0 (TID 263) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4607 bytes) taskResourceAssignments Map()
26/01/12 02:36:33 INFO BlockManagerInfo: Added broadcast_216_piece0 in memory on 172.18.0.5:42453 (size: 36.8 KiB, free: 365.9 MiB)
26/01/12 02:36:33 INFO TaskSetManager: Finished task 0.0 in stage 144.0 (TID 263) in 49 ms on 172.18.0.5 (executor 0) (1/1)
26/01/12 02:36:33 INFO TaskSchedulerImpl: Removed TaskSet 144.0, whose tasks have all completed, from pool 
26/01/12 02:36:33 INFO DAGScheduler: ResultStage 144 (parquet at <unknown>:0) finished in 0.062 s
26/01/12 02:36:33 INFO DAGScheduler: Job 144 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:36:33 INFO TaskSchedulerImpl: Killing all running tasks in stage 144: Stage finished
26/01/12 02:36:33 INFO DAGScheduler: Job 144 finished: parquet at <unknown>:0, took 0.066860 s
26/01/12 02:36:33 INFO FileSourceStrategy: Pushed Filters: 
26/01/12 02:36:33 INFO FileSourceStrategy: Post-Scan Filters: 
26/01/12 02:36:33 INFO FileSourceStrategy: Output Data Schema: struct<VendorID: bigint, tpep_pickup_datetime: timestamp, tpep_dropoff_datetime: timestamp, passenger_count: bigint, trip_distance: double ... 17 more fields>
26/01/12 02:36:33 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:36:33 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:36:33 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:36:33 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:36:33 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:36:33 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:36:33 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:36:34 INFO MemoryStore: Block broadcast_217 stored as values in memory (estimated size 358.4 KiB, free 363.6 MiB)
26/01/12 02:36:34 INFO MemoryStore: Block broadcast_217_piece0 stored as bytes in memory (estimated size 35.4 KiB, free 363.6 MiB)
26/01/12 02:36:34 INFO BlockManagerInfo: Added broadcast_217_piece0 in memory on 02926ee04bc9:45221 (size: 35.4 KiB, free: 365.9 MiB)
26/01/12 02:36:34 INFO SparkContext: Created broadcast 217 from parquet at <unknown>:0
26/01/12 02:36:34 INFO FileSourceScanExec: Planning scan with bin packing, max size: 89760035 bytes, open cost is considered as scanning 4194304 bytes.
26/01/12 02:36:34 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 02:36:34 INFO DAGScheduler: Got job 145 (parquet at <unknown>:0) with 2 output partitions
26/01/12 02:36:34 INFO DAGScheduler: Final stage: ResultStage 145 (parquet at <unknown>:0)
26/01/12 02:36:34 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:36:34 INFO DAGScheduler: Missing parents: List()
26/01/12 02:36:34 INFO DAGScheduler: Submitting ResultStage 145 (MapPartitionsRDD[364] at parquet at <unknown>:0), which has no missing parents
26/01/12 02:36:34 INFO MemoryStore: Block broadcast_218 stored as values in memory (estimated size 225.1 KiB, free 363.4 MiB)
26/01/12 02:36:34 INFO MemoryStore: Block broadcast_218_piece0 stored as bytes in memory (estimated size 77.4 KiB, free 363.3 MiB)
26/01/12 02:36:34 INFO BlockManagerInfo: Added broadcast_218_piece0 in memory on 02926ee04bc9:45221 (size: 77.4 KiB, free: 365.8 MiB)
26/01/12 02:36:34 INFO SparkContext: Created broadcast 218 from broadcast at DAGScheduler.scala:1513
26/01/12 02:36:34 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 145 (MapPartitionsRDD[364] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1))
26/01/12 02:36:34 INFO TaskSchedulerImpl: Adding task set 145.0 with 2 tasks resource profile 0
26/01/12 02:36:34 INFO TaskSetManager: Starting task 0.0 in stage 145.0 (TID 264) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:36:34 INFO TaskSetManager: Starting task 1.0 in stage 145.0 (TID 265) (172.18.0.5, executor 0, partition 1, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:36:34 INFO BlockManagerInfo: Added broadcast_218_piece0 in memory on 172.18.0.5:42453 (size: 77.4 KiB, free: 365.8 MiB)
26/01/12 02:36:34 INFO BlockManagerInfo: Added broadcast_217_piece0 in memory on 172.18.0.5:42453 (size: 35.4 KiB, free: 365.8 MiB)
26/01/12 02:36:34 INFO TaskSetManager: Finished task 1.0 in stage 145.0 (TID 265) in 55 ms on 172.18.0.5 (executor 0) (1/2)
26/01/12 02:37:03 INFO TaskSetManager: Finished task 0.0 in stage 145.0 (TID 264) in 29260 ms on 172.18.0.5 (executor 0) (2/2)
26/01/12 02:37:03 INFO TaskSchedulerImpl: Removed TaskSet 145.0, whose tasks have all completed, from pool 
26/01/12 02:37:03 INFO DAGScheduler: ResultStage 145 (parquet at <unknown>:0) finished in 29.279 s
26/01/12 02:37:03 INFO DAGScheduler: Job 145 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:37:03 INFO TaskSchedulerImpl: Killing all running tasks in stage 145: Stage finished
26/01/12 02:37:03 INFO DAGScheduler: Job 145 finished: parquet at <unknown>:0, took 29.287389 s
26/01/12 02:37:03 INFO FileFormatWriter: Start to commit write Job 0a368cd0-39ed-46cf-b5eb-cc98dc4abc23.
26/01/12 02:37:03 INFO FileFormatWriter: Write Job 0a368cd0-39ed-46cf-b5eb-cc98dc4abc23 committed. Elapsed time: 33 ms.
26/01/12 02:37:03 INFO FileFormatWriter: Finished processing stats for write job 0a368cd0-39ed-46cf-b5eb-cc98dc4abc23.
Cargando: yellow_tripdata_2015-02.parquet en hdfs://hadoop-namenode:8020/data/nyc/raw/taxi-trips/2015...
26/01/12 02:37:03 INFO InMemoryFileIndex: It took 6 ms to list leaf files for 1 paths.
26/01/12 02:37:03 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 02:37:03 INFO DAGScheduler: Got job 146 (parquet at <unknown>:0) with 1 output partitions
26/01/12 02:37:03 INFO DAGScheduler: Final stage: ResultStage 146 (parquet at <unknown>:0)
26/01/12 02:37:03 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:37:03 INFO DAGScheduler: Missing parents: List()
26/01/12 02:37:03 INFO DAGScheduler: Submitting ResultStage 146 (MapPartitionsRDD[366] at parquet at <unknown>:0), which has no missing parents
26/01/12 02:37:03 INFO MemoryStore: Block broadcast_219 stored as values in memory (estimated size 102.6 KiB, free 363.2 MiB)
26/01/12 02:37:03 INFO MemoryStore: Block broadcast_219_piece0 stored as bytes in memory (estimated size 36.8 KiB, free 363.2 MiB)
26/01/12 02:37:03 INFO BlockManagerInfo: Added broadcast_219_piece0 in memory on 02926ee04bc9:45221 (size: 36.8 KiB, free: 365.8 MiB)
26/01/12 02:37:03 INFO SparkContext: Created broadcast 219 from broadcast at DAGScheduler.scala:1513
26/01/12 02:37:03 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 146 (MapPartitionsRDD[366] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0))
26/01/12 02:37:03 INFO TaskSchedulerImpl: Adding task set 146.0 with 1 tasks resource profile 0
26/01/12 02:37:03 INFO TaskSetManager: Starting task 0.0 in stage 146.0 (TID 266) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4607 bytes) taskResourceAssignments Map()
26/01/12 02:37:03 INFO BlockManagerInfo: Added broadcast_219_piece0 in memory on 172.18.0.5:42453 (size: 36.8 KiB, free: 365.8 MiB)
26/01/12 02:37:03 INFO TaskSetManager: Finished task 0.0 in stage 146.0 (TID 266) in 46 ms on 172.18.0.5 (executor 0) (1/1)
26/01/12 02:37:03 INFO TaskSchedulerImpl: Removed TaskSet 146.0, whose tasks have all completed, from pool 
26/01/12 02:37:03 INFO DAGScheduler: ResultStage 146 (parquet at <unknown>:0) finished in 0.058 s
26/01/12 02:37:03 INFO DAGScheduler: Job 146 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:37:03 INFO TaskSchedulerImpl: Killing all running tasks in stage 146: Stage finished
26/01/12 02:37:03 INFO DAGScheduler: Job 146 finished: parquet at <unknown>:0, took 0.065516 s
26/01/12 02:37:03 INFO FileSourceStrategy: Pushed Filters: 
26/01/12 02:37:03 INFO FileSourceStrategy: Post-Scan Filters: 
26/01/12 02:37:03 INFO FileSourceStrategy: Output Data Schema: struct<VendorID: bigint, tpep_pickup_datetime: timestamp, tpep_dropoff_datetime: timestamp, passenger_count: bigint, trip_distance: double ... 17 more fields>
26/01/12 02:37:03 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:37:03 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:37:03 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:37:03 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:37:03 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:37:03 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:37:03 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:37:03 INFO MemoryStore: Block broadcast_220 stored as values in memory (estimated size 358.4 KiB, free 362.8 MiB)
26/01/12 02:37:03 INFO MemoryStore: Block broadcast_220_piece0 stored as bytes in memory (estimated size 35.4 KiB, free 362.8 MiB)
26/01/12 02:37:03 INFO BlockManagerInfo: Added broadcast_220_piece0 in memory on 02926ee04bc9:45221 (size: 35.4 KiB, free: 365.7 MiB)
26/01/12 02:37:03 INFO SparkContext: Created broadcast 220 from parquet at <unknown>:0
26/01/12 02:37:03 INFO FileSourceScanExec: Planning scan with bin packing, max size: 87917022 bytes, open cost is considered as scanning 4194304 bytes.
26/01/12 02:37:03 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 02:37:03 INFO DAGScheduler: Got job 147 (parquet at <unknown>:0) with 2 output partitions
26/01/12 02:37:03 INFO DAGScheduler: Final stage: ResultStage 147 (parquet at <unknown>:0)
26/01/12 02:37:03 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:37:03 INFO DAGScheduler: Missing parents: List()
26/01/12 02:37:03 INFO DAGScheduler: Submitting ResultStage 147 (MapPartitionsRDD[369] at parquet at <unknown>:0), which has no missing parents
26/01/12 02:37:03 INFO MemoryStore: Block broadcast_221 stored as values in memory (estimated size 225.1 KiB, free 362.6 MiB)
26/01/12 02:37:03 INFO MemoryStore: Block broadcast_221_piece0 stored as bytes in memory (estimated size 77.4 KiB, free 362.5 MiB)
26/01/12 02:37:03 INFO BlockManagerInfo: Added broadcast_221_piece0 in memory on 02926ee04bc9:45221 (size: 77.4 KiB, free: 365.6 MiB)
26/01/12 02:37:03 INFO SparkContext: Created broadcast 221 from broadcast at DAGScheduler.scala:1513
26/01/12 02:37:03 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 147 (MapPartitionsRDD[369] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1))
26/01/12 02:37:03 INFO TaskSchedulerImpl: Adding task set 147.0 with 2 tasks resource profile 0
26/01/12 02:37:03 INFO TaskSetManager: Starting task 0.0 in stage 147.0 (TID 267) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:37:03 INFO TaskSetManager: Starting task 1.0 in stage 147.0 (TID 268) (172.18.0.5, executor 0, partition 1, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:37:03 INFO BlockManagerInfo: Added broadcast_221_piece0 in memory on 172.18.0.5:42453 (size: 77.4 KiB, free: 365.7 MiB)
26/01/12 02:37:03 INFO BlockManagerInfo: Added broadcast_220_piece0 in memory on 172.18.0.5:42453 (size: 35.4 KiB, free: 365.6 MiB)
26/01/12 02:37:03 INFO TaskSetManager: Finished task 1.0 in stage 147.0 (TID 268) in 60 ms on 172.18.0.5 (executor 0) (1/2)
26/01/12 02:37:31 INFO TaskSetManager: Finished task 0.0 in stage 147.0 (TID 267) in 28249 ms on 172.18.0.5 (executor 0) (2/2)
26/01/12 02:37:31 INFO TaskSchedulerImpl: Removed TaskSet 147.0, whose tasks have all completed, from pool 
26/01/12 02:37:31 INFO DAGScheduler: ResultStage 147 (parquet at <unknown>:0) finished in 28.269 s
26/01/12 02:37:31 INFO DAGScheduler: Job 147 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:37:31 INFO TaskSchedulerImpl: Killing all running tasks in stage 147: Stage finished
26/01/12 02:37:31 INFO DAGScheduler: Job 147 finished: parquet at <unknown>:0, took 28.278660 s
26/01/12 02:37:31 INFO FileFormatWriter: Start to commit write Job bdafad7c-cd9c-4b02-b5dd-75ee27162b9f.
26/01/12 02:37:31 INFO FileFormatWriter: Write Job bdafad7c-cd9c-4b02-b5dd-75ee27162b9f committed. Elapsed time: 34 ms.
26/01/12 02:37:31 INFO FileFormatWriter: Finished processing stats for write job bdafad7c-cd9c-4b02-b5dd-75ee27162b9f.
Cargando: yellow_tripdata_2015-03.parquet en hdfs://hadoop-namenode:8020/data/nyc/raw/taxi-trips/2015...
26/01/12 02:37:31 INFO InMemoryFileIndex: It took 7 ms to list leaf files for 1 paths.
26/01/12 02:37:31 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 02:37:31 INFO DAGScheduler: Got job 148 (parquet at <unknown>:0) with 1 output partitions
26/01/12 02:37:31 INFO DAGScheduler: Final stage: ResultStage 148 (parquet at <unknown>:0)
26/01/12 02:37:31 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:37:31 INFO DAGScheduler: Missing parents: List()
26/01/12 02:37:31 INFO DAGScheduler: Submitting ResultStage 148 (MapPartitionsRDD[371] at parquet at <unknown>:0), which has no missing parents
26/01/12 02:37:31 INFO MemoryStore: Block broadcast_222 stored as values in memory (estimated size 102.6 KiB, free 362.4 MiB)
26/01/12 02:37:31 INFO MemoryStore: Block broadcast_222_piece0 stored as bytes in memory (estimated size 36.8 KiB, free 362.4 MiB)
26/01/12 02:37:31 INFO BlockManagerInfo: Added broadcast_222_piece0 in memory on 02926ee04bc9:45221 (size: 36.8 KiB, free: 365.6 MiB)
26/01/12 02:37:31 INFO SparkContext: Created broadcast 222 from broadcast at DAGScheduler.scala:1513
26/01/12 02:37:31 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 148 (MapPartitionsRDD[371] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0))
26/01/12 02:37:31 INFO TaskSchedulerImpl: Adding task set 148.0 with 1 tasks resource profile 0
26/01/12 02:37:31 INFO TaskSetManager: Starting task 0.0 in stage 148.0 (TID 269) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4607 bytes) taskResourceAssignments Map()
26/01/12 02:37:31 INFO BlockManagerInfo: Added broadcast_222_piece0 in memory on 172.18.0.5:42453 (size: 36.8 KiB, free: 365.6 MiB)
26/01/12 02:37:31 INFO TaskSetManager: Finished task 0.0 in stage 148.0 (TID 269) in 50 ms on 172.18.0.5 (executor 0) (1/1)
26/01/12 02:37:31 INFO TaskSchedulerImpl: Removed TaskSet 148.0, whose tasks have all completed, from pool 
26/01/12 02:37:31 INFO DAGScheduler: ResultStage 148 (parquet at <unknown>:0) finished in 0.062 s
26/01/12 02:37:31 INFO DAGScheduler: Job 148 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:37:31 INFO TaskSchedulerImpl: Killing all running tasks in stage 148: Stage finished
26/01/12 02:37:31 INFO DAGScheduler: Job 148 finished: parquet at <unknown>:0, took 0.066866 s
26/01/12 02:37:31 INFO FileSourceStrategy: Pushed Filters: 
26/01/12 02:37:31 INFO FileSourceStrategy: Post-Scan Filters: 
26/01/12 02:37:31 INFO FileSourceStrategy: Output Data Schema: struct<VendorID: bigint, tpep_pickup_datetime: timestamp, tpep_dropoff_datetime: timestamp, passenger_count: bigint, trip_distance: double ... 17 more fields>
26/01/12 02:37:31 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:37:31 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:37:31 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:37:31 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:37:31 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:37:31 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:37:31 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:37:31 INFO MemoryStore: Block broadcast_223 stored as values in memory (estimated size 358.4 KiB, free 362.0 MiB)
26/01/12 02:37:31 INFO MemoryStore: Block broadcast_223_piece0 stored as bytes in memory (estimated size 35.4 KiB, free 362.0 MiB)
26/01/12 02:37:31 INFO BlockManagerInfo: Added broadcast_223_piece0 in memory on 02926ee04bc9:45221 (size: 35.4 KiB, free: 365.6 MiB)
26/01/12 02:37:31 INFO SparkContext: Created broadcast 223 from parquet at <unknown>:0
26/01/12 02:37:31 INFO FileSourceScanExec: Planning scan with bin packing, max size: 94774881 bytes, open cost is considered as scanning 4194304 bytes.
26/01/12 02:37:32 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 02:37:32 INFO DAGScheduler: Got job 149 (parquet at <unknown>:0) with 2 output partitions
26/01/12 02:37:32 INFO DAGScheduler: Final stage: ResultStage 149 (parquet at <unknown>:0)
26/01/12 02:37:32 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:37:32 INFO DAGScheduler: Missing parents: List()
26/01/12 02:37:32 INFO DAGScheduler: Submitting ResultStage 149 (MapPartitionsRDD[374] at parquet at <unknown>:0), which has no missing parents
26/01/12 02:37:32 INFO MemoryStore: Block broadcast_224 stored as values in memory (estimated size 225.1 KiB, free 361.8 MiB)
26/01/12 02:37:32 INFO MemoryStore: Block broadcast_224_piece0 stored as bytes in memory (estimated size 77.4 KiB, free 361.9 MiB)
26/01/12 02:37:32 INFO BlockManagerInfo: Removed broadcast_221_piece0 on 02926ee04bc9:45221 in memory (size: 77.4 KiB, free: 365.6 MiB)
26/01/12 02:37:32 INFO BlockManagerInfo: Added broadcast_224_piece0 in memory on 02926ee04bc9:45221 (size: 77.4 KiB, free: 365.6 MiB)
26/01/12 02:37:32 INFO BlockManagerInfo: Removed broadcast_221_piece0 on 172.18.0.5:42453 in memory (size: 77.4 KiB, free: 365.7 MiB)
26/01/12 02:37:32 INFO SparkContext: Created broadcast 224 from broadcast at DAGScheduler.scala:1513
26/01/12 02:37:32 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 149 (MapPartitionsRDD[374] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1))
26/01/12 02:37:32 INFO TaskSchedulerImpl: Adding task set 149.0 with 2 tasks resource profile 0
26/01/12 02:37:32 INFO TaskSetManager: Starting task 0.0 in stage 149.0 (TID 270) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:37:32 INFO TaskSetManager: Starting task 1.0 in stage 149.0 (TID 271) (172.18.0.5, executor 0, partition 1, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:37:32 INFO BlockManagerInfo: Removed broadcast_219_piece0 on 02926ee04bc9:45221 in memory (size: 36.8 KiB, free: 365.6 MiB)
26/01/12 02:37:32 INFO BlockManagerInfo: Removed broadcast_219_piece0 on 172.18.0.5:42453 in memory (size: 36.8 KiB, free: 365.7 MiB)
26/01/12 02:37:32 INFO BlockManagerInfo: Removed broadcast_217_piece0 on 02926ee04bc9:45221 in memory (size: 35.4 KiB, free: 365.6 MiB)
26/01/12 02:37:32 INFO BlockManagerInfo: Added broadcast_224_piece0 in memory on 172.18.0.5:42453 (size: 77.4 KiB, free: 365.6 MiB)
26/01/12 02:37:32 INFO BlockManagerInfo: Removed broadcast_217_piece0 on 172.18.0.5:42453 in memory (size: 35.4 KiB, free: 365.7 MiB)
26/01/12 02:37:32 INFO BlockManagerInfo: Removed broadcast_218_piece0 on 02926ee04bc9:45221 in memory (size: 77.4 KiB, free: 365.7 MiB)
26/01/12 02:37:32 INFO BlockManagerInfo: Removed broadcast_218_piece0 on 172.18.0.5:42453 in memory (size: 77.4 KiB, free: 365.8 MiB)
26/01/12 02:37:32 INFO BlockManagerInfo: Removed broadcast_216_piece0 on 02926ee04bc9:45221 in memory (size: 36.8 KiB, free: 365.8 MiB)
26/01/12 02:37:32 INFO BlockManagerInfo: Removed broadcast_216_piece0 on 172.18.0.5:42453 in memory (size: 36.8 KiB, free: 365.8 MiB)
26/01/12 02:37:32 INFO BlockManagerInfo: Added broadcast_223_piece0 in memory on 172.18.0.5:42453 (size: 35.4 KiB, free: 365.8 MiB)
26/01/12 02:37:32 INFO BlockManagerInfo: Removed broadcast_211_piece0 on 02926ee04bc9:45221 in memory (size: 35.4 KiB, free: 365.8 MiB)
26/01/12 02:37:32 INFO BlockManagerInfo: Removed broadcast_211_piece0 on 172.18.0.5:42453 in memory (size: 35.4 KiB, free: 365.8 MiB)
26/01/12 02:37:32 INFO BlockManagerInfo: Removed broadcast_214_piece0 on 02926ee04bc9:45221 in memory (size: 35.4 KiB, free: 365.8 MiB)
26/01/12 02:37:32 INFO BlockManagerInfo: Removed broadcast_214_piece0 on 172.18.0.5:42453 in memory (size: 35.4 KiB, free: 365.8 MiB)
26/01/12 02:37:32 INFO BlockManagerInfo: Removed broadcast_212_piece0 on 02926ee04bc9:45221 in memory (size: 77.4 KiB, free: 365.9 MiB)
26/01/12 02:37:32 INFO BlockManagerInfo: Removed broadcast_212_piece0 on 172.18.0.5:42453 in memory (size: 77.4 KiB, free: 365.9 MiB)
26/01/12 02:37:32 INFO BlockManagerInfo: Removed broadcast_220_piece0 on 02926ee04bc9:45221 in memory (size: 35.4 KiB, free: 365.9 MiB)
26/01/12 02:37:32 INFO BlockManagerInfo: Removed broadcast_220_piece0 on 172.18.0.5:42453 in memory (size: 35.4 KiB, free: 365.9 MiB)
26/01/12 02:37:32 INFO BlockManagerInfo: Removed broadcast_222_piece0 on 02926ee04bc9:45221 in memory (size: 36.8 KiB, free: 366.0 MiB)
26/01/12 02:37:32 INFO BlockManagerInfo: Removed broadcast_222_piece0 on 172.18.0.5:42453 in memory (size: 36.8 KiB, free: 366.0 MiB)
26/01/12 02:37:32 INFO BlockManagerInfo: Removed broadcast_213_piece0 on 02926ee04bc9:45221 in memory (size: 36.8 KiB, free: 366.0 MiB)
26/01/12 02:37:32 INFO BlockManagerInfo: Removed broadcast_213_piece0 on 172.18.0.5:42453 in memory (size: 36.8 KiB, free: 366.0 MiB)
26/01/12 02:37:32 INFO TaskSetManager: Finished task 1.0 in stage 149.0 (TID 271) in 83 ms on 172.18.0.5 (executor 0) (1/2)
26/01/12 02:37:32 INFO BlockManagerInfo: Removed broadcast_215_piece0 on 02926ee04bc9:45221 in memory (size: 77.4 KiB, free: 366.1 MiB)
26/01/12 02:37:32 INFO BlockManagerInfo: Removed broadcast_215_piece0 on 172.18.0.5:42453 in memory (size: 77.4 KiB, free: 366.1 MiB)
26/01/12 02:38:02 INFO TaskSetManager: Finished task 0.0 in stage 149.0 (TID 270) in 30256 ms on 172.18.0.5 (executor 0) (2/2)
26/01/12 02:38:02 INFO TaskSchedulerImpl: Removed TaskSet 149.0, whose tasks have all completed, from pool 
26/01/12 02:38:02 INFO DAGScheduler: ResultStage 149 (parquet at <unknown>:0) finished in 30.311 s
26/01/12 02:38:02 INFO DAGScheduler: Job 149 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:38:02 INFO TaskSchedulerImpl: Killing all running tasks in stage 149: Stage finished
26/01/12 02:38:02 INFO DAGScheduler: Job 149 finished: parquet at <unknown>:0, took 30.315470 s
26/01/12 02:38:02 INFO FileFormatWriter: Start to commit write Job 4031b793-6fda-49ae-834b-c9b21b9e4223.
26/01/12 02:38:02 INFO FileFormatWriter: Write Job 4031b793-6fda-49ae-834b-c9b21b9e4223 committed. Elapsed time: 35 ms.
26/01/12 02:38:02 INFO FileFormatWriter: Finished processing stats for write job 4031b793-6fda-49ae-834b-c9b21b9e4223.
Cargando: yellow_tripdata_2015-04.parquet en hdfs://hadoop-namenode:8020/data/nyc/raw/taxi-trips/2015...
26/01/12 02:38:02 INFO InMemoryFileIndex: It took 7 ms to list leaf files for 1 paths.
26/01/12 02:38:02 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 02:38:02 INFO DAGScheduler: Got job 150 (parquet at <unknown>:0) with 1 output partitions
26/01/12 02:38:02 INFO DAGScheduler: Final stage: ResultStage 150 (parquet at <unknown>:0)
26/01/12 02:38:02 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:38:02 INFO DAGScheduler: Missing parents: List()
26/01/12 02:38:02 INFO DAGScheduler: Submitting ResultStage 150 (MapPartitionsRDD[376] at parquet at <unknown>:0), which has no missing parents
26/01/12 02:38:02 INFO MemoryStore: Block broadcast_225 stored as values in memory (estimated size 102.6 KiB, free 364.8 MiB)
26/01/12 02:38:02 INFO MemoryStore: Block broadcast_225_piece0 stored as bytes in memory (estimated size 36.8 KiB, free 364.8 MiB)
26/01/12 02:38:02 INFO BlockManagerInfo: Added broadcast_225_piece0 in memory on 02926ee04bc9:45221 (size: 36.8 KiB, free: 366.0 MiB)
26/01/12 02:38:02 INFO SparkContext: Created broadcast 225 from broadcast at DAGScheduler.scala:1513
26/01/12 02:38:02 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 150 (MapPartitionsRDD[376] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0))
26/01/12 02:38:02 INFO TaskSchedulerImpl: Adding task set 150.0 with 1 tasks resource profile 0
26/01/12 02:38:02 INFO TaskSetManager: Starting task 0.0 in stage 150.0 (TID 272) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4607 bytes) taskResourceAssignments Map()
26/01/12 02:38:02 INFO BlockManagerInfo: Added broadcast_225_piece0 in memory on 172.18.0.5:42453 (size: 36.8 KiB, free: 366.0 MiB)
26/01/12 02:38:02 INFO TaskSetManager: Finished task 0.0 in stage 150.0 (TID 272) in 52 ms on 172.18.0.5 (executor 0) (1/1)
26/01/12 02:38:02 INFO TaskSchedulerImpl: Removed TaskSet 150.0, whose tasks have all completed, from pool 
26/01/12 02:38:02 INFO DAGScheduler: ResultStage 150 (parquet at <unknown>:0) finished in 0.065 s
26/01/12 02:38:02 INFO DAGScheduler: Job 150 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:38:02 INFO TaskSchedulerImpl: Killing all running tasks in stage 150: Stage finished
26/01/12 02:38:02 INFO DAGScheduler: Job 150 finished: parquet at <unknown>:0, took 0.068149 s
26/01/12 02:38:02 INFO FileSourceStrategy: Pushed Filters: 
26/01/12 02:38:02 INFO FileSourceStrategy: Post-Scan Filters: 
26/01/12 02:38:02 INFO FileSourceStrategy: Output Data Schema: struct<VendorID: bigint, tpep_pickup_datetime: timestamp, tpep_dropoff_datetime: timestamp, passenger_count: bigint, trip_distance: double ... 17 more fields>
26/01/12 02:38:02 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:38:02 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:38:02 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:38:02 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:38:02 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:38:02 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:38:02 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:38:02 INFO MemoryStore: Block broadcast_226 stored as values in memory (estimated size 358.4 KiB, free 364.5 MiB)
26/01/12 02:38:02 INFO MemoryStore: Block broadcast_226_piece0 stored as bytes in memory (estimated size 35.4 KiB, free 364.4 MiB)
26/01/12 02:38:02 INFO BlockManagerInfo: Added broadcast_226_piece0 in memory on 02926ee04bc9:45221 (size: 35.4 KiB, free: 366.0 MiB)
26/01/12 02:38:02 INFO SparkContext: Created broadcast 226 from parquet at <unknown>:0
26/01/12 02:38:02 INFO FileSourceScanExec: Planning scan with bin packing, max size: 92342842 bytes, open cost is considered as scanning 4194304 bytes.
26/01/12 02:38:02 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 02:38:02 INFO DAGScheduler: Got job 151 (parquet at <unknown>:0) with 2 output partitions
26/01/12 02:38:02 INFO DAGScheduler: Final stage: ResultStage 151 (parquet at <unknown>:0)
26/01/12 02:38:02 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:38:02 INFO DAGScheduler: Missing parents: List()
26/01/12 02:38:02 INFO DAGScheduler: Submitting ResultStage 151 (MapPartitionsRDD[379] at parquet at <unknown>:0), which has no missing parents
26/01/12 02:38:02 INFO MemoryStore: Block broadcast_227 stored as values in memory (estimated size 225.1 KiB, free 364.2 MiB)
26/01/12 02:38:02 INFO MemoryStore: Block broadcast_227_piece0 stored as bytes in memory (estimated size 77.4 KiB, free 364.1 MiB)
26/01/12 02:38:02 INFO BlockManagerInfo: Added broadcast_227_piece0 in memory on 02926ee04bc9:45221 (size: 77.4 KiB, free: 365.9 MiB)
26/01/12 02:38:02 INFO SparkContext: Created broadcast 227 from broadcast at DAGScheduler.scala:1513
26/01/12 02:38:02 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 151 (MapPartitionsRDD[379] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1))
26/01/12 02:38:02 INFO TaskSchedulerImpl: Adding task set 151.0 with 2 tasks resource profile 0
26/01/12 02:38:02 INFO TaskSetManager: Starting task 0.0 in stage 151.0 (TID 273) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:38:02 INFO TaskSetManager: Starting task 1.0 in stage 151.0 (TID 274) (172.18.0.5, executor 0, partition 1, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:38:02 INFO BlockManagerInfo: Added broadcast_227_piece0 in memory on 172.18.0.5:42453 (size: 77.4 KiB, free: 366.0 MiB)
26/01/12 02:38:02 INFO BlockManagerInfo: Added broadcast_226_piece0 in memory on 172.18.0.5:42453 (size: 35.4 KiB, free: 365.9 MiB)
26/01/12 02:38:02 INFO TaskSetManager: Finished task 1.0 in stage 151.0 (TID 274) in 58 ms on 172.18.0.5 (executor 0) (1/2)
26/01/12 02:38:31 INFO TaskSetManager: Finished task 0.0 in stage 151.0 (TID 273) in 29311 ms on 172.18.0.5 (executor 0) (2/2)
26/01/12 02:38:31 INFO TaskSchedulerImpl: Removed TaskSet 151.0, whose tasks have all completed, from pool 
26/01/12 02:38:31 INFO DAGScheduler: ResultStage 151 (parquet at <unknown>:0) finished in 29.332 s
26/01/12 02:38:31 INFO DAGScheduler: Job 151 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:38:31 INFO TaskSchedulerImpl: Killing all running tasks in stage 151: Stage finished
26/01/12 02:38:31 INFO DAGScheduler: Job 151 finished: parquet at <unknown>:0, took 29.338781 s
26/01/12 02:38:31 INFO FileFormatWriter: Start to commit write Job 99ee9f59-80b6-42de-8e3c-760f7be5fd1e.
26/01/12 02:38:31 INFO FileFormatWriter: Write Job 99ee9f59-80b6-42de-8e3c-760f7be5fd1e committed. Elapsed time: 32 ms.
26/01/12 02:38:31 INFO FileFormatWriter: Finished processing stats for write job 99ee9f59-80b6-42de-8e3c-760f7be5fd1e.
Cargando: yellow_tripdata_2015-05.parquet en hdfs://hadoop-namenode:8020/data/nyc/raw/taxi-trips/2015...
26/01/12 02:38:31 INFO InMemoryFileIndex: It took 10 ms to list leaf files for 1 paths.
26/01/12 02:38:31 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 02:38:31 INFO DAGScheduler: Got job 152 (parquet at <unknown>:0) with 1 output partitions
26/01/12 02:38:31 INFO DAGScheduler: Final stage: ResultStage 152 (parquet at <unknown>:0)
26/01/12 02:38:31 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:38:31 INFO DAGScheduler: Missing parents: List()
26/01/12 02:38:31 INFO DAGScheduler: Submitting ResultStage 152 (MapPartitionsRDD[381] at parquet at <unknown>:0), which has no missing parents
26/01/12 02:38:31 INFO MemoryStore: Block broadcast_228 stored as values in memory (estimated size 102.6 KiB, free 364.0 MiB)
26/01/12 02:38:31 INFO MemoryStore: Block broadcast_228_piece0 stored as bytes in memory (estimated size 36.8 KiB, free 364.0 MiB)
26/01/12 02:38:31 INFO BlockManagerInfo: Added broadcast_228_piece0 in memory on 02926ee04bc9:45221 (size: 36.8 KiB, free: 365.9 MiB)
26/01/12 02:38:31 INFO SparkContext: Created broadcast 228 from broadcast at DAGScheduler.scala:1513
26/01/12 02:38:31 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 152 (MapPartitionsRDD[381] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0))
26/01/12 02:38:31 INFO TaskSchedulerImpl: Adding task set 152.0 with 1 tasks resource profile 0
26/01/12 02:38:31 INFO TaskSetManager: Starting task 0.0 in stage 152.0 (TID 275) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4607 bytes) taskResourceAssignments Map()
26/01/12 02:38:31 INFO BlockManagerInfo: Added broadcast_228_piece0 in memory on 172.18.0.5:42453 (size: 36.8 KiB, free: 365.9 MiB)
26/01/12 02:38:32 INFO TaskSetManager: Finished task 0.0 in stage 152.0 (TID 275) in 59 ms on 172.18.0.5 (executor 0) (1/1)
26/01/12 02:38:32 INFO TaskSchedulerImpl: Removed TaskSet 152.0, whose tasks have all completed, from pool 
26/01/12 02:38:32 INFO DAGScheduler: ResultStage 152 (parquet at <unknown>:0) finished in 0.075 s
26/01/12 02:38:32 INFO DAGScheduler: Job 152 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:38:32 INFO TaskSchedulerImpl: Killing all running tasks in stage 152: Stage finished
26/01/12 02:38:32 INFO DAGScheduler: Job 152 finished: parquet at <unknown>:0, took 0.080133 s
26/01/12 02:38:32 INFO FileSourceStrategy: Pushed Filters: 
26/01/12 02:38:32 INFO FileSourceStrategy: Post-Scan Filters: 
26/01/12 02:38:32 INFO FileSourceStrategy: Output Data Schema: struct<VendorID: bigint, tpep_pickup_datetime: timestamp, tpep_dropoff_datetime: timestamp, passenger_count: bigint, trip_distance: double ... 17 more fields>
26/01/12 02:38:32 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:38:32 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:38:32 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:38:32 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:38:32 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:38:32 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:38:32 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:38:32 INFO MemoryStore: Block broadcast_229 stored as values in memory (estimated size 358.4 KiB, free 363.6 MiB)
26/01/12 02:38:32 INFO MemoryStore: Block broadcast_229_piece0 stored as bytes in memory (estimated size 35.4 KiB, free 363.6 MiB)
26/01/12 02:38:32 INFO BlockManagerInfo: Added broadcast_229_piece0 in memory on 02926ee04bc9:45221 (size: 35.4 KiB, free: 365.9 MiB)
26/01/12 02:38:32 INFO SparkContext: Created broadcast 229 from parquet at <unknown>:0
26/01/12 02:38:32 INFO FileSourceScanExec: Planning scan with bin packing, max size: 93340880 bytes, open cost is considered as scanning 4194304 bytes.
26/01/12 02:38:32 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 02:38:32 INFO DAGScheduler: Got job 153 (parquet at <unknown>:0) with 2 output partitions
26/01/12 02:38:32 INFO DAGScheduler: Final stage: ResultStage 153 (parquet at <unknown>:0)
26/01/12 02:38:32 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:38:32 INFO DAGScheduler: Missing parents: List()
26/01/12 02:38:32 INFO DAGScheduler: Submitting ResultStage 153 (MapPartitionsRDD[384] at parquet at <unknown>:0), which has no missing parents
26/01/12 02:38:32 INFO MemoryStore: Block broadcast_230 stored as values in memory (estimated size 225.1 KiB, free 363.4 MiB)
26/01/12 02:38:32 INFO MemoryStore: Block broadcast_230_piece0 stored as bytes in memory (estimated size 77.4 KiB, free 363.3 MiB)
26/01/12 02:38:32 INFO BlockManagerInfo: Added broadcast_230_piece0 in memory on 02926ee04bc9:45221 (size: 77.4 KiB, free: 365.8 MiB)
26/01/12 02:38:32 INFO SparkContext: Created broadcast 230 from broadcast at DAGScheduler.scala:1513
26/01/12 02:38:32 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 153 (MapPartitionsRDD[384] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1))
26/01/12 02:38:32 INFO TaskSchedulerImpl: Adding task set 153.0 with 2 tasks resource profile 0
26/01/12 02:38:32 INFO TaskSetManager: Starting task 0.0 in stage 153.0 (TID 276) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:38:32 INFO TaskSetManager: Starting task 1.0 in stage 153.0 (TID 277) (172.18.0.5, executor 0, partition 1, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:38:32 INFO BlockManagerInfo: Added broadcast_230_piece0 in memory on 172.18.0.5:42453 (size: 77.4 KiB, free: 365.8 MiB)
26/01/12 02:38:32 INFO BlockManagerInfo: Added broadcast_229_piece0 in memory on 172.18.0.5:42453 (size: 35.4 KiB, free: 365.8 MiB)
26/01/12 02:38:32 INFO TaskSetManager: Finished task 1.0 in stage 153.0 (TID 277) in 50 ms on 172.18.0.5 (executor 0) (1/2)
26/01/12 02:39:02 INFO TaskSetManager: Finished task 0.0 in stage 153.0 (TID 276) in 30249 ms on 172.18.0.5 (executor 0) (2/2)
26/01/12 02:39:02 INFO TaskSchedulerImpl: Removed TaskSet 153.0, whose tasks have all completed, from pool 
26/01/12 02:39:02 INFO DAGScheduler: ResultStage 153 (parquet at <unknown>:0) finished in 30.268 s
26/01/12 02:39:02 INFO DAGScheduler: Job 153 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:39:02 INFO TaskSchedulerImpl: Killing all running tasks in stage 153: Stage finished
26/01/12 02:39:02 INFO DAGScheduler: Job 153 finished: parquet at <unknown>:0, took 30.273326 s
26/01/12 02:39:02 INFO FileFormatWriter: Start to commit write Job 11f329cb-42de-4c57-a9de-c787e7eb6f64.
26/01/12 02:39:02 INFO FileFormatWriter: Write Job 11f329cb-42de-4c57-a9de-c787e7eb6f64 committed. Elapsed time: 31 ms.
26/01/12 02:39:02 INFO FileFormatWriter: Finished processing stats for write job 11f329cb-42de-4c57-a9de-c787e7eb6f64.
Cargando: yellow_tripdata_2015-06.parquet en hdfs://hadoop-namenode:8020/data/nyc/raw/taxi-trips/2015...
26/01/12 02:39:02 INFO InMemoryFileIndex: It took 6 ms to list leaf files for 1 paths.
26/01/12 02:39:02 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 02:39:02 INFO DAGScheduler: Got job 154 (parquet at <unknown>:0) with 1 output partitions
26/01/12 02:39:02 INFO DAGScheduler: Final stage: ResultStage 154 (parquet at <unknown>:0)
26/01/12 02:39:02 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:39:02 INFO DAGScheduler: Missing parents: List()
26/01/12 02:39:02 INFO DAGScheduler: Submitting ResultStage 154 (MapPartitionsRDD[386] at parquet at <unknown>:0), which has no missing parents
26/01/12 02:39:02 INFO MemoryStore: Block broadcast_231 stored as values in memory (estimated size 102.6 KiB, free 363.2 MiB)
26/01/12 02:39:02 INFO MemoryStore: Block broadcast_231_piece0 stored as bytes in memory (estimated size 36.8 KiB, free 363.2 MiB)
26/01/12 02:39:02 INFO BlockManagerInfo: Added broadcast_231_piece0 in memory on 02926ee04bc9:45221 (size: 36.8 KiB, free: 365.8 MiB)
26/01/12 02:39:02 INFO SparkContext: Created broadcast 231 from broadcast at DAGScheduler.scala:1513
26/01/12 02:39:02 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 154 (MapPartitionsRDD[386] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0))
26/01/12 02:39:02 INFO TaskSchedulerImpl: Adding task set 154.0 with 1 tasks resource profile 0
26/01/12 02:39:02 INFO TaskSetManager: Starting task 0.0 in stage 154.0 (TID 278) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4607 bytes) taskResourceAssignments Map()
26/01/12 02:39:02 INFO BlockManagerInfo: Added broadcast_231_piece0 in memory on 172.18.0.5:42453 (size: 36.8 KiB, free: 365.8 MiB)
26/01/12 02:39:02 INFO TaskSetManager: Finished task 0.0 in stage 154.0 (TID 278) in 50 ms on 172.18.0.5 (executor 0) (1/1)
26/01/12 02:39:02 INFO TaskSchedulerImpl: Removed TaskSet 154.0, whose tasks have all completed, from pool 
26/01/12 02:39:02 INFO DAGScheduler: ResultStage 154 (parquet at <unknown>:0) finished in 0.063 s
26/01/12 02:39:02 INFO DAGScheduler: Job 154 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:39:02 INFO TaskSchedulerImpl: Killing all running tasks in stage 154: Stage finished
26/01/12 02:39:02 INFO DAGScheduler: Job 154 finished: parquet at <unknown>:0, took 0.067202 s
26/01/12 02:39:02 INFO FileSourceStrategy: Pushed Filters: 
26/01/12 02:39:02 INFO FileSourceStrategy: Post-Scan Filters: 
26/01/12 02:39:02 INFO FileSourceStrategy: Output Data Schema: struct<VendorID: bigint, tpep_pickup_datetime: timestamp, tpep_dropoff_datetime: timestamp, passenger_count: bigint, trip_distance: double ... 17 more fields>
26/01/12 02:39:02 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:39:02 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:39:02 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:39:02 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:39:02 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:39:02 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:39:02 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:39:02 INFO MemoryStore: Block broadcast_232 stored as values in memory (estimated size 358.4 KiB, free 362.8 MiB)
26/01/12 02:39:02 INFO MemoryStore: Block broadcast_232_piece0 stored as bytes in memory (estimated size 35.4 KiB, free 362.8 MiB)
26/01/12 02:39:02 INFO BlockManagerInfo: Added broadcast_232_piece0 in memory on 02926ee04bc9:45221 (size: 35.4 KiB, free: 365.7 MiB)
26/01/12 02:39:02 INFO SparkContext: Created broadcast 232 from parquet at <unknown>:0
26/01/12 02:39:02 INFO FileSourceScanExec: Planning scan with bin packing, max size: 87977534 bytes, open cost is considered as scanning 4194304 bytes.
26/01/12 02:39:02 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 02:39:02 INFO DAGScheduler: Got job 155 (parquet at <unknown>:0) with 2 output partitions
26/01/12 02:39:02 INFO DAGScheduler: Final stage: ResultStage 155 (parquet at <unknown>:0)
26/01/12 02:39:02 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:39:02 INFO DAGScheduler: Missing parents: List()
26/01/12 02:39:02 INFO DAGScheduler: Submitting ResultStage 155 (MapPartitionsRDD[389] at parquet at <unknown>:0), which has no missing parents
26/01/12 02:39:02 INFO MemoryStore: Block broadcast_233 stored as values in memory (estimated size 225.1 KiB, free 362.6 MiB)
26/01/12 02:39:02 INFO MemoryStore: Block broadcast_233_piece0 stored as bytes in memory (estimated size 77.4 KiB, free 362.5 MiB)
26/01/12 02:39:02 INFO BlockManagerInfo: Added broadcast_233_piece0 in memory on 02926ee04bc9:45221 (size: 77.4 KiB, free: 365.6 MiB)
26/01/12 02:39:02 INFO SparkContext: Created broadcast 233 from broadcast at DAGScheduler.scala:1513
26/01/12 02:39:02 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 155 (MapPartitionsRDD[389] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1))
26/01/12 02:39:02 INFO TaskSchedulerImpl: Adding task set 155.0 with 2 tasks resource profile 0
26/01/12 02:39:02 INFO TaskSetManager: Starting task 0.0 in stage 155.0 (TID 279) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:39:02 INFO TaskSetManager: Starting task 1.0 in stage 155.0 (TID 280) (172.18.0.5, executor 0, partition 1, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:39:02 INFO BlockManagerInfo: Added broadcast_233_piece0 in memory on 172.18.0.5:42453 (size: 77.4 KiB, free: 365.7 MiB)
26/01/12 02:39:02 INFO BlockManagerInfo: Added broadcast_232_piece0 in memory on 172.18.0.5:42453 (size: 35.4 KiB, free: 365.6 MiB)
26/01/12 02:39:02 INFO TaskSetManager: Finished task 1.0 in stage 155.0 (TID 280) in 56 ms on 172.18.0.5 (executor 0) (1/2)
26/01/12 02:39:31 INFO TaskSetManager: Finished task 0.0 in stage 155.0 (TID 279) in 28394 ms on 172.18.0.5 (executor 0) (2/2)
26/01/12 02:39:31 INFO TaskSchedulerImpl: Removed TaskSet 155.0, whose tasks have all completed, from pool 
26/01/12 02:39:31 INFO DAGScheduler: ResultStage 155 (parquet at <unknown>:0) finished in 28.413 s
26/01/12 02:39:31 INFO DAGScheduler: Job 155 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:39:31 INFO TaskSchedulerImpl: Killing all running tasks in stage 155: Stage finished
26/01/12 02:39:31 INFO DAGScheduler: Job 155 finished: parquet at <unknown>:0, took 28.421131 s
26/01/12 02:39:31 INFO FileFormatWriter: Start to commit write Job 2ddf0546-ae03-487b-817b-a11a0b63a008.
26/01/12 02:39:31 INFO FileFormatWriter: Write Job 2ddf0546-ae03-487b-817b-a11a0b63a008 committed. Elapsed time: 34 ms.
26/01/12 02:39:31 INFO FileFormatWriter: Finished processing stats for write job 2ddf0546-ae03-487b-817b-a11a0b63a008.
Cargando: yellow_tripdata_2015-07.parquet en hdfs://hadoop-namenode:8020/data/nyc/raw/taxi-trips/2015...
26/01/12 02:39:31 INFO InMemoryFileIndex: It took 8 ms to list leaf files for 1 paths.
26/01/12 02:39:31 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 02:39:31 INFO DAGScheduler: Got job 156 (parquet at <unknown>:0) with 1 output partitions
26/01/12 02:39:31 INFO DAGScheduler: Final stage: ResultStage 156 (parquet at <unknown>:0)
26/01/12 02:39:31 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:39:31 INFO DAGScheduler: Missing parents: List()
26/01/12 02:39:31 INFO DAGScheduler: Submitting ResultStage 156 (MapPartitionsRDD[391] at parquet at <unknown>:0), which has no missing parents
26/01/12 02:39:31 INFO MemoryStore: Block broadcast_234 stored as values in memory (estimated size 102.6 KiB, free 362.4 MiB)
26/01/12 02:39:31 INFO MemoryStore: Block broadcast_234_piece0 stored as bytes in memory (estimated size 36.8 KiB, free 362.4 MiB)
26/01/12 02:39:31 INFO BlockManagerInfo: Added broadcast_234_piece0 in memory on 02926ee04bc9:45221 (size: 36.8 KiB, free: 365.6 MiB)
26/01/12 02:39:31 INFO SparkContext: Created broadcast 234 from broadcast at DAGScheduler.scala:1513
26/01/12 02:39:31 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 156 (MapPartitionsRDD[391] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0))
26/01/12 02:39:31 INFO TaskSchedulerImpl: Adding task set 156.0 with 1 tasks resource profile 0
26/01/12 02:39:31 INFO TaskSetManager: Starting task 0.0 in stage 156.0 (TID 281) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4607 bytes) taskResourceAssignments Map()
26/01/12 02:39:31 INFO BlockManagerInfo: Added broadcast_234_piece0 in memory on 172.18.0.5:42453 (size: 36.8 KiB, free: 365.6 MiB)
26/01/12 02:39:31 INFO TaskSetManager: Finished task 0.0 in stage 156.0 (TID 281) in 52 ms on 172.18.0.5 (executor 0) (1/1)
26/01/12 02:39:31 INFO TaskSchedulerImpl: Removed TaskSet 156.0, whose tasks have all completed, from pool 
26/01/12 02:39:31 INFO DAGScheduler: ResultStage 156 (parquet at <unknown>:0) finished in 0.080 s
26/01/12 02:39:31 INFO DAGScheduler: Job 156 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:39:31 INFO TaskSchedulerImpl: Killing all running tasks in stage 156: Stage finished
26/01/12 02:39:31 INFO DAGScheduler: Job 156 finished: parquet at <unknown>:0, took 0.084992 s
26/01/12 02:39:31 INFO FileSourceStrategy: Pushed Filters: 
26/01/12 02:39:31 INFO FileSourceStrategy: Post-Scan Filters: 
26/01/12 02:39:31 INFO FileSourceStrategy: Output Data Schema: struct<VendorID: bigint, tpep_pickup_datetime: timestamp, tpep_dropoff_datetime: timestamp, passenger_count: bigint, trip_distance: double ... 17 more fields>
26/01/12 02:39:31 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:39:31 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:39:31 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:39:31 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:39:31 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:39:31 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:39:31 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:39:31 INFO MemoryStore: Block broadcast_235 stored as values in memory (estimated size 358.4 KiB, free 362.0 MiB)
26/01/12 02:39:31 INFO MemoryStore: Block broadcast_235_piece0 stored as bytes in memory (estimated size 35.4 KiB, free 362.0 MiB)
26/01/12 02:39:31 INFO BlockManagerInfo: Added broadcast_235_piece0 in memory on 02926ee04bc9:45221 (size: 35.4 KiB, free: 365.6 MiB)
26/01/12 02:39:31 INFO SparkContext: Created broadcast 235 from parquet at <unknown>:0
26/01/12 02:39:31 INFO FileSourceScanExec: Planning scan with bin packing, max size: 82441917 bytes, open cost is considered as scanning 4194304 bytes.
26/01/12 02:39:31 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 02:39:31 INFO DAGScheduler: Got job 157 (parquet at <unknown>:0) with 2 output partitions
26/01/12 02:39:31 INFO DAGScheduler: Final stage: ResultStage 157 (parquet at <unknown>:0)
26/01/12 02:39:31 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:39:31 INFO DAGScheduler: Missing parents: List()
26/01/12 02:39:31 INFO DAGScheduler: Submitting ResultStage 157 (MapPartitionsRDD[394] at parquet at <unknown>:0), which has no missing parents
26/01/12 02:39:31 INFO MemoryStore: Block broadcast_236 stored as values in memory (estimated size 225.1 KiB, free 361.8 MiB)
26/01/12 02:39:31 INFO MemoryStore: Block broadcast_236_piece0 stored as bytes in memory (estimated size 77.4 KiB, free 361.7 MiB)
26/01/12 02:39:31 INFO BlockManagerInfo: Added broadcast_236_piece0 in memory on 02926ee04bc9:45221 (size: 77.4 KiB, free: 365.5 MiB)
26/01/12 02:39:31 INFO SparkContext: Created broadcast 236 from broadcast at DAGScheduler.scala:1513
26/01/12 02:39:31 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 157 (MapPartitionsRDD[394] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1))
26/01/12 02:39:31 INFO TaskSchedulerImpl: Adding task set 157.0 with 2 tasks resource profile 0
26/01/12 02:39:31 INFO TaskSetManager: Starting task 0.0 in stage 157.0 (TID 282) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:39:31 INFO TaskSetManager: Starting task 1.0 in stage 157.0 (TID 283) (172.18.0.5, executor 0, partition 1, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:39:31 INFO BlockManagerInfo: Added broadcast_236_piece0 in memory on 172.18.0.5:42453 (size: 77.4 KiB, free: 365.5 MiB)
26/01/12 02:39:31 INFO BlockManagerInfo: Added broadcast_235_piece0 in memory on 172.18.0.5:42453 (size: 35.4 KiB, free: 365.5 MiB)
26/01/12 02:39:31 INFO TaskSetManager: Finished task 1.0 in stage 157.0 (TID 283) in 56 ms on 172.18.0.5 (executor 0) (1/2)
26/01/12 02:39:58 INFO TaskSetManager: Finished task 0.0 in stage 157.0 (TID 282) in 27348 ms on 172.18.0.5 (executor 0) (2/2)
26/01/12 02:39:58 INFO TaskSchedulerImpl: Removed TaskSet 157.0, whose tasks have all completed, from pool 
26/01/12 02:39:58 INFO DAGScheduler: ResultStage 157 (parquet at <unknown>:0) finished in 27.376 s
26/01/12 02:39:58 INFO DAGScheduler: Job 157 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:39:58 INFO TaskSchedulerImpl: Killing all running tasks in stage 157: Stage finished
26/01/12 02:39:58 INFO DAGScheduler: Job 157 finished: parquet at <unknown>:0, took 27.382426 s
26/01/12 02:39:58 INFO FileFormatWriter: Start to commit write Job 1c350af5-88f5-4971-91ad-9229a0c90a60.
26/01/12 02:39:58 INFO FileFormatWriter: Write Job 1c350af5-88f5-4971-91ad-9229a0c90a60 committed. Elapsed time: 32 ms.
26/01/12 02:39:58 INFO FileFormatWriter: Finished processing stats for write job 1c350af5-88f5-4971-91ad-9229a0c90a60.
Cargando: yellow_tripdata_2015-08.parquet en hdfs://hadoop-namenode:8020/data/nyc/raw/taxi-trips/2015...
26/01/12 02:39:58 INFO BlockManagerInfo: Removed broadcast_231_piece0 on 02926ee04bc9:45221 in memory (size: 36.8 KiB, free: 365.5 MiB)
26/01/12 02:39:58 INFO BlockManagerInfo: Removed broadcast_231_piece0 on 172.18.0.5:42453 in memory (size: 36.8 KiB, free: 365.5 MiB)
26/01/12 02:39:58 INFO BlockManagerInfo: Removed broadcast_225_piece0 on 02926ee04bc9:45221 in memory (size: 36.8 KiB, free: 365.6 MiB)
26/01/12 02:39:58 INFO BlockManagerInfo: Removed broadcast_225_piece0 on 172.18.0.5:42453 in memory (size: 36.8 KiB, free: 365.6 MiB)
26/01/12 02:39:58 INFO InMemoryFileIndex: It took 12 ms to list leaf files for 1 paths.
26/01/12 02:39:58 INFO BlockManagerInfo: Removed broadcast_229_piece0 on 02926ee04bc9:45221 in memory (size: 35.4 KiB, free: 365.6 MiB)
26/01/12 02:39:58 INFO BlockManagerInfo: Removed broadcast_229_piece0 on 172.18.0.5:42453 in memory (size: 35.4 KiB, free: 365.6 MiB)
26/01/12 02:39:58 INFO BlockManagerInfo: Removed broadcast_234_piece0 on 02926ee04bc9:45221 in memory (size: 36.8 KiB, free: 365.6 MiB)
26/01/12 02:39:58 INFO BlockManagerInfo: Removed broadcast_234_piece0 on 172.18.0.5:42453 in memory (size: 36.8 KiB, free: 365.6 MiB)
26/01/12 02:39:58 INFO BlockManagerInfo: Removed broadcast_224_piece0 on 02926ee04bc9:45221 in memory (size: 77.4 KiB, free: 365.7 MiB)
26/01/12 02:39:58 INFO BlockManagerInfo: Removed broadcast_224_piece0 on 172.18.0.5:42453 in memory (size: 77.4 KiB, free: 365.7 MiB)
26/01/12 02:39:58 INFO BlockManagerInfo: Removed broadcast_233_piece0 on 02926ee04bc9:45221 in memory (size: 77.4 KiB, free: 365.8 MiB)
26/01/12 02:39:58 INFO BlockManagerInfo: Removed broadcast_233_piece0 on 172.18.0.5:42453 in memory (size: 77.4 KiB, free: 365.8 MiB)
26/01/12 02:39:58 INFO BlockManagerInfo: Removed broadcast_223_piece0 on 02926ee04bc9:45221 in memory (size: 35.4 KiB, free: 365.8 MiB)
26/01/12 02:39:58 INFO BlockManagerInfo: Removed broadcast_223_piece0 on 172.18.0.5:42453 in memory (size: 35.4 KiB, free: 365.8 MiB)
26/01/12 02:39:58 INFO BlockManagerInfo: Removed broadcast_226_piece0 on 02926ee04bc9:45221 in memory (size: 35.4 KiB, free: 365.9 MiB)
26/01/12 02:39:58 INFO BlockManagerInfo: Removed broadcast_226_piece0 on 172.18.0.5:42453 in memory (size: 35.4 KiB, free: 365.9 MiB)
26/01/12 02:39:58 INFO BlockManagerInfo: Removed broadcast_227_piece0 on 02926ee04bc9:45221 in memory (size: 77.4 KiB, free: 365.9 MiB)
26/01/12 02:39:58 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 02:39:58 INFO BlockManagerInfo: Removed broadcast_227_piece0 on 172.18.0.5:42453 in memory (size: 77.4 KiB, free: 365.9 MiB)
26/01/12 02:39:58 INFO DAGScheduler: Got job 158 (parquet at <unknown>:0) with 1 output partitions
26/01/12 02:39:58 INFO DAGScheduler: Final stage: ResultStage 158 (parquet at <unknown>:0)
26/01/12 02:39:58 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:39:58 INFO DAGScheduler: Missing parents: List()
26/01/12 02:39:58 INFO DAGScheduler: Submitting ResultStage 158 (MapPartitionsRDD[396] at parquet at <unknown>:0), which has no missing parents
26/01/12 02:39:58 INFO BlockManagerInfo: Removed broadcast_230_piece0 on 02926ee04bc9:45221 in memory (size: 77.4 KiB, free: 366.0 MiB)
26/01/12 02:39:58 INFO BlockManagerInfo: Removed broadcast_230_piece0 on 172.18.0.5:42453 in memory (size: 77.4 KiB, free: 366.0 MiB)
26/01/12 02:39:58 INFO MemoryStore: Block broadcast_237 stored as values in memory (estimated size 102.6 KiB, free 364.3 MiB)
26/01/12 02:39:58 INFO MemoryStore: Block broadcast_237_piece0 stored as bytes in memory (estimated size 36.8 KiB, free 364.3 MiB)
26/01/12 02:39:58 INFO BlockManagerInfo: Added broadcast_237_piece0 in memory on 02926ee04bc9:45221 (size: 36.8 KiB, free: 366.0 MiB)
26/01/12 02:39:58 INFO SparkContext: Created broadcast 237 from broadcast at DAGScheduler.scala:1513
26/01/12 02:39:58 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 158 (MapPartitionsRDD[396] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0))
26/01/12 02:39:58 INFO BlockManagerInfo: Removed broadcast_236_piece0 on 02926ee04bc9:45221 in memory (size: 77.4 KiB, free: 366.0 MiB)
26/01/12 02:39:58 INFO TaskSchedulerImpl: Adding task set 158.0 with 1 tasks resource profile 0
26/01/12 02:39:58 INFO BlockManagerInfo: Removed broadcast_236_piece0 on 172.18.0.5:42453 in memory (size: 77.4 KiB, free: 366.1 MiB)
26/01/12 02:39:58 INFO TaskSetManager: Starting task 0.0 in stage 158.0 (TID 284) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4607 bytes) taskResourceAssignments Map()
26/01/12 02:39:58 INFO BlockManagerInfo: Removed broadcast_232_piece0 on 02926ee04bc9:45221 in memory (size: 35.4 KiB, free: 366.1 MiB)
26/01/12 02:39:58 INFO BlockManagerInfo: Removed broadcast_232_piece0 on 172.18.0.5:42453 in memory (size: 35.4 KiB, free: 366.1 MiB)
26/01/12 02:39:58 INFO BlockManagerInfo: Added broadcast_237_piece0 in memory on 172.18.0.5:42453 (size: 36.8 KiB, free: 366.1 MiB)
26/01/12 02:39:58 INFO BlockManagerInfo: Removed broadcast_228_piece0 on 02926ee04bc9:45221 in memory (size: 36.8 KiB, free: 366.1 MiB)
26/01/12 02:39:58 INFO BlockManagerInfo: Removed broadcast_228_piece0 on 172.18.0.5:42453 in memory (size: 36.8 KiB, free: 366.1 MiB)
26/01/12 02:39:58 INFO TaskSetManager: Finished task 0.0 in stage 158.0 (TID 284) in 59 ms on 172.18.0.5 (executor 0) (1/1)
26/01/12 02:39:58 INFO TaskSchedulerImpl: Removed TaskSet 158.0, whose tasks have all completed, from pool 
26/01/12 02:39:58 INFO DAGScheduler: ResultStage 158 (parquet at <unknown>:0) finished in 0.075 s
26/01/12 02:39:58 INFO DAGScheduler: Job 158 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:39:58 INFO TaskSchedulerImpl: Killing all running tasks in stage 158: Stage finished
26/01/12 02:39:58 INFO DAGScheduler: Job 158 finished: parquet at <unknown>:0, took 0.079008 s
26/01/12 02:39:58 INFO FileSourceStrategy: Pushed Filters: 
26/01/12 02:39:58 INFO FileSourceStrategy: Post-Scan Filters: 
26/01/12 02:39:58 INFO FileSourceStrategy: Output Data Schema: struct<VendorID: bigint, tpep_pickup_datetime: timestamp, tpep_dropoff_datetime: timestamp, passenger_count: bigint, trip_distance: double ... 17 more fields>
26/01/12 02:39:58 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:39:58 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:39:58 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:39:58 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:39:58 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:39:58 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:39:58 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:39:58 INFO MemoryStore: Block broadcast_238 stored as values in memory (estimated size 358.4 KiB, free 364.7 MiB)
26/01/12 02:39:58 INFO MemoryStore: Block broadcast_238_piece0 stored as bytes in memory (estimated size 35.4 KiB, free 364.7 MiB)
26/01/12 02:39:58 INFO BlockManagerInfo: Added broadcast_238_piece0 in memory on 02926ee04bc9:45221 (size: 35.4 KiB, free: 366.1 MiB)
26/01/12 02:39:58 INFO SparkContext: Created broadcast 238 from parquet at <unknown>:0
26/01/12 02:39:58 INFO FileSourceScanExec: Planning scan with bin packing, max size: 79217553 bytes, open cost is considered as scanning 4194304 bytes.
26/01/12 02:39:58 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 02:39:58 INFO DAGScheduler: Got job 159 (parquet at <unknown>:0) with 2 output partitions
26/01/12 02:39:58 INFO DAGScheduler: Final stage: ResultStage 159 (parquet at <unknown>:0)
26/01/12 02:39:58 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:39:58 INFO DAGScheduler: Missing parents: List()
26/01/12 02:39:58 INFO DAGScheduler: Submitting ResultStage 159 (MapPartitionsRDD[399] at parquet at <unknown>:0), which has no missing parents
26/01/12 02:39:58 INFO MemoryStore: Block broadcast_239 stored as values in memory (estimated size 225.1 KiB, free 364.5 MiB)
26/01/12 02:39:58 INFO MemoryStore: Block broadcast_239_piece0 stored as bytes in memory (estimated size 77.4 KiB, free 364.4 MiB)
26/01/12 02:39:58 INFO BlockManagerInfo: Added broadcast_239_piece0 in memory on 02926ee04bc9:45221 (size: 77.4 KiB, free: 366.0 MiB)
26/01/12 02:39:58 INFO SparkContext: Created broadcast 239 from broadcast at DAGScheduler.scala:1513
26/01/12 02:39:58 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 159 (MapPartitionsRDD[399] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1))
26/01/12 02:39:58 INFO TaskSchedulerImpl: Adding task set 159.0 with 2 tasks resource profile 0
26/01/12 02:39:58 INFO TaskSetManager: Starting task 0.0 in stage 159.0 (TID 285) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:39:58 INFO TaskSetManager: Starting task 1.0 in stage 159.0 (TID 286) (172.18.0.5, executor 0, partition 1, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:39:58 INFO BlockManagerInfo: Added broadcast_239_piece0 in memory on 172.18.0.5:42453 (size: 77.4 KiB, free: 366.0 MiB)
26/01/12 02:39:59 INFO BlockManagerInfo: Added broadcast_238_piece0 in memory on 172.18.0.5:42453 (size: 35.4 KiB, free: 366.0 MiB)
26/01/12 02:39:59 INFO TaskSetManager: Finished task 1.0 in stage 159.0 (TID 286) in 56 ms on 172.18.0.5 (executor 0) (1/2)
26/01/12 02:40:24 INFO TaskSetManager: Finished task 0.0 in stage 159.0 (TID 285) in 25172 ms on 172.18.0.5 (executor 0) (2/2)
26/01/12 02:40:24 INFO TaskSchedulerImpl: Removed TaskSet 159.0, whose tasks have all completed, from pool 
26/01/12 02:40:24 INFO DAGScheduler: ResultStage 159 (parquet at <unknown>:0) finished in 25.212 s
26/01/12 02:40:24 INFO DAGScheduler: Job 159 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:40:24 INFO TaskSchedulerImpl: Killing all running tasks in stage 159: Stage finished
26/01/12 02:40:24 INFO DAGScheduler: Job 159 finished: parquet at <unknown>:0, took 25.218306 s
26/01/12 02:40:24 INFO FileFormatWriter: Start to commit write Job 7de3148e-6bae-4b7d-8025-6c7d53d8afa4.
26/01/12 02:40:24 INFO FileFormatWriter: Write Job 7de3148e-6bae-4b7d-8025-6c7d53d8afa4 committed. Elapsed time: 33 ms.
26/01/12 02:40:24 INFO FileFormatWriter: Finished processing stats for write job 7de3148e-6bae-4b7d-8025-6c7d53d8afa4.
Cargando: yellow_tripdata_2015-09.parquet en hdfs://hadoop-namenode:8020/data/nyc/raw/taxi-trips/2015...
26/01/12 02:40:24 INFO InMemoryFileIndex: It took 8 ms to list leaf files for 1 paths.
26/01/12 02:40:24 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 02:40:24 INFO DAGScheduler: Got job 160 (parquet at <unknown>:0) with 1 output partitions
26/01/12 02:40:24 INFO DAGScheduler: Final stage: ResultStage 160 (parquet at <unknown>:0)
26/01/12 02:40:24 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:40:24 INFO DAGScheduler: Missing parents: List()
26/01/12 02:40:24 INFO DAGScheduler: Submitting ResultStage 160 (MapPartitionsRDD[401] at parquet at <unknown>:0), which has no missing parents
26/01/12 02:40:24 INFO MemoryStore: Block broadcast_240 stored as values in memory (estimated size 102.6 KiB, free 364.3 MiB)
26/01/12 02:40:24 INFO MemoryStore: Block broadcast_240_piece0 stored as bytes in memory (estimated size 36.8 KiB, free 364.3 MiB)
26/01/12 02:40:24 INFO BlockManagerInfo: Added broadcast_240_piece0 in memory on 02926ee04bc9:45221 (size: 36.8 KiB, free: 366.0 MiB)
26/01/12 02:40:24 INFO SparkContext: Created broadcast 240 from broadcast at DAGScheduler.scala:1513
26/01/12 02:40:24 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 160 (MapPartitionsRDD[401] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0))
26/01/12 02:40:24 INFO TaskSchedulerImpl: Adding task set 160.0 with 1 tasks resource profile 0
26/01/12 02:40:24 INFO TaskSetManager: Starting task 0.0 in stage 160.0 (TID 287) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4607 bytes) taskResourceAssignments Map()
26/01/12 02:40:24 INFO BlockManagerInfo: Added broadcast_240_piece0 in memory on 172.18.0.5:42453 (size: 36.8 KiB, free: 366.0 MiB)
26/01/12 02:40:24 INFO TaskSetManager: Finished task 0.0 in stage 160.0 (TID 287) in 48 ms on 172.18.0.5 (executor 0) (1/1)
26/01/12 02:40:24 INFO TaskSchedulerImpl: Removed TaskSet 160.0, whose tasks have all completed, from pool 
26/01/12 02:40:24 INFO DAGScheduler: ResultStage 160 (parquet at <unknown>:0) finished in 0.063 s
26/01/12 02:40:24 INFO DAGScheduler: Job 160 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:40:24 INFO TaskSchedulerImpl: Killing all running tasks in stage 160: Stage finished
26/01/12 02:40:24 INFO DAGScheduler: Job 160 finished: parquet at <unknown>:0, took 0.067022 s
26/01/12 02:40:24 INFO FileSourceStrategy: Pushed Filters: 
26/01/12 02:40:24 INFO FileSourceStrategy: Post-Scan Filters: 
26/01/12 02:40:24 INFO FileSourceStrategy: Output Data Schema: struct<VendorID: bigint, tpep_pickup_datetime: timestamp, tpep_dropoff_datetime: timestamp, passenger_count: bigint, trip_distance: double ... 17 more fields>
26/01/12 02:40:24 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:40:24 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:40:24 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:40:24 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:40:24 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:40:24 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:40:24 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:40:24 INFO MemoryStore: Block broadcast_241 stored as values in memory (estimated size 358.4 KiB, free 363.9 MiB)
26/01/12 02:40:24 INFO MemoryStore: Block broadcast_241_piece0 stored as bytes in memory (estimated size 35.4 KiB, free 363.9 MiB)
26/01/12 02:40:24 INFO BlockManagerInfo: Added broadcast_241_piece0 in memory on 02926ee04bc9:45221 (size: 35.4 KiB, free: 365.9 MiB)
26/01/12 02:40:24 INFO SparkContext: Created broadcast 241 from parquet at <unknown>:0
26/01/12 02:40:24 INFO FileSourceScanExec: Planning scan with bin packing, max size: 80297936 bytes, open cost is considered as scanning 4194304 bytes.
26/01/12 02:40:24 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 02:40:24 INFO DAGScheduler: Got job 161 (parquet at <unknown>:0) with 2 output partitions
26/01/12 02:40:24 INFO DAGScheduler: Final stage: ResultStage 161 (parquet at <unknown>:0)
26/01/12 02:40:24 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:40:24 INFO DAGScheduler: Missing parents: List()
26/01/12 02:40:24 INFO DAGScheduler: Submitting ResultStage 161 (MapPartitionsRDD[404] at parquet at <unknown>:0), which has no missing parents
26/01/12 02:40:24 INFO MemoryStore: Block broadcast_242 stored as values in memory (estimated size 225.1 KiB, free 363.7 MiB)
26/01/12 02:40:24 INFO MemoryStore: Block broadcast_242_piece0 stored as bytes in memory (estimated size 77.4 KiB, free 363.6 MiB)
26/01/12 02:40:24 INFO BlockManagerInfo: Added broadcast_242_piece0 in memory on 02926ee04bc9:45221 (size: 77.4 KiB, free: 365.9 MiB)
26/01/12 02:40:24 INFO SparkContext: Created broadcast 242 from broadcast at DAGScheduler.scala:1513
26/01/12 02:40:24 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 161 (MapPartitionsRDD[404] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1))
26/01/12 02:40:24 INFO TaskSchedulerImpl: Adding task set 161.0 with 2 tasks resource profile 0
26/01/12 02:40:24 INFO TaskSetManager: Starting task 0.0 in stage 161.0 (TID 288) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:40:24 INFO TaskSetManager: Starting task 1.0 in stage 161.0 (TID 289) (172.18.0.5, executor 0, partition 1, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:40:24 INFO BlockManagerInfo: Added broadcast_242_piece0 in memory on 172.18.0.5:42453 (size: 77.4 KiB, free: 365.9 MiB)
26/01/12 02:40:24 INFO BlockManagerInfo: Added broadcast_241_piece0 in memory on 172.18.0.5:42453 (size: 35.4 KiB, free: 365.9 MiB)
26/01/12 02:40:24 INFO TaskSetManager: Finished task 1.0 in stage 161.0 (TID 289) in 58 ms on 172.18.0.5 (executor 0) (1/2)
26/01/12 02:40:49 INFO TaskSetManager: Finished task 0.0 in stage 161.0 (TID 288) in 25517 ms on 172.18.0.5 (executor 0) (2/2)
26/01/12 02:40:49 INFO TaskSchedulerImpl: Removed TaskSet 161.0, whose tasks have all completed, from pool 
26/01/12 02:40:49 INFO DAGScheduler: ResultStage 161 (parquet at <unknown>:0) finished in 25.547 s
26/01/12 02:40:49 INFO DAGScheduler: Job 161 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:40:49 INFO TaskSchedulerImpl: Killing all running tasks in stage 161: Stage finished
26/01/12 02:40:49 INFO DAGScheduler: Job 161 finished: parquet at <unknown>:0, took 25.554498 s
26/01/12 02:40:49 INFO FileFormatWriter: Start to commit write Job a2a6c124-51bf-4ae6-b286-e472ba4d7fe1.
26/01/12 02:40:49 INFO FileFormatWriter: Write Job a2a6c124-51bf-4ae6-b286-e472ba4d7fe1 committed. Elapsed time: 32 ms.
26/01/12 02:40:49 INFO FileFormatWriter: Finished processing stats for write job a2a6c124-51bf-4ae6-b286-e472ba4d7fe1.
Cargando: yellow_tripdata_2015-10.parquet en hdfs://hadoop-namenode:8020/data/nyc/raw/taxi-trips/2015...
26/01/12 02:40:50 INFO InMemoryFileIndex: It took 8 ms to list leaf files for 1 paths.
26/01/12 02:40:50 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 02:40:50 INFO DAGScheduler: Got job 162 (parquet at <unknown>:0) with 1 output partitions
26/01/12 02:40:50 INFO DAGScheduler: Final stage: ResultStage 162 (parquet at <unknown>:0)
26/01/12 02:40:50 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:40:50 INFO DAGScheduler: Missing parents: List()
26/01/12 02:40:50 INFO DAGScheduler: Submitting ResultStage 162 (MapPartitionsRDD[406] at parquet at <unknown>:0), which has no missing parents
26/01/12 02:40:50 INFO MemoryStore: Block broadcast_243 stored as values in memory (estimated size 102.6 KiB, free 363.5 MiB)
26/01/12 02:40:50 INFO MemoryStore: Block broadcast_243_piece0 stored as bytes in memory (estimated size 36.8 KiB, free 363.5 MiB)
26/01/12 02:40:50 INFO BlockManagerInfo: Added broadcast_243_piece0 in memory on 02926ee04bc9:45221 (size: 36.8 KiB, free: 365.8 MiB)
26/01/12 02:40:50 INFO SparkContext: Created broadcast 243 from broadcast at DAGScheduler.scala:1513
26/01/12 02:40:50 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 162 (MapPartitionsRDD[406] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0))
26/01/12 02:40:50 INFO TaskSchedulerImpl: Adding task set 162.0 with 1 tasks resource profile 0
26/01/12 02:40:50 INFO TaskSetManager: Starting task 0.0 in stage 162.0 (TID 290) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4607 bytes) taskResourceAssignments Map()
26/01/12 02:40:50 INFO BlockManagerInfo: Added broadcast_243_piece0 in memory on 172.18.0.5:42453 (size: 36.8 KiB, free: 365.8 MiB)
26/01/12 02:40:50 INFO TaskSetManager: Finished task 0.0 in stage 162.0 (TID 290) in 49 ms on 172.18.0.5 (executor 0) (1/1)
26/01/12 02:40:50 INFO TaskSchedulerImpl: Removed TaskSet 162.0, whose tasks have all completed, from pool 
26/01/12 02:40:50 INFO DAGScheduler: ResultStage 162 (parquet at <unknown>:0) finished in 0.063 s
26/01/12 02:40:50 INFO DAGScheduler: Job 162 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:40:50 INFO TaskSchedulerImpl: Killing all running tasks in stage 162: Stage finished
26/01/12 02:40:50 INFO DAGScheduler: Job 162 finished: parquet at <unknown>:0, took 0.068389 s
26/01/12 02:40:50 INFO FileSourceStrategy: Pushed Filters: 
26/01/12 02:40:50 INFO FileSourceStrategy: Post-Scan Filters: 
26/01/12 02:40:50 INFO FileSourceStrategy: Output Data Schema: struct<VendorID: bigint, tpep_pickup_datetime: timestamp, tpep_dropoff_datetime: timestamp, passenger_count: bigint, trip_distance: double ... 17 more fields>
26/01/12 02:40:50 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:40:50 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:40:50 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:40:50 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:40:50 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:40:50 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:40:50 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:40:50 INFO MemoryStore: Block broadcast_244 stored as values in memory (estimated size 358.4 KiB, free 363.1 MiB)
26/01/12 02:40:50 INFO MemoryStore: Block broadcast_244_piece0 stored as bytes in memory (estimated size 35.4 KiB, free 363.1 MiB)
26/01/12 02:40:50 INFO BlockManagerInfo: Added broadcast_244_piece0 in memory on 02926ee04bc9:45221 (size: 35.4 KiB, free: 365.8 MiB)
26/01/12 02:40:50 INFO SparkContext: Created broadcast 244 from parquet at <unknown>:0
26/01/12 02:40:50 INFO FileSourceScanExec: Planning scan with bin packing, max size: 87642885 bytes, open cost is considered as scanning 4194304 bytes.
26/01/12 02:40:50 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 02:40:50 INFO DAGScheduler: Got job 163 (parquet at <unknown>:0) with 2 output partitions
26/01/12 02:40:50 INFO DAGScheduler: Final stage: ResultStage 163 (parquet at <unknown>:0)
26/01/12 02:40:50 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:40:50 INFO DAGScheduler: Missing parents: List()
26/01/12 02:40:50 INFO DAGScheduler: Submitting ResultStage 163 (MapPartitionsRDD[409] at parquet at <unknown>:0), which has no missing parents
26/01/12 02:40:50 INFO MemoryStore: Block broadcast_245 stored as values in memory (estimated size 225.1 KiB, free 362.9 MiB)
26/01/12 02:40:50 INFO MemoryStore: Block broadcast_245_piece0 stored as bytes in memory (estimated size 77.4 KiB, free 362.8 MiB)
26/01/12 02:40:50 INFO BlockManagerInfo: Added broadcast_245_piece0 in memory on 02926ee04bc9:45221 (size: 77.4 KiB, free: 365.7 MiB)
26/01/12 02:40:50 INFO SparkContext: Created broadcast 245 from broadcast at DAGScheduler.scala:1513
26/01/12 02:40:50 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 163 (MapPartitionsRDD[409] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1))
26/01/12 02:40:50 INFO TaskSchedulerImpl: Adding task set 163.0 with 2 tasks resource profile 0
26/01/12 02:40:50 INFO TaskSetManager: Starting task 0.0 in stage 163.0 (TID 291) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:40:50 INFO TaskSetManager: Starting task 1.0 in stage 163.0 (TID 292) (172.18.0.5, executor 0, partition 1, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:40:50 INFO BlockManagerInfo: Added broadcast_245_piece0 in memory on 172.18.0.5:42453 (size: 77.4 KiB, free: 365.8 MiB)
26/01/12 02:40:50 INFO BlockManagerInfo: Added broadcast_244_piece0 in memory on 172.18.0.5:42453 (size: 35.4 KiB, free: 365.7 MiB)
26/01/12 02:40:50 INFO TaskSetManager: Finished task 1.0 in stage 163.0 (TID 292) in 56 ms on 172.18.0.5 (executor 0) (1/2)
26/01/12 02:41:18 INFO TaskSetManager: Finished task 0.0 in stage 163.0 (TID 291) in 27818 ms on 172.18.0.5 (executor 0) (2/2)
26/01/12 02:41:18 INFO TaskSchedulerImpl: Removed TaskSet 163.0, whose tasks have all completed, from pool 
26/01/12 02:41:18 INFO DAGScheduler: ResultStage 163 (parquet at <unknown>:0) finished in 27.849 s
26/01/12 02:41:18 INFO DAGScheduler: Job 163 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:41:18 INFO TaskSchedulerImpl: Killing all running tasks in stage 163: Stage finished
26/01/12 02:41:18 INFO DAGScheduler: Job 163 finished: parquet at <unknown>:0, took 27.855469 s
26/01/12 02:41:18 INFO FileFormatWriter: Start to commit write Job 70a8f31d-cc35-4249-8cc9-a2dbe39659a7.
26/01/12 02:41:18 INFO FileFormatWriter: Write Job 70a8f31d-cc35-4249-8cc9-a2dbe39659a7 committed. Elapsed time: 30 ms.
26/01/12 02:41:18 INFO FileFormatWriter: Finished processing stats for write job 70a8f31d-cc35-4249-8cc9-a2dbe39659a7.
Cargando: yellow_tripdata_2015-11.parquet en hdfs://hadoop-namenode:8020/data/nyc/raw/taxi-trips/2015...
26/01/12 02:41:18 INFO InMemoryFileIndex: It took 6 ms to list leaf files for 1 paths.
26/01/12 02:41:18 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 02:41:18 INFO DAGScheduler: Got job 164 (parquet at <unknown>:0) with 1 output partitions
26/01/12 02:41:18 INFO DAGScheduler: Final stage: ResultStage 164 (parquet at <unknown>:0)
26/01/12 02:41:18 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:41:18 INFO DAGScheduler: Missing parents: List()
26/01/12 02:41:18 INFO DAGScheduler: Submitting ResultStage 164 (MapPartitionsRDD[411] at parquet at <unknown>:0), which has no missing parents
26/01/12 02:41:18 INFO MemoryStore: Block broadcast_246 stored as values in memory (estimated size 102.6 KiB, free 362.7 MiB)
26/01/12 02:41:18 INFO MemoryStore: Block broadcast_246_piece0 stored as bytes in memory (estimated size 36.8 KiB, free 362.7 MiB)
26/01/12 02:41:18 INFO BlockManagerInfo: Added broadcast_246_piece0 in memory on 02926ee04bc9:45221 (size: 36.8 KiB, free: 365.7 MiB)
26/01/12 02:41:18 INFO SparkContext: Created broadcast 246 from broadcast at DAGScheduler.scala:1513
26/01/12 02:41:18 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 164 (MapPartitionsRDD[411] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0))
26/01/12 02:41:18 INFO TaskSchedulerImpl: Adding task set 164.0 with 1 tasks resource profile 0
26/01/12 02:41:18 INFO TaskSetManager: Starting task 0.0 in stage 164.0 (TID 293) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4607 bytes) taskResourceAssignments Map()
26/01/12 02:41:18 INFO BlockManagerInfo: Added broadcast_246_piece0 in memory on 172.18.0.5:42453 (size: 36.8 KiB, free: 365.7 MiB)
26/01/12 02:41:18 INFO TaskSetManager: Finished task 0.0 in stage 164.0 (TID 293) in 49 ms on 172.18.0.5 (executor 0) (1/1)
26/01/12 02:41:18 INFO TaskSchedulerImpl: Removed TaskSet 164.0, whose tasks have all completed, from pool 
26/01/12 02:41:18 INFO DAGScheduler: ResultStage 164 (parquet at <unknown>:0) finished in 0.061 s
26/01/12 02:41:18 INFO DAGScheduler: Job 164 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:41:18 INFO TaskSchedulerImpl: Killing all running tasks in stage 164: Stage finished
26/01/12 02:41:18 INFO DAGScheduler: Job 164 finished: parquet at <unknown>:0, took 0.065237 s
26/01/12 02:41:18 INFO FileSourceStrategy: Pushed Filters: 
26/01/12 02:41:18 INFO FileSourceStrategy: Post-Scan Filters: 
26/01/12 02:41:18 INFO FileSourceStrategy: Output Data Schema: struct<VendorID: bigint, tpep_pickup_datetime: timestamp, tpep_dropoff_datetime: timestamp, passenger_count: bigint, trip_distance: double ... 17 more fields>
26/01/12 02:41:18 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:41:18 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:41:18 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:41:18 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:41:18 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:41:18 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:41:18 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:41:18 INFO MemoryStore: Block broadcast_247 stored as values in memory (estimated size 358.4 KiB, free 362.3 MiB)
26/01/12 02:41:18 INFO MemoryStore: Block broadcast_247_piece0 stored as bytes in memory (estimated size 35.4 KiB, free 362.3 MiB)
26/01/12 02:41:18 INFO BlockManagerInfo: Added broadcast_247_piece0 in memory on 02926ee04bc9:45221 (size: 35.4 KiB, free: 365.6 MiB)
26/01/12 02:41:18 INFO SparkContext: Created broadcast 247 from parquet at <unknown>:0
26/01/12 02:41:18 INFO FileSourceScanExec: Planning scan with bin packing, max size: 80931655 bytes, open cost is considered as scanning 4194304 bytes.
26/01/12 02:41:18 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 02:41:18 INFO DAGScheduler: Got job 165 (parquet at <unknown>:0) with 2 output partitions
26/01/12 02:41:18 INFO DAGScheduler: Final stage: ResultStage 165 (parquet at <unknown>:0)
26/01/12 02:41:18 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:41:18 INFO DAGScheduler: Missing parents: List()
26/01/12 02:41:18 INFO DAGScheduler: Submitting ResultStage 165 (MapPartitionsRDD[414] at parquet at <unknown>:0), which has no missing parents
26/01/12 02:41:18 INFO MemoryStore: Block broadcast_248 stored as values in memory (estimated size 225.1 KiB, free 362.0 MiB)
26/01/12 02:41:18 INFO MemoryStore: Block broadcast_248_piece0 stored as bytes in memory (estimated size 77.4 KiB, free 362.0 MiB)
26/01/12 02:41:18 INFO BlockManagerInfo: Added broadcast_248_piece0 in memory on 02926ee04bc9:45221 (size: 77.4 KiB, free: 365.6 MiB)
26/01/12 02:41:18 INFO SparkContext: Created broadcast 248 from broadcast at DAGScheduler.scala:1513
26/01/12 02:41:18 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 165 (MapPartitionsRDD[414] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1))
26/01/12 02:41:18 INFO TaskSchedulerImpl: Adding task set 165.0 with 2 tasks resource profile 0
26/01/12 02:41:18 INFO TaskSetManager: Starting task 0.0 in stage 165.0 (TID 294) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:41:18 INFO TaskSetManager: Starting task 1.0 in stage 165.0 (TID 295) (172.18.0.5, executor 0, partition 1, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:41:18 INFO BlockManagerInfo: Added broadcast_248_piece0 in memory on 172.18.0.5:42453 (size: 77.4 KiB, free: 365.6 MiB)
26/01/12 02:41:18 INFO BlockManagerInfo: Added broadcast_247_piece0 in memory on 172.18.0.5:42453 (size: 35.4 KiB, free: 365.6 MiB)
26/01/12 02:41:18 INFO TaskSetManager: Finished task 1.0 in stage 165.0 (TID 295) in 52 ms on 172.18.0.5 (executor 0) (1/2)
26/01/12 02:41:43 INFO TaskSetManager: Finished task 0.0 in stage 165.0 (TID 294) in 25680 ms on 172.18.0.5 (executor 0) (2/2)
26/01/12 02:41:43 INFO TaskSchedulerImpl: Removed TaskSet 165.0, whose tasks have all completed, from pool 
26/01/12 02:41:43 INFO DAGScheduler: ResultStage 165 (parquet at <unknown>:0) finished in 25.699 s
26/01/12 02:41:43 INFO DAGScheduler: Job 165 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:41:43 INFO TaskSchedulerImpl: Killing all running tasks in stage 165: Stage finished
26/01/12 02:41:43 INFO DAGScheduler: Job 165 finished: parquet at <unknown>:0, took 25.706094 s
26/01/12 02:41:43 INFO FileFormatWriter: Start to commit write Job 798082c4-3b79-4c01-a45e-41db33b7f996.
26/01/12 02:41:43 INFO FileFormatWriter: Write Job 798082c4-3b79-4c01-a45e-41db33b7f996 committed. Elapsed time: 29 ms.
26/01/12 02:41:43 INFO FileFormatWriter: Finished processing stats for write job 798082c4-3b79-4c01-a45e-41db33b7f996.
Cargando: yellow_tripdata_2015-12.parquet en hdfs://hadoop-namenode:8020/data/nyc/raw/taxi-trips/2015...
26/01/12 02:41:44 INFO InMemoryFileIndex: It took 7 ms to list leaf files for 1 paths.
26/01/12 02:41:44 INFO BlockManagerInfo: Removed broadcast_242_piece0 on 02926ee04bc9:45221 in memory (size: 77.4 KiB, free: 365.6 MiB)
26/01/12 02:41:44 INFO BlockManagerInfo: Removed broadcast_242_piece0 on 172.18.0.5:42453 in memory (size: 77.4 KiB, free: 365.6 MiB)
26/01/12 02:41:44 INFO BlockManagerInfo: Removed broadcast_237_piece0 on 02926ee04bc9:45221 in memory (size: 36.8 KiB, free: 365.7 MiB)
26/01/12 02:41:44 INFO BlockManagerInfo: Removed broadcast_237_piece0 on 172.18.0.5:42453 in memory (size: 36.8 KiB, free: 365.7 MiB)
26/01/12 02:41:44 INFO BlockManagerInfo: Removed broadcast_243_piece0 on 02926ee04bc9:45221 in memory (size: 36.8 KiB, free: 365.7 MiB)
26/01/12 02:41:44 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 02:41:44 INFO BlockManagerInfo: Removed broadcast_243_piece0 on 172.18.0.5:42453 in memory (size: 36.8 KiB, free: 365.7 MiB)
26/01/12 02:41:44 INFO DAGScheduler: Got job 166 (parquet at <unknown>:0) with 1 output partitions
26/01/12 02:41:44 INFO DAGScheduler: Final stage: ResultStage 166 (parquet at <unknown>:0)
26/01/12 02:41:44 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:41:44 INFO DAGScheduler: Missing parents: List()
26/01/12 02:41:44 INFO DAGScheduler: Submitting ResultStage 166 (MapPartitionsRDD[416] at parquet at <unknown>:0), which has no missing parents
26/01/12 02:41:44 INFO BlockManagerInfo: Removed broadcast_240_piece0 on 02926ee04bc9:45221 in memory (size: 36.8 KiB, free: 365.8 MiB)
26/01/12 02:41:44 INFO BlockManagerInfo: Removed broadcast_240_piece0 on 172.18.0.5:42453 in memory (size: 36.8 KiB, free: 365.8 MiB)
26/01/12 02:41:44 INFO MemoryStore: Block broadcast_249 stored as values in memory (estimated size 102.6 KiB, free 362.6 MiB)
26/01/12 02:41:44 INFO MemoryStore: Block broadcast_249_piece0 stored as bytes in memory (estimated size 36.8 KiB, free 362.5 MiB)
26/01/12 02:41:44 INFO BlockManagerInfo: Added broadcast_249_piece0 in memory on 02926ee04bc9:45221 (size: 36.8 KiB, free: 365.7 MiB)
26/01/12 02:41:44 INFO SparkContext: Created broadcast 249 from broadcast at DAGScheduler.scala:1513
26/01/12 02:41:44 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 166 (MapPartitionsRDD[416] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0))
26/01/12 02:41:44 INFO TaskSchedulerImpl: Adding task set 166.0 with 1 tasks resource profile 0
26/01/12 02:41:44 INFO BlockManagerInfo: Removed broadcast_244_piece0 on 02926ee04bc9:45221 in memory (size: 35.4 KiB, free: 365.8 MiB)
26/01/12 02:41:44 INFO TaskSetManager: Starting task 0.0 in stage 166.0 (TID 296) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4607 bytes) taskResourceAssignments Map()
26/01/12 02:41:44 INFO BlockManagerInfo: Removed broadcast_244_piece0 on 172.18.0.5:42453 in memory (size: 35.4 KiB, free: 365.8 MiB)
26/01/12 02:41:44 INFO BlockManagerInfo: Removed broadcast_245_piece0 on 02926ee04bc9:45221 in memory (size: 77.4 KiB, free: 365.8 MiB)
26/01/12 02:41:44 INFO BlockManagerInfo: Removed broadcast_245_piece0 on 172.18.0.5:42453 in memory (size: 77.4 KiB, free: 365.9 MiB)
26/01/12 02:41:44 INFO BlockManagerInfo: Added broadcast_249_piece0 in memory on 172.18.0.5:42453 (size: 36.8 KiB, free: 365.8 MiB)
26/01/12 02:41:44 INFO BlockManagerInfo: Removed broadcast_238_piece0 on 02926ee04bc9:45221 in memory (size: 35.4 KiB, free: 365.9 MiB)
26/01/12 02:41:44 INFO BlockManagerInfo: Removed broadcast_238_piece0 on 172.18.0.5:42453 in memory (size: 35.4 KiB, free: 365.9 MiB)
26/01/12 02:41:44 INFO BlockManagerInfo: Removed broadcast_239_piece0 on 02926ee04bc9:45221 in memory (size: 77.4 KiB, free: 365.9 MiB)
26/01/12 02:41:44 INFO BlockManagerInfo: Removed broadcast_239_piece0 on 172.18.0.5:42453 in memory (size: 77.4 KiB, free: 365.9 MiB)
26/01/12 02:41:44 INFO BlockManagerInfo: Removed broadcast_241_piece0 on 02926ee04bc9:45221 in memory (size: 35.4 KiB, free: 366.0 MiB)
26/01/12 02:41:44 INFO BlockManagerInfo: Removed broadcast_241_piece0 on 172.18.0.5:42453 in memory (size: 35.4 KiB, free: 366.0 MiB)
26/01/12 02:41:44 INFO BlockManagerInfo: Removed broadcast_248_piece0 on 02926ee04bc9:45221 in memory (size: 77.4 KiB, free: 366.0 MiB)
26/01/12 02:41:44 INFO BlockManagerInfo: Removed broadcast_248_piece0 on 172.18.0.5:42453 in memory (size: 77.4 KiB, free: 366.0 MiB)
26/01/12 02:41:44 INFO BlockManagerInfo: Removed broadcast_235_piece0 on 02926ee04bc9:45221 in memory (size: 35.4 KiB, free: 366.1 MiB)
26/01/12 02:41:44 INFO BlockManagerInfo: Removed broadcast_235_piece0 on 172.18.0.5:42453 in memory (size: 35.4 KiB, free: 366.1 MiB)
26/01/12 02:41:44 INFO BlockManagerInfo: Removed broadcast_246_piece0 on 02926ee04bc9:45221 in memory (size: 36.8 KiB, free: 366.1 MiB)
26/01/12 02:41:44 INFO BlockManagerInfo: Removed broadcast_246_piece0 on 172.18.0.5:42453 in memory (size: 36.8 KiB, free: 366.1 MiB)
26/01/12 02:41:44 INFO TaskSetManager: Finished task 0.0 in stage 166.0 (TID 296) in 62 ms on 172.18.0.5 (executor 0) (1/1)
26/01/12 02:41:44 INFO TaskSchedulerImpl: Removed TaskSet 166.0, whose tasks have all completed, from pool 
26/01/12 02:41:44 INFO DAGScheduler: ResultStage 166 (parquet at <unknown>:0) finished in 0.077 s
26/01/12 02:41:44 INFO DAGScheduler: Job 166 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:41:44 INFO TaskSchedulerImpl: Killing all running tasks in stage 166: Stage finished
26/01/12 02:41:44 INFO DAGScheduler: Job 166 finished: parquet at <unknown>:0, took 0.081159 s
26/01/12 02:41:44 INFO FileSourceStrategy: Pushed Filters: 
26/01/12 02:41:44 INFO FileSourceStrategy: Post-Scan Filters: 
26/01/12 02:41:44 INFO FileSourceStrategy: Output Data Schema: struct<VendorID: bigint, tpep_pickup_datetime: timestamp, tpep_dropoff_datetime: timestamp, passenger_count: bigint, trip_distance: double ... 17 more fields>
26/01/12 02:41:44 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:41:44 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:41:44 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:41:44 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:41:44 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:41:44 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:41:44 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:41:44 INFO MemoryStore: Block broadcast_250 stored as values in memory (estimated size 358.4 KiB, free 364.7 MiB)
26/01/12 02:41:44 INFO MemoryStore: Block broadcast_250_piece0 stored as bytes in memory (estimated size 35.4 KiB, free 364.7 MiB)
26/01/12 02:41:44 INFO BlockManagerInfo: Added broadcast_250_piece0 in memory on 02926ee04bc9:45221 (size: 35.4 KiB, free: 366.1 MiB)
26/01/12 02:41:44 INFO SparkContext: Created broadcast 250 from parquet at <unknown>:0
26/01/12 02:41:44 INFO FileSourceScanExec: Planning scan with bin packing, max size: 82049737 bytes, open cost is considered as scanning 4194304 bytes.
26/01/12 02:41:44 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 02:41:44 INFO DAGScheduler: Got job 167 (parquet at <unknown>:0) with 2 output partitions
26/01/12 02:41:44 INFO DAGScheduler: Final stage: ResultStage 167 (parquet at <unknown>:0)
26/01/12 02:41:44 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:41:44 INFO DAGScheduler: Missing parents: List()
26/01/12 02:41:44 INFO DAGScheduler: Submitting ResultStage 167 (MapPartitionsRDD[419] at parquet at <unknown>:0), which has no missing parents
26/01/12 02:41:44 INFO MemoryStore: Block broadcast_251 stored as values in memory (estimated size 225.1 KiB, free 364.5 MiB)
26/01/12 02:41:44 INFO MemoryStore: Block broadcast_251_piece0 stored as bytes in memory (estimated size 77.4 KiB, free 364.4 MiB)
26/01/12 02:41:44 INFO BlockManagerInfo: Added broadcast_251_piece0 in memory on 02926ee04bc9:45221 (size: 77.4 KiB, free: 366.0 MiB)
26/01/12 02:41:44 INFO SparkContext: Created broadcast 251 from broadcast at DAGScheduler.scala:1513
26/01/12 02:41:44 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 167 (MapPartitionsRDD[419] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1))
26/01/12 02:41:44 INFO TaskSchedulerImpl: Adding task set 167.0 with 2 tasks resource profile 0
26/01/12 02:41:44 INFO TaskSetManager: Starting task 0.0 in stage 167.0 (TID 297) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:41:44 INFO TaskSetManager: Starting task 1.0 in stage 167.0 (TID 298) (172.18.0.5, executor 0, partition 1, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:41:44 INFO BlockManagerInfo: Added broadcast_251_piece0 in memory on 172.18.0.5:42453 (size: 77.4 KiB, free: 366.0 MiB)
26/01/12 02:41:44 INFO BlockManagerInfo: Added broadcast_250_piece0 in memory on 172.18.0.5:42453 (size: 35.4 KiB, free: 366.0 MiB)
26/01/12 02:41:44 INFO TaskSetManager: Finished task 1.0 in stage 167.0 (TID 298) in 53 ms on 172.18.0.5 (executor 0) (1/2)
26/01/12 02:42:11 INFO TaskSetManager: Finished task 0.0 in stage 167.0 (TID 297) in 26810 ms on 172.18.0.5 (executor 0) (2/2)
26/01/12 02:42:11 INFO TaskSchedulerImpl: Removed TaskSet 167.0, whose tasks have all completed, from pool 
26/01/12 02:42:11 INFO DAGScheduler: ResultStage 167 (parquet at <unknown>:0) finished in 26.831 s
26/01/12 02:42:11 INFO DAGScheduler: Job 167 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:42:11 INFO TaskSchedulerImpl: Killing all running tasks in stage 167: Stage finished
26/01/12 02:42:11 INFO DAGScheduler: Job 167 finished: parquet at <unknown>:0, took 26.838473 s
26/01/12 02:42:11 INFO FileFormatWriter: Start to commit write Job 654f8f74-7fac-4d6f-96a7-acc2f47708b9.
26/01/12 02:42:11 INFO FileFormatWriter: Write Job 654f8f74-7fac-4d6f-96a7-acc2f47708b9 committed. Elapsed time: 39 ms.
26/01/12 02:42:11 INFO FileFormatWriter: Finished processing stats for write job 654f8f74-7fac-4d6f-96a7-acc2f47708b9.
Cargando: yellow_tripdata_2016-01.parquet en hdfs://hadoop-namenode:8020/data/nyc/raw/taxi-trips/2016...
26/01/12 02:42:11 INFO InMemoryFileIndex: It took 9 ms to list leaf files for 1 paths.
26/01/12 02:42:11 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 02:42:11 INFO DAGScheduler: Got job 168 (parquet at <unknown>:0) with 1 output partitions
26/01/12 02:42:11 INFO DAGScheduler: Final stage: ResultStage 168 (parquet at <unknown>:0)
26/01/12 02:42:11 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:42:11 INFO DAGScheduler: Missing parents: List()
26/01/12 02:42:11 INFO DAGScheduler: Submitting ResultStage 168 (MapPartitionsRDD[421] at parquet at <unknown>:0), which has no missing parents
26/01/12 02:42:11 INFO MemoryStore: Block broadcast_252 stored as values in memory (estimated size 102.6 KiB, free 364.3 MiB)
26/01/12 02:42:11 INFO MemoryStore: Block broadcast_252_piece0 stored as bytes in memory (estimated size 36.8 KiB, free 364.3 MiB)
26/01/12 02:42:11 INFO BlockManagerInfo: Added broadcast_252_piece0 in memory on 02926ee04bc9:45221 (size: 36.8 KiB, free: 366.0 MiB)
26/01/12 02:42:11 INFO SparkContext: Created broadcast 252 from broadcast at DAGScheduler.scala:1513
26/01/12 02:42:11 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 168 (MapPartitionsRDD[421] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0))
26/01/12 02:42:11 INFO TaskSchedulerImpl: Adding task set 168.0 with 1 tasks resource profile 0
26/01/12 02:42:11 INFO TaskSetManager: Starting task 0.0 in stage 168.0 (TID 299) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4607 bytes) taskResourceAssignments Map()
26/01/12 02:42:11 INFO BlockManagerInfo: Added broadcast_252_piece0 in memory on 172.18.0.5:42453 (size: 36.8 KiB, free: 366.0 MiB)
26/01/12 02:42:11 INFO TaskSetManager: Finished task 0.0 in stage 168.0 (TID 299) in 54 ms on 172.18.0.5 (executor 0) (1/1)
26/01/12 02:42:11 INFO TaskSchedulerImpl: Removed TaskSet 168.0, whose tasks have all completed, from pool 
26/01/12 02:42:11 INFO DAGScheduler: ResultStage 168 (parquet at <unknown>:0) finished in 0.067 s
26/01/12 02:42:11 INFO DAGScheduler: Job 168 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:42:11 INFO TaskSchedulerImpl: Killing all running tasks in stage 168: Stage finished
26/01/12 02:42:11 INFO DAGScheduler: Job 168 finished: parquet at <unknown>:0, took 0.072337 s
26/01/12 02:42:11 INFO FileSourceStrategy: Pushed Filters: 
26/01/12 02:42:11 INFO FileSourceStrategy: Post-Scan Filters: 
26/01/12 02:42:11 INFO FileSourceStrategy: Output Data Schema: struct<VendorID: bigint, tpep_pickup_datetime: timestamp, tpep_dropoff_datetime: timestamp, passenger_count: bigint, trip_distance: double ... 17 more fields>
26/01/12 02:42:11 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:42:11 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:42:11 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:42:11 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:42:11 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:42:11 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:42:11 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:42:11 INFO MemoryStore: Block broadcast_253 stored as values in memory (estimated size 358.4 KiB, free 363.9 MiB)
26/01/12 02:42:11 INFO MemoryStore: Block broadcast_253_piece0 stored as bytes in memory (estimated size 35.4 KiB, free 363.9 MiB)
26/01/12 02:42:11 INFO BlockManagerInfo: Added broadcast_253_piece0 in memory on 02926ee04bc9:45221 (size: 35.4 KiB, free: 365.9 MiB)
26/01/12 02:42:11 INFO SparkContext: Created broadcast 253 from parquet at <unknown>:0
26/01/12 02:42:11 INFO FileSourceScanExec: Planning scan with bin packing, max size: 77722695 bytes, open cost is considered as scanning 4194304 bytes.
26/01/12 02:42:11 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 02:42:11 INFO DAGScheduler: Got job 169 (parquet at <unknown>:0) with 2 output partitions
26/01/12 02:42:11 INFO DAGScheduler: Final stage: ResultStage 169 (parquet at <unknown>:0)
26/01/12 02:42:11 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:42:11 INFO DAGScheduler: Missing parents: List()
26/01/12 02:42:11 INFO DAGScheduler: Submitting ResultStage 169 (MapPartitionsRDD[424] at parquet at <unknown>:0), which has no missing parents
26/01/12 02:42:11 INFO MemoryStore: Block broadcast_254 stored as values in memory (estimated size 225.1 KiB, free 363.7 MiB)
26/01/12 02:42:11 INFO MemoryStore: Block broadcast_254_piece0 stored as bytes in memory (estimated size 77.4 KiB, free 363.6 MiB)
26/01/12 02:42:11 INFO BlockManagerInfo: Added broadcast_254_piece0 in memory on 02926ee04bc9:45221 (size: 77.4 KiB, free: 365.9 MiB)
26/01/12 02:42:11 INFO SparkContext: Created broadcast 254 from broadcast at DAGScheduler.scala:1513
26/01/12 02:42:11 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 169 (MapPartitionsRDD[424] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1))
26/01/12 02:42:11 INFO TaskSchedulerImpl: Adding task set 169.0 with 2 tasks resource profile 0
26/01/12 02:42:11 INFO TaskSetManager: Starting task 0.0 in stage 169.0 (TID 300) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:42:11 INFO TaskSetManager: Starting task 1.0 in stage 169.0 (TID 301) (172.18.0.5, executor 0, partition 1, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:42:11 INFO BlockManagerInfo: Added broadcast_254_piece0 in memory on 172.18.0.5:42453 (size: 77.4 KiB, free: 365.9 MiB)
26/01/12 02:42:11 INFO BlockManagerInfo: Added broadcast_253_piece0 in memory on 172.18.0.5:42453 (size: 35.4 KiB, free: 365.9 MiB)
26/01/12 02:42:11 INFO TaskSetManager: Finished task 1.0 in stage 169.0 (TID 301) in 74 ms on 172.18.0.5 (executor 0) (1/2)
26/01/12 02:42:35 INFO TaskSetManager: Finished task 0.0 in stage 169.0 (TID 300) in 24678 ms on 172.18.0.5 (executor 0) (2/2)
26/01/12 02:42:35 INFO TaskSchedulerImpl: Removed TaskSet 169.0, whose tasks have all completed, from pool 
26/01/12 02:42:35 INFO DAGScheduler: ResultStage 169 (parquet at <unknown>:0) finished in 24.699 s
26/01/12 02:42:35 INFO DAGScheduler: Job 169 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:42:35 INFO TaskSchedulerImpl: Killing all running tasks in stage 169: Stage finished
26/01/12 02:42:35 INFO DAGScheduler: Job 169 finished: parquet at <unknown>:0, took 24.705897 s
26/01/12 02:42:35 INFO FileFormatWriter: Start to commit write Job 0dabe4f7-05bc-4824-80a1-8719dff2a47d.
26/01/12 02:42:36 INFO FileFormatWriter: Write Job 0dabe4f7-05bc-4824-80a1-8719dff2a47d committed. Elapsed time: 34 ms.
26/01/12 02:42:36 INFO FileFormatWriter: Finished processing stats for write job 0dabe4f7-05bc-4824-80a1-8719dff2a47d.
Cargando: yellow_tripdata_2016-02.parquet en hdfs://hadoop-namenode:8020/data/nyc/raw/taxi-trips/2016...
26/01/12 02:42:36 INFO InMemoryFileIndex: It took 7 ms to list leaf files for 1 paths.
26/01/12 02:42:36 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 02:42:36 INFO DAGScheduler: Got job 170 (parquet at <unknown>:0) with 1 output partitions
26/01/12 02:42:36 INFO DAGScheduler: Final stage: ResultStage 170 (parquet at <unknown>:0)
26/01/12 02:42:36 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:42:36 INFO DAGScheduler: Missing parents: List()
26/01/12 02:42:36 INFO DAGScheduler: Submitting ResultStage 170 (MapPartitionsRDD[426] at parquet at <unknown>:0), which has no missing parents
26/01/12 02:42:36 INFO MemoryStore: Block broadcast_255 stored as values in memory (estimated size 102.6 KiB, free 363.5 MiB)
26/01/12 02:42:36 INFO MemoryStore: Block broadcast_255_piece0 stored as bytes in memory (estimated size 36.8 KiB, free 363.5 MiB)
26/01/12 02:42:36 INFO BlockManagerInfo: Added broadcast_255_piece0 in memory on 02926ee04bc9:45221 (size: 36.8 KiB, free: 365.8 MiB)
26/01/12 02:42:36 INFO SparkContext: Created broadcast 255 from broadcast at DAGScheduler.scala:1513
26/01/12 02:42:36 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 170 (MapPartitionsRDD[426] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0))
26/01/12 02:42:36 INFO TaskSchedulerImpl: Adding task set 170.0 with 1 tasks resource profile 0
26/01/12 02:42:36 INFO TaskSetManager: Starting task 0.0 in stage 170.0 (TID 302) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4607 bytes) taskResourceAssignments Map()
26/01/12 02:42:36 INFO BlockManagerInfo: Added broadcast_255_piece0 in memory on 172.18.0.5:42453 (size: 36.8 KiB, free: 365.8 MiB)
26/01/12 02:42:36 INFO TaskSetManager: Finished task 0.0 in stage 170.0 (TID 302) in 51 ms on 172.18.0.5 (executor 0) (1/1)
26/01/12 02:42:36 INFO TaskSchedulerImpl: Removed TaskSet 170.0, whose tasks have all completed, from pool 
26/01/12 02:42:36 INFO DAGScheduler: ResultStage 170 (parquet at <unknown>:0) finished in 0.064 s
26/01/12 02:42:36 INFO DAGScheduler: Job 170 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:42:36 INFO TaskSchedulerImpl: Killing all running tasks in stage 170: Stage finished
26/01/12 02:42:36 INFO DAGScheduler: Job 170 finished: parquet at <unknown>:0, took 0.068917 s
26/01/12 02:42:36 INFO FileSourceStrategy: Pushed Filters: 
26/01/12 02:42:36 INFO FileSourceStrategy: Post-Scan Filters: 
26/01/12 02:42:36 INFO FileSourceStrategy: Output Data Schema: struct<VendorID: bigint, tpep_pickup_datetime: timestamp, tpep_dropoff_datetime: timestamp, passenger_count: bigint, trip_distance: double ... 17 more fields>
26/01/12 02:42:36 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:42:36 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:42:36 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:42:36 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:42:36 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:42:36 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:42:36 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:42:36 INFO MemoryStore: Block broadcast_256 stored as values in memory (estimated size 358.4 KiB, free 363.1 MiB)
26/01/12 02:42:36 INFO MemoryStore: Block broadcast_256_piece0 stored as bytes in memory (estimated size 35.4 KiB, free 363.1 MiB)
26/01/12 02:42:36 INFO BlockManagerInfo: Added broadcast_256_piece0 in memory on 02926ee04bc9:45221 (size: 35.4 KiB, free: 365.8 MiB)
26/01/12 02:42:36 INFO SparkContext: Created broadcast 256 from parquet at <unknown>:0
26/01/12 02:42:36 INFO FileSourceScanExec: Planning scan with bin packing, max size: 81154021 bytes, open cost is considered as scanning 4194304 bytes.
26/01/12 02:42:36 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 02:42:36 INFO DAGScheduler: Got job 171 (parquet at <unknown>:0) with 2 output partitions
26/01/12 02:42:36 INFO DAGScheduler: Final stage: ResultStage 171 (parquet at <unknown>:0)
26/01/12 02:42:36 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:42:36 INFO DAGScheduler: Missing parents: List()
26/01/12 02:42:36 INFO DAGScheduler: Submitting ResultStage 171 (MapPartitionsRDD[429] at parquet at <unknown>:0), which has no missing parents
26/01/12 02:42:36 INFO MemoryStore: Block broadcast_257 stored as values in memory (estimated size 225.1 KiB, free 362.9 MiB)
26/01/12 02:42:36 INFO MemoryStore: Block broadcast_257_piece0 stored as bytes in memory (estimated size 77.4 KiB, free 362.8 MiB)
26/01/12 02:42:36 INFO BlockManagerInfo: Added broadcast_257_piece0 in memory on 02926ee04bc9:45221 (size: 77.4 KiB, free: 365.7 MiB)
26/01/12 02:42:36 INFO SparkContext: Created broadcast 257 from broadcast at DAGScheduler.scala:1513
26/01/12 02:42:36 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 171 (MapPartitionsRDD[429] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1))
26/01/12 02:42:36 INFO TaskSchedulerImpl: Adding task set 171.0 with 2 tasks resource profile 0
26/01/12 02:42:36 INFO TaskSetManager: Starting task 0.0 in stage 171.0 (TID 303) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:42:36 INFO TaskSetManager: Starting task 1.0 in stage 171.0 (TID 304) (172.18.0.5, executor 0, partition 1, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:42:36 INFO BlockManagerInfo: Added broadcast_257_piece0 in memory on 172.18.0.5:42453 (size: 77.4 KiB, free: 365.8 MiB)
26/01/12 02:42:36 INFO BlockManagerInfo: Added broadcast_256_piece0 in memory on 172.18.0.5:42453 (size: 35.4 KiB, free: 365.7 MiB)
26/01/12 02:42:36 INFO TaskSetManager: Finished task 1.0 in stage 171.0 (TID 304) in 53 ms on 172.18.0.5 (executor 0) (1/2)
26/01/12 02:43:02 INFO TaskSetManager: Finished task 0.0 in stage 171.0 (TID 303) in 26152 ms on 172.18.0.5 (executor 0) (2/2)
26/01/12 02:43:02 INFO TaskSchedulerImpl: Removed TaskSet 171.0, whose tasks have all completed, from pool 
26/01/12 02:43:02 INFO DAGScheduler: ResultStage 171 (parquet at <unknown>:0) finished in 26.172 s
26/01/12 02:43:02 INFO DAGScheduler: Job 171 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:43:02 INFO TaskSchedulerImpl: Killing all running tasks in stage 171: Stage finished
26/01/12 02:43:02 INFO DAGScheduler: Job 171 finished: parquet at <unknown>:0, took 26.184512 s
26/01/12 02:43:02 INFO FileFormatWriter: Start to commit write Job 0726f6d1-046b-47c8-aa8a-b309cf2645b0.
26/01/12 02:43:02 INFO FileFormatWriter: Write Job 0726f6d1-046b-47c8-aa8a-b309cf2645b0 committed. Elapsed time: 34 ms.
26/01/12 02:43:02 INFO FileFormatWriter: Finished processing stats for write job 0726f6d1-046b-47c8-aa8a-b309cf2645b0.
Cargando: yellow_tripdata_2016-03.parquet en hdfs://hadoop-namenode:8020/data/nyc/raw/taxi-trips/2016...
26/01/12 02:43:02 INFO InMemoryFileIndex: It took 5 ms to list leaf files for 1 paths.
26/01/12 02:43:02 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 02:43:02 INFO DAGScheduler: Got job 172 (parquet at <unknown>:0) with 1 output partitions
26/01/12 02:43:02 INFO DAGScheduler: Final stage: ResultStage 172 (parquet at <unknown>:0)
26/01/12 02:43:02 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:43:02 INFO DAGScheduler: Missing parents: List()
26/01/12 02:43:02 INFO DAGScheduler: Submitting ResultStage 172 (MapPartitionsRDD[431] at parquet at <unknown>:0), which has no missing parents
26/01/12 02:43:02 INFO MemoryStore: Block broadcast_258 stored as values in memory (estimated size 102.6 KiB, free 362.7 MiB)
26/01/12 02:43:02 INFO MemoryStore: Block broadcast_258_piece0 stored as bytes in memory (estimated size 36.8 KiB, free 362.7 MiB)
26/01/12 02:43:02 INFO BlockManagerInfo: Added broadcast_258_piece0 in memory on 02926ee04bc9:45221 (size: 36.8 KiB, free: 365.7 MiB)
26/01/12 02:43:02 INFO SparkContext: Created broadcast 258 from broadcast at DAGScheduler.scala:1513
26/01/12 02:43:02 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 172 (MapPartitionsRDD[431] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0))
26/01/12 02:43:02 INFO TaskSchedulerImpl: Adding task set 172.0 with 1 tasks resource profile 0
26/01/12 02:43:02 INFO TaskSetManager: Starting task 0.0 in stage 172.0 (TID 305) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4607 bytes) taskResourceAssignments Map()
26/01/12 02:43:02 INFO BlockManagerInfo: Added broadcast_258_piece0 in memory on 172.18.0.5:42453 (size: 36.8 KiB, free: 365.7 MiB)
26/01/12 02:43:02 INFO TaskSetManager: Finished task 0.0 in stage 172.0 (TID 305) in 47 ms on 172.18.0.5 (executor 0) (1/1)
26/01/12 02:43:02 INFO TaskSchedulerImpl: Removed TaskSet 172.0, whose tasks have all completed, from pool 
26/01/12 02:43:02 INFO DAGScheduler: ResultStage 172 (parquet at <unknown>:0) finished in 0.059 s
26/01/12 02:43:02 INFO DAGScheduler: Job 172 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:43:02 INFO TaskSchedulerImpl: Killing all running tasks in stage 172: Stage finished
26/01/12 02:43:02 INFO DAGScheduler: Job 172 finished: parquet at <unknown>:0, took 0.063960 s
26/01/12 02:43:02 INFO FileSourceStrategy: Pushed Filters: 
26/01/12 02:43:02 INFO FileSourceStrategy: Post-Scan Filters: 
26/01/12 02:43:02 INFO FileSourceStrategy: Output Data Schema: struct<VendorID: bigint, tpep_pickup_datetime: timestamp, tpep_dropoff_datetime: timestamp, passenger_count: bigint, trip_distance: double ... 17 more fields>
26/01/12 02:43:02 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:43:02 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:43:02 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:43:02 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:43:02 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:43:02 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:43:02 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:43:02 INFO MemoryStore: Block broadcast_259 stored as values in memory (estimated size 358.4 KiB, free 362.3 MiB)
26/01/12 02:43:02 INFO MemoryStore: Block broadcast_259_piece0 stored as bytes in memory (estimated size 35.4 KiB, free 362.3 MiB)
26/01/12 02:43:02 INFO BlockManagerInfo: Added broadcast_259_piece0 in memory on 02926ee04bc9:45221 (size: 35.4 KiB, free: 365.6 MiB)
26/01/12 02:43:02 INFO SparkContext: Created broadcast 259 from parquet at <unknown>:0
26/01/12 02:43:02 INFO FileSourceScanExec: Planning scan with bin packing, max size: 87107084 bytes, open cost is considered as scanning 4194304 bytes.
26/01/12 02:43:02 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 02:43:02 INFO DAGScheduler: Got job 173 (parquet at <unknown>:0) with 2 output partitions
26/01/12 02:43:02 INFO DAGScheduler: Final stage: ResultStage 173 (parquet at <unknown>:0)
26/01/12 02:43:02 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:43:02 INFO DAGScheduler: Missing parents: List()
26/01/12 02:43:02 INFO DAGScheduler: Submitting ResultStage 173 (MapPartitionsRDD[434] at parquet at <unknown>:0), which has no missing parents
26/01/12 02:43:02 INFO MemoryStore: Block broadcast_260 stored as values in memory (estimated size 225.1 KiB, free 362.0 MiB)
26/01/12 02:43:02 INFO MemoryStore: Block broadcast_260_piece0 stored as bytes in memory (estimated size 77.4 KiB, free 362.0 MiB)
26/01/12 02:43:02 INFO BlockManagerInfo: Added broadcast_260_piece0 in memory on 02926ee04bc9:45221 (size: 77.4 KiB, free: 365.6 MiB)
26/01/12 02:43:02 INFO SparkContext: Created broadcast 260 from broadcast at DAGScheduler.scala:1513
26/01/12 02:43:02 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 173 (MapPartitionsRDD[434] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1))
26/01/12 02:43:02 INFO TaskSchedulerImpl: Adding task set 173.0 with 2 tasks resource profile 0
26/01/12 02:43:02 INFO TaskSetManager: Starting task 0.0 in stage 173.0 (TID 306) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:43:02 INFO TaskSetManager: Starting task 1.0 in stage 173.0 (TID 307) (172.18.0.5, executor 0, partition 1, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:43:02 INFO BlockManagerInfo: Added broadcast_260_piece0 in memory on 172.18.0.5:42453 (size: 77.4 KiB, free: 365.6 MiB)
26/01/12 02:43:02 INFO BlockManagerInfo: Added broadcast_259_piece0 in memory on 172.18.0.5:42453 (size: 35.4 KiB, free: 365.6 MiB)
26/01/12 02:43:02 INFO TaskSetManager: Finished task 1.0 in stage 173.0 (TID 307) in 57 ms on 172.18.0.5 (executor 0) (1/2)
26/01/12 02:43:31 INFO TaskSetManager: Finished task 0.0 in stage 173.0 (TID 306) in 29259 ms on 172.18.0.5 (executor 0) (2/2)
26/01/12 02:43:31 INFO TaskSchedulerImpl: Removed TaskSet 173.0, whose tasks have all completed, from pool 
26/01/12 02:43:31 INFO DAGScheduler: ResultStage 173 (parquet at <unknown>:0) finished in 29.280 s
26/01/12 02:43:31 INFO DAGScheduler: Job 173 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:43:31 INFO TaskSchedulerImpl: Killing all running tasks in stage 173: Stage finished
26/01/12 02:43:31 INFO DAGScheduler: Job 173 finished: parquet at <unknown>:0, took 29.284640 s
26/01/12 02:43:31 INFO FileFormatWriter: Start to commit write Job 4ae4821d-6640-45c2-ba9f-8382f89b2f66.
26/01/12 02:43:31 INFO FileFormatWriter: Write Job 4ae4821d-6640-45c2-ba9f-8382f89b2f66 committed. Elapsed time: 31 ms.
26/01/12 02:43:31 INFO FileFormatWriter: Finished processing stats for write job 4ae4821d-6640-45c2-ba9f-8382f89b2f66.
Cargando: yellow_tripdata_2016-04.parquet en hdfs://hadoop-namenode:8020/data/nyc/raw/taxi-trips/2016...
26/01/12 02:43:31 INFO InMemoryFileIndex: It took 8 ms to list leaf files for 1 paths.
26/01/12 02:43:31 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 02:43:31 INFO DAGScheduler: Got job 174 (parquet at <unknown>:0) with 1 output partitions
26/01/12 02:43:31 INFO DAGScheduler: Final stage: ResultStage 174 (parquet at <unknown>:0)
26/01/12 02:43:31 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:43:32 INFO DAGScheduler: Missing parents: List()
26/01/12 02:43:32 INFO BlockManagerInfo: Removed broadcast_256_piece0 on 02926ee04bc9:45221 in memory (size: 35.4 KiB, free: 365.6 MiB)
26/01/12 02:43:32 INFO BlockManagerInfo: Removed broadcast_256_piece0 on 172.18.0.5:42453 in memory (size: 35.4 KiB, free: 365.6 MiB)
26/01/12 02:43:32 INFO DAGScheduler: Submitting ResultStage 174 (MapPartitionsRDD[436] at parquet at <unknown>:0), which has no missing parents
26/01/12 02:43:32 INFO BlockManagerInfo: Removed broadcast_253_piece0 on 02926ee04bc9:45221 in memory (size: 35.4 KiB, free: 365.6 MiB)
26/01/12 02:43:32 INFO MemoryStore: Block broadcast_261 stored as values in memory (estimated size 102.6 KiB, free 362.3 MiB)
26/01/12 02:43:32 INFO BlockManagerInfo: Removed broadcast_253_piece0 on 172.18.0.5:42453 in memory (size: 35.4 KiB, free: 365.6 MiB)
26/01/12 02:43:32 INFO MemoryStore: Block broadcast_261_piece0 stored as bytes in memory (estimated size 36.8 KiB, free 362.6 MiB)
26/01/12 02:43:32 INFO BlockManagerInfo: Added broadcast_261_piece0 in memory on 02926ee04bc9:45221 (size: 36.8 KiB, free: 365.6 MiB)
26/01/12 02:43:32 INFO SparkContext: Created broadcast 261 from broadcast at DAGScheduler.scala:1513
26/01/12 02:43:32 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 174 (MapPartitionsRDD[436] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0))
26/01/12 02:43:32 INFO TaskSchedulerImpl: Adding task set 174.0 with 1 tasks resource profile 0
26/01/12 02:43:32 INFO BlockManagerInfo: Removed broadcast_260_piece0 on 02926ee04bc9:45221 in memory (size: 77.4 KiB, free: 365.7 MiB)
26/01/12 02:43:32 INFO TaskSetManager: Starting task 0.0 in stage 174.0 (TID 308) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4607 bytes) taskResourceAssignments Map()
26/01/12 02:43:32 INFO BlockManagerInfo: Removed broadcast_260_piece0 on 172.18.0.5:42453 in memory (size: 77.4 KiB, free: 365.7 MiB)
26/01/12 02:43:32 INFO BlockManagerInfo: Removed broadcast_249_piece0 on 02926ee04bc9:45221 in memory (size: 36.8 KiB, free: 365.7 MiB)
26/01/12 02:43:32 INFO BlockManagerInfo: Removed broadcast_249_piece0 on 172.18.0.5:42453 in memory (size: 36.8 KiB, free: 365.8 MiB)
26/01/12 02:43:32 INFO BlockManagerInfo: Added broadcast_261_piece0 in memory on 172.18.0.5:42453 (size: 36.8 KiB, free: 365.7 MiB)
26/01/12 02:43:32 INFO BlockManagerInfo: Removed broadcast_250_piece0 on 02926ee04bc9:45221 in memory (size: 35.4 KiB, free: 365.8 MiB)
26/01/12 02:43:32 INFO BlockManagerInfo: Removed broadcast_250_piece0 on 172.18.0.5:42453 in memory (size: 35.4 KiB, free: 365.8 MiB)
26/01/12 02:43:32 INFO BlockManagerInfo: Removed broadcast_254_piece0 on 02926ee04bc9:45221 in memory (size: 77.4 KiB, free: 365.8 MiB)
26/01/12 02:43:32 INFO BlockManagerInfo: Removed broadcast_254_piece0 on 172.18.0.5:42453 in memory (size: 77.4 KiB, free: 365.8 MiB)
26/01/12 02:43:32 INFO BlockManagerInfo: Removed broadcast_251_piece0 on 02926ee04bc9:45221 in memory (size: 77.4 KiB, free: 365.9 MiB)
26/01/12 02:43:32 INFO BlockManagerInfo: Removed broadcast_251_piece0 on 172.18.0.5:42453 in memory (size: 77.4 KiB, free: 365.9 MiB)
26/01/12 02:43:32 INFO BlockManagerInfo: Removed broadcast_247_piece0 on 02926ee04bc9:45221 in memory (size: 35.4 KiB, free: 365.9 MiB)
26/01/12 02:43:32 INFO BlockManagerInfo: Removed broadcast_247_piece0 on 172.18.0.5:42453 in memory (size: 35.4 KiB, free: 365.9 MiB)
26/01/12 02:43:32 INFO BlockManagerInfo: Removed broadcast_258_piece0 on 02926ee04bc9:45221 in memory (size: 36.8 KiB, free: 366.0 MiB)
26/01/12 02:43:32 INFO BlockManagerInfo: Removed broadcast_258_piece0 on 172.18.0.5:42453 in memory (size: 36.8 KiB, free: 366.0 MiB)
26/01/12 02:43:32 INFO BlockManagerInfo: Removed broadcast_255_piece0 on 02926ee04bc9:45221 in memory (size: 36.8 KiB, free: 366.0 MiB)
26/01/12 02:43:32 INFO BlockManagerInfo: Removed broadcast_255_piece0 on 172.18.0.5:42453 in memory (size: 36.8 KiB, free: 366.0 MiB)
26/01/12 02:43:32 INFO BlockManagerInfo: Removed broadcast_257_piece0 on 02926ee04bc9:45221 in memory (size: 77.4 KiB, free: 366.1 MiB)
26/01/12 02:43:32 INFO BlockManagerInfo: Removed broadcast_257_piece0 on 172.18.0.5:42453 in memory (size: 77.4 KiB, free: 366.1 MiB)
26/01/12 02:43:32 INFO BlockManagerInfo: Removed broadcast_252_piece0 on 02926ee04bc9:45221 in memory (size: 36.8 KiB, free: 366.1 MiB)
26/01/12 02:43:32 INFO BlockManagerInfo: Removed broadcast_252_piece0 on 172.18.0.5:42453 in memory (size: 36.8 KiB, free: 366.1 MiB)
26/01/12 02:43:32 INFO TaskSetManager: Finished task 0.0 in stage 174.0 (TID 308) in 72 ms on 172.18.0.5 (executor 0) (1/1)
26/01/12 02:43:32 INFO TaskSchedulerImpl: Removed TaskSet 174.0, whose tasks have all completed, from pool 
26/01/12 02:43:32 INFO DAGScheduler: ResultStage 174 (parquet at <unknown>:0) finished in 0.085 s
26/01/12 02:43:32 INFO DAGScheduler: Job 174 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:43:32 INFO TaskSchedulerImpl: Killing all running tasks in stage 174: Stage finished
26/01/12 02:43:32 INFO DAGScheduler: Job 174 finished: parquet at <unknown>:0, took 0.095437 s
26/01/12 02:43:32 INFO FileSourceStrategy: Pushed Filters: 
26/01/12 02:43:32 INFO FileSourceStrategy: Post-Scan Filters: 
26/01/12 02:43:32 INFO FileSourceStrategy: Output Data Schema: struct<VendorID: bigint, tpep_pickup_datetime: timestamp, tpep_dropoff_datetime: timestamp, passenger_count: bigint, trip_distance: double ... 17 more fields>
26/01/12 02:43:32 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:43:32 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:43:32 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:43:32 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:43:32 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:43:32 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:43:32 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:43:32 INFO MemoryStore: Block broadcast_262 stored as values in memory (estimated size 358.4 KiB, free 364.7 MiB)
26/01/12 02:43:32 INFO MemoryStore: Block broadcast_262_piece0 stored as bytes in memory (estimated size 35.4 KiB, free 364.7 MiB)
26/01/12 02:43:32 INFO BlockManagerInfo: Added broadcast_262_piece0 in memory on 02926ee04bc9:45221 (size: 35.4 KiB, free: 366.1 MiB)
26/01/12 02:43:32 INFO SparkContext: Created broadcast 262 from parquet at <unknown>:0
26/01/12 02:43:32 INFO FileSourceScanExec: Planning scan with bin packing, max size: 84873648 bytes, open cost is considered as scanning 4194304 bytes.
26/01/12 02:43:32 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 02:43:32 INFO DAGScheduler: Got job 175 (parquet at <unknown>:0) with 2 output partitions
26/01/12 02:43:32 INFO DAGScheduler: Final stage: ResultStage 175 (parquet at <unknown>:0)
26/01/12 02:43:32 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:43:32 INFO DAGScheduler: Missing parents: List()
26/01/12 02:43:32 INFO DAGScheduler: Submitting ResultStage 175 (MapPartitionsRDD[439] at parquet at <unknown>:0), which has no missing parents
26/01/12 02:43:32 INFO MemoryStore: Block broadcast_263 stored as values in memory (estimated size 225.1 KiB, free 364.5 MiB)
26/01/12 02:43:32 INFO MemoryStore: Block broadcast_263_piece0 stored as bytes in memory (estimated size 77.4 KiB, free 364.4 MiB)
26/01/12 02:43:32 INFO BlockManagerInfo: Added broadcast_263_piece0 in memory on 02926ee04bc9:45221 (size: 77.4 KiB, free: 366.0 MiB)
26/01/12 02:43:32 INFO SparkContext: Created broadcast 263 from broadcast at DAGScheduler.scala:1513
26/01/12 02:43:32 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 175 (MapPartitionsRDD[439] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1))
26/01/12 02:43:32 INFO TaskSchedulerImpl: Adding task set 175.0 with 2 tasks resource profile 0
26/01/12 02:43:32 INFO TaskSetManager: Starting task 0.0 in stage 175.0 (TID 309) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:43:32 INFO TaskSetManager: Starting task 1.0 in stage 175.0 (TID 310) (172.18.0.5, executor 0, partition 1, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:43:32 INFO BlockManagerInfo: Added broadcast_263_piece0 in memory on 172.18.0.5:42453 (size: 77.4 KiB, free: 366.0 MiB)
26/01/12 02:43:32 INFO BlockManagerInfo: Added broadcast_262_piece0 in memory on 172.18.0.5:42453 (size: 35.4 KiB, free: 366.0 MiB)
26/01/12 02:43:32 INFO TaskSetManager: Finished task 1.0 in stage 175.0 (TID 310) in 56 ms on 172.18.0.5 (executor 0) (1/2)
26/01/12 02:43:59 INFO TaskSetManager: Finished task 0.0 in stage 175.0 (TID 309) in 26908 ms on 172.18.0.5 (executor 0) (2/2)
26/01/12 02:43:59 INFO TaskSchedulerImpl: Removed TaskSet 175.0, whose tasks have all completed, from pool 
26/01/12 02:43:59 INFO DAGScheduler: ResultStage 175 (parquet at <unknown>:0) finished in 26.927 s
26/01/12 02:43:59 INFO DAGScheduler: Job 175 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:43:59 INFO TaskSchedulerImpl: Killing all running tasks in stage 175: Stage finished
26/01/12 02:43:59 INFO DAGScheduler: Job 175 finished: parquet at <unknown>:0, took 26.933584 s
26/01/12 02:43:59 INFO FileFormatWriter: Start to commit write Job b5aa00b1-5884-43af-9e55-7f0342e4b1f1.
26/01/12 02:43:59 INFO FileFormatWriter: Write Job b5aa00b1-5884-43af-9e55-7f0342e4b1f1 committed. Elapsed time: 34 ms.
26/01/12 02:43:59 INFO FileFormatWriter: Finished processing stats for write job b5aa00b1-5884-43af-9e55-7f0342e4b1f1.
Cargando: yellow_tripdata_2016-05.parquet en hdfs://hadoop-namenode:8020/data/nyc/raw/taxi-trips/2016...
26/01/12 02:43:59 INFO InMemoryFileIndex: It took 7 ms to list leaf files for 1 paths.
26/01/12 02:43:59 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 02:43:59 INFO DAGScheduler: Got job 176 (parquet at <unknown>:0) with 1 output partitions
26/01/12 02:43:59 INFO DAGScheduler: Final stage: ResultStage 176 (parquet at <unknown>:0)
26/01/12 02:43:59 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:43:59 INFO DAGScheduler: Missing parents: List()
26/01/12 02:43:59 INFO DAGScheduler: Submitting ResultStage 176 (MapPartitionsRDD[441] at parquet at <unknown>:0), which has no missing parents
26/01/12 02:43:59 INFO MemoryStore: Block broadcast_264 stored as values in memory (estimated size 102.6 KiB, free 364.3 MiB)
26/01/12 02:43:59 INFO MemoryStore: Block broadcast_264_piece0 stored as bytes in memory (estimated size 36.8 KiB, free 364.3 MiB)
26/01/12 02:43:59 INFO BlockManagerInfo: Added broadcast_264_piece0 in memory on 02926ee04bc9:45221 (size: 36.8 KiB, free: 366.0 MiB)
26/01/12 02:43:59 INFO SparkContext: Created broadcast 264 from broadcast at DAGScheduler.scala:1513
26/01/12 02:43:59 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 176 (MapPartitionsRDD[441] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0))
26/01/12 02:43:59 INFO TaskSchedulerImpl: Adding task set 176.0 with 1 tasks resource profile 0
26/01/12 02:43:59 INFO TaskSetManager: Starting task 0.0 in stage 176.0 (TID 311) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4607 bytes) taskResourceAssignments Map()
26/01/12 02:43:59 INFO BlockManagerInfo: Added broadcast_264_piece0 in memory on 172.18.0.5:42453 (size: 36.8 KiB, free: 366.0 MiB)
26/01/12 02:43:59 INFO TaskSetManager: Finished task 0.0 in stage 176.0 (TID 311) in 50 ms on 172.18.0.5 (executor 0) (1/1)
26/01/12 02:43:59 INFO TaskSchedulerImpl: Removed TaskSet 176.0, whose tasks have all completed, from pool 
26/01/12 02:43:59 INFO DAGScheduler: ResultStage 176 (parquet at <unknown>:0) finished in 0.062 s
26/01/12 02:43:59 INFO DAGScheduler: Job 176 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:43:59 INFO TaskSchedulerImpl: Killing all running tasks in stage 176: Stage finished
26/01/12 02:43:59 INFO DAGScheduler: Job 176 finished: parquet at <unknown>:0, took 0.066238 s
26/01/12 02:43:59 INFO FileSourceStrategy: Pushed Filters: 
26/01/12 02:43:59 INFO FileSourceStrategy: Post-Scan Filters: 
26/01/12 02:43:59 INFO FileSourceStrategy: Output Data Schema: struct<VendorID: bigint, tpep_pickup_datetime: timestamp, tpep_dropoff_datetime: timestamp, passenger_count: bigint, trip_distance: double ... 17 more fields>
26/01/12 02:43:59 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:43:59 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:43:59 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:43:59 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:43:59 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:43:59 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:43:59 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:43:59 INFO MemoryStore: Block broadcast_265 stored as values in memory (estimated size 358.4 KiB, free 363.9 MiB)
26/01/12 02:43:59 INFO MemoryStore: Block broadcast_265_piece0 stored as bytes in memory (estimated size 35.4 KiB, free 363.9 MiB)
26/01/12 02:43:59 INFO BlockManagerInfo: Added broadcast_265_piece0 in memory on 02926ee04bc9:45221 (size: 35.4 KiB, free: 365.9 MiB)
26/01/12 02:43:59 INFO SparkContext: Created broadcast 265 from parquet at <unknown>:0
26/01/12 02:43:59 INFO FileSourceScanExec: Planning scan with bin packing, max size: 85000787 bytes, open cost is considered as scanning 4194304 bytes.
26/01/12 02:43:59 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 02:43:59 INFO DAGScheduler: Got job 177 (parquet at <unknown>:0) with 2 output partitions
26/01/12 02:43:59 INFO DAGScheduler: Final stage: ResultStage 177 (parquet at <unknown>:0)
26/01/12 02:43:59 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:43:59 INFO DAGScheduler: Missing parents: List()
26/01/12 02:43:59 INFO DAGScheduler: Submitting ResultStage 177 (MapPartitionsRDD[444] at parquet at <unknown>:0), which has no missing parents
26/01/12 02:43:59 INFO MemoryStore: Block broadcast_266 stored as values in memory (estimated size 225.1 KiB, free 363.7 MiB)
26/01/12 02:43:59 INFO MemoryStore: Block broadcast_266_piece0 stored as bytes in memory (estimated size 77.4 KiB, free 363.6 MiB)
26/01/12 02:43:59 INFO BlockManagerInfo: Added broadcast_266_piece0 in memory on 02926ee04bc9:45221 (size: 77.4 KiB, free: 365.9 MiB)
26/01/12 02:43:59 INFO SparkContext: Created broadcast 266 from broadcast at DAGScheduler.scala:1513
26/01/12 02:43:59 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 177 (MapPartitionsRDD[444] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1))
26/01/12 02:43:59 INFO TaskSchedulerImpl: Adding task set 177.0 with 2 tasks resource profile 0
26/01/12 02:43:59 INFO TaskSetManager: Starting task 0.0 in stage 177.0 (TID 312) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:43:59 INFO TaskSetManager: Starting task 1.0 in stage 177.0 (TID 313) (172.18.0.5, executor 0, partition 1, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:43:59 INFO BlockManagerInfo: Added broadcast_266_piece0 in memory on 172.18.0.5:42453 (size: 77.4 KiB, free: 365.9 MiB)
26/01/12 02:43:59 INFO BlockManagerInfo: Added broadcast_265_piece0 in memory on 172.18.0.5:42453 (size: 35.4 KiB, free: 365.9 MiB)
26/01/12 02:43:59 INFO TaskSetManager: Finished task 1.0 in stage 177.0 (TID 313) in 52 ms on 172.18.0.5 (executor 0) (1/2)
26/01/12 02:44:26 INFO TaskSetManager: Finished task 0.0 in stage 177.0 (TID 312) in 26696 ms on 172.18.0.5 (executor 0) (2/2)
26/01/12 02:44:26 INFO TaskSchedulerImpl: Removed TaskSet 177.0, whose tasks have all completed, from pool 
26/01/12 02:44:26 INFO DAGScheduler: ResultStage 177 (parquet at <unknown>:0) finished in 26.717 s
26/01/12 02:44:26 INFO DAGScheduler: Job 177 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:44:26 INFO TaskSchedulerImpl: Killing all running tasks in stage 177: Stage finished
26/01/12 02:44:26 INFO DAGScheduler: Job 177 finished: parquet at <unknown>:0, took 26.723307 s
26/01/12 02:44:26 INFO FileFormatWriter: Start to commit write Job 2c0a6e38-b326-4b4d-a027-1e8c2ace0f51.
26/01/12 02:44:26 INFO FileFormatWriter: Write Job 2c0a6e38-b326-4b4d-a027-1e8c2ace0f51 committed. Elapsed time: 34 ms.
26/01/12 02:44:26 INFO FileFormatWriter: Finished processing stats for write job 2c0a6e38-b326-4b4d-a027-1e8c2ace0f51.
Cargando: yellow_tripdata_2016-06.parquet en hdfs://hadoop-namenode:8020/data/nyc/raw/taxi-trips/2016...
26/01/12 02:44:26 INFO InMemoryFileIndex: It took 8 ms to list leaf files for 1 paths.
26/01/12 02:44:26 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 02:44:26 INFO DAGScheduler: Got job 178 (parquet at <unknown>:0) with 1 output partitions
26/01/12 02:44:26 INFO DAGScheduler: Final stage: ResultStage 178 (parquet at <unknown>:0)
26/01/12 02:44:26 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:44:26 INFO DAGScheduler: Missing parents: List()
26/01/12 02:44:26 INFO DAGScheduler: Submitting ResultStage 178 (MapPartitionsRDD[446] at parquet at <unknown>:0), which has no missing parents
26/01/12 02:44:26 INFO MemoryStore: Block broadcast_267 stored as values in memory (estimated size 102.6 KiB, free 363.5 MiB)
26/01/12 02:44:26 INFO MemoryStore: Block broadcast_267_piece0 stored as bytes in memory (estimated size 36.8 KiB, free 363.5 MiB)
26/01/12 02:44:26 INFO BlockManagerInfo: Added broadcast_267_piece0 in memory on 02926ee04bc9:45221 (size: 36.8 KiB, free: 365.8 MiB)
26/01/12 02:44:26 INFO SparkContext: Created broadcast 267 from broadcast at DAGScheduler.scala:1513
26/01/12 02:44:26 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 178 (MapPartitionsRDD[446] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0))
26/01/12 02:44:26 INFO TaskSchedulerImpl: Adding task set 178.0 with 1 tasks resource profile 0
26/01/12 02:44:26 INFO TaskSetManager: Starting task 0.0 in stage 178.0 (TID 314) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4607 bytes) taskResourceAssignments Map()
26/01/12 02:44:26 INFO BlockManagerInfo: Added broadcast_267_piece0 in memory on 172.18.0.5:42453 (size: 36.8 KiB, free: 365.8 MiB)
26/01/12 02:44:26 INFO TaskSetManager: Finished task 0.0 in stage 178.0 (TID 314) in 50 ms on 172.18.0.5 (executor 0) (1/1)
26/01/12 02:44:26 INFO TaskSchedulerImpl: Removed TaskSet 178.0, whose tasks have all completed, from pool 
26/01/12 02:44:26 INFO DAGScheduler: ResultStage 178 (parquet at <unknown>:0) finished in 0.064 s
26/01/12 02:44:26 INFO DAGScheduler: Job 178 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:44:26 INFO TaskSchedulerImpl: Killing all running tasks in stage 178: Stage finished
26/01/12 02:44:26 INFO DAGScheduler: Job 178 finished: parquet at <unknown>:0, took 0.068609 s
26/01/12 02:44:26 INFO FileSourceStrategy: Pushed Filters: 
26/01/12 02:44:26 INFO FileSourceStrategy: Post-Scan Filters: 
26/01/12 02:44:26 INFO FileSourceStrategy: Output Data Schema: struct<VendorID: bigint, tpep_pickup_datetime: timestamp, tpep_dropoff_datetime: timestamp, passenger_count: bigint, trip_distance: double ... 17 more fields>
26/01/12 02:44:26 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:44:26 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:44:26 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:44:26 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:44:26 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:44:26 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:44:26 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:44:26 INFO MemoryStore: Block broadcast_268 stored as values in memory (estimated size 358.4 KiB, free 363.1 MiB)
26/01/12 02:44:26 INFO MemoryStore: Block broadcast_268_piece0 stored as bytes in memory (estimated size 35.4 KiB, free 363.1 MiB)
26/01/12 02:44:26 INFO BlockManagerInfo: Added broadcast_268_piece0 in memory on 02926ee04bc9:45221 (size: 35.4 KiB, free: 365.8 MiB)
26/01/12 02:44:26 INFO SparkContext: Created broadcast 268 from parquet at <unknown>:0
26/01/12 02:44:26 INFO FileSourceScanExec: Planning scan with bin packing, max size: 80241526 bytes, open cost is considered as scanning 4194304 bytes.
26/01/12 02:44:26 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 02:44:26 INFO DAGScheduler: Got job 179 (parquet at <unknown>:0) with 2 output partitions
26/01/12 02:44:26 INFO DAGScheduler: Final stage: ResultStage 179 (parquet at <unknown>:0)
26/01/12 02:44:26 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:44:26 INFO DAGScheduler: Missing parents: List()
26/01/12 02:44:26 INFO DAGScheduler: Submitting ResultStage 179 (MapPartitionsRDD[449] at parquet at <unknown>:0), which has no missing parents
26/01/12 02:44:26 INFO MemoryStore: Block broadcast_269 stored as values in memory (estimated size 225.1 KiB, free 362.9 MiB)
26/01/12 02:44:26 INFO MemoryStore: Block broadcast_269_piece0 stored as bytes in memory (estimated size 77.4 KiB, free 362.8 MiB)
26/01/12 02:44:26 INFO BlockManagerInfo: Added broadcast_269_piece0 in memory on 02926ee04bc9:45221 (size: 77.4 KiB, free: 365.7 MiB)
26/01/12 02:44:26 INFO SparkContext: Created broadcast 269 from broadcast at DAGScheduler.scala:1513
26/01/12 02:44:26 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 179 (MapPartitionsRDD[449] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1))
26/01/12 02:44:26 INFO TaskSchedulerImpl: Adding task set 179.0 with 2 tasks resource profile 0
26/01/12 02:44:26 INFO TaskSetManager: Starting task 0.0 in stage 179.0 (TID 315) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:44:26 INFO TaskSetManager: Starting task 1.0 in stage 179.0 (TID 316) (172.18.0.5, executor 0, partition 1, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:44:26 INFO BlockManagerInfo: Added broadcast_269_piece0 in memory on 172.18.0.5:42453 (size: 77.4 KiB, free: 365.8 MiB)
26/01/12 02:44:26 INFO BlockManagerInfo: Added broadcast_268_piece0 in memory on 172.18.0.5:42453 (size: 35.4 KiB, free: 365.7 MiB)
26/01/12 02:44:26 INFO TaskSetManager: Finished task 1.0 in stage 179.0 (TID 316) in 61 ms on 172.18.0.5 (executor 0) (1/2)
26/01/12 02:44:52 INFO TaskSetManager: Finished task 0.0 in stage 179.0 (TID 315) in 25827 ms on 172.18.0.5 (executor 0) (2/2)
26/01/12 02:44:52 INFO TaskSchedulerImpl: Removed TaskSet 179.0, whose tasks have all completed, from pool 
26/01/12 02:44:52 INFO DAGScheduler: ResultStage 179 (parquet at <unknown>:0) finished in 25.850 s
26/01/12 02:44:52 INFO DAGScheduler: Job 179 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:44:52 INFO TaskSchedulerImpl: Killing all running tasks in stage 179: Stage finished
26/01/12 02:44:52 INFO DAGScheduler: Job 179 finished: parquet at <unknown>:0, took 25.858660 s
26/01/12 02:44:52 INFO FileFormatWriter: Start to commit write Job a67695f7-6f57-4864-baab-77911f1c6005.
26/01/12 02:44:52 INFO FileFormatWriter: Write Job a67695f7-6f57-4864-baab-77911f1c6005 committed. Elapsed time: 26 ms.
26/01/12 02:44:52 INFO FileFormatWriter: Finished processing stats for write job a67695f7-6f57-4864-baab-77911f1c6005.
Cargando: yellow_tripdata_2016-07.parquet en hdfs://hadoop-namenode:8020/data/nyc/raw/taxi-trips/2016...
26/01/12 02:44:52 INFO InMemoryFileIndex: It took 6 ms to list leaf files for 1 paths.
26/01/12 02:44:52 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 02:44:52 INFO DAGScheduler: Got job 180 (parquet at <unknown>:0) with 1 output partitions
26/01/12 02:44:52 INFO DAGScheduler: Final stage: ResultStage 180 (parquet at <unknown>:0)
26/01/12 02:44:52 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:44:52 INFO DAGScheduler: Missing parents: List()
26/01/12 02:44:52 INFO DAGScheduler: Submitting ResultStage 180 (MapPartitionsRDD[451] at parquet at <unknown>:0), which has no missing parents
26/01/12 02:44:52 INFO MemoryStore: Block broadcast_270 stored as values in memory (estimated size 102.6 KiB, free 362.7 MiB)
26/01/12 02:44:52 INFO MemoryStore: Block broadcast_270_piece0 stored as bytes in memory (estimated size 36.8 KiB, free 362.7 MiB)
26/01/12 02:44:52 INFO BlockManagerInfo: Added broadcast_270_piece0 in memory on 02926ee04bc9:45221 (size: 36.8 KiB, free: 365.7 MiB)
26/01/12 02:44:52 INFO SparkContext: Created broadcast 270 from broadcast at DAGScheduler.scala:1513
26/01/12 02:44:52 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 180 (MapPartitionsRDD[451] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0))
26/01/12 02:44:52 INFO TaskSchedulerImpl: Adding task set 180.0 with 1 tasks resource profile 0
26/01/12 02:44:52 INFO TaskSetManager: Starting task 0.0 in stage 180.0 (TID 317) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4607 bytes) taskResourceAssignments Map()
26/01/12 02:44:52 INFO BlockManagerInfo: Added broadcast_270_piece0 in memory on 172.18.0.5:42453 (size: 36.8 KiB, free: 365.7 MiB)
26/01/12 02:44:52 INFO TaskSetManager: Finished task 0.0 in stage 180.0 (TID 317) in 43 ms on 172.18.0.5 (executor 0) (1/1)
26/01/12 02:44:52 INFO TaskSchedulerImpl: Removed TaskSet 180.0, whose tasks have all completed, from pool 
26/01/12 02:44:52 INFO DAGScheduler: ResultStage 180 (parquet at <unknown>:0) finished in 0.056 s
26/01/12 02:44:52 INFO DAGScheduler: Job 180 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:44:52 INFO TaskSchedulerImpl: Killing all running tasks in stage 180: Stage finished
26/01/12 02:44:52 INFO DAGScheduler: Job 180 finished: parquet at <unknown>:0, took 0.060015 s
26/01/12 02:44:52 INFO FileSourceStrategy: Pushed Filters: 
26/01/12 02:44:52 INFO FileSourceStrategy: Post-Scan Filters: 
26/01/12 02:44:52 INFO FileSourceStrategy: Output Data Schema: struct<VendorID: bigint, tpep_pickup_datetime: timestamp, tpep_dropoff_datetime: timestamp, passenger_count: bigint, trip_distance: double ... 17 more fields>
26/01/12 02:44:52 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:44:52 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:44:52 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:44:52 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:44:52 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:44:52 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:44:52 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:44:52 INFO MemoryStore: Block broadcast_271 stored as values in memory (estimated size 358.4 KiB, free 362.3 MiB)
26/01/12 02:44:52 INFO MemoryStore: Block broadcast_271_piece0 stored as bytes in memory (estimated size 35.4 KiB, free 362.3 MiB)
26/01/12 02:44:52 INFO BlockManagerInfo: Added broadcast_271_piece0 in memory on 02926ee04bc9:45221 (size: 35.4 KiB, free: 365.6 MiB)
26/01/12 02:44:52 INFO SparkContext: Created broadcast 271 from parquet at <unknown>:0
26/01/12 02:44:52 INFO FileSourceScanExec: Planning scan with bin packing, max size: 74407708 bytes, open cost is considered as scanning 4194304 bytes.
26/01/12 02:44:52 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 02:44:52 INFO DAGScheduler: Got job 181 (parquet at <unknown>:0) with 2 output partitions
26/01/12 02:44:52 INFO DAGScheduler: Final stage: ResultStage 181 (parquet at <unknown>:0)
26/01/12 02:44:52 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:44:52 INFO DAGScheduler: Missing parents: List()
26/01/12 02:44:52 INFO DAGScheduler: Submitting ResultStage 181 (MapPartitionsRDD[454] at parquet at <unknown>:0), which has no missing parents
26/01/12 02:44:52 INFO MemoryStore: Block broadcast_272 stored as values in memory (estimated size 225.1 KiB, free 362.0 MiB)
26/01/12 02:44:52 INFO MemoryStore: Block broadcast_272_piece0 stored as bytes in memory (estimated size 77.4 KiB, free 362.0 MiB)
26/01/12 02:44:52 INFO BlockManagerInfo: Added broadcast_272_piece0 in memory on 02926ee04bc9:45221 (size: 77.4 KiB, free: 365.6 MiB)
26/01/12 02:44:52 INFO SparkContext: Created broadcast 272 from broadcast at DAGScheduler.scala:1513
26/01/12 02:44:52 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 181 (MapPartitionsRDD[454] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1))
26/01/12 02:44:52 INFO TaskSchedulerImpl: Adding task set 181.0 with 2 tasks resource profile 0
26/01/12 02:44:52 INFO TaskSetManager: Starting task 0.0 in stage 181.0 (TID 318) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:44:52 INFO TaskSetManager: Starting task 1.0 in stage 181.0 (TID 319) (172.18.0.5, executor 0, partition 1, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:44:52 INFO BlockManagerInfo: Added broadcast_272_piece0 in memory on 172.18.0.5:42453 (size: 77.4 KiB, free: 365.6 MiB)
26/01/12 02:44:52 INFO BlockManagerInfo: Added broadcast_271_piece0 in memory on 172.18.0.5:42453 (size: 35.4 KiB, free: 365.6 MiB)
26/01/12 02:44:52 INFO TaskSetManager: Finished task 1.0 in stage 181.0 (TID 319) in 61 ms on 172.18.0.5 (executor 0) (1/2)
26/01/12 02:45:16 INFO TaskSetManager: Finished task 0.0 in stage 181.0 (TID 318) in 23958 ms on 172.18.0.5 (executor 0) (2/2)
26/01/12 02:45:16 INFO TaskSchedulerImpl: Removed TaskSet 181.0, whose tasks have all completed, from pool 
26/01/12 02:45:16 INFO DAGScheduler: ResultStage 181 (parquet at <unknown>:0) finished in 23.978 s
26/01/12 02:45:16 INFO DAGScheduler: Job 181 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:45:16 INFO TaskSchedulerImpl: Killing all running tasks in stage 181: Stage finished
26/01/12 02:45:16 INFO DAGScheduler: Job 181 finished: parquet at <unknown>:0, took 23.990529 s
26/01/12 02:45:16 INFO FileFormatWriter: Start to commit write Job 36276d39-63aa-414f-8afa-7144cbda3d52.
26/01/12 02:45:16 INFO FileFormatWriter: Write Job 36276d39-63aa-414f-8afa-7144cbda3d52 committed. Elapsed time: 36 ms.
26/01/12 02:45:16 INFO FileFormatWriter: Finished processing stats for write job 36276d39-63aa-414f-8afa-7144cbda3d52.
Cargando: yellow_tripdata_2016-08.parquet en hdfs://hadoop-namenode:8020/data/nyc/raw/taxi-trips/2016...
26/01/12 02:45:16 INFO InMemoryFileIndex: It took 7 ms to list leaf files for 1 paths.
26/01/12 02:45:16 INFO BlockManagerInfo: Removed broadcast_266_piece0 on 02926ee04bc9:45221 in memory (size: 77.4 KiB, free: 365.6 MiB)
26/01/12 02:45:16 INFO BlockManagerInfo: Removed broadcast_266_piece0 on 172.18.0.5:42453 in memory (size: 77.4 KiB, free: 365.6 MiB)
26/01/12 02:45:16 INFO BlockManagerInfo: Removed broadcast_268_piece0 on 02926ee04bc9:45221 in memory (size: 35.4 KiB, free: 365.7 MiB)
26/01/12 02:45:16 INFO BlockManagerInfo: Removed broadcast_268_piece0 on 172.18.0.5:42453 in memory (size: 35.4 KiB, free: 365.7 MiB)
26/01/12 02:45:16 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 02:45:16 INFO DAGScheduler: Got job 182 (parquet at <unknown>:0) with 1 output partitions
26/01/12 02:45:16 INFO DAGScheduler: Final stage: ResultStage 182 (parquet at <unknown>:0)
26/01/12 02:45:16 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:45:16 INFO DAGScheduler: Missing parents: List()
26/01/12 02:45:16 INFO DAGScheduler: Submitting ResultStage 182 (MapPartitionsRDD[456] at parquet at <unknown>:0), which has no missing parents
26/01/12 02:45:16 INFO BlockManagerInfo: Removed broadcast_270_piece0 on 02926ee04bc9:45221 in memory (size: 36.8 KiB, free: 365.7 MiB)
26/01/12 02:45:16 INFO BlockManagerInfo: Removed broadcast_270_piece0 on 172.18.0.5:42453 in memory (size: 36.8 KiB, free: 365.7 MiB)
26/01/12 02:45:16 INFO BlockManagerInfo: Removed broadcast_261_piece0 on 02926ee04bc9:45221 in memory (size: 36.8 KiB, free: 365.8 MiB)
26/01/12 02:45:16 INFO BlockManagerInfo: Removed broadcast_261_piece0 on 172.18.0.5:42453 in memory (size: 36.8 KiB, free: 365.8 MiB)
26/01/12 02:45:16 INFO MemoryStore: Block broadcast_273 stored as values in memory (estimated size 102.6 KiB, free 362.8 MiB)
26/01/12 02:45:16 INFO MemoryStore: Block broadcast_273_piece0 stored as bytes in memory (estimated size 36.8 KiB, free 362.8 MiB)
26/01/12 02:45:16 INFO BlockManagerInfo: Added broadcast_273_piece0 in memory on 02926ee04bc9:45221 (size: 36.8 KiB, free: 365.7 MiB)
26/01/12 02:45:16 INFO SparkContext: Created broadcast 273 from broadcast at DAGScheduler.scala:1513
26/01/12 02:45:16 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 182 (MapPartitionsRDD[456] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0))
26/01/12 02:45:16 INFO BlockManagerInfo: Removed broadcast_267_piece0 on 02926ee04bc9:45221 in memory (size: 36.8 KiB, free: 365.8 MiB)
26/01/12 02:45:16 INFO TaskSchedulerImpl: Adding task set 182.0 with 1 tasks resource profile 0
26/01/12 02:45:16 INFO BlockManagerInfo: Removed broadcast_267_piece0 on 172.18.0.5:42453 in memory (size: 36.8 KiB, free: 365.8 MiB)
26/01/12 02:45:16 INFO TaskSetManager: Starting task 0.0 in stage 182.0 (TID 320) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4607 bytes) taskResourceAssignments Map()
26/01/12 02:45:16 INFO BlockManagerInfo: Removed broadcast_264_piece0 on 02926ee04bc9:45221 in memory (size: 36.8 KiB, free: 365.8 MiB)
26/01/12 02:45:16 INFO BlockManagerInfo: Removed broadcast_264_piece0 on 172.18.0.5:42453 in memory (size: 36.8 KiB, free: 365.8 MiB)
26/01/12 02:45:16 INFO BlockManagerInfo: Added broadcast_273_piece0 in memory on 172.18.0.5:42453 (size: 36.8 KiB, free: 365.8 MiB)
26/01/12 02:45:16 INFO BlockManagerInfo: Removed broadcast_263_piece0 on 02926ee04bc9:45221 in memory (size: 77.4 KiB, free: 365.9 MiB)
26/01/12 02:45:16 INFO BlockManagerInfo: Removed broadcast_263_piece0 on 172.18.0.5:42453 in memory (size: 77.4 KiB, free: 365.9 MiB)
26/01/12 02:45:16 INFO BlockManagerInfo: Removed broadcast_262_piece0 on 02926ee04bc9:45221 in memory (size: 35.4 KiB, free: 365.9 MiB)
26/01/12 02:45:16 INFO BlockManagerInfo: Removed broadcast_262_piece0 on 172.18.0.5:42453 in memory (size: 35.4 KiB, free: 365.9 MiB)
26/01/12 02:45:16 INFO BlockManagerInfo: Removed broadcast_272_piece0 on 02926ee04bc9:45221 in memory (size: 77.4 KiB, free: 366.0 MiB)
26/01/12 02:45:16 INFO BlockManagerInfo: Removed broadcast_272_piece0 on 172.18.0.5:42453 in memory (size: 77.4 KiB, free: 366.0 MiB)
26/01/12 02:45:16 INFO BlockManagerInfo: Removed broadcast_265_piece0 on 02926ee04bc9:45221 in memory (size: 35.4 KiB, free: 366.0 MiB)
26/01/12 02:45:16 INFO BlockManagerInfo: Removed broadcast_265_piece0 on 172.18.0.5:42453 in memory (size: 35.4 KiB, free: 366.0 MiB)
26/01/12 02:45:16 INFO BlockManagerInfo: Removed broadcast_259_piece0 on 02926ee04bc9:45221 in memory (size: 35.4 KiB, free: 366.0 MiB)
26/01/12 02:45:16 INFO BlockManagerInfo: Removed broadcast_259_piece0 on 172.18.0.5:42453 in memory (size: 35.4 KiB, free: 366.0 MiB)
26/01/12 02:45:16 INFO BlockManagerInfo: Removed broadcast_269_piece0 on 02926ee04bc9:45221 in memory (size: 77.4 KiB, free: 366.1 MiB)
26/01/12 02:45:16 INFO BlockManagerInfo: Removed broadcast_269_piece0 on 172.18.0.5:42453 in memory (size: 77.4 KiB, free: 366.1 MiB)
26/01/12 02:45:16 INFO TaskSetManager: Finished task 0.0 in stage 182.0 (TID 320) in 57 ms on 172.18.0.5 (executor 0) (1/1)
26/01/12 02:45:16 INFO TaskSchedulerImpl: Removed TaskSet 182.0, whose tasks have all completed, from pool 
26/01/12 02:45:16 INFO DAGScheduler: ResultStage 182 (parquet at <unknown>:0) finished in 0.070 s
26/01/12 02:45:16 INFO DAGScheduler: Job 182 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:45:16 INFO TaskSchedulerImpl: Killing all running tasks in stage 182: Stage finished
26/01/12 02:45:16 INFO DAGScheduler: Job 182 finished: parquet at <unknown>:0, took 0.075638 s
26/01/12 02:45:16 INFO FileSourceStrategy: Pushed Filters: 
26/01/12 02:45:16 INFO FileSourceStrategy: Post-Scan Filters: 
26/01/12 02:45:16 INFO FileSourceStrategy: Output Data Schema: struct<VendorID: bigint, tpep_pickup_datetime: timestamp, tpep_dropoff_datetime: timestamp, passenger_count: bigint, trip_distance: double ... 17 more fields>
26/01/12 02:45:16 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:45:16 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:45:16 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:45:16 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:45:16 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:45:16 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:45:16 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:45:16 INFO MemoryStore: Block broadcast_274 stored as values in memory (estimated size 358.4 KiB, free 364.7 MiB)
26/01/12 02:45:16 INFO MemoryStore: Block broadcast_274_piece0 stored as bytes in memory (estimated size 35.4 KiB, free 364.7 MiB)
26/01/12 02:45:16 INFO BlockManagerInfo: Added broadcast_274_piece0 in memory on 02926ee04bc9:45221 (size: 35.4 KiB, free: 366.1 MiB)
26/01/12 02:45:16 INFO SparkContext: Created broadcast 274 from parquet at <unknown>:0
26/01/12 02:45:16 INFO FileSourceScanExec: Planning scan with bin packing, max size: 72035021 bytes, open cost is considered as scanning 4194304 bytes.
26/01/12 02:45:16 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 02:45:16 INFO DAGScheduler: Got job 183 (parquet at <unknown>:0) with 2 output partitions
26/01/12 02:45:16 INFO DAGScheduler: Final stage: ResultStage 183 (parquet at <unknown>:0)
26/01/12 02:45:16 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:45:16 INFO DAGScheduler: Missing parents: List()
26/01/12 02:45:16 INFO DAGScheduler: Submitting ResultStage 183 (MapPartitionsRDD[459] at parquet at <unknown>:0), which has no missing parents
26/01/12 02:45:16 INFO MemoryStore: Block broadcast_275 stored as values in memory (estimated size 225.1 KiB, free 364.5 MiB)
26/01/12 02:45:16 INFO MemoryStore: Block broadcast_275_piece0 stored as bytes in memory (estimated size 77.4 KiB, free 364.4 MiB)
26/01/12 02:45:16 INFO BlockManagerInfo: Added broadcast_275_piece0 in memory on 02926ee04bc9:45221 (size: 77.4 KiB, free: 366.0 MiB)
26/01/12 02:45:16 INFO SparkContext: Created broadcast 275 from broadcast at DAGScheduler.scala:1513
26/01/12 02:45:16 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 183 (MapPartitionsRDD[459] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1))
26/01/12 02:45:16 INFO TaskSchedulerImpl: Adding task set 183.0 with 2 tasks resource profile 0
26/01/12 02:45:16 INFO TaskSetManager: Starting task 0.0 in stage 183.0 (TID 321) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:45:16 INFO TaskSetManager: Starting task 1.0 in stage 183.0 (TID 322) (172.18.0.5, executor 0, partition 1, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:45:16 INFO BlockManagerInfo: Added broadcast_275_piece0 in memory on 172.18.0.5:42453 (size: 77.4 KiB, free: 366.0 MiB)
26/01/12 02:45:16 INFO BlockManagerInfo: Added broadcast_274_piece0 in memory on 172.18.0.5:42453 (size: 35.4 KiB, free: 366.0 MiB)
26/01/12 02:45:16 INFO TaskSetManager: Finished task 1.0 in stage 183.0 (TID 322) in 63 ms on 172.18.0.5 (executor 0) (1/2)
26/01/12 02:45:39 INFO TaskSetManager: Finished task 0.0 in stage 183.0 (TID 321) in 22958 ms on 172.18.0.5 (executor 0) (2/2)
26/01/12 02:45:39 INFO TaskSchedulerImpl: Removed TaskSet 183.0, whose tasks have all completed, from pool 
26/01/12 02:45:39 INFO DAGScheduler: ResultStage 183 (parquet at <unknown>:0) finished in 22.978 s
26/01/12 02:45:39 INFO DAGScheduler: Job 183 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:45:39 INFO TaskSchedulerImpl: Killing all running tasks in stage 183: Stage finished
26/01/12 02:45:39 INFO DAGScheduler: Job 183 finished: parquet at <unknown>:0, took 22.986332 s
26/01/12 02:45:39 INFO FileFormatWriter: Start to commit write Job 60740faa-cffd-4d65-a0f5-512a802b0746.
26/01/12 02:45:39 INFO FileFormatWriter: Write Job 60740faa-cffd-4d65-a0f5-512a802b0746 committed. Elapsed time: 31 ms.
26/01/12 02:45:39 INFO FileFormatWriter: Finished processing stats for write job 60740faa-cffd-4d65-a0f5-512a802b0746.
Cargando: yellow_tripdata_2016-09.parquet en hdfs://hadoop-namenode:8020/data/nyc/raw/taxi-trips/2016...
26/01/12 02:45:39 INFO InMemoryFileIndex: It took 13 ms to list leaf files for 1 paths.
26/01/12 02:45:39 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 02:45:39 INFO DAGScheduler: Got job 184 (parquet at <unknown>:0) with 1 output partitions
26/01/12 02:45:39 INFO DAGScheduler: Final stage: ResultStage 184 (parquet at <unknown>:0)
26/01/12 02:45:39 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:45:39 INFO DAGScheduler: Missing parents: List()
26/01/12 02:45:39 INFO DAGScheduler: Submitting ResultStage 184 (MapPartitionsRDD[461] at parquet at <unknown>:0), which has no missing parents
26/01/12 02:45:39 INFO MemoryStore: Block broadcast_276 stored as values in memory (estimated size 102.6 KiB, free 364.3 MiB)
26/01/12 02:45:39 INFO MemoryStore: Block broadcast_276_piece0 stored as bytes in memory (estimated size 36.8 KiB, free 364.3 MiB)
26/01/12 02:45:39 INFO BlockManagerInfo: Added broadcast_276_piece0 in memory on 02926ee04bc9:45221 (size: 36.8 KiB, free: 366.0 MiB)
26/01/12 02:45:39 INFO SparkContext: Created broadcast 276 from broadcast at DAGScheduler.scala:1513
26/01/12 02:45:39 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 184 (MapPartitionsRDD[461] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0))
26/01/12 02:45:39 INFO TaskSchedulerImpl: Adding task set 184.0 with 1 tasks resource profile 0
26/01/12 02:45:39 INFO TaskSetManager: Starting task 0.0 in stage 184.0 (TID 323) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4607 bytes) taskResourceAssignments Map()
26/01/12 02:45:39 INFO BlockManagerInfo: Added broadcast_276_piece0 in memory on 172.18.0.5:42453 (size: 36.8 KiB, free: 366.0 MiB)
26/01/12 02:45:39 INFO TaskSetManager: Finished task 0.0 in stage 184.0 (TID 323) in 65 ms on 172.18.0.5 (executor 0) (1/1)
26/01/12 02:45:39 INFO TaskSchedulerImpl: Removed TaskSet 184.0, whose tasks have all completed, from pool 
26/01/12 02:45:39 INFO DAGScheduler: ResultStage 184 (parquet at <unknown>:0) finished in 0.078 s
26/01/12 02:45:39 INFO DAGScheduler: Job 184 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:45:39 INFO TaskSchedulerImpl: Killing all running tasks in stage 184: Stage finished
26/01/12 02:45:39 INFO DAGScheduler: Job 184 finished: parquet at <unknown>:0, took 0.082744 s
26/01/12 02:45:39 INFO FileSourceStrategy: Pushed Filters: 
26/01/12 02:45:39 INFO FileSourceStrategy: Post-Scan Filters: 
26/01/12 02:45:39 INFO FileSourceStrategy: Output Data Schema: struct<VendorID: bigint, tpep_pickup_datetime: timestamp, tpep_dropoff_datetime: timestamp, passenger_count: bigint, trip_distance: double ... 17 more fields>
26/01/12 02:45:39 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:45:39 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:45:39 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:45:39 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:45:39 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:45:39 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:45:39 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:45:39 INFO MemoryStore: Block broadcast_277 stored as values in memory (estimated size 358.4 KiB, free 363.9 MiB)
26/01/12 02:45:39 INFO MemoryStore: Block broadcast_277_piece0 stored as bytes in memory (estimated size 35.4 KiB, free 363.9 MiB)
26/01/12 02:45:39 INFO BlockManagerInfo: Added broadcast_277_piece0 in memory on 02926ee04bc9:45221 (size: 35.4 KiB, free: 365.9 MiB)
26/01/12 02:45:39 INFO SparkContext: Created broadcast 277 from parquet at <unknown>:0
26/01/12 02:45:39 INFO FileSourceScanExec: Planning scan with bin packing, max size: 73021439 bytes, open cost is considered as scanning 4194304 bytes.
26/01/12 02:45:39 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 02:45:39 INFO DAGScheduler: Got job 185 (parquet at <unknown>:0) with 2 output partitions
26/01/12 02:45:39 INFO DAGScheduler: Final stage: ResultStage 185 (parquet at <unknown>:0)
26/01/12 02:45:39 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:45:39 INFO DAGScheduler: Missing parents: List()
26/01/12 02:45:39 INFO DAGScheduler: Submitting ResultStage 185 (MapPartitionsRDD[464] at parquet at <unknown>:0), which has no missing parents
26/01/12 02:45:39 INFO MemoryStore: Block broadcast_278 stored as values in memory (estimated size 225.1 KiB, free 363.7 MiB)
26/01/12 02:45:39 INFO MemoryStore: Block broadcast_278_piece0 stored as bytes in memory (estimated size 77.4 KiB, free 363.6 MiB)
26/01/12 02:45:39 INFO BlockManagerInfo: Added broadcast_278_piece0 in memory on 02926ee04bc9:45221 (size: 77.4 KiB, free: 365.9 MiB)
26/01/12 02:45:39 INFO SparkContext: Created broadcast 278 from broadcast at DAGScheduler.scala:1513
26/01/12 02:45:39 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 185 (MapPartitionsRDD[464] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1))
26/01/12 02:45:39 INFO TaskSchedulerImpl: Adding task set 185.0 with 2 tasks resource profile 0
26/01/12 02:45:39 INFO TaskSetManager: Starting task 0.0 in stage 185.0 (TID 324) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:45:39 INFO TaskSetManager: Starting task 1.0 in stage 185.0 (TID 325) (172.18.0.5, executor 0, partition 1, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:45:39 INFO BlockManagerInfo: Added broadcast_278_piece0 in memory on 172.18.0.5:42453 (size: 77.4 KiB, free: 365.9 MiB)
26/01/12 02:45:39 INFO BlockManagerInfo: Added broadcast_277_piece0 in memory on 172.18.0.5:42453 (size: 35.4 KiB, free: 365.9 MiB)
26/01/12 02:45:39 INFO TaskSetManager: Finished task 1.0 in stage 185.0 (TID 325) in 51 ms on 172.18.0.5 (executor 0) (1/2)
26/01/12 02:46:03 INFO TaskSetManager: Finished task 0.0 in stage 185.0 (TID 324) in 23759 ms on 172.18.0.5 (executor 0) (2/2)
26/01/12 02:46:03 INFO TaskSchedulerImpl: Removed TaskSet 185.0, whose tasks have all completed, from pool 
26/01/12 02:46:03 INFO DAGScheduler: ResultStage 185 (parquet at <unknown>:0) finished in 23.779 s
26/01/12 02:46:03 INFO DAGScheduler: Job 185 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:46:03 INFO TaskSchedulerImpl: Killing all running tasks in stage 185: Stage finished
26/01/12 02:46:03 INFO DAGScheduler: Job 185 finished: parquet at <unknown>:0, took 23.785974 s
26/01/12 02:46:03 INFO FileFormatWriter: Start to commit write Job 403fea4e-c1a9-4ec6-9b0f-57109af28063.
26/01/12 02:46:03 INFO FileFormatWriter: Write Job 403fea4e-c1a9-4ec6-9b0f-57109af28063 committed. Elapsed time: 31 ms.
26/01/12 02:46:03 INFO FileFormatWriter: Finished processing stats for write job 403fea4e-c1a9-4ec6-9b0f-57109af28063.
Cargando: yellow_tripdata_2016-10.parquet en hdfs://hadoop-namenode:8020/data/nyc/raw/taxi-trips/2016...
26/01/12 02:46:03 INFO InMemoryFileIndex: It took 6 ms to list leaf files for 1 paths.
26/01/12 02:46:03 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 02:46:03 INFO DAGScheduler: Got job 186 (parquet at <unknown>:0) with 1 output partitions
26/01/12 02:46:03 INFO DAGScheduler: Final stage: ResultStage 186 (parquet at <unknown>:0)
26/01/12 02:46:03 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:46:03 INFO DAGScheduler: Missing parents: List()
26/01/12 02:46:03 INFO DAGScheduler: Submitting ResultStage 186 (MapPartitionsRDD[466] at parquet at <unknown>:0), which has no missing parents
26/01/12 02:46:03 INFO MemoryStore: Block broadcast_279 stored as values in memory (estimated size 102.6 KiB, free 363.5 MiB)
26/01/12 02:46:03 INFO MemoryStore: Block broadcast_279_piece0 stored as bytes in memory (estimated size 36.8 KiB, free 363.5 MiB)
26/01/12 02:46:03 INFO BlockManagerInfo: Added broadcast_279_piece0 in memory on 02926ee04bc9:45221 (size: 36.8 KiB, free: 365.8 MiB)
26/01/12 02:46:03 INFO SparkContext: Created broadcast 279 from broadcast at DAGScheduler.scala:1513
26/01/12 02:46:03 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 186 (MapPartitionsRDD[466] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0))
26/01/12 02:46:03 INFO TaskSchedulerImpl: Adding task set 186.0 with 1 tasks resource profile 0
26/01/12 02:46:03 INFO TaskSetManager: Starting task 0.0 in stage 186.0 (TID 326) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4607 bytes) taskResourceAssignments Map()
26/01/12 02:46:03 INFO BlockManagerInfo: Added broadcast_279_piece0 in memory on 172.18.0.5:42453 (size: 36.8 KiB, free: 365.8 MiB)
26/01/12 02:46:03 INFO TaskSetManager: Finished task 0.0 in stage 186.0 (TID 326) in 47 ms on 172.18.0.5 (executor 0) (1/1)
26/01/12 02:46:03 INFO TaskSchedulerImpl: Removed TaskSet 186.0, whose tasks have all completed, from pool 
26/01/12 02:46:03 INFO DAGScheduler: ResultStage 186 (parquet at <unknown>:0) finished in 0.059 s
26/01/12 02:46:03 INFO DAGScheduler: Job 186 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:46:03 INFO TaskSchedulerImpl: Killing all running tasks in stage 186: Stage finished
26/01/12 02:46:03 INFO DAGScheduler: Job 186 finished: parquet at <unknown>:0, took 0.063631 s
26/01/12 02:46:03 INFO FileSourceStrategy: Pushed Filters: 
26/01/12 02:46:03 INFO FileSourceStrategy: Post-Scan Filters: 
26/01/12 02:46:03 INFO FileSourceStrategy: Output Data Schema: struct<VendorID: bigint, tpep_pickup_datetime: timestamp, tpep_dropoff_datetime: timestamp, passenger_count: bigint, trip_distance: double ... 17 more fields>
26/01/12 02:46:03 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:46:03 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:46:03 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:46:03 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:46:03 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:46:03 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:46:03 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:46:03 INFO MemoryStore: Block broadcast_280 stored as values in memory (estimated size 358.4 KiB, free 363.1 MiB)
26/01/12 02:46:03 INFO MemoryStore: Block broadcast_280_piece0 stored as bytes in memory (estimated size 35.4 KiB, free 363.1 MiB)
26/01/12 02:46:03 INFO BlockManagerInfo: Added broadcast_280_piece0 in memory on 02926ee04bc9:45221 (size: 35.4 KiB, free: 365.8 MiB)
26/01/12 02:46:03 INFO SparkContext: Created broadcast 280 from parquet at <unknown>:0
26/01/12 02:46:03 INFO FileSourceScanExec: Planning scan with bin packing, max size: 78386846 bytes, open cost is considered as scanning 4194304 bytes.
26/01/12 02:46:03 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 02:46:03 INFO DAGScheduler: Got job 187 (parquet at <unknown>:0) with 2 output partitions
26/01/12 02:46:03 INFO DAGScheduler: Final stage: ResultStage 187 (parquet at <unknown>:0)
26/01/12 02:46:03 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:46:03 INFO DAGScheduler: Missing parents: List()
26/01/12 02:46:03 INFO DAGScheduler: Submitting ResultStage 187 (MapPartitionsRDD[469] at parquet at <unknown>:0), which has no missing parents
26/01/12 02:46:03 INFO MemoryStore: Block broadcast_281 stored as values in memory (estimated size 225.1 KiB, free 362.9 MiB)
26/01/12 02:46:03 INFO MemoryStore: Block broadcast_281_piece0 stored as bytes in memory (estimated size 77.4 KiB, free 362.8 MiB)
26/01/12 02:46:03 INFO BlockManagerInfo: Added broadcast_281_piece0 in memory on 02926ee04bc9:45221 (size: 77.4 KiB, free: 365.7 MiB)
26/01/12 02:46:03 INFO SparkContext: Created broadcast 281 from broadcast at DAGScheduler.scala:1513
26/01/12 02:46:03 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 187 (MapPartitionsRDD[469] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1))
26/01/12 02:46:03 INFO TaskSchedulerImpl: Adding task set 187.0 with 2 tasks resource profile 0
26/01/12 02:46:03 INFO TaskSetManager: Starting task 0.0 in stage 187.0 (TID 327) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:46:03 INFO TaskSetManager: Starting task 1.0 in stage 187.0 (TID 328) (172.18.0.5, executor 0, partition 1, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:46:03 INFO BlockManagerInfo: Added broadcast_281_piece0 in memory on 172.18.0.5:42453 (size: 77.4 KiB, free: 365.8 MiB)
26/01/12 02:46:03 INFO BlockManagerInfo: Added broadcast_280_piece0 in memory on 172.18.0.5:42453 (size: 35.4 KiB, free: 365.7 MiB)
26/01/12 02:46:03 INFO TaskSetManager: Finished task 1.0 in stage 187.0 (TID 328) in 54 ms on 172.18.0.5 (executor 0) (1/2)
26/01/12 02:46:28 INFO TaskSetManager: Finished task 0.0 in stage 187.0 (TID 327) in 25214 ms on 172.18.0.5 (executor 0) (2/2)
26/01/12 02:46:28 INFO TaskSchedulerImpl: Removed TaskSet 187.0, whose tasks have all completed, from pool 
26/01/12 02:46:28 INFO DAGScheduler: ResultStage 187 (parquet at <unknown>:0) finished in 25.234 s
26/01/12 02:46:28 INFO DAGScheduler: Job 187 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:46:28 INFO TaskSchedulerImpl: Killing all running tasks in stage 187: Stage finished
26/01/12 02:46:28 INFO DAGScheduler: Job 187 finished: parquet at <unknown>:0, took 25.238730 s
26/01/12 02:46:28 INFO FileFormatWriter: Start to commit write Job 696040d9-4a48-467c-9e8e-c056194134f5.
26/01/12 02:46:28 INFO FileFormatWriter: Write Job 696040d9-4a48-467c-9e8e-c056194134f5 committed. Elapsed time: 33 ms.
26/01/12 02:46:28 INFO FileFormatWriter: Finished processing stats for write job 696040d9-4a48-467c-9e8e-c056194134f5.
Cargando: yellow_tripdata_2016-11.parquet en hdfs://hadoop-namenode:8020/data/nyc/raw/taxi-trips/2016...
26/01/12 02:46:28 INFO InMemoryFileIndex: It took 6 ms to list leaf files for 1 paths.
26/01/12 02:46:28 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 02:46:29 INFO DAGScheduler: Got job 188 (parquet at <unknown>:0) with 1 output partitions
26/01/12 02:46:29 INFO DAGScheduler: Final stage: ResultStage 188 (parquet at <unknown>:0)
26/01/12 02:46:29 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:46:29 INFO DAGScheduler: Missing parents: List()
26/01/12 02:46:29 INFO DAGScheduler: Submitting ResultStage 188 (MapPartitionsRDD[471] at parquet at <unknown>:0), which has no missing parents
26/01/12 02:46:29 INFO MemoryStore: Block broadcast_282 stored as values in memory (estimated size 102.6 KiB, free 362.7 MiB)
26/01/12 02:46:29 INFO MemoryStore: Block broadcast_282_piece0 stored as bytes in memory (estimated size 36.8 KiB, free 362.7 MiB)
26/01/12 02:46:29 INFO BlockManagerInfo: Added broadcast_282_piece0 in memory on 02926ee04bc9:45221 (size: 36.8 KiB, free: 365.7 MiB)
26/01/12 02:46:29 INFO SparkContext: Created broadcast 282 from broadcast at DAGScheduler.scala:1513
26/01/12 02:46:29 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 188 (MapPartitionsRDD[471] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0))
26/01/12 02:46:29 INFO TaskSchedulerImpl: Adding task set 188.0 with 1 tasks resource profile 0
26/01/12 02:46:29 INFO TaskSetManager: Starting task 0.0 in stage 188.0 (TID 329) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4607 bytes) taskResourceAssignments Map()
26/01/12 02:46:29 INFO BlockManagerInfo: Added broadcast_282_piece0 in memory on 172.18.0.5:42453 (size: 36.8 KiB, free: 365.7 MiB)
26/01/12 02:46:29 INFO TaskSetManager: Finished task 0.0 in stage 188.0 (TID 329) in 52 ms on 172.18.0.5 (executor 0) (1/1)
26/01/12 02:46:29 INFO TaskSchedulerImpl: Removed TaskSet 188.0, whose tasks have all completed, from pool 
26/01/12 02:46:29 INFO DAGScheduler: ResultStage 188 (parquet at <unknown>:0) finished in 0.065 s
26/01/12 02:46:29 INFO DAGScheduler: Job 188 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:46:29 INFO TaskSchedulerImpl: Killing all running tasks in stage 188: Stage finished
26/01/12 02:46:29 INFO DAGScheduler: Job 188 finished: parquet at <unknown>:0, took 0.068744 s
26/01/12 02:46:29 INFO FileSourceStrategy: Pushed Filters: 
26/01/12 02:46:29 INFO FileSourceStrategy: Post-Scan Filters: 
26/01/12 02:46:29 INFO FileSourceStrategy: Output Data Schema: struct<VendorID: bigint, tpep_pickup_datetime: timestamp, tpep_dropoff_datetime: timestamp, passenger_count: bigint, trip_distance: double ... 17 more fields>
26/01/12 02:46:29 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:46:29 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:46:29 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:46:29 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:46:29 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:46:29 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:46:29 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:46:29 INFO MemoryStore: Block broadcast_283 stored as values in memory (estimated size 358.4 KiB, free 362.3 MiB)
26/01/12 02:46:29 INFO MemoryStore: Block broadcast_283_piece0 stored as bytes in memory (estimated size 35.4 KiB, free 362.3 MiB)
26/01/12 02:46:29 INFO BlockManagerInfo: Added broadcast_283_piece0 in memory on 02926ee04bc9:45221 (size: 35.4 KiB, free: 365.6 MiB)
26/01/12 02:46:29 INFO SparkContext: Created broadcast 283 from parquet at <unknown>:0
26/01/12 02:46:29 INFO FileSourceScanExec: Planning scan with bin packing, max size: 72671618 bytes, open cost is considered as scanning 4194304 bytes.
26/01/12 02:46:29 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 02:46:29 INFO DAGScheduler: Got job 189 (parquet at <unknown>:0) with 2 output partitions
26/01/12 02:46:29 INFO DAGScheduler: Final stage: ResultStage 189 (parquet at <unknown>:0)
26/01/12 02:46:29 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:46:29 INFO DAGScheduler: Missing parents: List()
26/01/12 02:46:29 INFO DAGScheduler: Submitting ResultStage 189 (MapPartitionsRDD[474] at parquet at <unknown>:0), which has no missing parents
26/01/12 02:46:29 INFO MemoryStore: Block broadcast_284 stored as values in memory (estimated size 225.1 KiB, free 362.0 MiB)
26/01/12 02:46:29 INFO MemoryStore: Block broadcast_284_piece0 stored as bytes in memory (estimated size 77.4 KiB, free 362.0 MiB)
26/01/12 02:46:29 INFO BlockManagerInfo: Added broadcast_284_piece0 in memory on 02926ee04bc9:45221 (size: 77.4 KiB, free: 365.6 MiB)
26/01/12 02:46:29 INFO SparkContext: Created broadcast 284 from broadcast at DAGScheduler.scala:1513
26/01/12 02:46:29 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 189 (MapPartitionsRDD[474] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1))
26/01/12 02:46:29 INFO TaskSchedulerImpl: Adding task set 189.0 with 2 tasks resource profile 0
26/01/12 02:46:29 INFO TaskSetManager: Starting task 0.0 in stage 189.0 (TID 330) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:46:29 INFO TaskSetManager: Starting task 1.0 in stage 189.0 (TID 331) (172.18.0.5, executor 0, partition 1, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:46:29 INFO BlockManagerInfo: Removed broadcast_281_piece0 on 172.18.0.5:42453 in memory (size: 77.4 KiB, free: 365.8 MiB)
26/01/12 02:46:29 INFO BlockManagerInfo: Removed broadcast_281_piece0 on 02926ee04bc9:45221 in memory (size: 77.4 KiB, free: 365.6 MiB)
26/01/12 02:46:29 INFO BlockManagerInfo: Removed broadcast_276_piece0 on 02926ee04bc9:45221 in memory (size: 36.8 KiB, free: 365.7 MiB)
26/01/12 02:46:29 INFO BlockManagerInfo: Removed broadcast_276_piece0 on 172.18.0.5:42453 in memory (size: 36.8 KiB, free: 365.8 MiB)
26/01/12 02:46:29 INFO BlockManagerInfo: Added broadcast_284_piece0 in memory on 172.18.0.5:42453 (size: 77.4 KiB, free: 365.7 MiB)
26/01/12 02:46:29 INFO BlockManagerInfo: Removed broadcast_280_piece0 on 02926ee04bc9:45221 in memory (size: 35.4 KiB, free: 365.7 MiB)
26/01/12 02:46:29 INFO BlockManagerInfo: Removed broadcast_280_piece0 on 172.18.0.5:42453 in memory (size: 35.4 KiB, free: 365.8 MiB)
26/01/12 02:46:29 INFO BlockManagerInfo: Removed broadcast_278_piece0 on 02926ee04bc9:45221 in memory (size: 77.4 KiB, free: 365.8 MiB)
26/01/12 02:46:29 INFO BlockManagerInfo: Removed broadcast_278_piece0 on 172.18.0.5:42453 in memory (size: 77.4 KiB, free: 365.8 MiB)
26/01/12 02:46:29 INFO BlockManagerInfo: Removed broadcast_274_piece0 on 02926ee04bc9:45221 in memory (size: 35.4 KiB, free: 365.8 MiB)
26/01/12 02:46:29 INFO BlockManagerInfo: Added broadcast_283_piece0 in memory on 172.18.0.5:42453 (size: 35.4 KiB, free: 365.8 MiB)
26/01/12 02:46:29 INFO BlockManagerInfo: Removed broadcast_274_piece0 on 172.18.0.5:42453 in memory (size: 35.4 KiB, free: 365.8 MiB)
26/01/12 02:46:29 INFO BlockManagerInfo: Removed broadcast_277_piece0 on 02926ee04bc9:45221 in memory (size: 35.4 KiB, free: 365.9 MiB)
26/01/12 02:46:29 INFO BlockManagerInfo: Removed broadcast_277_piece0 on 172.18.0.5:42453 in memory (size: 35.4 KiB, free: 365.9 MiB)
26/01/12 02:46:29 INFO BlockManagerInfo: Removed broadcast_271_piece0 on 02926ee04bc9:45221 in memory (size: 35.4 KiB, free: 365.9 MiB)
26/01/12 02:46:29 INFO BlockManagerInfo: Removed broadcast_271_piece0 on 172.18.0.5:42453 in memory (size: 35.4 KiB, free: 365.9 MiB)
26/01/12 02:46:29 INFO BlockManagerInfo: Removed broadcast_273_piece0 on 02926ee04bc9:45221 in memory (size: 36.8 KiB, free: 365.9 MiB)
26/01/12 02:46:29 INFO BlockManagerInfo: Removed broadcast_273_piece0 on 172.18.0.5:42453 in memory (size: 36.8 KiB, free: 365.9 MiB)
26/01/12 02:46:29 INFO BlockManagerInfo: Removed broadcast_275_piece0 on 02926ee04bc9:45221 in memory (size: 77.4 KiB, free: 366.0 MiB)
26/01/12 02:46:29 INFO BlockManagerInfo: Removed broadcast_275_piece0 on 172.18.0.5:42453 in memory (size: 77.4 KiB, free: 366.0 MiB)
26/01/12 02:46:29 INFO BlockManagerInfo: Removed broadcast_282_piece0 on 02926ee04bc9:45221 in memory (size: 36.8 KiB, free: 366.0 MiB)
26/01/12 02:46:29 INFO BlockManagerInfo: Removed broadcast_282_piece0 on 172.18.0.5:42453 in memory (size: 36.8 KiB, free: 366.0 MiB)
26/01/12 02:46:29 INFO BlockManagerInfo: Removed broadcast_279_piece0 on 02926ee04bc9:45221 in memory (size: 36.8 KiB, free: 366.1 MiB)
26/01/12 02:46:29 INFO BlockManagerInfo: Removed broadcast_279_piece0 on 172.18.0.5:42453 in memory (size: 36.8 KiB, free: 366.1 MiB)
26/01/12 02:46:29 INFO TaskSetManager: Finished task 1.0 in stage 189.0 (TID 331) in 80 ms on 172.18.0.5 (executor 0) (1/2)
26/01/12 02:46:52 INFO TaskSetManager: Finished task 0.0 in stage 189.0 (TID 330) in 23636 ms on 172.18.0.5 (executor 0) (2/2)
26/01/12 02:46:52 INFO TaskSchedulerImpl: Removed TaskSet 189.0, whose tasks have all completed, from pool 
26/01/12 02:46:52 INFO DAGScheduler: ResultStage 189 (parquet at <unknown>:0) finished in 23.684 s
26/01/12 02:46:52 INFO DAGScheduler: Job 189 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:46:52 INFO TaskSchedulerImpl: Killing all running tasks in stage 189: Stage finished
26/01/12 02:46:52 INFO DAGScheduler: Job 189 finished: parquet at <unknown>:0, took 23.690314 s
26/01/12 02:46:52 INFO FileFormatWriter: Start to commit write Job ba044bd8-707e-4b68-8c45-048aa7513ca8.
26/01/12 02:46:52 INFO FileFormatWriter: Write Job ba044bd8-707e-4b68-8c45-048aa7513ca8 committed. Elapsed time: 33 ms.
26/01/12 02:46:52 INFO FileFormatWriter: Finished processing stats for write job ba044bd8-707e-4b68-8c45-048aa7513ca8.
Cargando: yellow_tripdata_2016-12.parquet en hdfs://hadoop-namenode:8020/data/nyc/raw/taxi-trips/2016...
26/01/12 02:46:52 INFO InMemoryFileIndex: It took 6 ms to list leaf files for 1 paths.
26/01/12 02:46:52 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 02:46:52 INFO DAGScheduler: Got job 190 (parquet at <unknown>:0) with 1 output partitions
26/01/12 02:46:52 INFO DAGScheduler: Final stage: ResultStage 190 (parquet at <unknown>:0)
26/01/12 02:46:52 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:46:52 INFO DAGScheduler: Missing parents: List()
26/01/12 02:46:52 INFO DAGScheduler: Submitting ResultStage 190 (MapPartitionsRDD[476] at parquet at <unknown>:0), which has no missing parents
26/01/12 02:46:52 INFO MemoryStore: Block broadcast_285 stored as values in memory (estimated size 102.6 KiB, free 364.8 MiB)
26/01/12 02:46:52 INFO MemoryStore: Block broadcast_285_piece0 stored as bytes in memory (estimated size 36.8 KiB, free 364.8 MiB)
26/01/12 02:46:52 INFO BlockManagerInfo: Added broadcast_285_piece0 in memory on 02926ee04bc9:45221 (size: 36.8 KiB, free: 366.0 MiB)
26/01/12 02:46:52 INFO SparkContext: Created broadcast 285 from broadcast at DAGScheduler.scala:1513
26/01/12 02:46:52 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 190 (MapPartitionsRDD[476] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0))
26/01/12 02:46:52 INFO TaskSchedulerImpl: Adding task set 190.0 with 1 tasks resource profile 0
26/01/12 02:46:52 INFO TaskSetManager: Starting task 0.0 in stage 190.0 (TID 332) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4607 bytes) taskResourceAssignments Map()
26/01/12 02:46:52 INFO BlockManagerInfo: Added broadcast_285_piece0 in memory on 172.18.0.5:42453 (size: 36.8 KiB, free: 366.0 MiB)
26/01/12 02:46:52 INFO TaskSetManager: Finished task 0.0 in stage 190.0 (TID 332) in 52 ms on 172.18.0.5 (executor 0) (1/1)
26/01/12 02:46:52 INFO TaskSchedulerImpl: Removed TaskSet 190.0, whose tasks have all completed, from pool 
26/01/12 02:46:52 INFO DAGScheduler: ResultStage 190 (parquet at <unknown>:0) finished in 0.063 s
26/01/12 02:46:52 INFO DAGScheduler: Job 190 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:46:52 INFO TaskSchedulerImpl: Killing all running tasks in stage 190: Stage finished
26/01/12 02:46:52 INFO DAGScheduler: Job 190 finished: parquet at <unknown>:0, took 0.066746 s
26/01/12 02:46:52 INFO FileSourceStrategy: Pushed Filters: 
26/01/12 02:46:52 INFO FileSourceStrategy: Post-Scan Filters: 
26/01/12 02:46:52 INFO FileSourceStrategy: Output Data Schema: struct<VendorID: bigint, tpep_pickup_datetime: timestamp, tpep_dropoff_datetime: timestamp, passenger_count: bigint, trip_distance: double ... 17 more fields>
26/01/12 02:46:52 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:46:52 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:46:52 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:46:52 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:46:52 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:46:52 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:46:52 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:46:52 INFO MemoryStore: Block broadcast_286 stored as values in memory (estimated size 358.4 KiB, free 364.5 MiB)
26/01/12 02:46:52 INFO MemoryStore: Block broadcast_286_piece0 stored as bytes in memory (estimated size 35.4 KiB, free 364.4 MiB)
26/01/12 02:46:52 INFO BlockManagerInfo: Added broadcast_286_piece0 in memory on 02926ee04bc9:45221 (size: 35.4 KiB, free: 366.0 MiB)
26/01/12 02:46:52 INFO SparkContext: Created broadcast 286 from parquet at <unknown>:0
26/01/12 02:46:52 INFO FileSourceScanExec: Planning scan with bin packing, max size: 75075750 bytes, open cost is considered as scanning 4194304 bytes.
26/01/12 02:46:53 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 02:46:53 INFO DAGScheduler: Got job 191 (parquet at <unknown>:0) with 2 output partitions
26/01/12 02:46:53 INFO DAGScheduler: Final stage: ResultStage 191 (parquet at <unknown>:0)
26/01/12 02:46:53 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:46:53 INFO DAGScheduler: Missing parents: List()
26/01/12 02:46:53 INFO DAGScheduler: Submitting ResultStage 191 (MapPartitionsRDD[479] at parquet at <unknown>:0), which has no missing parents
26/01/12 02:46:53 INFO MemoryStore: Block broadcast_287 stored as values in memory (estimated size 225.1 KiB, free 364.2 MiB)
26/01/12 02:46:53 INFO MemoryStore: Block broadcast_287_piece0 stored as bytes in memory (estimated size 77.4 KiB, free 364.1 MiB)
26/01/12 02:46:53 INFO BlockManagerInfo: Added broadcast_287_piece0 in memory on 02926ee04bc9:45221 (size: 77.4 KiB, free: 365.9 MiB)
26/01/12 02:46:53 INFO SparkContext: Created broadcast 287 from broadcast at DAGScheduler.scala:1513
26/01/12 02:46:53 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 191 (MapPartitionsRDD[479] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1))
26/01/12 02:46:53 INFO TaskSchedulerImpl: Adding task set 191.0 with 2 tasks resource profile 0
26/01/12 02:46:53 INFO TaskSetManager: Starting task 0.0 in stage 191.0 (TID 333) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:46:53 INFO TaskSetManager: Starting task 1.0 in stage 191.0 (TID 334) (172.18.0.5, executor 0, partition 1, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:46:53 INFO BlockManagerInfo: Added broadcast_287_piece0 in memory on 172.18.0.5:42453 (size: 77.4 KiB, free: 366.0 MiB)
26/01/12 02:46:53 INFO BlockManagerInfo: Added broadcast_286_piece0 in memory on 172.18.0.5:42453 (size: 35.4 KiB, free: 365.9 MiB)
26/01/12 02:46:53 INFO TaskSetManager: Finished task 1.0 in stage 191.0 (TID 334) in 57 ms on 172.18.0.5 (executor 0) (1/2)
26/01/12 02:47:17 INFO TaskSetManager: Finished task 0.0 in stage 191.0 (TID 333) in 24292 ms on 172.18.0.5 (executor 0) (2/2)
26/01/12 02:47:17 INFO TaskSchedulerImpl: Removed TaskSet 191.0, whose tasks have all completed, from pool 
26/01/12 02:47:17 INFO DAGScheduler: ResultStage 191 (parquet at <unknown>:0) finished in 24.314 s
26/01/12 02:47:17 INFO DAGScheduler: Job 191 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:47:17 INFO TaskSchedulerImpl: Killing all running tasks in stage 191: Stage finished
26/01/12 02:47:17 INFO DAGScheduler: Job 191 finished: parquet at <unknown>:0, took 24.320775 s
26/01/12 02:47:17 INFO FileFormatWriter: Start to commit write Job 977e18ee-fcae-47f0-a81e-5d0f4c3b9e0d.
26/01/12 02:47:17 INFO FileFormatWriter: Write Job 977e18ee-fcae-47f0-a81e-5d0f4c3b9e0d committed. Elapsed time: 32 ms.
26/01/12 02:47:17 INFO FileFormatWriter: Finished processing stats for write job 977e18ee-fcae-47f0-a81e-5d0f4c3b9e0d.
Cargando: yellow_tripdata_2017-01.parquet en hdfs://hadoop-namenode:8020/data/nyc/raw/taxi-trips/2017...
26/01/12 02:47:17 INFO InMemoryFileIndex: It took 9 ms to list leaf files for 1 paths.
26/01/12 02:47:17 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 02:47:17 INFO DAGScheduler: Got job 192 (parquet at <unknown>:0) with 1 output partitions
26/01/12 02:47:17 INFO DAGScheduler: Final stage: ResultStage 192 (parquet at <unknown>:0)
26/01/12 02:47:17 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:47:17 INFO DAGScheduler: Missing parents: List()
26/01/12 02:47:17 INFO DAGScheduler: Submitting ResultStage 192 (MapPartitionsRDD[481] at parquet at <unknown>:0), which has no missing parents
26/01/12 02:47:17 INFO MemoryStore: Block broadcast_288 stored as values in memory (estimated size 102.6 KiB, free 364.0 MiB)
26/01/12 02:47:17 INFO MemoryStore: Block broadcast_288_piece0 stored as bytes in memory (estimated size 36.8 KiB, free 364.0 MiB)
26/01/12 02:47:17 INFO BlockManagerInfo: Added broadcast_288_piece0 in memory on 02926ee04bc9:45221 (size: 36.8 KiB, free: 365.9 MiB)
26/01/12 02:47:17 INFO SparkContext: Created broadcast 288 from broadcast at DAGScheduler.scala:1513
26/01/12 02:47:17 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 192 (MapPartitionsRDD[481] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0))
26/01/12 02:47:17 INFO TaskSchedulerImpl: Adding task set 192.0 with 1 tasks resource profile 0
26/01/12 02:47:17 INFO TaskSetManager: Starting task 0.0 in stage 192.0 (TID 335) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4607 bytes) taskResourceAssignments Map()
26/01/12 02:47:17 INFO BlockManagerInfo: Added broadcast_288_piece0 in memory on 172.18.0.5:42453 (size: 36.8 KiB, free: 365.9 MiB)
26/01/12 02:47:17 INFO TaskSetManager: Finished task 0.0 in stage 192.0 (TID 335) in 50 ms on 172.18.0.5 (executor 0) (1/1)
26/01/12 02:47:17 INFO TaskSchedulerImpl: Removed TaskSet 192.0, whose tasks have all completed, from pool 
26/01/12 02:47:17 INFO DAGScheduler: ResultStage 192 (parquet at <unknown>:0) finished in 0.062 s
26/01/12 02:47:17 INFO DAGScheduler: Job 192 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:47:17 INFO TaskSchedulerImpl: Killing all running tasks in stage 192: Stage finished
26/01/12 02:47:17 INFO DAGScheduler: Job 192 finished: parquet at <unknown>:0, took 0.067612 s
26/01/12 02:47:17 INFO FileSourceStrategy: Pushed Filters: 
26/01/12 02:47:17 INFO FileSourceStrategy: Post-Scan Filters: 
26/01/12 02:47:17 INFO FileSourceStrategy: Output Data Schema: struct<VendorID: bigint, tpep_pickup_datetime: timestamp, tpep_dropoff_datetime: timestamp, passenger_count: bigint, trip_distance: double ... 17 more fields>
26/01/12 02:47:17 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:47:17 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:47:17 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:47:17 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:47:17 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:47:17 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:47:17 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:47:17 INFO MemoryStore: Block broadcast_289 stored as values in memory (estimated size 358.4 KiB, free 363.6 MiB)
26/01/12 02:47:17 INFO MemoryStore: Block broadcast_289_piece0 stored as bytes in memory (estimated size 35.4 KiB, free 363.6 MiB)
26/01/12 02:47:17 INFO BlockManagerInfo: Added broadcast_289_piece0 in memory on 02926ee04bc9:45221 (size: 35.4 KiB, free: 365.9 MiB)
26/01/12 02:47:17 INFO SparkContext: Created broadcast 289 from parquet at <unknown>:0
26/01/12 02:47:17 INFO FileSourceScanExec: Planning scan with bin packing, max size: 69512156 bytes, open cost is considered as scanning 4194304 bytes.
26/01/12 02:47:17 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 02:47:17 INFO DAGScheduler: Got job 193 (parquet at <unknown>:0) with 2 output partitions
26/01/12 02:47:17 INFO DAGScheduler: Final stage: ResultStage 193 (parquet at <unknown>:0)
26/01/12 02:47:17 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:47:17 INFO DAGScheduler: Missing parents: List()
26/01/12 02:47:17 INFO DAGScheduler: Submitting ResultStage 193 (MapPartitionsRDD[484] at parquet at <unknown>:0), which has no missing parents
26/01/12 02:47:17 INFO MemoryStore: Block broadcast_290 stored as values in memory (estimated size 225.1 KiB, free 363.4 MiB)
26/01/12 02:47:17 INFO MemoryStore: Block broadcast_290_piece0 stored as bytes in memory (estimated size 77.4 KiB, free 363.3 MiB)
26/01/12 02:47:17 INFO BlockManagerInfo: Added broadcast_290_piece0 in memory on 02926ee04bc9:45221 (size: 77.4 KiB, free: 365.8 MiB)
26/01/12 02:47:17 INFO SparkContext: Created broadcast 290 from broadcast at DAGScheduler.scala:1513
26/01/12 02:47:17 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 193 (MapPartitionsRDD[484] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1))
26/01/12 02:47:17 INFO TaskSchedulerImpl: Adding task set 193.0 with 2 tasks resource profile 0
26/01/12 02:47:17 INFO TaskSetManager: Starting task 0.0 in stage 193.0 (TID 336) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:47:17 INFO TaskSetManager: Starting task 1.0 in stage 193.0 (TID 337) (172.18.0.5, executor 0, partition 1, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:47:17 INFO BlockManagerInfo: Added broadcast_290_piece0 in memory on 172.18.0.5:42453 (size: 77.4 KiB, free: 365.8 MiB)
26/01/12 02:47:17 INFO BlockManagerInfo: Added broadcast_289_piece0 in memory on 172.18.0.5:42453 (size: 35.4 KiB, free: 365.8 MiB)
26/01/12 02:47:17 INFO TaskSetManager: Finished task 1.0 in stage 193.0 (TID 337) in 58 ms on 172.18.0.5 (executor 0) (1/2)
26/01/12 02:47:39 INFO TaskSetManager: Finished task 0.0 in stage 193.0 (TID 336) in 22384 ms on 172.18.0.5 (executor 0) (2/2)
26/01/12 02:47:39 INFO TaskSchedulerImpl: Removed TaskSet 193.0, whose tasks have all completed, from pool 
26/01/12 02:47:39 INFO DAGScheduler: ResultStage 193 (parquet at <unknown>:0) finished in 22.405 s
26/01/12 02:47:39 INFO DAGScheduler: Job 193 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:47:39 INFO TaskSchedulerImpl: Killing all running tasks in stage 193: Stage finished
26/01/12 02:47:39 INFO DAGScheduler: Job 193 finished: parquet at <unknown>:0, took 22.412384 s
26/01/12 02:47:39 INFO FileFormatWriter: Start to commit write Job 684ae5ec-5ef2-44f7-bc83-31e85eb658de.
26/01/12 02:47:39 INFO FileFormatWriter: Write Job 684ae5ec-5ef2-44f7-bc83-31e85eb658de committed. Elapsed time: 28 ms.
26/01/12 02:47:39 INFO FileFormatWriter: Finished processing stats for write job 684ae5ec-5ef2-44f7-bc83-31e85eb658de.
Cargando: yellow_tripdata_2017-02.parquet en hdfs://hadoop-namenode:8020/data/nyc/raw/taxi-trips/2017...
26/01/12 02:47:40 INFO InMemoryFileIndex: It took 7 ms to list leaf files for 1 paths.
26/01/12 02:47:40 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 02:47:40 INFO DAGScheduler: Got job 194 (parquet at <unknown>:0) with 1 output partitions
26/01/12 02:47:40 INFO DAGScheduler: Final stage: ResultStage 194 (parquet at <unknown>:0)
26/01/12 02:47:40 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:47:40 INFO DAGScheduler: Missing parents: List()
26/01/12 02:47:40 INFO DAGScheduler: Submitting ResultStage 194 (MapPartitionsRDD[486] at parquet at <unknown>:0), which has no missing parents
26/01/12 02:47:40 INFO MemoryStore: Block broadcast_291 stored as values in memory (estimated size 102.6 KiB, free 363.2 MiB)
26/01/12 02:47:40 INFO MemoryStore: Block broadcast_291_piece0 stored as bytes in memory (estimated size 36.8 KiB, free 363.2 MiB)
26/01/12 02:47:40 INFO BlockManagerInfo: Added broadcast_291_piece0 in memory on 02926ee04bc9:45221 (size: 36.8 KiB, free: 365.8 MiB)
26/01/12 02:47:40 INFO SparkContext: Created broadcast 291 from broadcast at DAGScheduler.scala:1513
26/01/12 02:47:40 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 194 (MapPartitionsRDD[486] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0))
26/01/12 02:47:40 INFO TaskSchedulerImpl: Adding task set 194.0 with 1 tasks resource profile 0
26/01/12 02:47:40 INFO TaskSetManager: Starting task 0.0 in stage 194.0 (TID 338) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4607 bytes) taskResourceAssignments Map()
26/01/12 02:47:40 INFO BlockManagerInfo: Added broadcast_291_piece0 in memory on 172.18.0.5:42453 (size: 36.8 KiB, free: 365.8 MiB)
26/01/12 02:47:40 INFO TaskSetManager: Finished task 0.0 in stage 194.0 (TID 338) in 51 ms on 172.18.0.5 (executor 0) (1/1)
26/01/12 02:47:40 INFO TaskSchedulerImpl: Removed TaskSet 194.0, whose tasks have all completed, from pool 
26/01/12 02:47:40 INFO DAGScheduler: ResultStage 194 (parquet at <unknown>:0) finished in 0.063 s
26/01/12 02:47:40 INFO DAGScheduler: Job 194 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:47:40 INFO TaskSchedulerImpl: Killing all running tasks in stage 194: Stage finished
26/01/12 02:47:40 INFO DAGScheduler: Job 194 finished: parquet at <unknown>:0, took 0.067113 s
26/01/12 02:47:40 INFO FileSourceStrategy: Pushed Filters: 
26/01/12 02:47:40 INFO FileSourceStrategy: Post-Scan Filters: 
26/01/12 02:47:40 INFO FileSourceStrategy: Output Data Schema: struct<VendorID: bigint, tpep_pickup_datetime: timestamp, tpep_dropoff_datetime: timestamp, passenger_count: bigint, trip_distance: double ... 17 more fields>
26/01/12 02:47:40 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:47:40 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:47:40 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:47:40 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:47:40 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:47:40 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:47:40 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:47:40 INFO MemoryStore: Block broadcast_292 stored as values in memory (estimated size 358.4 KiB, free 362.8 MiB)
26/01/12 02:47:40 INFO MemoryStore: Block broadcast_292_piece0 stored as bytes in memory (estimated size 35.4 KiB, free 362.8 MiB)
26/01/12 02:47:40 INFO BlockManagerInfo: Added broadcast_292_piece0 in memory on 02926ee04bc9:45221 (size: 35.4 KiB, free: 365.7 MiB)
26/01/12 02:47:40 INFO SparkContext: Created broadcast 292 from parquet at <unknown>:0
26/01/12 02:47:40 INFO FileSourceScanExec: Planning scan with bin packing, max size: 65919048 bytes, open cost is considered as scanning 4194304 bytes.
26/01/12 02:47:40 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 02:47:40 INFO DAGScheduler: Got job 195 (parquet at <unknown>:0) with 2 output partitions
26/01/12 02:47:40 INFO DAGScheduler: Final stage: ResultStage 195 (parquet at <unknown>:0)
26/01/12 02:47:40 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:47:40 INFO DAGScheduler: Missing parents: List()
26/01/12 02:47:40 INFO DAGScheduler: Submitting ResultStage 195 (MapPartitionsRDD[489] at parquet at <unknown>:0), which has no missing parents
26/01/12 02:47:40 INFO MemoryStore: Block broadcast_293 stored as values in memory (estimated size 225.1 KiB, free 362.6 MiB)
26/01/12 02:47:40 INFO MemoryStore: Block broadcast_293_piece0 stored as bytes in memory (estimated size 77.4 KiB, free 362.5 MiB)
26/01/12 02:47:40 INFO BlockManagerInfo: Added broadcast_293_piece0 in memory on 02926ee04bc9:45221 (size: 77.4 KiB, free: 365.6 MiB)
26/01/12 02:47:40 INFO SparkContext: Created broadcast 293 from broadcast at DAGScheduler.scala:1513
26/01/12 02:47:40 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 195 (MapPartitionsRDD[489] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1))
26/01/12 02:47:40 INFO TaskSchedulerImpl: Adding task set 195.0 with 2 tasks resource profile 0
26/01/12 02:47:40 INFO TaskSetManager: Starting task 0.0 in stage 195.0 (TID 339) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:47:40 INFO TaskSetManager: Starting task 1.0 in stage 195.0 (TID 340) (172.18.0.5, executor 0, partition 1, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:47:40 INFO BlockManagerInfo: Added broadcast_293_piece0 in memory on 172.18.0.5:42453 (size: 77.4 KiB, free: 365.7 MiB)
26/01/12 02:47:40 INFO BlockManagerInfo: Added broadcast_292_piece0 in memory on 172.18.0.5:42453 (size: 35.4 KiB, free: 365.6 MiB)
26/01/12 02:47:40 INFO TaskSetManager: Finished task 1.0 in stage 195.0 (TID 340) in 54 ms on 172.18.0.5 (executor 0) (1/2)
26/01/12 02:48:02 INFO TaskSetManager: Finished task 0.0 in stage 195.0 (TID 339) in 21956 ms on 172.18.0.5 (executor 0) (2/2)
26/01/12 02:48:02 INFO TaskSchedulerImpl: Removed TaskSet 195.0, whose tasks have all completed, from pool 
26/01/12 02:48:02 INFO DAGScheduler: ResultStage 195 (parquet at <unknown>:0) finished in 21.977 s
26/01/12 02:48:02 INFO DAGScheduler: Job 195 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:48:02 INFO TaskSchedulerImpl: Killing all running tasks in stage 195: Stage finished
26/01/12 02:48:02 INFO DAGScheduler: Job 195 finished: parquet at <unknown>:0, took 21.981916 s
26/01/12 02:48:02 INFO FileFormatWriter: Start to commit write Job 717c2d29-02f2-4813-966d-2e235d607660.
26/01/12 02:48:02 INFO FileFormatWriter: Write Job 717c2d29-02f2-4813-966d-2e235d607660 committed. Elapsed time: 31 ms.
26/01/12 02:48:02 INFO FileFormatWriter: Finished processing stats for write job 717c2d29-02f2-4813-966d-2e235d607660.
Cargando: yellow_tripdata_2017-03.parquet en hdfs://hadoop-namenode:8020/data/nyc/raw/taxi-trips/2017...
26/01/12 02:48:02 INFO InMemoryFileIndex: It took 7 ms to list leaf files for 1 paths.
26/01/12 02:48:02 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 02:48:02 INFO DAGScheduler: Got job 196 (parquet at <unknown>:0) with 1 output partitions
26/01/12 02:48:02 INFO DAGScheduler: Final stage: ResultStage 196 (parquet at <unknown>:0)
26/01/12 02:48:02 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:48:02 INFO DAGScheduler: Missing parents: List()
26/01/12 02:48:02 INFO DAGScheduler: Submitting ResultStage 196 (MapPartitionsRDD[491] at parquet at <unknown>:0), which has no missing parents
26/01/12 02:48:02 INFO MemoryStore: Block broadcast_294 stored as values in memory (estimated size 102.6 KiB, free 362.4 MiB)
26/01/12 02:48:02 INFO MemoryStore: Block broadcast_294_piece0 stored as bytes in memory (estimated size 36.8 KiB, free 362.4 MiB)
26/01/12 02:48:02 INFO BlockManagerInfo: Added broadcast_294_piece0 in memory on 02926ee04bc9:45221 (size: 36.8 KiB, free: 365.6 MiB)
26/01/12 02:48:02 INFO SparkContext: Created broadcast 294 from broadcast at DAGScheduler.scala:1513
26/01/12 02:48:02 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 196 (MapPartitionsRDD[491] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0))
26/01/12 02:48:02 INFO TaskSchedulerImpl: Adding task set 196.0 with 1 tasks resource profile 0
26/01/12 02:48:02 INFO TaskSetManager: Starting task 0.0 in stage 196.0 (TID 341) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4607 bytes) taskResourceAssignments Map()
26/01/12 02:48:02 INFO BlockManagerInfo: Added broadcast_294_piece0 in memory on 172.18.0.5:42453 (size: 36.8 KiB, free: 365.6 MiB)
26/01/12 02:48:02 INFO TaskSetManager: Finished task 0.0 in stage 196.0 (TID 341) in 46 ms on 172.18.0.5 (executor 0) (1/1)
26/01/12 02:48:02 INFO TaskSchedulerImpl: Removed TaskSet 196.0, whose tasks have all completed, from pool 
26/01/12 02:48:02 INFO DAGScheduler: ResultStage 196 (parquet at <unknown>:0) finished in 0.057 s
26/01/12 02:48:02 INFO DAGScheduler: Job 196 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:48:02 INFO TaskSchedulerImpl: Killing all running tasks in stage 196: Stage finished
26/01/12 02:48:02 INFO DAGScheduler: Job 196 finished: parquet at <unknown>:0, took 0.062550 s
26/01/12 02:48:02 INFO FileSourceStrategy: Pushed Filters: 
26/01/12 02:48:02 INFO FileSourceStrategy: Post-Scan Filters: 
26/01/12 02:48:02 INFO FileSourceStrategy: Output Data Schema: struct<VendorID: bigint, tpep_pickup_datetime: timestamp, tpep_dropoff_datetime: timestamp, passenger_count: bigint, trip_distance: double ... 17 more fields>
26/01/12 02:48:02 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:48:02 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:48:02 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:48:02 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:48:02 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:48:02 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:48:02 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:48:02 INFO MemoryStore: Block broadcast_295 stored as values in memory (estimated size 358.4 KiB, free 362.0 MiB)
26/01/12 02:48:02 INFO MemoryStore: Block broadcast_295_piece0 stored as bytes in memory (estimated size 35.4 KiB, free 362.0 MiB)
26/01/12 02:48:02 INFO BlockManagerInfo: Added broadcast_295_piece0 in memory on 02926ee04bc9:45221 (size: 35.4 KiB, free: 365.6 MiB)
26/01/12 02:48:02 INFO SparkContext: Created broadcast 295 from parquet at <unknown>:0
26/01/12 02:48:02 INFO FileSourceScanExec: Planning scan with bin packing, max size: 74386259 bytes, open cost is considered as scanning 4194304 bytes.
26/01/12 02:48:02 INFO BlockManagerInfo: Removed broadcast_285_piece0 on 02926ee04bc9:45221 in memory (size: 36.8 KiB, free: 365.6 MiB)
26/01/12 02:48:02 INFO BlockManagerInfo: Removed broadcast_285_piece0 on 172.18.0.5:42453 in memory (size: 36.8 KiB, free: 365.6 MiB)
26/01/12 02:48:02 INFO BlockManagerInfo: Removed broadcast_291_piece0 on 02926ee04bc9:45221 in memory (size: 36.8 KiB, free: 365.6 MiB)
26/01/12 02:48:02 INFO BlockManagerInfo: Removed broadcast_291_piece0 on 172.18.0.5:42453 in memory (size: 36.8 KiB, free: 365.7 MiB)
26/01/12 02:48:02 INFO BlockManagerInfo: Removed broadcast_293_piece0 on 02926ee04bc9:45221 in memory (size: 77.4 KiB, free: 365.7 MiB)
26/01/12 02:48:02 INFO BlockManagerInfo: Removed broadcast_293_piece0 on 172.18.0.5:42453 in memory (size: 77.4 KiB, free: 365.8 MiB)
26/01/12 02:48:02 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 02:48:02 INFO DAGScheduler: Got job 197 (parquet at <unknown>:0) with 2 output partitions
26/01/12 02:48:02 INFO DAGScheduler: Final stage: ResultStage 197 (parquet at <unknown>:0)
26/01/12 02:48:02 INFO BlockManagerInfo: Removed broadcast_287_piece0 on 02926ee04bc9:45221 in memory (size: 77.4 KiB, free: 365.8 MiB)
26/01/12 02:48:02 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:48:02 INFO DAGScheduler: Missing parents: List()
26/01/12 02:48:02 INFO BlockManagerInfo: Removed broadcast_287_piece0 on 172.18.0.5:42453 in memory (size: 77.4 KiB, free: 365.8 MiB)
26/01/12 02:48:02 INFO DAGScheduler: Submitting ResultStage 197 (MapPartitionsRDD[494] at parquet at <unknown>:0), which has no missing parents
26/01/12 02:48:02 INFO BlockManagerInfo: Removed broadcast_288_piece0 on 02926ee04bc9:45221 in memory (size: 36.8 KiB, free: 365.8 MiB)
26/01/12 02:48:02 INFO BlockManagerInfo: Removed broadcast_288_piece0 on 172.18.0.5:42453 in memory (size: 36.8 KiB, free: 365.9 MiB)
26/01/12 02:48:02 INFO BlockManagerInfo: Removed broadcast_294_piece0 on 02926ee04bc9:45221 in memory (size: 36.8 KiB, free: 365.9 MiB)
26/01/12 02:48:02 INFO BlockManagerInfo: Removed broadcast_294_piece0 on 172.18.0.5:42453 in memory (size: 36.8 KiB, free: 365.9 MiB)
26/01/12 02:48:02 INFO MemoryStore: Block broadcast_296 stored as values in memory (estimated size 225.1 KiB, free 362.9 MiB)
26/01/12 02:48:02 INFO BlockManagerInfo: Removed broadcast_292_piece0 on 02926ee04bc9:45221 in memory (size: 35.4 KiB, free: 365.9 MiB)
26/01/12 02:48:02 INFO MemoryStore: Block broadcast_296_piece0 stored as bytes in memory (estimated size 77.4 KiB, free 362.8 MiB)
26/01/12 02:48:02 INFO BlockManagerInfo: Removed broadcast_292_piece0 on 172.18.0.5:42453 in memory (size: 35.4 KiB, free: 365.9 MiB)
26/01/12 02:48:02 INFO BlockManagerInfo: Added broadcast_296_piece0 in memory on 02926ee04bc9:45221 (size: 77.4 KiB, free: 365.8 MiB)
26/01/12 02:48:02 INFO SparkContext: Created broadcast 296 from broadcast at DAGScheduler.scala:1513
26/01/12 02:48:02 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 197 (MapPartitionsRDD[494] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1))
26/01/12 02:48:02 INFO TaskSchedulerImpl: Adding task set 197.0 with 2 tasks resource profile 0
26/01/12 02:48:02 INFO TaskSetManager: Starting task 0.0 in stage 197.0 (TID 342) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:48:02 INFO TaskSetManager: Starting task 1.0 in stage 197.0 (TID 343) (172.18.0.5, executor 0, partition 1, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:48:02 INFO BlockManagerInfo: Removed broadcast_283_piece0 on 02926ee04bc9:45221 in memory (size: 35.4 KiB, free: 365.9 MiB)
26/01/12 02:48:02 INFO BlockManagerInfo: Removed broadcast_283_piece0 on 172.18.0.5:42453 in memory (size: 35.4 KiB, free: 366.0 MiB)
26/01/12 02:48:02 INFO BlockManagerInfo: Removed broadcast_289_piece0 on 02926ee04bc9:45221 in memory (size: 35.4 KiB, free: 365.9 MiB)
26/01/12 02:48:02 INFO BlockManagerInfo: Added broadcast_296_piece0 in memory on 172.18.0.5:42453 (size: 77.4 KiB, free: 365.9 MiB)
26/01/12 02:48:02 INFO BlockManagerInfo: Removed broadcast_289_piece0 on 172.18.0.5:42453 in memory (size: 35.4 KiB, free: 365.9 MiB)
26/01/12 02:48:02 INFO BlockManagerInfo: Removed broadcast_286_piece0 on 02926ee04bc9:45221 in memory (size: 35.4 KiB, free: 365.9 MiB)
26/01/12 02:48:02 INFO BlockManagerInfo: Removed broadcast_286_piece0 on 172.18.0.5:42453 in memory (size: 35.4 KiB, free: 366.0 MiB)
26/01/12 02:48:02 INFO BlockManagerInfo: Removed broadcast_290_piece0 on 02926ee04bc9:45221 in memory (size: 77.4 KiB, free: 366.0 MiB)
26/01/12 02:48:02 INFO BlockManagerInfo: Removed broadcast_290_piece0 on 172.18.0.5:42453 in memory (size: 77.4 KiB, free: 366.0 MiB)
26/01/12 02:48:02 INFO BlockManagerInfo: Added broadcast_295_piece0 in memory on 172.18.0.5:42453 (size: 35.4 KiB, free: 366.0 MiB)
26/01/12 02:48:02 INFO BlockManagerInfo: Removed broadcast_284_piece0 on 02926ee04bc9:45221 in memory (size: 77.4 KiB, free: 366.1 MiB)
26/01/12 02:48:02 INFO BlockManagerInfo: Removed broadcast_284_piece0 on 172.18.0.5:42453 in memory (size: 77.4 KiB, free: 366.1 MiB)
26/01/12 02:48:02 INFO TaskSetManager: Finished task 1.0 in stage 197.0 (TID 343) in 57 ms on 172.18.0.5 (executor 0) (1/2)
26/01/12 02:48:26 INFO TaskSetManager: Finished task 0.0 in stage 197.0 (TID 342) in 23627 ms on 172.18.0.5 (executor 0) (2/2)
26/01/12 02:48:26 INFO TaskSchedulerImpl: Removed TaskSet 197.0, whose tasks have all completed, from pool 
26/01/12 02:48:26 INFO DAGScheduler: ResultStage 197 (parquet at <unknown>:0) finished in 23.649 s
26/01/12 02:48:26 INFO DAGScheduler: Job 197 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:48:26 INFO TaskSchedulerImpl: Killing all running tasks in stage 197: Stage finished
26/01/12 02:48:26 INFO DAGScheduler: Job 197 finished: parquet at <unknown>:0, took 23.654087 s
26/01/12 02:48:26 INFO FileFormatWriter: Start to commit write Job 787a1cf8-d9db-4e33-8630-6b632afad53d.
26/01/12 02:48:26 INFO FileFormatWriter: Write Job 787a1cf8-d9db-4e33-8630-6b632afad53d committed. Elapsed time: 37 ms.
26/01/12 02:48:26 INFO FileFormatWriter: Finished processing stats for write job 787a1cf8-d9db-4e33-8630-6b632afad53d.
Cargando: yellow_tripdata_2017-04.parquet en hdfs://hadoop-namenode:8020/data/nyc/raw/taxi-trips/2017...
26/01/12 02:48:26 INFO InMemoryFileIndex: It took 6 ms to list leaf files for 1 paths.
26/01/12 02:48:26 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 02:48:26 INFO DAGScheduler: Got job 198 (parquet at <unknown>:0) with 1 output partitions
26/01/12 02:48:26 INFO DAGScheduler: Final stage: ResultStage 198 (parquet at <unknown>:0)
26/01/12 02:48:26 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:48:26 INFO DAGScheduler: Missing parents: List()
26/01/12 02:48:26 INFO DAGScheduler: Submitting ResultStage 198 (MapPartitionsRDD[496] at parquet at <unknown>:0), which has no missing parents
26/01/12 02:48:26 INFO MemoryStore: Block broadcast_297 stored as values in memory (estimated size 102.6 KiB, free 364.8 MiB)
26/01/12 02:48:26 INFO MemoryStore: Block broadcast_297_piece0 stored as bytes in memory (estimated size 36.8 KiB, free 364.8 MiB)
26/01/12 02:48:26 INFO BlockManagerInfo: Added broadcast_297_piece0 in memory on 02926ee04bc9:45221 (size: 36.8 KiB, free: 366.0 MiB)
26/01/12 02:48:26 INFO SparkContext: Created broadcast 297 from broadcast at DAGScheduler.scala:1513
26/01/12 02:48:26 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 198 (MapPartitionsRDD[496] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0))
26/01/12 02:48:26 INFO TaskSchedulerImpl: Adding task set 198.0 with 1 tasks resource profile 0
26/01/12 02:48:26 INFO TaskSetManager: Starting task 0.0 in stage 198.0 (TID 344) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4607 bytes) taskResourceAssignments Map()
26/01/12 02:48:26 INFO BlockManagerInfo: Added broadcast_297_piece0 in memory on 172.18.0.5:42453 (size: 36.8 KiB, free: 366.0 MiB)
26/01/12 02:48:26 INFO TaskSetManager: Finished task 0.0 in stage 198.0 (TID 344) in 57 ms on 172.18.0.5 (executor 0) (1/1)
26/01/12 02:48:26 INFO TaskSchedulerImpl: Removed TaskSet 198.0, whose tasks have all completed, from pool 
26/01/12 02:48:26 INFO DAGScheduler: ResultStage 198 (parquet at <unknown>:0) finished in 0.070 s
26/01/12 02:48:26 INFO DAGScheduler: Job 198 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:48:26 INFO TaskSchedulerImpl: Killing all running tasks in stage 198: Stage finished
26/01/12 02:48:26 INFO DAGScheduler: Job 198 finished: parquet at <unknown>:0, took 0.074165 s
26/01/12 02:48:26 INFO FileSourceStrategy: Pushed Filters: 
26/01/12 02:48:26 INFO FileSourceStrategy: Post-Scan Filters: 
26/01/12 02:48:26 INFO FileSourceStrategy: Output Data Schema: struct<VendorID: bigint, tpep_pickup_datetime: timestamp, tpep_dropoff_datetime: timestamp, passenger_count: bigint, trip_distance: double ... 17 more fields>
26/01/12 02:48:26 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:48:26 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:48:26 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:48:26 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:48:26 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:48:26 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:48:26 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:48:26 INFO MemoryStore: Block broadcast_298 stored as values in memory (estimated size 358.4 KiB, free 364.5 MiB)
26/01/12 02:48:26 INFO MemoryStore: Block broadcast_298_piece0 stored as bytes in memory (estimated size 35.4 KiB, free 364.4 MiB)
26/01/12 02:48:26 INFO BlockManagerInfo: Added broadcast_298_piece0 in memory on 02926ee04bc9:45221 (size: 35.4 KiB, free: 366.0 MiB)
26/01/12 02:48:26 INFO SparkContext: Created broadcast 298 from parquet at <unknown>:0
26/01/12 02:48:26 INFO FileSourceScanExec: Planning scan with bin packing, max size: 72771749 bytes, open cost is considered as scanning 4194304 bytes.
26/01/12 02:48:26 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 02:48:26 INFO DAGScheduler: Got job 199 (parquet at <unknown>:0) with 2 output partitions
26/01/12 02:48:26 INFO DAGScheduler: Final stage: ResultStage 199 (parquet at <unknown>:0)
26/01/12 02:48:26 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:48:26 INFO DAGScheduler: Missing parents: List()
26/01/12 02:48:26 INFO DAGScheduler: Submitting ResultStage 199 (MapPartitionsRDD[499] at parquet at <unknown>:0), which has no missing parents
26/01/12 02:48:26 INFO MemoryStore: Block broadcast_299 stored as values in memory (estimated size 225.1 KiB, free 364.2 MiB)
26/01/12 02:48:26 INFO MemoryStore: Block broadcast_299_piece0 stored as bytes in memory (estimated size 77.4 KiB, free 364.1 MiB)
26/01/12 02:48:26 INFO BlockManagerInfo: Added broadcast_299_piece0 in memory on 02926ee04bc9:45221 (size: 77.4 KiB, free: 365.9 MiB)
26/01/12 02:48:26 INFO SparkContext: Created broadcast 299 from broadcast at DAGScheduler.scala:1513
26/01/12 02:48:26 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 199 (MapPartitionsRDD[499] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1))
26/01/12 02:48:26 INFO TaskSchedulerImpl: Adding task set 199.0 with 2 tasks resource profile 0
26/01/12 02:48:26 INFO TaskSetManager: Starting task 0.0 in stage 199.0 (TID 345) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:48:26 INFO TaskSetManager: Starting task 1.0 in stage 199.0 (TID 346) (172.18.0.5, executor 0, partition 1, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:48:26 INFO BlockManagerInfo: Added broadcast_299_piece0 in memory on 172.18.0.5:42453 (size: 77.4 KiB, free: 366.0 MiB)
26/01/12 02:48:26 INFO BlockManagerInfo: Added broadcast_298_piece0 in memory on 172.18.0.5:42453 (size: 35.4 KiB, free: 365.9 MiB)
26/01/12 02:48:26 INFO TaskSetManager: Finished task 1.0 in stage 199.0 (TID 346) in 52 ms on 172.18.0.5 (executor 0) (1/2)
26/01/12 02:48:49 INFO TaskSetManager: Finished task 0.0 in stage 199.0 (TID 345) in 23545 ms on 172.18.0.5 (executor 0) (2/2)
26/01/12 02:48:49 INFO TaskSchedulerImpl: Removed TaskSet 199.0, whose tasks have all completed, from pool 
26/01/12 02:48:49 INFO DAGScheduler: ResultStage 199 (parquet at <unknown>:0) finished in 23.567 s
26/01/12 02:48:49 INFO DAGScheduler: Job 199 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:48:49 INFO TaskSchedulerImpl: Killing all running tasks in stage 199: Stage finished
26/01/12 02:48:49 INFO DAGScheduler: Job 199 finished: parquet at <unknown>:0, took 23.574850 s
26/01/12 02:48:49 INFO FileFormatWriter: Start to commit write Job b7305950-85df-4b23-8228-541a0a8eb7d5.
26/01/12 02:48:49 INFO FileFormatWriter: Write Job b7305950-85df-4b23-8228-541a0a8eb7d5 committed. Elapsed time: 32 ms.
26/01/12 02:48:49 INFO FileFormatWriter: Finished processing stats for write job b7305950-85df-4b23-8228-541a0a8eb7d5.
Cargando: yellow_tripdata_2017-05.parquet en hdfs://hadoop-namenode:8020/data/nyc/raw/taxi-trips/2017...
26/01/12 02:48:49 INFO InMemoryFileIndex: It took 7 ms to list leaf files for 1 paths.
26/01/12 02:48:49 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 02:48:49 INFO DAGScheduler: Got job 200 (parquet at <unknown>:0) with 1 output partitions
26/01/12 02:48:49 INFO DAGScheduler: Final stage: ResultStage 200 (parquet at <unknown>:0)
26/01/12 02:48:49 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:48:49 INFO DAGScheduler: Missing parents: List()
26/01/12 02:48:49 INFO DAGScheduler: Submitting ResultStage 200 (MapPartitionsRDD[501] at parquet at <unknown>:0), which has no missing parents
26/01/12 02:48:49 INFO MemoryStore: Block broadcast_300 stored as values in memory (estimated size 102.6 KiB, free 364.0 MiB)
26/01/12 02:48:49 INFO MemoryStore: Block broadcast_300_piece0 stored as bytes in memory (estimated size 36.8 KiB, free 364.0 MiB)
26/01/12 02:48:49 INFO BlockManagerInfo: Added broadcast_300_piece0 in memory on 02926ee04bc9:45221 (size: 36.8 KiB, free: 365.9 MiB)
26/01/12 02:48:49 INFO SparkContext: Created broadcast 300 from broadcast at DAGScheduler.scala:1513
26/01/12 02:48:49 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 200 (MapPartitionsRDD[501] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0))
26/01/12 02:48:49 INFO TaskSchedulerImpl: Adding task set 200.0 with 1 tasks resource profile 0
26/01/12 02:48:49 INFO TaskSetManager: Starting task 0.0 in stage 200.0 (TID 347) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4607 bytes) taskResourceAssignments Map()
26/01/12 02:48:49 INFO BlockManagerInfo: Added broadcast_300_piece0 in memory on 172.18.0.5:42453 (size: 36.8 KiB, free: 365.9 MiB)
26/01/12 02:48:49 INFO TaskSetManager: Finished task 0.0 in stage 200.0 (TID 347) in 52 ms on 172.18.0.5 (executor 0) (1/1)
26/01/12 02:48:49 INFO TaskSchedulerImpl: Removed TaskSet 200.0, whose tasks have all completed, from pool 
26/01/12 02:48:49 INFO DAGScheduler: ResultStage 200 (parquet at <unknown>:0) finished in 0.064 s
26/01/12 02:48:49 INFO DAGScheduler: Job 200 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:48:49 INFO TaskSchedulerImpl: Killing all running tasks in stage 200: Stage finished
26/01/12 02:48:49 INFO DAGScheduler: Job 200 finished: parquet at <unknown>:0, took 0.069454 s
26/01/12 02:48:49 INFO FileSourceStrategy: Pushed Filters: 
26/01/12 02:48:49 INFO FileSourceStrategy: Post-Scan Filters: 
26/01/12 02:48:49 INFO FileSourceStrategy: Output Data Schema: struct<VendorID: bigint, tpep_pickup_datetime: timestamp, tpep_dropoff_datetime: timestamp, passenger_count: bigint, trip_distance: double ... 17 more fields>
26/01/12 02:48:49 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:48:49 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:48:49 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:48:49 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:48:49 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:48:49 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:48:49 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:48:49 INFO MemoryStore: Block broadcast_301 stored as values in memory (estimated size 358.4 KiB, free 363.6 MiB)
26/01/12 02:48:49 INFO MemoryStore: Block broadcast_301_piece0 stored as bytes in memory (estimated size 35.4 KiB, free 363.6 MiB)
26/01/12 02:48:49 INFO BlockManagerInfo: Added broadcast_301_piece0 in memory on 02926ee04bc9:45221 (size: 35.4 KiB, free: 365.9 MiB)
26/01/12 02:48:49 INFO SparkContext: Created broadcast 301 from parquet at <unknown>:0
26/01/12 02:48:49 INFO FileSourceScanExec: Planning scan with bin packing, max size: 73286690 bytes, open cost is considered as scanning 4194304 bytes.
26/01/12 02:48:50 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 02:48:50 INFO DAGScheduler: Got job 201 (parquet at <unknown>:0) with 2 output partitions
26/01/12 02:48:50 INFO DAGScheduler: Final stage: ResultStage 201 (parquet at <unknown>:0)
26/01/12 02:48:50 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:48:50 INFO DAGScheduler: Missing parents: List()
26/01/12 02:48:50 INFO DAGScheduler: Submitting ResultStage 201 (MapPartitionsRDD[504] at parquet at <unknown>:0), which has no missing parents
26/01/12 02:48:50 INFO MemoryStore: Block broadcast_302 stored as values in memory (estimated size 225.1 KiB, free 363.4 MiB)
26/01/12 02:48:50 INFO MemoryStore: Block broadcast_302_piece0 stored as bytes in memory (estimated size 77.4 KiB, free 363.3 MiB)
26/01/12 02:48:50 INFO BlockManagerInfo: Added broadcast_302_piece0 in memory on 02926ee04bc9:45221 (size: 77.4 KiB, free: 365.8 MiB)
26/01/12 02:48:50 INFO SparkContext: Created broadcast 302 from broadcast at DAGScheduler.scala:1513
26/01/12 02:48:50 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 201 (MapPartitionsRDD[504] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1))
26/01/12 02:48:50 INFO TaskSchedulerImpl: Adding task set 201.0 with 2 tasks resource profile 0
26/01/12 02:48:50 INFO TaskSetManager: Starting task 0.0 in stage 201.0 (TID 348) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:48:50 INFO TaskSetManager: Starting task 1.0 in stage 201.0 (TID 349) (172.18.0.5, executor 0, partition 1, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:48:50 INFO BlockManagerInfo: Added broadcast_302_piece0 in memory on 172.18.0.5:42453 (size: 77.4 KiB, free: 365.8 MiB)
26/01/12 02:48:50 INFO BlockManagerInfo: Added broadcast_301_piece0 in memory on 172.18.0.5:42453 (size: 35.4 KiB, free: 365.8 MiB)
26/01/12 02:48:50 INFO TaskSetManager: Finished task 1.0 in stage 201.0 (TID 349) in 66 ms on 172.18.0.5 (executor 0) (1/2)
26/01/12 02:49:13 INFO TaskSetManager: Finished task 0.0 in stage 201.0 (TID 348) in 23791 ms on 172.18.0.5 (executor 0) (2/2)
26/01/12 02:49:13 INFO TaskSchedulerImpl: Removed TaskSet 201.0, whose tasks have all completed, from pool 
26/01/12 02:49:13 INFO DAGScheduler: ResultStage 201 (parquet at <unknown>:0) finished in 23.810 s
26/01/12 02:49:13 INFO DAGScheduler: Job 201 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:49:13 INFO TaskSchedulerImpl: Killing all running tasks in stage 201: Stage finished
26/01/12 02:49:13 INFO DAGScheduler: Job 201 finished: parquet at <unknown>:0, took 23.817082 s
26/01/12 02:49:13 INFO FileFormatWriter: Start to commit write Job 71a54ea1-3c01-45d3-a5bf-4b598d593665.
26/01/12 02:49:13 INFO FileFormatWriter: Write Job 71a54ea1-3c01-45d3-a5bf-4b598d593665 committed. Elapsed time: 33 ms.
26/01/12 02:49:13 INFO FileFormatWriter: Finished processing stats for write job 71a54ea1-3c01-45d3-a5bf-4b598d593665.
Cargando: yellow_tripdata_2017-06.parquet en hdfs://hadoop-namenode:8020/data/nyc/raw/taxi-trips/2017...
26/01/12 02:49:13 INFO InMemoryFileIndex: It took 6 ms to list leaf files for 1 paths.
26/01/12 02:49:13 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 02:49:13 INFO DAGScheduler: Got job 202 (parquet at <unknown>:0) with 1 output partitions
26/01/12 02:49:13 INFO DAGScheduler: Final stage: ResultStage 202 (parquet at <unknown>:0)
26/01/12 02:49:13 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:49:13 INFO DAGScheduler: Missing parents: List()
26/01/12 02:49:13 INFO DAGScheduler: Submitting ResultStage 202 (MapPartitionsRDD[506] at parquet at <unknown>:0), which has no missing parents
26/01/12 02:49:13 INFO MemoryStore: Block broadcast_303 stored as values in memory (estimated size 102.6 KiB, free 363.2 MiB)
26/01/12 02:49:13 INFO MemoryStore: Block broadcast_303_piece0 stored as bytes in memory (estimated size 36.8 KiB, free 363.2 MiB)
26/01/12 02:49:13 INFO BlockManagerInfo: Added broadcast_303_piece0 in memory on 02926ee04bc9:45221 (size: 36.8 KiB, free: 365.8 MiB)
26/01/12 02:49:13 INFO SparkContext: Created broadcast 303 from broadcast at DAGScheduler.scala:1513
26/01/12 02:49:13 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 202 (MapPartitionsRDD[506] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0))
26/01/12 02:49:13 INFO TaskSchedulerImpl: Adding task set 202.0 with 1 tasks resource profile 0
26/01/12 02:49:13 INFO TaskSetManager: Starting task 0.0 in stage 202.0 (TID 350) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4607 bytes) taskResourceAssignments Map()
26/01/12 02:49:13 INFO BlockManagerInfo: Added broadcast_303_piece0 in memory on 172.18.0.5:42453 (size: 36.8 KiB, free: 365.8 MiB)
26/01/12 02:49:13 INFO TaskSetManager: Finished task 0.0 in stage 202.0 (TID 350) in 45 ms on 172.18.0.5 (executor 0) (1/1)
26/01/12 02:49:13 INFO TaskSchedulerImpl: Removed TaskSet 202.0, whose tasks have all completed, from pool 
26/01/12 02:49:13 INFO DAGScheduler: ResultStage 202 (parquet at <unknown>:0) finished in 0.057 s
26/01/12 02:49:13 INFO DAGScheduler: Job 202 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:49:13 INFO TaskSchedulerImpl: Killing all running tasks in stage 202: Stage finished
26/01/12 02:49:13 INFO DAGScheduler: Job 202 finished: parquet at <unknown>:0, took 0.060807 s
26/01/12 02:49:13 INFO FileSourceStrategy: Pushed Filters: 
26/01/12 02:49:13 INFO FileSourceStrategy: Post-Scan Filters: 
26/01/12 02:49:13 INFO FileSourceStrategy: Output Data Schema: struct<VendorID: bigint, tpep_pickup_datetime: timestamp, tpep_dropoff_datetime: timestamp, passenger_count: bigint, trip_distance: double ... 17 more fields>
26/01/12 02:49:13 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:49:13 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:49:13 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:49:13 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:49:13 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:49:13 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:49:13 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:49:13 INFO MemoryStore: Block broadcast_304 stored as values in memory (estimated size 358.4 KiB, free 362.8 MiB)
26/01/12 02:49:13 INFO MemoryStore: Block broadcast_304_piece0 stored as bytes in memory (estimated size 35.4 KiB, free 362.8 MiB)
26/01/12 02:49:13 INFO BlockManagerInfo: Added broadcast_304_piece0 in memory on 02926ee04bc9:45221 (size: 35.4 KiB, free: 365.7 MiB)
26/01/12 02:49:13 INFO SparkContext: Created broadcast 304 from parquet at <unknown>:0
26/01/12 02:49:14 INFO FileSourceScanExec: Planning scan with bin packing, max size: 69838202 bytes, open cost is considered as scanning 4194304 bytes.
26/01/12 02:49:14 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 02:49:14 INFO DAGScheduler: Got job 203 (parquet at <unknown>:0) with 2 output partitions
26/01/12 02:49:14 INFO DAGScheduler: Final stage: ResultStage 203 (parquet at <unknown>:0)
26/01/12 02:49:14 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:49:14 INFO DAGScheduler: Missing parents: List()
26/01/12 02:49:14 INFO DAGScheduler: Submitting ResultStage 203 (MapPartitionsRDD[509] at parquet at <unknown>:0), which has no missing parents
26/01/12 02:49:14 INFO MemoryStore: Block broadcast_305 stored as values in memory (estimated size 225.1 KiB, free 362.6 MiB)
26/01/12 02:49:14 INFO MemoryStore: Block broadcast_305_piece0 stored as bytes in memory (estimated size 77.4 KiB, free 362.5 MiB)
26/01/12 02:49:14 INFO BlockManagerInfo: Added broadcast_305_piece0 in memory on 02926ee04bc9:45221 (size: 77.4 KiB, free: 365.6 MiB)
26/01/12 02:49:14 INFO SparkContext: Created broadcast 305 from broadcast at DAGScheduler.scala:1513
26/01/12 02:49:14 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 203 (MapPartitionsRDD[509] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1))
26/01/12 02:49:14 INFO TaskSchedulerImpl: Adding task set 203.0 with 2 tasks resource profile 0
26/01/12 02:49:14 INFO TaskSetManager: Starting task 0.0 in stage 203.0 (TID 351) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:49:14 INFO TaskSetManager: Starting task 1.0 in stage 203.0 (TID 352) (172.18.0.5, executor 0, partition 1, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:49:14 INFO BlockManagerInfo: Added broadcast_305_piece0 in memory on 172.18.0.5:42453 (size: 77.4 KiB, free: 365.7 MiB)
26/01/12 02:49:14 INFO BlockManagerInfo: Added broadcast_304_piece0 in memory on 172.18.0.5:42453 (size: 35.4 KiB, free: 365.6 MiB)
26/01/12 02:49:14 INFO TaskSetManager: Finished task 1.0 in stage 203.0 (TID 352) in 60 ms on 172.18.0.5 (executor 0) (1/2)
26/01/12 02:49:36 INFO TaskSetManager: Finished task 0.0 in stage 203.0 (TID 351) in 22167 ms on 172.18.0.5 (executor 0) (2/2)
26/01/12 02:49:36 INFO TaskSchedulerImpl: Removed TaskSet 203.0, whose tasks have all completed, from pool 
26/01/12 02:49:36 INFO DAGScheduler: ResultStage 203 (parquet at <unknown>:0) finished in 22.187 s
26/01/12 02:49:36 INFO DAGScheduler: Job 203 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:49:36 INFO TaskSchedulerImpl: Killing all running tasks in stage 203: Stage finished
26/01/12 02:49:36 INFO DAGScheduler: Job 203 finished: parquet at <unknown>:0, took 22.193513 s
26/01/12 02:49:36 INFO FileFormatWriter: Start to commit write Job 0c7f653d-447f-4c02-82ab-3419309bc312.
26/01/12 02:49:36 INFO FileFormatWriter: Write Job 0c7f653d-447f-4c02-82ab-3419309bc312 committed. Elapsed time: 36 ms.
26/01/12 02:49:36 INFO FileFormatWriter: Finished processing stats for write job 0c7f653d-447f-4c02-82ab-3419309bc312.
Cargando: yellow_tripdata_2017-07.parquet en hdfs://hadoop-namenode:8020/data/nyc/raw/taxi-trips/2017...
26/01/12 02:49:36 INFO InMemoryFileIndex: It took 6 ms to list leaf files for 1 paths.
26/01/12 02:49:36 INFO BlockManagerInfo: Removed broadcast_299_piece0 on 02926ee04bc9:45221 in memory (size: 77.4 KiB, free: 365.7 MiB)
26/01/12 02:49:36 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 02:49:36 INFO BlockManagerInfo: Removed broadcast_299_piece0 on 172.18.0.5:42453 in memory (size: 77.4 KiB, free: 365.7 MiB)
26/01/12 02:49:36 INFO DAGScheduler: Got job 204 (parquet at <unknown>:0) with 1 output partitions
26/01/12 02:49:36 INFO DAGScheduler: Final stage: ResultStage 204 (parquet at <unknown>:0)
26/01/12 02:49:36 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:49:36 INFO DAGScheduler: Missing parents: List()
26/01/12 02:49:36 INFO DAGScheduler: Submitting ResultStage 204 (MapPartitionsRDD[511] at parquet at <unknown>:0), which has no missing parents
26/01/12 02:49:36 INFO BlockManagerInfo: Removed broadcast_303_piece0 on 02926ee04bc9:45221 in memory (size: 36.8 KiB, free: 365.8 MiB)
26/01/12 02:49:36 INFO BlockManagerInfo: Removed broadcast_303_piece0 on 172.18.0.5:42453 in memory (size: 36.8 KiB, free: 365.8 MiB)
26/01/12 02:49:36 INFO BlockManagerInfo: Removed broadcast_305_piece0 on 02926ee04bc9:45221 in memory (size: 77.4 KiB, free: 365.8 MiB)
26/01/12 02:49:36 INFO MemoryStore: Block broadcast_306 stored as values in memory (estimated size 102.6 KiB, free 363.1 MiB)
26/01/12 02:49:36 INFO BlockManagerInfo: Removed broadcast_305_piece0 on 172.18.0.5:42453 in memory (size: 77.4 KiB, free: 365.8 MiB)
26/01/12 02:49:36 INFO MemoryStore: Block broadcast_306_piece0 stored as bytes in memory (estimated size 36.8 KiB, free 363.1 MiB)
26/01/12 02:49:36 INFO BlockManagerInfo: Added broadcast_306_piece0 in memory on 02926ee04bc9:45221 (size: 36.8 KiB, free: 365.8 MiB)
26/01/12 02:49:36 INFO SparkContext: Created broadcast 306 from broadcast at DAGScheduler.scala:1513
26/01/12 02:49:36 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 204 (MapPartitionsRDD[511] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0))
26/01/12 02:49:36 INFO TaskSchedulerImpl: Adding task set 204.0 with 1 tasks resource profile 0
26/01/12 02:49:36 INFO TaskSetManager: Starting task 0.0 in stage 204.0 (TID 353) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4607 bytes) taskResourceAssignments Map()
26/01/12 02:49:36 INFO BlockManagerInfo: Removed broadcast_298_piece0 on 02926ee04bc9:45221 in memory (size: 35.4 KiB, free: 365.8 MiB)
26/01/12 02:49:36 INFO BlockManagerInfo: Removed broadcast_298_piece0 on 172.18.0.5:42453 in memory (size: 35.4 KiB, free: 365.9 MiB)
26/01/12 02:49:36 INFO BlockManagerInfo: Removed broadcast_302_piece0 on 02926ee04bc9:45221 in memory (size: 77.4 KiB, free: 365.9 MiB)
26/01/12 02:49:36 INFO BlockManagerInfo: Removed broadcast_302_piece0 on 172.18.0.5:42453 in memory (size: 77.4 KiB, free: 365.9 MiB)
26/01/12 02:49:36 INFO BlockManagerInfo: Added broadcast_306_piece0 in memory on 172.18.0.5:42453 (size: 36.8 KiB, free: 365.9 MiB)
26/01/12 02:49:36 INFO BlockManagerInfo: Removed broadcast_301_piece0 on 02926ee04bc9:45221 in memory (size: 35.4 KiB, free: 365.9 MiB)
26/01/12 02:49:36 INFO BlockManagerInfo: Removed broadcast_301_piece0 on 172.18.0.5:42453 in memory (size: 35.4 KiB, free: 365.9 MiB)
26/01/12 02:49:36 INFO BlockManagerInfo: Removed broadcast_295_piece0 on 02926ee04bc9:45221 in memory (size: 35.4 KiB, free: 366.0 MiB)
26/01/12 02:49:36 INFO BlockManagerInfo: Removed broadcast_295_piece0 on 172.18.0.5:42453 in memory (size: 35.4 KiB, free: 366.0 MiB)
26/01/12 02:49:36 INFO BlockManagerInfo: Removed broadcast_297_piece0 on 02926ee04bc9:45221 in memory (size: 36.8 KiB, free: 366.0 MiB)
26/01/12 02:49:36 INFO BlockManagerInfo: Removed broadcast_297_piece0 on 172.18.0.5:42453 in memory (size: 36.8 KiB, free: 366.0 MiB)
26/01/12 02:49:36 INFO BlockManagerInfo: Removed broadcast_296_piece0 on 02926ee04bc9:45221 in memory (size: 77.4 KiB, free: 366.1 MiB)
26/01/12 02:49:36 INFO BlockManagerInfo: Removed broadcast_296_piece0 on 172.18.0.5:42453 in memory (size: 77.4 KiB, free: 366.1 MiB)
26/01/12 02:49:36 INFO BlockManagerInfo: Removed broadcast_300_piece0 on 02926ee04bc9:45221 in memory (size: 36.8 KiB, free: 366.1 MiB)
26/01/12 02:49:36 INFO BlockManagerInfo: Removed broadcast_300_piece0 on 172.18.0.5:42453 in memory (size: 36.8 KiB, free: 366.1 MiB)
26/01/12 02:49:36 INFO TaskSetManager: Finished task 0.0 in stage 204.0 (TID 353) in 60 ms on 172.18.0.5 (executor 0) (1/1)
26/01/12 02:49:36 INFO TaskSchedulerImpl: Removed TaskSet 204.0, whose tasks have all completed, from pool 
26/01/12 02:49:36 INFO DAGScheduler: ResultStage 204 (parquet at <unknown>:0) finished in 0.075 s
26/01/12 02:49:36 INFO DAGScheduler: Job 204 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:49:36 INFO TaskSchedulerImpl: Killing all running tasks in stage 204: Stage finished
26/01/12 02:49:36 INFO DAGScheduler: Job 204 finished: parquet at <unknown>:0, took 0.080258 s
26/01/12 02:49:36 INFO FileSourceStrategy: Pushed Filters: 
26/01/12 02:49:36 INFO FileSourceStrategy: Post-Scan Filters: 
26/01/12 02:49:36 INFO FileSourceStrategy: Output Data Schema: struct<VendorID: bigint, tpep_pickup_datetime: timestamp, tpep_dropoff_datetime: timestamp, passenger_count: bigint, trip_distance: double ... 17 more fields>
26/01/12 02:49:36 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:49:36 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:49:36 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:49:36 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:49:36 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:49:36 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:49:36 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:49:36 INFO MemoryStore: Block broadcast_307 stored as values in memory (estimated size 358.4 KiB, free 364.7 MiB)
26/01/12 02:49:36 INFO MemoryStore: Block broadcast_307_piece0 stored as bytes in memory (estimated size 35.4 KiB, free 364.7 MiB)
26/01/12 02:49:36 INFO BlockManagerInfo: Added broadcast_307_piece0 in memory on 02926ee04bc9:45221 (size: 35.4 KiB, free: 366.1 MiB)
26/01/12 02:49:36 INFO SparkContext: Created broadcast 307 from parquet at <unknown>:0
26/01/12 02:49:36 INFO FileSourceScanExec: Planning scan with bin packing, max size: 62517919 bytes, open cost is considered as scanning 4194304 bytes.
26/01/12 02:49:36 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 02:49:36 INFO DAGScheduler: Got job 205 (parquet at <unknown>:0) with 2 output partitions
26/01/12 02:49:36 INFO DAGScheduler: Final stage: ResultStage 205 (parquet at <unknown>:0)
26/01/12 02:49:36 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:49:36 INFO DAGScheduler: Missing parents: List()
26/01/12 02:49:36 INFO DAGScheduler: Submitting ResultStage 205 (MapPartitionsRDD[514] at parquet at <unknown>:0), which has no missing parents
26/01/12 02:49:36 INFO MemoryStore: Block broadcast_308 stored as values in memory (estimated size 225.1 KiB, free 364.5 MiB)
26/01/12 02:49:36 INFO MemoryStore: Block broadcast_308_piece0 stored as bytes in memory (estimated size 77.4 KiB, free 364.4 MiB)
26/01/12 02:49:36 INFO BlockManagerInfo: Added broadcast_308_piece0 in memory on 02926ee04bc9:45221 (size: 77.4 KiB, free: 366.0 MiB)
26/01/12 02:49:36 INFO SparkContext: Created broadcast 308 from broadcast at DAGScheduler.scala:1513
26/01/12 02:49:36 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 205 (MapPartitionsRDD[514] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1))
26/01/12 02:49:36 INFO TaskSchedulerImpl: Adding task set 205.0 with 2 tasks resource profile 0
26/01/12 02:49:36 INFO TaskSetManager: Starting task 0.0 in stage 205.0 (TID 354) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:49:36 INFO TaskSetManager: Starting task 1.0 in stage 205.0 (TID 355) (172.18.0.5, executor 0, partition 1, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:49:36 INFO BlockManagerInfo: Added broadcast_308_piece0 in memory on 172.18.0.5:42453 (size: 77.4 KiB, free: 366.0 MiB)
26/01/12 02:49:36 INFO BlockManagerInfo: Added broadcast_307_piece0 in memory on 172.18.0.5:42453 (size: 35.4 KiB, free: 366.0 MiB)
26/01/12 02:49:36 INFO TaskSetManager: Finished task 1.0 in stage 205.0 (TID 355) in 52 ms on 172.18.0.5 (executor 0) (1/2)
26/01/12 02:49:57 INFO TaskSetManager: Finished task 0.0 in stage 205.0 (TID 354) in 20542 ms on 172.18.0.5 (executor 0) (2/2)
26/01/12 02:49:57 INFO TaskSchedulerImpl: Removed TaskSet 205.0, whose tasks have all completed, from pool 
26/01/12 02:49:57 INFO DAGScheduler: ResultStage 205 (parquet at <unknown>:0) finished in 20.563 s
26/01/12 02:49:57 INFO DAGScheduler: Job 205 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:49:57 INFO TaskSchedulerImpl: Killing all running tasks in stage 205: Stage finished
26/01/12 02:49:57 INFO DAGScheduler: Job 205 finished: parquet at <unknown>:0, took 20.567783 s
26/01/12 02:49:57 INFO FileFormatWriter: Start to commit write Job 89895a22-c764-4f13-bbd8-e6a3ef528fd0.
26/01/12 02:49:57 INFO FileFormatWriter: Write Job 89895a22-c764-4f13-bbd8-e6a3ef528fd0 committed. Elapsed time: 24 ms.
26/01/12 02:49:57 INFO FileFormatWriter: Finished processing stats for write job 89895a22-c764-4f13-bbd8-e6a3ef528fd0.
Cargando: yellow_tripdata_2017-08.parquet en hdfs://hadoop-namenode:8020/data/nyc/raw/taxi-trips/2017...
26/01/12 02:49:57 INFO InMemoryFileIndex: It took 6 ms to list leaf files for 1 paths.
26/01/12 02:49:57 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 02:49:57 INFO DAGScheduler: Got job 206 (parquet at <unknown>:0) with 1 output partitions
26/01/12 02:49:57 INFO DAGScheduler: Final stage: ResultStage 206 (parquet at <unknown>:0)
26/01/12 02:49:57 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:49:57 INFO DAGScheduler: Missing parents: List()
26/01/12 02:49:57 INFO DAGScheduler: Submitting ResultStage 206 (MapPartitionsRDD[516] at parquet at <unknown>:0), which has no missing parents
26/01/12 02:49:57 INFO MemoryStore: Block broadcast_309 stored as values in memory (estimated size 102.6 KiB, free 364.3 MiB)
26/01/12 02:49:57 INFO MemoryStore: Block broadcast_309_piece0 stored as bytes in memory (estimated size 36.8 KiB, free 364.3 MiB)
26/01/12 02:49:57 INFO BlockManagerInfo: Added broadcast_309_piece0 in memory on 02926ee04bc9:45221 (size: 36.8 KiB, free: 366.0 MiB)
26/01/12 02:49:57 INFO SparkContext: Created broadcast 309 from broadcast at DAGScheduler.scala:1513
26/01/12 02:49:57 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 206 (MapPartitionsRDD[516] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0))
26/01/12 02:49:57 INFO TaskSchedulerImpl: Adding task set 206.0 with 1 tasks resource profile 0
26/01/12 02:49:57 INFO TaskSetManager: Starting task 0.0 in stage 206.0 (TID 356) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4607 bytes) taskResourceAssignments Map()
26/01/12 02:49:57 INFO BlockManagerInfo: Added broadcast_309_piece0 in memory on 172.18.0.5:42453 (size: 36.8 KiB, free: 366.0 MiB)
26/01/12 02:49:57 INFO TaskSetManager: Finished task 0.0 in stage 206.0 (TID 356) in 60 ms on 172.18.0.5 (executor 0) (1/1)
26/01/12 02:49:57 INFO TaskSchedulerImpl: Removed TaskSet 206.0, whose tasks have all completed, from pool 
26/01/12 02:49:57 INFO DAGScheduler: ResultStage 206 (parquet at <unknown>:0) finished in 0.072 s
26/01/12 02:49:57 INFO DAGScheduler: Job 206 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:49:57 INFO TaskSchedulerImpl: Killing all running tasks in stage 206: Stage finished
26/01/12 02:49:57 INFO DAGScheduler: Job 206 finished: parquet at <unknown>:0, took 0.075823 s
26/01/12 02:49:57 INFO FileSourceStrategy: Pushed Filters: 
26/01/12 02:49:57 INFO FileSourceStrategy: Post-Scan Filters: 
26/01/12 02:49:57 INFO FileSourceStrategy: Output Data Schema: struct<VendorID: bigint, tpep_pickup_datetime: timestamp, tpep_dropoff_datetime: timestamp, passenger_count: bigint, trip_distance: double ... 17 more fields>
26/01/12 02:49:57 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:49:57 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:49:57 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:49:57 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:49:57 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:49:57 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:49:57 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:49:57 INFO MemoryStore: Block broadcast_310 stored as values in memory (estimated size 358.4 KiB, free 363.9 MiB)
26/01/12 02:49:57 INFO MemoryStore: Block broadcast_310_piece0 stored as bytes in memory (estimated size 35.4 KiB, free 363.9 MiB)
26/01/12 02:49:57 INFO BlockManagerInfo: Added broadcast_310_piece0 in memory on 02926ee04bc9:45221 (size: 35.4 KiB, free: 365.9 MiB)
26/01/12 02:49:57 INFO SparkContext: Created broadcast 310 from parquet at <unknown>:0
26/01/12 02:49:57 INFO FileSourceScanExec: Planning scan with bin packing, max size: 61408334 bytes, open cost is considered as scanning 4194304 bytes.
26/01/12 02:49:57 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 02:49:57 INFO DAGScheduler: Got job 207 (parquet at <unknown>:0) with 2 output partitions
26/01/12 02:49:57 INFO DAGScheduler: Final stage: ResultStage 207 (parquet at <unknown>:0)
26/01/12 02:49:57 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:49:57 INFO DAGScheduler: Missing parents: List()
26/01/12 02:49:57 INFO DAGScheduler: Submitting ResultStage 207 (MapPartitionsRDD[519] at parquet at <unknown>:0), which has no missing parents
26/01/12 02:49:57 INFO MemoryStore: Block broadcast_311 stored as values in memory (estimated size 225.1 KiB, free 363.7 MiB)
26/01/12 02:49:57 INFO MemoryStore: Block broadcast_311_piece0 stored as bytes in memory (estimated size 77.4 KiB, free 363.6 MiB)
26/01/12 02:49:57 INFO BlockManagerInfo: Added broadcast_311_piece0 in memory on 02926ee04bc9:45221 (size: 77.4 KiB, free: 365.9 MiB)
26/01/12 02:49:57 INFO SparkContext: Created broadcast 311 from broadcast at DAGScheduler.scala:1513
26/01/12 02:49:57 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 207 (MapPartitionsRDD[519] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1))
26/01/12 02:49:57 INFO TaskSchedulerImpl: Adding task set 207.0 with 2 tasks resource profile 0
26/01/12 02:49:57 INFO TaskSetManager: Starting task 0.0 in stage 207.0 (TID 357) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:49:57 INFO TaskSetManager: Starting task 1.0 in stage 207.0 (TID 358) (172.18.0.5, executor 0, partition 1, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:49:57 INFO BlockManagerInfo: Added broadcast_311_piece0 in memory on 172.18.0.5:42453 (size: 77.4 KiB, free: 365.9 MiB)
26/01/12 02:49:57 INFO BlockManagerInfo: Added broadcast_310_piece0 in memory on 172.18.0.5:42453 (size: 35.4 KiB, free: 365.9 MiB)
26/01/12 02:49:57 INFO TaskSetManager: Finished task 1.0 in stage 207.0 (TID 358) in 59 ms on 172.18.0.5 (executor 0) (1/2)
26/01/12 02:50:16 INFO TaskSetManager: Finished task 0.0 in stage 207.0 (TID 357) in 19270 ms on 172.18.0.5 (executor 0) (2/2)
26/01/12 02:50:16 INFO TaskSchedulerImpl: Removed TaskSet 207.0, whose tasks have all completed, from pool 
26/01/12 02:50:16 INFO DAGScheduler: ResultStage 207 (parquet at <unknown>:0) finished in 19.297 s
26/01/12 02:50:16 INFO DAGScheduler: Job 207 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:50:16 INFO TaskSchedulerImpl: Killing all running tasks in stage 207: Stage finished
26/01/12 02:50:16 INFO DAGScheduler: Job 207 finished: parquet at <unknown>:0, took 19.304710 s
26/01/12 02:50:16 INFO FileFormatWriter: Start to commit write Job 4b917d35-b240-48d1-8f6b-b275307f59e2.
26/01/12 02:50:16 INFO FileFormatWriter: Write Job 4b917d35-b240-48d1-8f6b-b275307f59e2 committed. Elapsed time: 35 ms.
26/01/12 02:50:16 INFO FileFormatWriter: Finished processing stats for write job 4b917d35-b240-48d1-8f6b-b275307f59e2.
Cargando: yellow_tripdata_2017-09.parquet en hdfs://hadoop-namenode:8020/data/nyc/raw/taxi-trips/2017...
26/01/12 02:50:16 INFO InMemoryFileIndex: It took 6 ms to list leaf files for 1 paths.
26/01/12 02:50:16 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 02:50:16 INFO DAGScheduler: Got job 208 (parquet at <unknown>:0) with 1 output partitions
26/01/12 02:50:16 INFO DAGScheduler: Final stage: ResultStage 208 (parquet at <unknown>:0)
26/01/12 02:50:16 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:50:16 INFO DAGScheduler: Missing parents: List()
26/01/12 02:50:16 INFO DAGScheduler: Submitting ResultStage 208 (MapPartitionsRDD[521] at parquet at <unknown>:0), which has no missing parents
26/01/12 02:50:16 INFO MemoryStore: Block broadcast_312 stored as values in memory (estimated size 102.6 KiB, free 363.5 MiB)
26/01/12 02:50:16 INFO MemoryStore: Block broadcast_312_piece0 stored as bytes in memory (estimated size 36.8 KiB, free 363.5 MiB)
26/01/12 02:50:16 INFO BlockManagerInfo: Added broadcast_312_piece0 in memory on 02926ee04bc9:45221 (size: 36.8 KiB, free: 365.8 MiB)
26/01/12 02:50:16 INFO SparkContext: Created broadcast 312 from broadcast at DAGScheduler.scala:1513
26/01/12 02:50:16 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 208 (MapPartitionsRDD[521] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0))
26/01/12 02:50:16 INFO TaskSchedulerImpl: Adding task set 208.0 with 1 tasks resource profile 0
26/01/12 02:50:16 INFO TaskSetManager: Starting task 0.0 in stage 208.0 (TID 359) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4607 bytes) taskResourceAssignments Map()
26/01/12 02:50:16 INFO BlockManagerInfo: Added broadcast_312_piece0 in memory on 172.18.0.5:42453 (size: 36.8 KiB, free: 365.8 MiB)
26/01/12 02:50:16 INFO TaskSetManager: Finished task 0.0 in stage 208.0 (TID 359) in 51 ms on 172.18.0.5 (executor 0) (1/1)
26/01/12 02:50:16 INFO TaskSchedulerImpl: Removed TaskSet 208.0, whose tasks have all completed, from pool 
26/01/12 02:50:16 INFO DAGScheduler: ResultStage 208 (parquet at <unknown>:0) finished in 0.065 s
26/01/12 02:50:16 INFO DAGScheduler: Job 208 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:50:16 INFO TaskSchedulerImpl: Killing all running tasks in stage 208: Stage finished
26/01/12 02:50:16 INFO DAGScheduler: Job 208 finished: parquet at <unknown>:0, took 0.070559 s
26/01/12 02:50:16 INFO FileSourceStrategy: Pushed Filters: 
26/01/12 02:50:16 INFO FileSourceStrategy: Post-Scan Filters: 
26/01/12 02:50:16 INFO FileSourceStrategy: Output Data Schema: struct<VendorID: bigint, tpep_pickup_datetime: timestamp, tpep_dropoff_datetime: timestamp, passenger_count: bigint, trip_distance: double ... 17 more fields>
26/01/12 02:50:16 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:50:16 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:50:16 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:50:16 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:50:16 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:50:16 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:50:16 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:50:16 INFO MemoryStore: Block broadcast_313 stored as values in memory (estimated size 358.4 KiB, free 363.1 MiB)
26/01/12 02:50:16 INFO MemoryStore: Block broadcast_313_piece0 stored as bytes in memory (estimated size 35.4 KiB, free 363.1 MiB)
26/01/12 02:50:16 INFO BlockManagerInfo: Added broadcast_313_piece0 in memory on 02926ee04bc9:45221 (size: 35.4 KiB, free: 365.8 MiB)
26/01/12 02:50:16 INFO SparkContext: Created broadcast 313 from parquet at <unknown>:0
26/01/12 02:50:16 INFO FileSourceScanExec: Planning scan with bin packing, max size: 65546800 bytes, open cost is considered as scanning 4194304 bytes.
26/01/12 02:50:16 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 02:50:16 INFO DAGScheduler: Got job 209 (parquet at <unknown>:0) with 2 output partitions
26/01/12 02:50:16 INFO DAGScheduler: Final stage: ResultStage 209 (parquet at <unknown>:0)
26/01/12 02:50:16 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:50:16 INFO DAGScheduler: Missing parents: List()
26/01/12 02:50:16 INFO DAGScheduler: Submitting ResultStage 209 (MapPartitionsRDD[524] at parquet at <unknown>:0), which has no missing parents
26/01/12 02:50:16 INFO MemoryStore: Block broadcast_314 stored as values in memory (estimated size 225.1 KiB, free 362.9 MiB)
26/01/12 02:50:16 INFO MemoryStore: Block broadcast_314_piece0 stored as bytes in memory (estimated size 77.4 KiB, free 362.8 MiB)
26/01/12 02:50:16 INFO BlockManagerInfo: Added broadcast_314_piece0 in memory on 02926ee04bc9:45221 (size: 77.4 KiB, free: 365.7 MiB)
26/01/12 02:50:16 INFO SparkContext: Created broadcast 314 from broadcast at DAGScheduler.scala:1513
26/01/12 02:50:16 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 209 (MapPartitionsRDD[524] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1))
26/01/12 02:50:16 INFO TaskSchedulerImpl: Adding task set 209.0 with 2 tasks resource profile 0
26/01/12 02:50:16 INFO TaskSetManager: Starting task 0.0 in stage 209.0 (TID 360) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:50:16 INFO TaskSetManager: Starting task 1.0 in stage 209.0 (TID 361) (172.18.0.5, executor 0, partition 1, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:50:16 INFO BlockManagerInfo: Added broadcast_314_piece0 in memory on 172.18.0.5:42453 (size: 77.4 KiB, free: 365.8 MiB)
26/01/12 02:50:16 INFO BlockManagerInfo: Added broadcast_313_piece0 in memory on 172.18.0.5:42453 (size: 35.4 KiB, free: 365.7 MiB)
26/01/12 02:50:16 INFO TaskSetManager: Finished task 1.0 in stage 209.0 (TID 361) in 55 ms on 172.18.0.5 (executor 0) (1/2)
26/01/12 02:50:36 INFO TaskSetManager: Finished task 0.0 in stage 209.0 (TID 360) in 19871 ms on 172.18.0.5 (executor 0) (2/2)
26/01/12 02:50:36 INFO TaskSchedulerImpl: Removed TaskSet 209.0, whose tasks have all completed, from pool 
26/01/12 02:50:36 INFO DAGScheduler: ResultStage 209 (parquet at <unknown>:0) finished in 19.893 s
26/01/12 02:50:36 INFO DAGScheduler: Job 209 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:50:36 INFO TaskSchedulerImpl: Killing all running tasks in stage 209: Stage finished
26/01/12 02:50:36 INFO DAGScheduler: Job 209 finished: parquet at <unknown>:0, took 19.899055 s
26/01/12 02:50:36 INFO FileFormatWriter: Start to commit write Job 635182a0-3f44-4b5c-9606-bcaf7d409b29.
26/01/12 02:50:36 INFO FileFormatWriter: Write Job 635182a0-3f44-4b5c-9606-bcaf7d409b29 committed. Elapsed time: 30 ms.
26/01/12 02:50:36 INFO FileFormatWriter: Finished processing stats for write job 635182a0-3f44-4b5c-9606-bcaf7d409b29.
Cargando: yellow_tripdata_2017-10.parquet en hdfs://hadoop-namenode:8020/data/nyc/raw/taxi-trips/2017...
26/01/12 02:50:36 INFO InMemoryFileIndex: It took 6 ms to list leaf files for 1 paths.
26/01/12 02:50:36 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 02:50:36 INFO DAGScheduler: Got job 210 (parquet at <unknown>:0) with 1 output partitions
26/01/12 02:50:36 INFO DAGScheduler: Final stage: ResultStage 210 (parquet at <unknown>:0)
26/01/12 02:50:36 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:50:36 INFO DAGScheduler: Missing parents: List()
26/01/12 02:50:36 INFO DAGScheduler: Submitting ResultStage 210 (MapPartitionsRDD[526] at parquet at <unknown>:0), which has no missing parents
26/01/12 02:50:36 INFO MemoryStore: Block broadcast_315 stored as values in memory (estimated size 102.6 KiB, free 362.7 MiB)
26/01/12 02:50:36 INFO MemoryStore: Block broadcast_315_piece0 stored as bytes in memory (estimated size 36.8 KiB, free 362.7 MiB)
26/01/12 02:50:36 INFO BlockManagerInfo: Added broadcast_315_piece0 in memory on 02926ee04bc9:45221 (size: 36.8 KiB, free: 365.7 MiB)
26/01/12 02:50:36 INFO SparkContext: Created broadcast 315 from broadcast at DAGScheduler.scala:1513
26/01/12 02:50:36 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 210 (MapPartitionsRDD[526] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0))
26/01/12 02:50:36 INFO TaskSchedulerImpl: Adding task set 210.0 with 1 tasks resource profile 0
26/01/12 02:50:36 INFO TaskSetManager: Starting task 0.0 in stage 210.0 (TID 362) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4607 bytes) taskResourceAssignments Map()
26/01/12 02:50:36 INFO BlockManagerInfo: Added broadcast_315_piece0 in memory on 172.18.0.5:42453 (size: 36.8 KiB, free: 365.7 MiB)
26/01/12 02:50:36 INFO TaskSetManager: Finished task 0.0 in stage 210.0 (TID 362) in 48 ms on 172.18.0.5 (executor 0) (1/1)
26/01/12 02:50:36 INFO TaskSchedulerImpl: Removed TaskSet 210.0, whose tasks have all completed, from pool 
26/01/12 02:50:36 INFO DAGScheduler: ResultStage 210 (parquet at <unknown>:0) finished in 0.059 s
26/01/12 02:50:36 INFO DAGScheduler: Job 210 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:50:36 INFO TaskSchedulerImpl: Killing all running tasks in stage 210: Stage finished
26/01/12 02:50:36 INFO DAGScheduler: Job 210 finished: parquet at <unknown>:0, took 0.062561 s
26/01/12 02:50:36 INFO FileSourceStrategy: Pushed Filters: 
26/01/12 02:50:36 INFO FileSourceStrategy: Post-Scan Filters: 
26/01/12 02:50:36 INFO FileSourceStrategy: Output Data Schema: struct<VendorID: bigint, tpep_pickup_datetime: timestamp, tpep_dropoff_datetime: timestamp, passenger_count: bigint, trip_distance: double ... 17 more fields>
26/01/12 02:50:36 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:50:36 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:50:36 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:50:36 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:50:36 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:50:36 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:50:36 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:50:36 INFO MemoryStore: Block broadcast_316 stored as values in memory (estimated size 358.4 KiB, free 362.3 MiB)
26/01/12 02:50:36 INFO MemoryStore: Block broadcast_316_piece0 stored as bytes in memory (estimated size 35.4 KiB, free 362.3 MiB)
26/01/12 02:50:36 INFO BlockManagerInfo: Added broadcast_316_piece0 in memory on 02926ee04bc9:45221 (size: 35.4 KiB, free: 365.6 MiB)
26/01/12 02:50:36 INFO SparkContext: Created broadcast 316 from parquet at <unknown>:0
26/01/12 02:50:36 INFO FileSourceScanExec: Planning scan with bin packing, max size: 70468407 bytes, open cost is considered as scanning 4194304 bytes.
26/01/12 02:50:36 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 02:50:36 INFO DAGScheduler: Got job 211 (parquet at <unknown>:0) with 2 output partitions
26/01/12 02:50:36 INFO DAGScheduler: Final stage: ResultStage 211 (parquet at <unknown>:0)
26/01/12 02:50:36 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:50:36 INFO DAGScheduler: Missing parents: List()
26/01/12 02:50:36 INFO DAGScheduler: Submitting ResultStage 211 (MapPartitionsRDD[529] at parquet at <unknown>:0), which has no missing parents
26/01/12 02:50:36 INFO BlockManagerInfo: Removed broadcast_307_piece0 on 02926ee04bc9:45221 in memory (size: 35.4 KiB, free: 365.7 MiB)
26/01/12 02:50:36 INFO BlockManagerInfo: Removed broadcast_307_piece0 on 172.18.0.5:42453 in memory (size: 35.4 KiB, free: 365.7 MiB)
26/01/12 02:50:36 INFO BlockManagerInfo: Removed broadcast_310_piece0 on 02926ee04bc9:45221 in memory (size: 35.4 KiB, free: 365.7 MiB)
26/01/12 02:50:36 INFO BlockManagerInfo: Removed broadcast_310_piece0 on 172.18.0.5:42453 in memory (size: 35.4 KiB, free: 365.8 MiB)
26/01/12 02:50:36 INFO BlockManagerInfo: Removed broadcast_314_piece0 on 02926ee04bc9:45221 in memory (size: 77.4 KiB, free: 365.8 MiB)
26/01/12 02:50:36 INFO BlockManagerInfo: Removed broadcast_314_piece0 on 172.18.0.5:42453 in memory (size: 77.4 KiB, free: 365.8 MiB)
26/01/12 02:50:36 INFO MemoryStore: Block broadcast_317 stored as values in memory (estimated size 225.1 KiB, free 363.1 MiB)
26/01/12 02:50:36 INFO BlockManagerInfo: Removed broadcast_312_piece0 on 02926ee04bc9:45221 in memory (size: 36.8 KiB, free: 365.8 MiB)
26/01/12 02:50:36 INFO MemoryStore: Block broadcast_317_piece0 stored as bytes in memory (estimated size 77.4 KiB, free 363.2 MiB)
26/01/12 02:50:36 INFO BlockManagerInfo: Added broadcast_317_piece0 in memory on 02926ee04bc9:45221 (size: 77.4 KiB, free: 365.8 MiB)
26/01/12 02:50:36 INFO BlockManagerInfo: Removed broadcast_312_piece0 on 172.18.0.5:42453 in memory (size: 36.8 KiB, free: 365.9 MiB)
26/01/12 02:50:36 INFO SparkContext: Created broadcast 317 from broadcast at DAGScheduler.scala:1513
26/01/12 02:50:36 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 211 (MapPartitionsRDD[529] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1))
26/01/12 02:50:36 INFO TaskSchedulerImpl: Adding task set 211.0 with 2 tasks resource profile 0
26/01/12 02:50:36 INFO TaskSetManager: Starting task 0.0 in stage 211.0 (TID 363) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:50:36 INFO TaskSetManager: Starting task 1.0 in stage 211.0 (TID 364) (172.18.0.5, executor 0, partition 1, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:50:36 INFO BlockManagerInfo: Removed broadcast_313_piece0 on 02926ee04bc9:45221 in memory (size: 35.4 KiB, free: 365.8 MiB)
26/01/12 02:50:36 INFO BlockManagerInfo: Removed broadcast_313_piece0 on 172.18.0.5:42453 in memory (size: 35.4 KiB, free: 365.9 MiB)
26/01/12 02:50:36 INFO BlockManagerInfo: Removed broadcast_304_piece0 on 02926ee04bc9:45221 in memory (size: 35.4 KiB, free: 365.8 MiB)
26/01/12 02:50:36 INFO BlockManagerInfo: Added broadcast_317_piece0 in memory on 172.18.0.5:42453 (size: 77.4 KiB, free: 365.8 MiB)
26/01/12 02:50:36 INFO BlockManagerInfo: Removed broadcast_304_piece0 on 172.18.0.5:42453 in memory (size: 35.4 KiB, free: 365.9 MiB)
26/01/12 02:50:36 INFO BlockManagerInfo: Removed broadcast_315_piece0 on 02926ee04bc9:45221 in memory (size: 36.8 KiB, free: 365.9 MiB)
26/01/12 02:50:36 INFO BlockManagerInfo: Removed broadcast_315_piece0 on 172.18.0.5:42453 in memory (size: 36.8 KiB, free: 365.9 MiB)
26/01/12 02:50:36 INFO BlockManagerInfo: Removed broadcast_308_piece0 on 02926ee04bc9:45221 in memory (size: 77.4 KiB, free: 365.9 MiB)
26/01/12 02:50:36 INFO BlockManagerInfo: Removed broadcast_308_piece0 on 172.18.0.5:42453 in memory (size: 77.4 KiB, free: 366.0 MiB)
26/01/12 02:50:36 INFO BlockManagerInfo: Added broadcast_316_piece0 in memory on 172.18.0.5:42453 (size: 35.4 KiB, free: 365.9 MiB)
26/01/12 02:50:36 INFO BlockManagerInfo: Removed broadcast_309_piece0 on 02926ee04bc9:45221 in memory (size: 36.8 KiB, free: 366.0 MiB)
26/01/12 02:50:36 INFO BlockManagerInfo: Removed broadcast_309_piece0 on 172.18.0.5:42453 in memory (size: 36.8 KiB, free: 366.0 MiB)
26/01/12 02:50:36 INFO BlockManagerInfo: Removed broadcast_306_piece0 on 02926ee04bc9:45221 in memory (size: 36.8 KiB, free: 366.0 MiB)
26/01/12 02:50:36 INFO BlockManagerInfo: Removed broadcast_306_piece0 on 172.18.0.5:42453 in memory (size: 36.8 KiB, free: 366.0 MiB)
26/01/12 02:50:36 INFO BlockManagerInfo: Removed broadcast_311_piece0 on 02926ee04bc9:45221 in memory (size: 77.4 KiB, free: 366.1 MiB)
26/01/12 02:50:36 INFO BlockManagerInfo: Removed broadcast_311_piece0 on 172.18.0.5:42453 in memory (size: 77.4 KiB, free: 366.1 MiB)
26/01/12 02:50:36 INFO TaskSetManager: Finished task 1.0 in stage 211.0 (TID 364) in 62 ms on 172.18.0.5 (executor 0) (1/2)
26/01/12 02:50:58 INFO TaskSetManager: Finished task 0.0 in stage 211.0 (TID 363) in 21560 ms on 172.18.0.5 (executor 0) (2/2)
26/01/12 02:50:58 INFO TaskSchedulerImpl: Removed TaskSet 211.0, whose tasks have all completed, from pool 
26/01/12 02:50:58 INFO DAGScheduler: ResultStage 211 (parquet at <unknown>:0) finished in 21.587 s
26/01/12 02:50:58 INFO DAGScheduler: Job 211 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:50:58 INFO TaskSchedulerImpl: Killing all running tasks in stage 211: Stage finished
26/01/12 02:50:58 INFO DAGScheduler: Job 211 finished: parquet at <unknown>:0, took 21.593323 s
26/01/12 02:50:58 INFO FileFormatWriter: Start to commit write Job a99e4cc0-2e2d-4865-842c-e92dbdb19c12.
26/01/12 02:50:58 INFO FileFormatWriter: Write Job a99e4cc0-2e2d-4865-842c-e92dbdb19c12 committed. Elapsed time: 28 ms.
26/01/12 02:50:58 INFO FileFormatWriter: Finished processing stats for write job a99e4cc0-2e2d-4865-842c-e92dbdb19c12.
Cargando: yellow_tripdata_2017-11.parquet en hdfs://hadoop-namenode:8020/data/nyc/raw/taxi-trips/2017...
26/01/12 02:50:58 INFO InMemoryFileIndex: It took 6 ms to list leaf files for 1 paths.
26/01/12 02:50:58 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 02:50:58 INFO DAGScheduler: Got job 212 (parquet at <unknown>:0) with 1 output partitions
26/01/12 02:50:58 INFO DAGScheduler: Final stage: ResultStage 212 (parquet at <unknown>:0)
26/01/12 02:50:58 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:50:58 INFO DAGScheduler: Missing parents: List()
26/01/12 02:50:58 INFO DAGScheduler: Submitting ResultStage 212 (MapPartitionsRDD[531] at parquet at <unknown>:0), which has no missing parents
26/01/12 02:50:58 INFO MemoryStore: Block broadcast_318 stored as values in memory (estimated size 102.6 KiB, free 364.8 MiB)
26/01/12 02:50:58 INFO MemoryStore: Block broadcast_318_piece0 stored as bytes in memory (estimated size 36.8 KiB, free 364.8 MiB)
26/01/12 02:50:58 INFO BlockManagerInfo: Added broadcast_318_piece0 in memory on 02926ee04bc9:45221 (size: 36.8 KiB, free: 366.0 MiB)
26/01/12 02:50:58 INFO SparkContext: Created broadcast 318 from broadcast at DAGScheduler.scala:1513
26/01/12 02:50:58 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 212 (MapPartitionsRDD[531] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0))
26/01/12 02:50:58 INFO TaskSchedulerImpl: Adding task set 212.0 with 1 tasks resource profile 0
26/01/12 02:50:58 INFO TaskSetManager: Starting task 0.0 in stage 212.0 (TID 365) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4607 bytes) taskResourceAssignments Map()
26/01/12 02:50:58 INFO BlockManagerInfo: Added broadcast_318_piece0 in memory on 172.18.0.5:42453 (size: 36.8 KiB, free: 366.0 MiB)
26/01/12 02:50:58 INFO TaskSetManager: Finished task 0.0 in stage 212.0 (TID 365) in 47 ms on 172.18.0.5 (executor 0) (1/1)
26/01/12 02:50:58 INFO TaskSchedulerImpl: Removed TaskSet 212.0, whose tasks have all completed, from pool 
26/01/12 02:50:58 INFO DAGScheduler: ResultStage 212 (parquet at <unknown>:0) finished in 0.060 s
26/01/12 02:50:58 INFO DAGScheduler: Job 212 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:50:58 INFO TaskSchedulerImpl: Killing all running tasks in stage 212: Stage finished
26/01/12 02:50:58 INFO DAGScheduler: Job 212 finished: parquet at <unknown>:0, took 0.064356 s
26/01/12 02:50:58 INFO FileSourceStrategy: Pushed Filters: 
26/01/12 02:50:58 INFO FileSourceStrategy: Post-Scan Filters: 
26/01/12 02:50:58 INFO FileSourceStrategy: Output Data Schema: struct<VendorID: bigint, tpep_pickup_datetime: timestamp, tpep_dropoff_datetime: timestamp, passenger_count: bigint, trip_distance: double ... 17 more fields>
26/01/12 02:50:58 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:50:58 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:50:58 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:50:58 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:50:58 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:50:58 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:50:58 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:50:58 INFO MemoryStore: Block broadcast_319 stored as values in memory (estimated size 358.4 KiB, free 364.5 MiB)
26/01/12 02:50:58 INFO MemoryStore: Block broadcast_319_piece0 stored as bytes in memory (estimated size 35.4 KiB, free 364.4 MiB)
26/01/12 02:50:58 INFO BlockManagerInfo: Added broadcast_319_piece0 in memory on 02926ee04bc9:45221 (size: 35.4 KiB, free: 366.0 MiB)
26/01/12 02:50:58 INFO SparkContext: Created broadcast 319 from parquet at <unknown>:0
26/01/12 02:50:58 INFO FileSourceScanExec: Planning scan with bin packing, max size: 67628505 bytes, open cost is considered as scanning 4194304 bytes.
26/01/12 02:50:58 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 02:50:58 INFO DAGScheduler: Got job 213 (parquet at <unknown>:0) with 2 output partitions
26/01/12 02:50:58 INFO DAGScheduler: Final stage: ResultStage 213 (parquet at <unknown>:0)
26/01/12 02:50:58 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:50:58 INFO DAGScheduler: Missing parents: List()
26/01/12 02:50:58 INFO DAGScheduler: Submitting ResultStage 213 (MapPartitionsRDD[534] at parquet at <unknown>:0), which has no missing parents
26/01/12 02:50:58 INFO MemoryStore: Block broadcast_320 stored as values in memory (estimated size 225.1 KiB, free 364.2 MiB)
26/01/12 02:50:58 INFO MemoryStore: Block broadcast_320_piece0 stored as bytes in memory (estimated size 77.4 KiB, free 364.1 MiB)
26/01/12 02:50:58 INFO BlockManagerInfo: Added broadcast_320_piece0 in memory on 02926ee04bc9:45221 (size: 77.4 KiB, free: 365.9 MiB)
26/01/12 02:50:58 INFO SparkContext: Created broadcast 320 from broadcast at DAGScheduler.scala:1513
26/01/12 02:50:58 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 213 (MapPartitionsRDD[534] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1))
26/01/12 02:50:58 INFO TaskSchedulerImpl: Adding task set 213.0 with 2 tasks resource profile 0
26/01/12 02:50:58 INFO TaskSetManager: Starting task 0.0 in stage 213.0 (TID 366) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:50:58 INFO TaskSetManager: Starting task 1.0 in stage 213.0 (TID 367) (172.18.0.5, executor 0, partition 1, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:50:58 INFO BlockManagerInfo: Added broadcast_320_piece0 in memory on 172.18.0.5:42453 (size: 77.4 KiB, free: 366.0 MiB)
26/01/12 02:50:58 INFO BlockManagerInfo: Added broadcast_319_piece0 in memory on 172.18.0.5:42453 (size: 35.4 KiB, free: 365.9 MiB)
26/01/12 02:50:58 INFO TaskSetManager: Finished task 1.0 in stage 213.0 (TID 367) in 62 ms on 172.18.0.5 (executor 0) (1/2)
26/01/12 02:51:20 INFO TaskSetManager: Finished task 0.0 in stage 213.0 (TID 366) in 21519 ms on 172.18.0.5 (executor 0) (2/2)
26/01/12 02:51:20 INFO TaskSchedulerImpl: Removed TaskSet 213.0, whose tasks have all completed, from pool 
26/01/12 02:51:20 INFO DAGScheduler: ResultStage 213 (parquet at <unknown>:0) finished in 21.540 s
26/01/12 02:51:20 INFO DAGScheduler: Job 213 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:51:20 INFO TaskSchedulerImpl: Killing all running tasks in stage 213: Stage finished
26/01/12 02:51:20 INFO DAGScheduler: Job 213 finished: parquet at <unknown>:0, took 21.547924 s
26/01/12 02:51:20 INFO FileFormatWriter: Start to commit write Job a1574c7d-aa5d-43c4-95b4-ce1c5cd8a23a.
26/01/12 02:51:20 INFO FileFormatWriter: Write Job a1574c7d-aa5d-43c4-95b4-ce1c5cd8a23a committed. Elapsed time: 38 ms.
26/01/12 02:51:20 INFO FileFormatWriter: Finished processing stats for write job a1574c7d-aa5d-43c4-95b4-ce1c5cd8a23a.
Cargando: yellow_tripdata_2017-12.parquet en hdfs://hadoop-namenode:8020/data/nyc/raw/taxi-trips/2017...
26/01/12 02:51:20 INFO InMemoryFileIndex: It took 6 ms to list leaf files for 1 paths.
26/01/12 02:51:20 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 02:51:20 INFO DAGScheduler: Got job 214 (parquet at <unknown>:0) with 1 output partitions
26/01/12 02:51:20 INFO DAGScheduler: Final stage: ResultStage 214 (parquet at <unknown>:0)
26/01/12 02:51:20 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:51:20 INFO DAGScheduler: Missing parents: List()
26/01/12 02:51:20 INFO DAGScheduler: Submitting ResultStage 214 (MapPartitionsRDD[536] at parquet at <unknown>:0), which has no missing parents
26/01/12 02:51:20 INFO MemoryStore: Block broadcast_321 stored as values in memory (estimated size 102.6 KiB, free 364.0 MiB)
26/01/12 02:51:20 INFO MemoryStore: Block broadcast_321_piece0 stored as bytes in memory (estimated size 36.8 KiB, free 364.0 MiB)
26/01/12 02:51:20 INFO BlockManagerInfo: Added broadcast_321_piece0 in memory on 02926ee04bc9:45221 (size: 36.8 KiB, free: 365.9 MiB)
26/01/12 02:51:20 INFO SparkContext: Created broadcast 321 from broadcast at DAGScheduler.scala:1513
26/01/12 02:51:20 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 214 (MapPartitionsRDD[536] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0))
26/01/12 02:51:20 INFO TaskSchedulerImpl: Adding task set 214.0 with 1 tasks resource profile 0
26/01/12 02:51:20 INFO TaskSetManager: Starting task 0.0 in stage 214.0 (TID 368) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4607 bytes) taskResourceAssignments Map()
26/01/12 02:51:20 INFO BlockManagerInfo: Added broadcast_321_piece0 in memory on 172.18.0.5:42453 (size: 36.8 KiB, free: 365.9 MiB)
26/01/12 02:51:20 INFO TaskSetManager: Finished task 0.0 in stage 214.0 (TID 368) in 46 ms on 172.18.0.5 (executor 0) (1/1)
26/01/12 02:51:20 INFO TaskSchedulerImpl: Removed TaskSet 214.0, whose tasks have all completed, from pool 
26/01/12 02:51:20 INFO DAGScheduler: ResultStage 214 (parquet at <unknown>:0) finished in 0.058 s
26/01/12 02:51:20 INFO DAGScheduler: Job 214 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:51:20 INFO TaskSchedulerImpl: Killing all running tasks in stage 214: Stage finished
26/01/12 02:51:20 INFO DAGScheduler: Job 214 finished: parquet at <unknown>:0, took 0.062368 s
26/01/12 02:51:20 INFO FileSourceStrategy: Pushed Filters: 
26/01/12 02:51:20 INFO FileSourceStrategy: Post-Scan Filters: 
26/01/12 02:51:20 INFO FileSourceStrategy: Output Data Schema: struct<VendorID: bigint, tpep_pickup_datetime: timestamp, tpep_dropoff_datetime: timestamp, passenger_count: bigint, trip_distance: double ... 17 more fields>
26/01/12 02:51:20 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:51:20 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:51:20 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:51:20 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:51:20 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:51:20 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:51:20 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:51:20 INFO MemoryStore: Block broadcast_322 stored as values in memory (estimated size 358.4 KiB, free 363.6 MiB)
26/01/12 02:51:20 INFO MemoryStore: Block broadcast_322_piece0 stored as bytes in memory (estimated size 35.4 KiB, free 363.6 MiB)
26/01/12 02:51:20 INFO BlockManagerInfo: Added broadcast_322_piece0 in memory on 02926ee04bc9:45221 (size: 35.4 KiB, free: 365.9 MiB)
26/01/12 02:51:20 INFO SparkContext: Created broadcast 322 from parquet at <unknown>:0
26/01/12 02:51:20 INFO FileSourceScanExec: Planning scan with bin packing, max size: 69224840 bytes, open cost is considered as scanning 4194304 bytes.
26/01/12 02:51:20 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 02:51:20 INFO DAGScheduler: Got job 215 (parquet at <unknown>:0) with 2 output partitions
26/01/12 02:51:20 INFO DAGScheduler: Final stage: ResultStage 215 (parquet at <unknown>:0)
26/01/12 02:51:20 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:51:20 INFO DAGScheduler: Missing parents: List()
26/01/12 02:51:20 INFO DAGScheduler: Submitting ResultStage 215 (MapPartitionsRDD[539] at parquet at <unknown>:0), which has no missing parents
26/01/12 02:51:20 INFO MemoryStore: Block broadcast_323 stored as values in memory (estimated size 225.1 KiB, free 363.4 MiB)
26/01/12 02:51:20 INFO MemoryStore: Block broadcast_323_piece0 stored as bytes in memory (estimated size 77.4 KiB, free 363.3 MiB)
26/01/12 02:51:20 INFO BlockManagerInfo: Added broadcast_323_piece0 in memory on 02926ee04bc9:45221 (size: 77.4 KiB, free: 365.8 MiB)
26/01/12 02:51:20 INFO SparkContext: Created broadcast 323 from broadcast at DAGScheduler.scala:1513
26/01/12 02:51:20 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 215 (MapPartitionsRDD[539] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1))
26/01/12 02:51:20 INFO TaskSchedulerImpl: Adding task set 215.0 with 2 tasks resource profile 0
26/01/12 02:51:20 INFO TaskSetManager: Starting task 0.0 in stage 215.0 (TID 369) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:51:20 INFO TaskSetManager: Starting task 1.0 in stage 215.0 (TID 370) (172.18.0.5, executor 0, partition 1, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:51:20 INFO BlockManagerInfo: Added broadcast_323_piece0 in memory on 172.18.0.5:42453 (size: 77.4 KiB, free: 365.8 MiB)
26/01/12 02:51:20 INFO BlockManagerInfo: Added broadcast_322_piece0 in memory on 172.18.0.5:42453 (size: 35.4 KiB, free: 365.8 MiB)
26/01/12 02:51:20 INFO TaskSetManager: Finished task 1.0 in stage 215.0 (TID 370) in 57 ms on 172.18.0.5 (executor 0) (1/2)
26/01/12 02:51:42 INFO TaskSetManager: Finished task 0.0 in stage 215.0 (TID 369) in 21799 ms on 172.18.0.5 (executor 0) (2/2)
26/01/12 02:51:42 INFO TaskSchedulerImpl: Removed TaskSet 215.0, whose tasks have all completed, from pool 
26/01/12 02:51:42 INFO DAGScheduler: ResultStage 215 (parquet at <unknown>:0) finished in 21.818 s
26/01/12 02:51:42 INFO DAGScheduler: Job 215 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:51:42 INFO TaskSchedulerImpl: Killing all running tasks in stage 215: Stage finished
26/01/12 02:51:42 INFO DAGScheduler: Job 215 finished: parquet at <unknown>:0, took 21.825880 s
26/01/12 02:51:42 INFO FileFormatWriter: Start to commit write Job 18c7139a-f7e7-48da-af79-af3fbe10b642.
26/01/12 02:51:42 INFO FileFormatWriter: Write Job 18c7139a-f7e7-48da-af79-af3fbe10b642 committed. Elapsed time: 31 ms.
26/01/12 02:51:42 INFO FileFormatWriter: Finished processing stats for write job 18c7139a-f7e7-48da-af79-af3fbe10b642.
Cargando: yellow_tripdata_2018-01.parquet en hdfs://hadoop-namenode:8020/data/nyc/raw/taxi-trips/2018...
26/01/12 02:51:42 INFO InMemoryFileIndex: It took 6 ms to list leaf files for 1 paths.
26/01/12 02:51:42 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 02:51:42 INFO DAGScheduler: Got job 216 (parquet at <unknown>:0) with 1 output partitions
26/01/12 02:51:42 INFO DAGScheduler: Final stage: ResultStage 216 (parquet at <unknown>:0)
26/01/12 02:51:42 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:51:42 INFO DAGScheduler: Missing parents: List()
26/01/12 02:51:42 INFO DAGScheduler: Submitting ResultStage 216 (MapPartitionsRDD[541] at parquet at <unknown>:0), which has no missing parents
26/01/12 02:51:42 INFO MemoryStore: Block broadcast_324 stored as values in memory (estimated size 102.6 KiB, free 363.2 MiB)
26/01/12 02:51:42 INFO MemoryStore: Block broadcast_324_piece0 stored as bytes in memory (estimated size 36.8 KiB, free 363.2 MiB)
26/01/12 02:51:42 INFO BlockManagerInfo: Added broadcast_324_piece0 in memory on 02926ee04bc9:45221 (size: 36.8 KiB, free: 365.8 MiB)
26/01/12 02:51:42 INFO SparkContext: Created broadcast 324 from broadcast at DAGScheduler.scala:1513
26/01/12 02:51:42 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 216 (MapPartitionsRDD[541] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0))
26/01/12 02:51:42 INFO TaskSchedulerImpl: Adding task set 216.0 with 1 tasks resource profile 0
26/01/12 02:51:42 INFO TaskSetManager: Starting task 0.0 in stage 216.0 (TID 371) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4607 bytes) taskResourceAssignments Map()
26/01/12 02:51:42 INFO BlockManagerInfo: Added broadcast_324_piece0 in memory on 172.18.0.5:42453 (size: 36.8 KiB, free: 365.8 MiB)
26/01/12 02:51:42 INFO TaskSetManager: Finished task 0.0 in stage 216.0 (TID 371) in 46 ms on 172.18.0.5 (executor 0) (1/1)
26/01/12 02:51:42 INFO TaskSchedulerImpl: Removed TaskSet 216.0, whose tasks have all completed, from pool 
26/01/12 02:51:42 INFO DAGScheduler: ResultStage 216 (parquet at <unknown>:0) finished in 0.057 s
26/01/12 02:51:42 INFO DAGScheduler: Job 216 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:51:42 INFO TaskSchedulerImpl: Killing all running tasks in stage 216: Stage finished
26/01/12 02:51:42 INFO DAGScheduler: Job 216 finished: parquet at <unknown>:0, took 0.060284 s
26/01/12 02:51:42 INFO FileSourceStrategy: Pushed Filters: 
26/01/12 02:51:42 INFO FileSourceStrategy: Post-Scan Filters: 
26/01/12 02:51:42 INFO FileSourceStrategy: Output Data Schema: struct<VendorID: bigint, tpep_pickup_datetime: timestamp, tpep_dropoff_datetime: timestamp, passenger_count: bigint, trip_distance: double ... 17 more fields>
26/01/12 02:51:42 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:51:42 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:51:42 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:51:42 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:51:42 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:51:42 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:51:42 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:51:42 INFO MemoryStore: Block broadcast_325 stored as values in memory (estimated size 358.4 KiB, free 362.8 MiB)
26/01/12 02:51:42 INFO MemoryStore: Block broadcast_325_piece0 stored as bytes in memory (estimated size 35.3 KiB, free 362.8 MiB)
26/01/12 02:51:42 INFO BlockManagerInfo: Added broadcast_325_piece0 in memory on 02926ee04bc9:45221 (size: 35.3 KiB, free: 365.7 MiB)
26/01/12 02:51:42 INFO SparkContext: Created broadcast 325 from parquet at <unknown>:0
26/01/12 02:51:42 INFO FileSourceScanExec: Planning scan with bin packing, max size: 63931410 bytes, open cost is considered as scanning 4194304 bytes.
26/01/12 02:51:42 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 02:51:42 INFO DAGScheduler: Got job 217 (parquet at <unknown>:0) with 2 output partitions
26/01/12 02:51:42 INFO DAGScheduler: Final stage: ResultStage 217 (parquet at <unknown>:0)
26/01/12 02:51:42 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:51:42 INFO DAGScheduler: Missing parents: List()
26/01/12 02:51:42 INFO DAGScheduler: Submitting ResultStage 217 (MapPartitionsRDD[544] at parquet at <unknown>:0), which has no missing parents
26/01/12 02:51:42 INFO MemoryStore: Block broadcast_326 stored as values in memory (estimated size 225.0 KiB, free 362.6 MiB)
26/01/12 02:51:42 INFO MemoryStore: Block broadcast_326_piece0 stored as bytes in memory (estimated size 77.3 KiB, free 362.5 MiB)
26/01/12 02:51:42 INFO BlockManagerInfo: Added broadcast_326_piece0 in memory on 02926ee04bc9:45221 (size: 77.3 KiB, free: 365.6 MiB)
26/01/12 02:51:42 INFO SparkContext: Created broadcast 326 from broadcast at DAGScheduler.scala:1513
26/01/12 02:51:42 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 217 (MapPartitionsRDD[544] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1))
26/01/12 02:51:42 INFO TaskSchedulerImpl: Adding task set 217.0 with 2 tasks resource profile 0
26/01/12 02:51:42 INFO TaskSetManager: Starting task 0.0 in stage 217.0 (TID 372) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:51:42 INFO TaskSetManager: Starting task 1.0 in stage 217.0 (TID 373) (172.18.0.5, executor 0, partition 1, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:51:42 INFO BlockManagerInfo: Added broadcast_326_piece0 in memory on 172.18.0.5:42453 (size: 77.3 KiB, free: 365.7 MiB)
26/01/12 02:51:42 INFO BlockManagerInfo: Added broadcast_325_piece0 in memory on 172.18.0.5:42453 (size: 35.3 KiB, free: 365.6 MiB)
26/01/12 02:51:42 INFO TaskSetManager: Finished task 1.0 in stage 217.0 (TID 373) in 53 ms on 172.18.0.5 (executor 0) (1/2)
26/01/12 02:52:02 INFO TaskSetManager: Finished task 0.0 in stage 217.0 (TID 372) in 20295 ms on 172.18.0.5 (executor 0) (2/2)
26/01/12 02:52:02 INFO TaskSchedulerImpl: Removed TaskSet 217.0, whose tasks have all completed, from pool 
26/01/12 02:52:02 INFO DAGScheduler: ResultStage 217 (parquet at <unknown>:0) finished in 20.313 s
26/01/12 02:52:02 INFO DAGScheduler: Job 217 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:52:02 INFO TaskSchedulerImpl: Killing all running tasks in stage 217: Stage finished
26/01/12 02:52:02 INFO DAGScheduler: Job 217 finished: parquet at <unknown>:0, took 20.318424 s
26/01/12 02:52:02 INFO FileFormatWriter: Start to commit write Job f1f735b4-b06e-4cf0-ae0a-cb48068f084b.
26/01/12 02:52:02 INFO FileFormatWriter: Write Job f1f735b4-b06e-4cf0-ae0a-cb48068f084b committed. Elapsed time: 32 ms.
26/01/12 02:52:02 INFO FileFormatWriter: Finished processing stats for write job f1f735b4-b06e-4cf0-ae0a-cb48068f084b.
Cargando: yellow_tripdata_2018-02.parquet en hdfs://hadoop-namenode:8020/data/nyc/raw/taxi-trips/2018...
26/01/12 02:52:02 INFO InMemoryFileIndex: It took 6 ms to list leaf files for 1 paths.
26/01/12 02:52:02 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 02:52:02 INFO DAGScheduler: Got job 218 (parquet at <unknown>:0) with 1 output partitions
26/01/12 02:52:02 INFO DAGScheduler: Final stage: ResultStage 218 (parquet at <unknown>:0)
26/01/12 02:52:02 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:52:02 INFO DAGScheduler: Missing parents: List()
26/01/12 02:52:02 INFO DAGScheduler: Submitting ResultStage 218 (MapPartitionsRDD[546] at parquet at <unknown>:0), which has no missing parents
26/01/12 02:52:02 INFO BlockManagerInfo: Removed broadcast_320_piece0 on 02926ee04bc9:45221 in memory (size: 77.4 KiB, free: 365.7 MiB)
26/01/12 02:52:02 INFO BlockManagerInfo: Removed broadcast_320_piece0 on 172.18.0.5:42453 in memory (size: 77.4 KiB, free: 365.7 MiB)
26/01/12 02:52:02 INFO MemoryStore: Block broadcast_327 stored as values in memory (estimated size 102.6 KiB, free 362.7 MiB)
26/01/12 02:52:02 INFO BlockManagerInfo: Removed broadcast_319_piece0 on 02926ee04bc9:45221 in memory (size: 35.4 KiB, free: 365.8 MiB)
26/01/12 02:52:02 INFO BlockManagerInfo: Removed broadcast_319_piece0 on 172.18.0.5:42453 in memory (size: 35.4 KiB, free: 365.8 MiB)
26/01/12 02:52:02 INFO MemoryStore: Block broadcast_327_piece0 stored as bytes in memory (estimated size 36.8 KiB, free 363.0 MiB)
26/01/12 02:52:02 INFO BlockManagerInfo: Added broadcast_327_piece0 in memory on 02926ee04bc9:45221 (size: 36.8 KiB, free: 365.7 MiB)
26/01/12 02:52:02 INFO SparkContext: Created broadcast 327 from broadcast at DAGScheduler.scala:1513
26/01/12 02:52:02 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 218 (MapPartitionsRDD[546] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0))
26/01/12 02:52:02 INFO TaskSchedulerImpl: Adding task set 218.0 with 1 tasks resource profile 0
26/01/12 02:52:02 INFO TaskSetManager: Starting task 0.0 in stage 218.0 (TID 374) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4607 bytes) taskResourceAssignments Map()
26/01/12 02:52:02 INFO BlockManagerInfo: Removed broadcast_326_piece0 on 02926ee04bc9:45221 in memory (size: 77.3 KiB, free: 365.8 MiB)
26/01/12 02:52:02 INFO BlockManagerInfo: Removed broadcast_326_piece0 on 172.18.0.5:42453 in memory (size: 77.3 KiB, free: 365.8 MiB)
26/01/12 02:52:02 INFO BlockManagerInfo: Removed broadcast_317_piece0 on 02926ee04bc9:45221 in memory (size: 77.4 KiB, free: 365.9 MiB)
26/01/12 02:52:02 INFO BlockManagerInfo: Removed broadcast_317_piece0 on 172.18.0.5:42453 in memory (size: 77.4 KiB, free: 365.9 MiB)
26/01/12 02:52:02 INFO BlockManagerInfo: Added broadcast_327_piece0 in memory on 172.18.0.5:42453 (size: 36.8 KiB, free: 365.9 MiB)
26/01/12 02:52:02 INFO BlockManagerInfo: Removed broadcast_324_piece0 on 02926ee04bc9:45221 in memory (size: 36.8 KiB, free: 365.9 MiB)
26/01/12 02:52:02 INFO BlockManagerInfo: Removed broadcast_324_piece0 on 172.18.0.5:42453 in memory (size: 36.8 KiB, free: 365.9 MiB)
26/01/12 02:52:02 INFO BlockManagerInfo: Removed broadcast_323_piece0 on 02926ee04bc9:45221 in memory (size: 77.4 KiB, free: 366.0 MiB)
26/01/12 02:52:02 INFO BlockManagerInfo: Removed broadcast_323_piece0 on 172.18.0.5:42453 in memory (size: 77.4 KiB, free: 366.0 MiB)
26/01/12 02:52:02 INFO BlockManagerInfo: Removed broadcast_321_piece0 on 02926ee04bc9:45221 in memory (size: 36.8 KiB, free: 366.0 MiB)
26/01/12 02:52:02 INFO BlockManagerInfo: Removed broadcast_321_piece0 on 172.18.0.5:42453 in memory (size: 36.8 KiB, free: 366.0 MiB)
26/01/12 02:52:02 INFO BlockManagerInfo: Removed broadcast_322_piece0 on 02926ee04bc9:45221 in memory (size: 35.4 KiB, free: 366.0 MiB)
26/01/12 02:52:02 INFO BlockManagerInfo: Removed broadcast_322_piece0 on 172.18.0.5:42453 in memory (size: 35.4 KiB, free: 366.0 MiB)
26/01/12 02:52:02 INFO BlockManagerInfo: Removed broadcast_318_piece0 on 02926ee04bc9:45221 in memory (size: 36.8 KiB, free: 366.1 MiB)
26/01/12 02:52:02 INFO BlockManagerInfo: Removed broadcast_318_piece0 on 172.18.0.5:42453 in memory (size: 36.8 KiB, free: 366.1 MiB)
26/01/12 02:52:02 INFO BlockManagerInfo: Removed broadcast_316_piece0 on 02926ee04bc9:45221 in memory (size: 35.4 KiB, free: 366.1 MiB)
26/01/12 02:52:02 INFO BlockManagerInfo: Removed broadcast_316_piece0 on 172.18.0.5:42453 in memory (size: 35.4 KiB, free: 366.1 MiB)
26/01/12 02:52:02 INFO TaskSetManager: Finished task 0.0 in stage 218.0 (TID 374) in 74 ms on 172.18.0.5 (executor 0) (1/1)
26/01/12 02:52:02 INFO TaskSchedulerImpl: Removed TaskSet 218.0, whose tasks have all completed, from pool 
26/01/12 02:52:02 INFO DAGScheduler: ResultStage 218 (parquet at <unknown>:0) finished in 0.092 s
26/01/12 02:52:02 INFO DAGScheduler: Job 218 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:52:02 INFO TaskSchedulerImpl: Killing all running tasks in stage 218: Stage finished
26/01/12 02:52:02 INFO DAGScheduler: Job 218 finished: parquet at <unknown>:0, took 0.097012 s
26/01/12 02:52:02 INFO FileSourceStrategy: Pushed Filters: 
26/01/12 02:52:02 INFO FileSourceStrategy: Post-Scan Filters: 
26/01/12 02:52:02 INFO FileSourceStrategy: Output Data Schema: struct<VendorID: bigint, tpep_pickup_datetime: timestamp, tpep_dropoff_datetime: timestamp, passenger_count: bigint, trip_distance: double ... 17 more fields>
26/01/12 02:52:02 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:52:02 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:52:02 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:52:02 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:52:02 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:52:02 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:52:02 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:52:02 INFO MemoryStore: Block broadcast_328 stored as values in memory (estimated size 358.4 KiB, free 364.7 MiB)
26/01/12 02:52:02 INFO MemoryStore: Block broadcast_328_piece0 stored as bytes in memory (estimated size 35.4 KiB, free 364.7 MiB)
26/01/12 02:52:02 INFO BlockManagerInfo: Added broadcast_328_piece0 in memory on 02926ee04bc9:45221 (size: 35.4 KiB, free: 366.1 MiB)
26/01/12 02:52:02 INFO SparkContext: Created broadcast 328 from parquet at <unknown>:0
26/01/12 02:52:02 INFO FileSourceScanExec: Planning scan with bin packing, max size: 61824794 bytes, open cost is considered as scanning 4194304 bytes.
26/01/12 02:52:02 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 02:52:02 INFO DAGScheduler: Got job 219 (parquet at <unknown>:0) with 2 output partitions
26/01/12 02:52:02 INFO DAGScheduler: Final stage: ResultStage 219 (parquet at <unknown>:0)
26/01/12 02:52:02 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:52:02 INFO DAGScheduler: Missing parents: List()
26/01/12 02:52:02 INFO DAGScheduler: Submitting ResultStage 219 (MapPartitionsRDD[549] at parquet at <unknown>:0), which has no missing parents
26/01/12 02:52:02 INFO MemoryStore: Block broadcast_329 stored as values in memory (estimated size 225.1 KiB, free 364.5 MiB)
26/01/12 02:52:02 INFO MemoryStore: Block broadcast_329_piece0 stored as bytes in memory (estimated size 77.4 KiB, free 364.4 MiB)
26/01/12 02:52:02 INFO BlockManagerInfo: Added broadcast_329_piece0 in memory on 02926ee04bc9:45221 (size: 77.4 KiB, free: 366.0 MiB)
26/01/12 02:52:02 INFO SparkContext: Created broadcast 329 from broadcast at DAGScheduler.scala:1513
26/01/12 02:52:02 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 219 (MapPartitionsRDD[549] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1))
26/01/12 02:52:02 INFO TaskSchedulerImpl: Adding task set 219.0 with 2 tasks resource profile 0
26/01/12 02:52:02 INFO TaskSetManager: Starting task 0.0 in stage 219.0 (TID 375) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:52:02 INFO TaskSetManager: Starting task 1.0 in stage 219.0 (TID 376) (172.18.0.5, executor 0, partition 1, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:52:02 INFO BlockManagerInfo: Added broadcast_329_piece0 in memory on 172.18.0.5:42453 (size: 77.4 KiB, free: 366.0 MiB)
26/01/12 02:52:03 INFO BlockManagerInfo: Added broadcast_328_piece0 in memory on 172.18.0.5:42453 (size: 35.4 KiB, free: 366.0 MiB)
26/01/12 02:52:03 INFO TaskSetManager: Finished task 1.0 in stage 219.0 (TID 376) in 48 ms on 172.18.0.5 (executor 0) (1/2)
26/01/12 02:52:23 INFO TaskSetManager: Finished task 0.0 in stage 219.0 (TID 375) in 20149 ms on 172.18.0.5 (executor 0) (2/2)
26/01/12 02:52:23 INFO TaskSchedulerImpl: Removed TaskSet 219.0, whose tasks have all completed, from pool 
26/01/12 02:52:23 INFO DAGScheduler: ResultStage 219 (parquet at <unknown>:0) finished in 20.168 s
26/01/12 02:52:23 INFO DAGScheduler: Job 219 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:52:23 INFO TaskSchedulerImpl: Killing all running tasks in stage 219: Stage finished
26/01/12 02:52:23 INFO DAGScheduler: Job 219 finished: parquet at <unknown>:0, took 20.171930 s
26/01/12 02:52:23 INFO FileFormatWriter: Start to commit write Job 6bf952bc-c013-4bda-8a29-72f4150a91b8.
26/01/12 02:52:23 INFO FileFormatWriter: Write Job 6bf952bc-c013-4bda-8a29-72f4150a91b8 committed. Elapsed time: 30 ms.
26/01/12 02:52:23 INFO FileFormatWriter: Finished processing stats for write job 6bf952bc-c013-4bda-8a29-72f4150a91b8.
Cargando: yellow_tripdata_2018-03.parquet en hdfs://hadoop-namenode:8020/data/nyc/raw/taxi-trips/2018...
26/01/12 02:52:23 INFO InMemoryFileIndex: It took 6 ms to list leaf files for 1 paths.
26/01/12 02:52:23 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 02:52:23 INFO DAGScheduler: Got job 220 (parquet at <unknown>:0) with 1 output partitions
26/01/12 02:52:23 INFO DAGScheduler: Final stage: ResultStage 220 (parquet at <unknown>:0)
26/01/12 02:52:23 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:52:23 INFO DAGScheduler: Missing parents: List()
26/01/12 02:52:23 INFO DAGScheduler: Submitting ResultStage 220 (MapPartitionsRDD[551] at parquet at <unknown>:0), which has no missing parents
26/01/12 02:52:23 INFO MemoryStore: Block broadcast_330 stored as values in memory (estimated size 102.6 KiB, free 364.3 MiB)
26/01/12 02:52:23 INFO MemoryStore: Block broadcast_330_piece0 stored as bytes in memory (estimated size 36.8 KiB, free 364.3 MiB)
26/01/12 02:52:23 INFO BlockManagerInfo: Added broadcast_330_piece0 in memory on 02926ee04bc9:45221 (size: 36.8 KiB, free: 366.0 MiB)
26/01/12 02:52:23 INFO SparkContext: Created broadcast 330 from broadcast at DAGScheduler.scala:1513
26/01/12 02:52:23 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 220 (MapPartitionsRDD[551] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0))
26/01/12 02:52:23 INFO TaskSchedulerImpl: Adding task set 220.0 with 1 tasks resource profile 0
26/01/12 02:52:23 INFO TaskSetManager: Starting task 0.0 in stage 220.0 (TID 377) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4607 bytes) taskResourceAssignments Map()
26/01/12 02:52:23 INFO BlockManagerInfo: Added broadcast_330_piece0 in memory on 172.18.0.5:42453 (size: 36.8 KiB, free: 366.0 MiB)
26/01/12 02:52:23 INFO TaskSetManager: Finished task 0.0 in stage 220.0 (TID 377) in 45 ms on 172.18.0.5 (executor 0) (1/1)
26/01/12 02:52:23 INFO TaskSchedulerImpl: Removed TaskSet 220.0, whose tasks have all completed, from pool 
26/01/12 02:52:23 INFO DAGScheduler: ResultStage 220 (parquet at <unknown>:0) finished in 0.057 s
26/01/12 02:52:23 INFO DAGScheduler: Job 220 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:52:23 INFO TaskSchedulerImpl: Killing all running tasks in stage 220: Stage finished
26/01/12 02:52:23 INFO DAGScheduler: Job 220 finished: parquet at <unknown>:0, took 0.061014 s
26/01/12 02:52:23 INFO FileSourceStrategy: Pushed Filters: 
26/01/12 02:52:23 INFO FileSourceStrategy: Post-Scan Filters: 
26/01/12 02:52:23 INFO FileSourceStrategy: Output Data Schema: struct<VendorID: bigint, tpep_pickup_datetime: timestamp, tpep_dropoff_datetime: timestamp, passenger_count: bigint, trip_distance: double ... 17 more fields>
26/01/12 02:52:23 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:52:23 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:52:23 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:52:23 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:52:23 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:52:23 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:52:23 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:52:23 INFO MemoryStore: Block broadcast_331 stored as values in memory (estimated size 358.4 KiB, free 363.9 MiB)
26/01/12 02:52:23 INFO MemoryStore: Block broadcast_331_piece0 stored as bytes in memory (estimated size 35.4 KiB, free 363.9 MiB)
26/01/12 02:52:23 INFO BlockManagerInfo: Added broadcast_331_piece0 in memory on 02926ee04bc9:45221 (size: 35.4 KiB, free: 365.9 MiB)
26/01/12 02:52:23 INFO SparkContext: Created broadcast 331 from parquet at <unknown>:0
26/01/12 02:52:23 INFO FileSourceScanExec: Planning scan with bin packing, max size: 68873155 bytes, open cost is considered as scanning 4194304 bytes.
26/01/12 02:52:23 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 02:52:23 INFO DAGScheduler: Got job 221 (parquet at <unknown>:0) with 2 output partitions
26/01/12 02:52:23 INFO DAGScheduler: Final stage: ResultStage 221 (parquet at <unknown>:0)
26/01/12 02:52:23 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:52:23 INFO DAGScheduler: Missing parents: List()
26/01/12 02:52:23 INFO DAGScheduler: Submitting ResultStage 221 (MapPartitionsRDD[554] at parquet at <unknown>:0), which has no missing parents
26/01/12 02:52:23 INFO MemoryStore: Block broadcast_332 stored as values in memory (estimated size 225.1 KiB, free 363.7 MiB)
26/01/12 02:52:23 INFO MemoryStore: Block broadcast_332_piece0 stored as bytes in memory (estimated size 77.4 KiB, free 363.6 MiB)
26/01/12 02:52:23 INFO BlockManagerInfo: Added broadcast_332_piece0 in memory on 02926ee04bc9:45221 (size: 77.4 KiB, free: 365.9 MiB)
26/01/12 02:52:23 INFO SparkContext: Created broadcast 332 from broadcast at DAGScheduler.scala:1513
26/01/12 02:52:23 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 221 (MapPartitionsRDD[554] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1))
26/01/12 02:52:23 INFO TaskSchedulerImpl: Adding task set 221.0 with 2 tasks resource profile 0
26/01/12 02:52:23 INFO TaskSetManager: Starting task 0.0 in stage 221.0 (TID 378) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:52:23 INFO TaskSetManager: Starting task 1.0 in stage 221.0 (TID 379) (172.18.0.5, executor 0, partition 1, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:52:23 INFO BlockManagerInfo: Added broadcast_332_piece0 in memory on 172.18.0.5:42453 (size: 77.4 KiB, free: 365.9 MiB)
26/01/12 02:52:23 INFO BlockManagerInfo: Added broadcast_331_piece0 in memory on 172.18.0.5:42453 (size: 35.4 KiB, free: 365.9 MiB)
26/01/12 02:52:23 INFO TaskSetManager: Finished task 1.0 in stage 221.0 (TID 379) in 49 ms on 172.18.0.5 (executor 0) (1/2)
26/01/12 02:52:45 INFO TaskSetManager: Finished task 0.0 in stage 221.0 (TID 378) in 22366 ms on 172.18.0.5 (executor 0) (2/2)
26/01/12 02:52:45 INFO TaskSchedulerImpl: Removed TaskSet 221.0, whose tasks have all completed, from pool 
26/01/12 02:52:45 INFO DAGScheduler: ResultStage 221 (parquet at <unknown>:0) finished in 22.386 s
26/01/12 02:52:45 INFO DAGScheduler: Job 221 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:52:45 INFO TaskSchedulerImpl: Killing all running tasks in stage 221: Stage finished
26/01/12 02:52:45 INFO DAGScheduler: Job 221 finished: parquet at <unknown>:0, took 22.392796 s
26/01/12 02:52:45 INFO FileFormatWriter: Start to commit write Job 571e04fc-c600-4b0c-97f1-d59e54ba16b4.
26/01/12 02:52:45 INFO FileFormatWriter: Write Job 571e04fc-c600-4b0c-97f1-d59e54ba16b4 committed. Elapsed time: 29 ms.
26/01/12 02:52:45 INFO FileFormatWriter: Finished processing stats for write job 571e04fc-c600-4b0c-97f1-d59e54ba16b4.
Cargando: yellow_tripdata_2018-04.parquet en hdfs://hadoop-namenode:8020/data/nyc/raw/taxi-trips/2018...
26/01/12 02:52:45 INFO InMemoryFileIndex: It took 6 ms to list leaf files for 1 paths.
26/01/12 02:52:45 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 02:52:45 INFO DAGScheduler: Got job 222 (parquet at <unknown>:0) with 1 output partitions
26/01/12 02:52:45 INFO DAGScheduler: Final stage: ResultStage 222 (parquet at <unknown>:0)
26/01/12 02:52:45 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:52:45 INFO DAGScheduler: Missing parents: List()
26/01/12 02:52:45 INFO DAGScheduler: Submitting ResultStage 222 (MapPartitionsRDD[556] at parquet at <unknown>:0), which has no missing parents
26/01/12 02:52:45 INFO MemoryStore: Block broadcast_333 stored as values in memory (estimated size 102.6 KiB, free 363.5 MiB)
26/01/12 02:52:45 INFO MemoryStore: Block broadcast_333_piece0 stored as bytes in memory (estimated size 36.8 KiB, free 363.5 MiB)
26/01/12 02:52:45 INFO BlockManagerInfo: Added broadcast_333_piece0 in memory on 02926ee04bc9:45221 (size: 36.8 KiB, free: 365.8 MiB)
26/01/12 02:52:45 INFO SparkContext: Created broadcast 333 from broadcast at DAGScheduler.scala:1513
26/01/12 02:52:45 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 222 (MapPartitionsRDD[556] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0))
26/01/12 02:52:45 INFO TaskSchedulerImpl: Adding task set 222.0 with 1 tasks resource profile 0
26/01/12 02:52:45 INFO TaskSetManager: Starting task 0.0 in stage 222.0 (TID 380) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4607 bytes) taskResourceAssignments Map()
26/01/12 02:52:45 INFO BlockManagerInfo: Added broadcast_333_piece0 in memory on 172.18.0.5:42453 (size: 36.8 KiB, free: 365.8 MiB)
26/01/12 02:52:45 INFO TaskSetManager: Finished task 0.0 in stage 222.0 (TID 380) in 46 ms on 172.18.0.5 (executor 0) (1/1)
26/01/12 02:52:45 INFO TaskSchedulerImpl: Removed TaskSet 222.0, whose tasks have all completed, from pool 
26/01/12 02:52:45 INFO DAGScheduler: ResultStage 222 (parquet at <unknown>:0) finished in 0.057 s
26/01/12 02:52:45 INFO DAGScheduler: Job 222 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:52:45 INFO TaskSchedulerImpl: Killing all running tasks in stage 222: Stage finished
26/01/12 02:52:45 INFO DAGScheduler: Job 222 finished: parquet at <unknown>:0, took 0.061175 s
26/01/12 02:52:45 INFO FileSourceStrategy: Pushed Filters: 
26/01/12 02:52:45 INFO FileSourceStrategy: Post-Scan Filters: 
26/01/12 02:52:45 INFO FileSourceStrategy: Output Data Schema: struct<VendorID: bigint, tpep_pickup_datetime: timestamp, tpep_dropoff_datetime: timestamp, passenger_count: bigint, trip_distance: double ... 17 more fields>
26/01/12 02:52:45 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:52:45 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:52:45 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:52:45 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:52:45 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:52:45 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:52:45 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:52:45 INFO MemoryStore: Block broadcast_334 stored as values in memory (estimated size 358.4 KiB, free 363.1 MiB)
26/01/12 02:52:45 INFO MemoryStore: Block broadcast_334_piece0 stored as bytes in memory (estimated size 35.4 KiB, free 363.1 MiB)
26/01/12 02:52:45 INFO BlockManagerInfo: Added broadcast_334_piece0 in memory on 02926ee04bc9:45221 (size: 35.4 KiB, free: 365.8 MiB)
26/01/12 02:52:45 INFO SparkContext: Created broadcast 334 from parquet at <unknown>:0
26/01/12 02:52:45 INFO FileSourceScanExec: Planning scan with bin packing, max size: 67902009 bytes, open cost is considered as scanning 4194304 bytes.
26/01/12 02:52:45 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 02:52:45 INFO DAGScheduler: Got job 223 (parquet at <unknown>:0) with 2 output partitions
26/01/12 02:52:45 INFO DAGScheduler: Final stage: ResultStage 223 (parquet at <unknown>:0)
26/01/12 02:52:45 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:52:45 INFO DAGScheduler: Missing parents: List()
26/01/12 02:52:45 INFO DAGScheduler: Submitting ResultStage 223 (MapPartitionsRDD[559] at parquet at <unknown>:0), which has no missing parents
26/01/12 02:52:45 INFO MemoryStore: Block broadcast_335 stored as values in memory (estimated size 225.1 KiB, free 362.9 MiB)
26/01/12 02:52:45 INFO MemoryStore: Block broadcast_335_piece0 stored as bytes in memory (estimated size 77.4 KiB, free 362.8 MiB)
26/01/12 02:52:45 INFO BlockManagerInfo: Added broadcast_335_piece0 in memory on 02926ee04bc9:45221 (size: 77.4 KiB, free: 365.7 MiB)
26/01/12 02:52:45 INFO SparkContext: Created broadcast 335 from broadcast at DAGScheduler.scala:1513
26/01/12 02:52:45 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 223 (MapPartitionsRDD[559] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1))
26/01/12 02:52:45 INFO TaskSchedulerImpl: Adding task set 223.0 with 2 tasks resource profile 0
26/01/12 02:52:45 INFO TaskSetManager: Starting task 0.0 in stage 223.0 (TID 381) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:52:45 INFO TaskSetManager: Starting task 1.0 in stage 223.0 (TID 382) (172.18.0.5, executor 0, partition 1, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:52:45 INFO BlockManagerInfo: Added broadcast_335_piece0 in memory on 172.18.0.5:42453 (size: 77.4 KiB, free: 365.8 MiB)
26/01/12 02:52:45 INFO BlockManagerInfo: Added broadcast_334_piece0 in memory on 172.18.0.5:42453 (size: 35.4 KiB, free: 365.7 MiB)
26/01/12 02:52:45 INFO TaskSetManager: Finished task 1.0 in stage 223.0 (TID 382) in 64 ms on 172.18.0.5 (executor 0) (1/2)
26/01/12 02:53:06 INFO TaskSetManager: Finished task 0.0 in stage 223.0 (TID 381) in 21017 ms on 172.18.0.5 (executor 0) (2/2)
26/01/12 02:53:06 INFO TaskSchedulerImpl: Removed TaskSet 223.0, whose tasks have all completed, from pool 
26/01/12 02:53:06 INFO DAGScheduler: ResultStage 223 (parquet at <unknown>:0) finished in 21.036 s
26/01/12 02:53:06 INFO DAGScheduler: Job 223 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:53:06 INFO TaskSchedulerImpl: Killing all running tasks in stage 223: Stage finished
26/01/12 02:53:06 INFO DAGScheduler: Job 223 finished: parquet at <unknown>:0, took 21.043197 s
26/01/12 02:53:06 INFO FileFormatWriter: Start to commit write Job f6eb1f88-751b-4295-9faf-dd74bbb73533.
26/01/12 02:53:06 INFO FileFormatWriter: Write Job f6eb1f88-751b-4295-9faf-dd74bbb73533 committed. Elapsed time: 32 ms.
26/01/12 02:53:06 INFO FileFormatWriter: Finished processing stats for write job f6eb1f88-751b-4295-9faf-dd74bbb73533.
Cargando: yellow_tripdata_2018-05.parquet en hdfs://hadoop-namenode:8020/data/nyc/raw/taxi-trips/2018...
26/01/12 02:53:06 INFO InMemoryFileIndex: It took 6 ms to list leaf files for 1 paths.
26/01/12 02:53:07 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 02:53:07 INFO DAGScheduler: Got job 224 (parquet at <unknown>:0) with 1 output partitions
26/01/12 02:53:07 INFO DAGScheduler: Final stage: ResultStage 224 (parquet at <unknown>:0)
26/01/12 02:53:07 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:53:07 INFO DAGScheduler: Missing parents: List()
26/01/12 02:53:07 INFO DAGScheduler: Submitting ResultStage 224 (MapPartitionsRDD[561] at parquet at <unknown>:0), which has no missing parents
26/01/12 02:53:07 INFO MemoryStore: Block broadcast_336 stored as values in memory (estimated size 102.6 KiB, free 362.7 MiB)
26/01/12 02:53:07 INFO MemoryStore: Block broadcast_336_piece0 stored as bytes in memory (estimated size 36.8 KiB, free 362.7 MiB)
26/01/12 02:53:07 INFO BlockManagerInfo: Added broadcast_336_piece0 in memory on 02926ee04bc9:45221 (size: 36.8 KiB, free: 365.7 MiB)
26/01/12 02:53:07 INFO SparkContext: Created broadcast 336 from broadcast at DAGScheduler.scala:1513
26/01/12 02:53:07 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 224 (MapPartitionsRDD[561] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0))
26/01/12 02:53:07 INFO TaskSchedulerImpl: Adding task set 224.0 with 1 tasks resource profile 0
26/01/12 02:53:07 INFO TaskSetManager: Starting task 0.0 in stage 224.0 (TID 383) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4607 bytes) taskResourceAssignments Map()
26/01/12 02:53:07 INFO BlockManagerInfo: Added broadcast_336_piece0 in memory on 172.18.0.5:42453 (size: 36.8 KiB, free: 365.7 MiB)
26/01/12 02:53:07 INFO TaskSetManager: Finished task 0.0 in stage 224.0 (TID 383) in 46 ms on 172.18.0.5 (executor 0) (1/1)
26/01/12 02:53:07 INFO TaskSchedulerImpl: Removed TaskSet 224.0, whose tasks have all completed, from pool 
26/01/12 02:53:07 INFO DAGScheduler: ResultStage 224 (parquet at <unknown>:0) finished in 0.061 s
26/01/12 02:53:07 INFO DAGScheduler: Job 224 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:53:07 INFO TaskSchedulerImpl: Killing all running tasks in stage 224: Stage finished
26/01/12 02:53:07 INFO DAGScheduler: Job 224 finished: parquet at <unknown>:0, took 0.065317 s
26/01/12 02:53:07 INFO FileSourceStrategy: Pushed Filters: 
26/01/12 02:53:07 INFO FileSourceStrategy: Post-Scan Filters: 
26/01/12 02:53:07 INFO FileSourceStrategy: Output Data Schema: struct<VendorID: bigint, tpep_pickup_datetime: timestamp, tpep_dropoff_datetime: timestamp, passenger_count: bigint, trip_distance: double ... 17 more fields>
26/01/12 02:53:07 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:53:07 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:53:07 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:53:07 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:53:07 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:53:07 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:53:07 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:53:07 INFO MemoryStore: Block broadcast_337 stored as values in memory (estimated size 358.4 KiB, free 362.3 MiB)
26/01/12 02:53:07 INFO MemoryStore: Block broadcast_337_piece0 stored as bytes in memory (estimated size 35.4 KiB, free 362.3 MiB)
26/01/12 02:53:07 INFO BlockManagerInfo: Added broadcast_337_piece0 in memory on 02926ee04bc9:45221 (size: 35.4 KiB, free: 365.6 MiB)
26/01/12 02:53:07 INFO SparkContext: Created broadcast 337 from parquet at <unknown>:0
26/01/12 02:53:07 INFO FileSourceScanExec: Planning scan with bin packing, max size: 67522293 bytes, open cost is considered as scanning 4194304 bytes.
26/01/12 02:53:07 INFO BlockManagerInfo: Removed broadcast_330_piece0 on 02926ee04bc9:45221 in memory (size: 36.8 KiB, free: 365.7 MiB)
26/01/12 02:53:07 INFO BlockManagerInfo: Removed broadcast_330_piece0 on 172.18.0.5:42453 in memory (size: 36.8 KiB, free: 365.7 MiB)
26/01/12 02:53:07 INFO BlockManagerInfo: Removed broadcast_336_piece0 on 02926ee04bc9:45221 in memory (size: 36.8 KiB, free: 365.7 MiB)
26/01/12 02:53:07 INFO BlockManagerInfo: Removed broadcast_336_piece0 on 172.18.0.5:42453 in memory (size: 36.8 KiB, free: 365.8 MiB)
26/01/12 02:53:07 INFO BlockManagerInfo: Removed broadcast_333_piece0 on 02926ee04bc9:45221 in memory (size: 36.8 KiB, free: 365.8 MiB)
26/01/12 02:53:07 INFO BlockManagerInfo: Removed broadcast_333_piece0 on 172.18.0.5:42453 in memory (size: 36.8 KiB, free: 365.8 MiB)
26/01/12 02:53:07 INFO BlockManagerInfo: Removed broadcast_328_piece0 on 02926ee04bc9:45221 in memory (size: 35.4 KiB, free: 365.8 MiB)
26/01/12 02:53:07 INFO BlockManagerInfo: Removed broadcast_328_piece0 on 172.18.0.5:42453 in memory (size: 35.4 KiB, free: 365.8 MiB)
26/01/12 02:53:07 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 02:53:07 INFO DAGScheduler: Got job 225 (parquet at <unknown>:0) with 2 output partitions
26/01/12 02:53:07 INFO DAGScheduler: Final stage: ResultStage 225 (parquet at <unknown>:0)
26/01/12 02:53:07 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:53:07 INFO DAGScheduler: Missing parents: List()
26/01/12 02:53:07 INFO DAGScheduler: Submitting ResultStage 225 (MapPartitionsRDD[564] at parquet at <unknown>:0), which has no missing parents
26/01/12 02:53:07 INFO BlockManagerInfo: Removed broadcast_325_piece0 on 02926ee04bc9:45221 in memory (size: 35.3 KiB, free: 365.8 MiB)
26/01/12 02:53:07 INFO BlockManagerInfo: Removed broadcast_325_piece0 on 172.18.0.5:42453 in memory (size: 35.3 KiB, free: 365.9 MiB)
26/01/12 02:53:07 INFO BlockManagerInfo: Removed broadcast_335_piece0 on 02926ee04bc9:45221 in memory (size: 77.4 KiB, free: 365.9 MiB)
26/01/12 02:53:07 INFO BlockManagerInfo: Removed broadcast_335_piece0 on 172.18.0.5:42453 in memory (size: 77.4 KiB, free: 365.9 MiB)
26/01/12 02:53:07 INFO BlockManagerInfo: Removed broadcast_327_piece0 on 02926ee04bc9:45221 in memory (size: 36.8 KiB, free: 365.9 MiB)
26/01/12 02:53:07 INFO BlockManagerInfo: Removed broadcast_327_piece0 on 172.18.0.5:42453 in memory (size: 36.8 KiB, free: 366.0 MiB)
26/01/12 02:53:07 INFO MemoryStore: Block broadcast_338 stored as values in memory (estimated size 225.1 KiB, free 363.7 MiB)
26/01/12 02:53:07 INFO MemoryStore: Block broadcast_338_piece0 stored as bytes in memory (estimated size 77.4 KiB, free 363.6 MiB)
26/01/12 02:53:07 INFO BlockManagerInfo: Added broadcast_338_piece0 in memory on 02926ee04bc9:45221 (size: 77.4 KiB, free: 365.9 MiB)
26/01/12 02:53:07 INFO SparkContext: Created broadcast 338 from broadcast at DAGScheduler.scala:1513
26/01/12 02:53:07 INFO BlockManagerInfo: Removed broadcast_329_piece0 on 02926ee04bc9:45221 in memory (size: 77.4 KiB, free: 365.9 MiB)
26/01/12 02:53:07 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 225 (MapPartitionsRDD[564] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1))
26/01/12 02:53:07 INFO TaskSchedulerImpl: Adding task set 225.0 with 2 tasks resource profile 0
26/01/12 02:53:07 INFO BlockManagerInfo: Removed broadcast_329_piece0 on 172.18.0.5:42453 in memory (size: 77.4 KiB, free: 366.0 MiB)
26/01/12 02:53:07 INFO TaskSetManager: Starting task 0.0 in stage 225.0 (TID 384) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:53:07 INFO TaskSetManager: Starting task 1.0 in stage 225.0 (TID 385) (172.18.0.5, executor 0, partition 1, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:53:07 INFO BlockManagerInfo: Removed broadcast_334_piece0 on 02926ee04bc9:45221 in memory (size: 35.4 KiB, free: 366.0 MiB)
26/01/12 02:53:07 INFO BlockManagerInfo: Removed broadcast_334_piece0 on 172.18.0.5:42453 in memory (size: 35.4 KiB, free: 366.1 MiB)
26/01/12 02:53:07 INFO BlockManagerInfo: Added broadcast_338_piece0 in memory on 172.18.0.5:42453 (size: 77.4 KiB, free: 366.0 MiB)
26/01/12 02:53:07 INFO BlockManagerInfo: Removed broadcast_332_piece0 on 02926ee04bc9:45221 in memory (size: 77.4 KiB, free: 366.0 MiB)
26/01/12 02:53:07 INFO BlockManagerInfo: Removed broadcast_332_piece0 on 172.18.0.5:42453 in memory (size: 77.4 KiB, free: 366.1 MiB)
26/01/12 02:53:07 INFO BlockManagerInfo: Removed broadcast_331_piece0 on 02926ee04bc9:45221 in memory (size: 35.4 KiB, free: 366.1 MiB)
26/01/12 02:53:07 INFO BlockManagerInfo: Removed broadcast_331_piece0 on 172.18.0.5:42453 in memory (size: 35.4 KiB, free: 366.1 MiB)
26/01/12 02:53:07 INFO BlockManagerInfo: Added broadcast_337_piece0 in memory on 172.18.0.5:42453 (size: 35.4 KiB, free: 366.1 MiB)
26/01/12 02:53:07 INFO TaskSetManager: Finished task 1.0 in stage 225.0 (TID 385) in 62 ms on 172.18.0.5 (executor 0) (1/2)
26/01/12 02:53:09 INFO BlockManagerInfo: Removed broadcast_140_piece0 on 02926ee04bc9:45221 in memory (size: 77.4 KiB, free: 366.2 MiB)
26/01/12 02:53:09 INFO BlockManagerInfo: Removed broadcast_140_piece0 on 172.18.0.5:42453 in memory (size: 77.4 KiB, free: 366.2 MiB)
26/01/12 02:53:09 INFO BlockManagerInfo: Removed broadcast_139_piece0 on 02926ee04bc9:45221 in memory (size: 35.4 KiB, free: 366.2 MiB)
26/01/12 02:53:09 INFO BlockManagerInfo: Removed broadcast_139_piece0 on 172.18.0.5:42453 in memory (size: 35.4 KiB, free: 366.2 MiB)
26/01/12 02:53:28 INFO TaskSetManager: Finished task 0.0 in stage 225.0 (TID 384) in 20905 ms on 172.18.0.5 (executor 0) (2/2)
26/01/12 02:53:28 INFO TaskSchedulerImpl: Removed TaskSet 225.0, whose tasks have all completed, from pool 
26/01/12 02:53:28 INFO DAGScheduler: ResultStage 225 (parquet at <unknown>:0) finished in 20.924 s
26/01/12 02:53:28 INFO DAGScheduler: Job 225 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:53:28 INFO TaskSchedulerImpl: Killing all running tasks in stage 225: Stage finished
26/01/12 02:53:28 INFO DAGScheduler: Job 225 finished: parquet at <unknown>:0, took 20.929557 s
26/01/12 02:53:28 INFO FileFormatWriter: Start to commit write Job 2860c894-1e80-4f18-a793-f88a4e4ddbda.
26/01/12 02:53:28 INFO FileFormatWriter: Write Job 2860c894-1e80-4f18-a793-f88a4e4ddbda committed. Elapsed time: 37 ms.
26/01/12 02:53:28 INFO FileFormatWriter: Finished processing stats for write job 2860c894-1e80-4f18-a793-f88a4e4ddbda.
Cargando: yellow_tripdata_2018-06.parquet en hdfs://hadoop-namenode:8020/data/nyc/raw/taxi-trips/2018...
26/01/12 02:53:28 INFO InMemoryFileIndex: It took 10 ms to list leaf files for 1 paths.
26/01/12 02:53:28 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 02:53:28 INFO DAGScheduler: Got job 226 (parquet at <unknown>:0) with 1 output partitions
26/01/12 02:53:28 INFO DAGScheduler: Final stage: ResultStage 226 (parquet at <unknown>:0)
26/01/12 02:53:28 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:53:28 INFO DAGScheduler: Missing parents: List()
26/01/12 02:53:28 INFO DAGScheduler: Submitting ResultStage 226 (MapPartitionsRDD[566] at parquet at <unknown>:0), which has no missing parents
26/01/12 02:53:28 INFO MemoryStore: Block broadcast_339 stored as values in memory (estimated size 102.6 KiB, free 365.5 MiB)
26/01/12 02:53:28 INFO MemoryStore: Block broadcast_339_piece0 stored as bytes in memory (estimated size 36.8 KiB, free 365.5 MiB)
26/01/12 02:53:28 INFO BlockManagerInfo: Added broadcast_339_piece0 in memory on 02926ee04bc9:45221 (size: 36.8 KiB, free: 366.2 MiB)
26/01/12 02:53:28 INFO SparkContext: Created broadcast 339 from broadcast at DAGScheduler.scala:1513
26/01/12 02:53:28 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 226 (MapPartitionsRDD[566] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0))
26/01/12 02:53:28 INFO TaskSchedulerImpl: Adding task set 226.0 with 1 tasks resource profile 0
26/01/12 02:53:28 INFO TaskSetManager: Starting task 0.0 in stage 226.0 (TID 386) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4607 bytes) taskResourceAssignments Map()
26/01/12 02:53:28 INFO BlockManagerInfo: Added broadcast_339_piece0 in memory on 172.18.0.5:42453 (size: 36.8 KiB, free: 366.2 MiB)
26/01/12 02:53:28 INFO TaskSetManager: Finished task 0.0 in stage 226.0 (TID 386) in 60 ms on 172.18.0.5 (executor 0) (1/1)
26/01/12 02:53:28 INFO TaskSchedulerImpl: Removed TaskSet 226.0, whose tasks have all completed, from pool 
26/01/12 02:53:28 INFO DAGScheduler: ResultStage 226 (parquet at <unknown>:0) finished in 0.074 s
26/01/12 02:53:28 INFO DAGScheduler: Job 226 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:53:28 INFO TaskSchedulerImpl: Killing all running tasks in stage 226: Stage finished
26/01/12 02:53:28 INFO DAGScheduler: Job 226 finished: parquet at <unknown>:0, took 0.079434 s
26/01/12 02:53:28 INFO FileSourceStrategy: Pushed Filters: 
26/01/12 02:53:28 INFO FileSourceStrategy: Post-Scan Filters: 
26/01/12 02:53:28 INFO FileSourceStrategy: Output Data Schema: struct<VendorID: bigint, tpep_pickup_datetime: timestamp, tpep_dropoff_datetime: timestamp, passenger_count: bigint, trip_distance: double ... 17 more fields>
26/01/12 02:53:28 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:53:28 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:53:28 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:53:28 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:53:28 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:53:28 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:53:28 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:53:28 INFO MemoryStore: Block broadcast_340 stored as values in memory (estimated size 358.4 KiB, free 365.1 MiB)
26/01/12 02:53:28 INFO MemoryStore: Block broadcast_340_piece0 stored as bytes in memory (estimated size 35.4 KiB, free 365.1 MiB)
26/01/12 02:53:28 INFO BlockManagerInfo: Added broadcast_340_piece0 in memory on 02926ee04bc9:45221 (size: 35.4 KiB, free: 366.1 MiB)
26/01/12 02:53:28 INFO SparkContext: Created broadcast 340 from parquet at <unknown>:0
26/01/12 02:53:28 INFO FileSourceScanExec: Planning scan with bin packing, max size: 64191833 bytes, open cost is considered as scanning 4194304 bytes.
26/01/12 02:53:28 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 02:53:28 INFO DAGScheduler: Got job 227 (parquet at <unknown>:0) with 2 output partitions
26/01/12 02:53:28 INFO DAGScheduler: Final stage: ResultStage 227 (parquet at <unknown>:0)
26/01/12 02:53:28 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:53:28 INFO DAGScheduler: Missing parents: List()
26/01/12 02:53:28 INFO DAGScheduler: Submitting ResultStage 227 (MapPartitionsRDD[569] at parquet at <unknown>:0), which has no missing parents
26/01/12 02:53:28 INFO MemoryStore: Block broadcast_341 stored as values in memory (estimated size 225.1 KiB, free 364.9 MiB)
26/01/12 02:53:28 INFO MemoryStore: Block broadcast_341_piece0 stored as bytes in memory (estimated size 77.4 KiB, free 364.8 MiB)
26/01/12 02:53:28 INFO BlockManagerInfo: Added broadcast_341_piece0 in memory on 02926ee04bc9:45221 (size: 77.4 KiB, free: 366.0 MiB)
26/01/12 02:53:28 INFO SparkContext: Created broadcast 341 from broadcast at DAGScheduler.scala:1513
26/01/12 02:53:28 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 227 (MapPartitionsRDD[569] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1))
26/01/12 02:53:28 INFO TaskSchedulerImpl: Adding task set 227.0 with 2 tasks resource profile 0
26/01/12 02:53:28 INFO TaskSetManager: Starting task 0.0 in stage 227.0 (TID 387) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:53:28 INFO TaskSetManager: Starting task 1.0 in stage 227.0 (TID 388) (172.18.0.5, executor 0, partition 1, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:53:28 INFO BlockManagerInfo: Added broadcast_341_piece0 in memory on 172.18.0.5:42453 (size: 77.4 KiB, free: 366.1 MiB)
26/01/12 02:53:28 INFO BlockManagerInfo: Added broadcast_340_piece0 in memory on 172.18.0.5:42453 (size: 35.4 KiB, free: 366.0 MiB)
26/01/12 02:53:28 INFO TaskSetManager: Finished task 1.0 in stage 227.0 (TID 388) in 61 ms on 172.18.0.5 (executor 0) (1/2)
26/01/12 02:53:47 INFO TaskSetManager: Finished task 0.0 in stage 227.0 (TID 387) in 19519 ms on 172.18.0.5 (executor 0) (2/2)
26/01/12 02:53:47 INFO TaskSchedulerImpl: Removed TaskSet 227.0, whose tasks have all completed, from pool 
26/01/12 02:53:47 INFO DAGScheduler: ResultStage 227 (parquet at <unknown>:0) finished in 19.537 s
26/01/12 02:53:47 INFO DAGScheduler: Job 227 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:53:47 INFO TaskSchedulerImpl: Killing all running tasks in stage 227: Stage finished
26/01/12 02:53:47 INFO DAGScheduler: Job 227 finished: parquet at <unknown>:0, took 19.543713 s
26/01/12 02:53:47 INFO FileFormatWriter: Start to commit write Job 9c2e708d-8e0c-4490-8ea2-39c0312b8183.
26/01/12 02:53:47 INFO FileFormatWriter: Write Job 9c2e708d-8e0c-4490-8ea2-39c0312b8183 committed. Elapsed time: 33 ms.
26/01/12 02:53:47 INFO FileFormatWriter: Finished processing stats for write job 9c2e708d-8e0c-4490-8ea2-39c0312b8183.
Cargando: yellow_tripdata_2018-07.parquet en hdfs://hadoop-namenode:8020/data/nyc/raw/taxi-trips/2018...
26/01/12 02:53:47 INFO InMemoryFileIndex: It took 74 ms to list leaf files for 1 paths.
26/01/12 02:53:48 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 02:53:48 INFO DAGScheduler: Got job 228 (parquet at <unknown>:0) with 1 output partitions
26/01/12 02:53:48 INFO DAGScheduler: Final stage: ResultStage 228 (parquet at <unknown>:0)
26/01/12 02:53:48 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:53:48 INFO DAGScheduler: Missing parents: List()
26/01/12 02:53:48 INFO DAGScheduler: Submitting ResultStage 228 (MapPartitionsRDD[571] at parquet at <unknown>:0), which has no missing parents
26/01/12 02:53:48 INFO MemoryStore: Block broadcast_342 stored as values in memory (estimated size 102.6 KiB, free 364.7 MiB)
26/01/12 02:53:48 INFO MemoryStore: Block broadcast_342_piece0 stored as bytes in memory (estimated size 36.8 KiB, free 364.7 MiB)
26/01/12 02:53:48 INFO BlockManagerInfo: Added broadcast_342_piece0 in memory on 02926ee04bc9:45221 (size: 36.8 KiB, free: 366.0 MiB)
26/01/12 02:53:48 INFO SparkContext: Created broadcast 342 from broadcast at DAGScheduler.scala:1513
26/01/12 02:53:48 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 228 (MapPartitionsRDD[571] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0))
26/01/12 02:53:48 INFO TaskSchedulerImpl: Adding task set 228.0 with 1 tasks resource profile 0
26/01/12 02:53:48 INFO TaskSetManager: Starting task 0.0 in stage 228.0 (TID 389) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4607 bytes) taskResourceAssignments Map()
26/01/12 02:53:48 INFO BlockManagerInfo: Added broadcast_342_piece0 in memory on 172.18.0.5:42453 (size: 36.8 KiB, free: 366.0 MiB)
26/01/12 02:53:48 INFO TaskSetManager: Finished task 0.0 in stage 228.0 (TID 389) in 60 ms on 172.18.0.5 (executor 0) (1/1)
26/01/12 02:53:48 INFO TaskSchedulerImpl: Removed TaskSet 228.0, whose tasks have all completed, from pool 
26/01/12 02:53:48 INFO DAGScheduler: ResultStage 228 (parquet at <unknown>:0) finished in 0.073 s
26/01/12 02:53:48 INFO DAGScheduler: Job 228 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:53:48 INFO TaskSchedulerImpl: Killing all running tasks in stage 228: Stage finished
26/01/12 02:53:48 INFO DAGScheduler: Job 228 finished: parquet at <unknown>:0, took 0.078367 s
26/01/12 02:53:48 INFO FileSourceStrategy: Pushed Filters: 
26/01/12 02:53:48 INFO FileSourceStrategy: Post-Scan Filters: 
26/01/12 02:53:48 INFO FileSourceStrategy: Output Data Schema: struct<VendorID: bigint, tpep_pickup_datetime: timestamp, tpep_dropoff_datetime: timestamp, passenger_count: double, trip_distance: double ... 17 more fields>
26/01/12 02:53:48 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:53:48 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:53:48 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:53:48 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:53:48 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:53:48 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:53:48 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:53:48 INFO CodeGenerator: Code generated in 18.722552 ms
26/01/12 02:53:48 INFO MemoryStore: Block broadcast_343 stored as values in memory (estimated size 358.5 KiB, free 364.3 MiB)
26/01/12 02:53:48 INFO MemoryStore: Block broadcast_343_piece0 stored as bytes in memory (estimated size 35.3 KiB, free 364.3 MiB)
26/01/12 02:53:48 INFO BlockManagerInfo: Added broadcast_343_piece0 in memory on 02926ee04bc9:45221 (size: 35.3 KiB, free: 366.0 MiB)
26/01/12 02:53:48 INFO SparkContext: Created broadcast 343 from parquet at <unknown>:0
26/01/12 02:53:48 INFO FileSourceScanExec: Planning scan with bin packing, max size: 58219374 bytes, open cost is considered as scanning 4194304 bytes.
26/01/12 02:53:48 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 02:53:48 INFO DAGScheduler: Got job 229 (parquet at <unknown>:0) with 2 output partitions
26/01/12 02:53:48 INFO DAGScheduler: Final stage: ResultStage 229 (parquet at <unknown>:0)
26/01/12 02:53:48 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:53:48 INFO DAGScheduler: Missing parents: List()
26/01/12 02:53:48 INFO DAGScheduler: Submitting ResultStage 229 (MapPartitionsRDD[574] at parquet at <unknown>:0), which has no missing parents
26/01/12 02:53:48 INFO MemoryStore: Block broadcast_344 stored as values in memory (estimated size 225.1 KiB, free 364.1 MiB)
26/01/12 02:53:48 INFO MemoryStore: Block broadcast_344_piece0 stored as bytes in memory (estimated size 77.4 KiB, free 364.0 MiB)
26/01/12 02:53:48 INFO BlockManagerInfo: Added broadcast_344_piece0 in memory on 02926ee04bc9:45221 (size: 77.4 KiB, free: 365.9 MiB)
26/01/12 02:53:48 INFO SparkContext: Created broadcast 344 from broadcast at DAGScheduler.scala:1513
26/01/12 02:53:48 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 229 (MapPartitionsRDD[574] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1))
26/01/12 02:53:48 INFO TaskSchedulerImpl: Adding task set 229.0 with 2 tasks resource profile 0
26/01/12 02:53:48 INFO TaskSetManager: Starting task 0.0 in stage 229.0 (TID 390) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:53:48 INFO TaskSetManager: Starting task 1.0 in stage 229.0 (TID 391) (172.18.0.5, executor 0, partition 1, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:53:48 INFO BlockManagerInfo: Added broadcast_344_piece0 in memory on 172.18.0.5:42453 (size: 77.4 KiB, free: 365.9 MiB)
26/01/12 02:53:48 INFO BlockManagerInfo: Added broadcast_343_piece0 in memory on 172.18.0.5:42453 (size: 35.3 KiB, free: 365.9 MiB)
26/01/12 02:53:48 INFO TaskSetManager: Finished task 1.0 in stage 229.0 (TID 391) in 93 ms on 172.18.0.5 (executor 0) (1/2)
26/01/12 02:54:06 INFO TaskSetManager: Finished task 0.0 in stage 229.0 (TID 390) in 18542 ms on 172.18.0.5 (executor 0) (2/2)
26/01/12 02:54:06 INFO TaskSchedulerImpl: Removed TaskSet 229.0, whose tasks have all completed, from pool 
26/01/12 02:54:06 INFO DAGScheduler: ResultStage 229 (parquet at <unknown>:0) finished in 18.566 s
26/01/12 02:54:06 INFO DAGScheduler: Job 229 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:54:06 INFO TaskSchedulerImpl: Killing all running tasks in stage 229: Stage finished
26/01/12 02:54:06 INFO DAGScheduler: Job 229 finished: parquet at <unknown>:0, took 18.572573 s
26/01/12 02:54:06 INFO FileFormatWriter: Start to commit write Job 3b3c015b-f8dd-4e74-b341-ab01c9cc3c50.
26/01/12 02:54:06 INFO FileFormatWriter: Write Job 3b3c015b-f8dd-4e74-b341-ab01c9cc3c50 committed. Elapsed time: 34 ms.
26/01/12 02:54:06 INFO FileFormatWriter: Finished processing stats for write job 3b3c015b-f8dd-4e74-b341-ab01c9cc3c50.
Cargando: yellow_tripdata_2018-08.parquet en hdfs://hadoop-namenode:8020/data/nyc/raw/taxi-trips/2018...
26/01/12 02:54:06 INFO InMemoryFileIndex: It took 6 ms to list leaf files for 1 paths.
26/01/12 02:54:06 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 02:54:06 INFO DAGScheduler: Got job 230 (parquet at <unknown>:0) with 1 output partitions
26/01/12 02:54:06 INFO DAGScheduler: Final stage: ResultStage 230 (parquet at <unknown>:0)
26/01/12 02:54:06 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:54:06 INFO DAGScheduler: Missing parents: List()
26/01/12 02:54:06 INFO DAGScheduler: Submitting ResultStage 230 (MapPartitionsRDD[576] at parquet at <unknown>:0), which has no missing parents
26/01/12 02:54:06 INFO MemoryStore: Block broadcast_345 stored as values in memory (estimated size 102.6 KiB, free 363.9 MiB)
26/01/12 02:54:06 INFO MemoryStore: Block broadcast_345_piece0 stored as bytes in memory (estimated size 36.8 KiB, free 363.9 MiB)
26/01/12 02:54:06 INFO BlockManagerInfo: Added broadcast_345_piece0 in memory on 02926ee04bc9:45221 (size: 36.8 KiB, free: 365.9 MiB)
26/01/12 02:54:06 INFO SparkContext: Created broadcast 345 from broadcast at DAGScheduler.scala:1513
26/01/12 02:54:06 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 230 (MapPartitionsRDD[576] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0))
26/01/12 02:54:06 INFO TaskSchedulerImpl: Adding task set 230.0 with 1 tasks resource profile 0
26/01/12 02:54:06 INFO TaskSetManager: Starting task 0.0 in stage 230.0 (TID 392) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4607 bytes) taskResourceAssignments Map()
26/01/12 02:54:06 INFO BlockManagerInfo: Added broadcast_345_piece0 in memory on 172.18.0.5:42453 (size: 36.8 KiB, free: 365.9 MiB)
26/01/12 02:54:07 INFO TaskSetManager: Finished task 0.0 in stage 230.0 (TID 392) in 136 ms on 172.18.0.5 (executor 0) (1/1)
26/01/12 02:54:07 INFO TaskSchedulerImpl: Removed TaskSet 230.0, whose tasks have all completed, from pool 
26/01/12 02:54:07 INFO DAGScheduler: ResultStage 230 (parquet at <unknown>:0) finished in 0.186 s
26/01/12 02:54:07 INFO DAGScheduler: Job 230 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:54:07 INFO TaskSchedulerImpl: Killing all running tasks in stage 230: Stage finished
26/01/12 02:54:07 INFO DAGScheduler: Job 230 finished: parquet at <unknown>:0, took 0.189386 s
26/01/12 02:54:07 INFO FileSourceStrategy: Pushed Filters: 
26/01/12 02:54:07 INFO FileSourceStrategy: Post-Scan Filters: 
26/01/12 02:54:07 INFO FileSourceStrategy: Output Data Schema: struct<VendorID: bigint, tpep_pickup_datetime: timestamp, tpep_dropoff_datetime: timestamp, passenger_count: double, trip_distance: double ... 17 more fields>
26/01/12 02:54:07 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:54:07 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:54:07 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:54:07 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:54:07 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:54:07 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:54:07 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:54:07 INFO MemoryStore: Block broadcast_346 stored as values in memory (estimated size 358.5 KiB, free 363.5 MiB)
26/01/12 02:54:07 INFO MemoryStore: Block broadcast_346_piece0 stored as bytes in memory (estimated size 35.3 KiB, free 363.5 MiB)
26/01/12 02:54:07 INFO BlockManagerInfo: Added broadcast_346_piece0 in memory on 02926ee04bc9:45221 (size: 35.3 KiB, free: 365.8 MiB)
26/01/12 02:54:07 INFO SparkContext: Created broadcast 346 from parquet at <unknown>:0
26/01/12 02:54:07 INFO FileSourceScanExec: Planning scan with bin packing, max size: 57810421 bytes, open cost is considered as scanning 4194304 bytes.
26/01/12 02:54:07 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 02:54:07 INFO DAGScheduler: Got job 231 (parquet at <unknown>:0) with 2 output partitions
26/01/12 02:54:07 INFO DAGScheduler: Final stage: ResultStage 231 (parquet at <unknown>:0)
26/01/12 02:54:07 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:54:07 INFO DAGScheduler: Missing parents: List()
26/01/12 02:54:07 INFO DAGScheduler: Submitting ResultStage 231 (MapPartitionsRDD[579] at parquet at <unknown>:0), which has no missing parents
26/01/12 02:54:07 INFO MemoryStore: Block broadcast_347 stored as values in memory (estimated size 225.1 KiB, free 363.2 MiB)
26/01/12 02:54:07 INFO MemoryStore: Block broadcast_347_piece0 stored as bytes in memory (estimated size 77.4 KiB, free 363.2 MiB)
26/01/12 02:54:07 INFO BlockManagerInfo: Added broadcast_347_piece0 in memory on 02926ee04bc9:45221 (size: 77.4 KiB, free: 365.8 MiB)
26/01/12 02:54:07 INFO SparkContext: Created broadcast 347 from broadcast at DAGScheduler.scala:1513
26/01/12 02:54:07 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 231 (MapPartitionsRDD[579] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1))
26/01/12 02:54:07 INFO TaskSchedulerImpl: Adding task set 231.0 with 2 tasks resource profile 0
26/01/12 02:54:07 INFO TaskSetManager: Starting task 0.0 in stage 231.0 (TID 393) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:54:07 INFO TaskSetManager: Starting task 1.0 in stage 231.0 (TID 394) (172.18.0.5, executor 0, partition 1, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:54:07 INFO BlockManagerInfo: Added broadcast_347_piece0 in memory on 172.18.0.5:42453 (size: 77.4 KiB, free: 365.8 MiB)
26/01/12 02:54:07 INFO BlockManagerInfo: Added broadcast_346_piece0 in memory on 172.18.0.5:42453 (size: 35.3 KiB, free: 365.8 MiB)
26/01/12 02:54:07 INFO TaskSetManager: Finished task 1.0 in stage 231.0 (TID 394) in 57 ms on 172.18.0.5 (executor 0) (1/2)
26/01/12 02:54:25 INFO TaskSetManager: Finished task 0.0 in stage 231.0 (TID 393) in 18519 ms on 172.18.0.5 (executor 0) (2/2)
26/01/12 02:54:25 INFO TaskSchedulerImpl: Removed TaskSet 231.0, whose tasks have all completed, from pool 
26/01/12 02:54:25 INFO DAGScheduler: ResultStage 231 (parquet at <unknown>:0) finished in 18.537 s
26/01/12 02:54:25 INFO DAGScheduler: Job 231 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:54:25 INFO TaskSchedulerImpl: Killing all running tasks in stage 231: Stage finished
26/01/12 02:54:25 INFO DAGScheduler: Job 231 finished: parquet at <unknown>:0, took 18.540761 s
26/01/12 02:54:25 INFO FileFormatWriter: Start to commit write Job a742c6ac-7589-4a3f-830f-e285a3d508ce.
26/01/12 02:54:25 INFO FileFormatWriter: Write Job a742c6ac-7589-4a3f-830f-e285a3d508ce committed. Elapsed time: 32 ms.
26/01/12 02:54:25 INFO FileFormatWriter: Finished processing stats for write job a742c6ac-7589-4a3f-830f-e285a3d508ce.
Cargando: yellow_tripdata_2018-09.parquet en hdfs://hadoop-namenode:8020/data/nyc/raw/taxi-trips/2018...
26/01/12 02:54:25 INFO InMemoryFileIndex: It took 8 ms to list leaf files for 1 paths.
26/01/12 02:54:25 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 02:54:25 INFO DAGScheduler: Got job 232 (parquet at <unknown>:0) with 1 output partitions
26/01/12 02:54:25 INFO DAGScheduler: Final stage: ResultStage 232 (parquet at <unknown>:0)
26/01/12 02:54:25 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:54:25 INFO DAGScheduler: Missing parents: List()
26/01/12 02:54:25 INFO DAGScheduler: Submitting ResultStage 232 (MapPartitionsRDD[581] at parquet at <unknown>:0), which has no missing parents
26/01/12 02:54:25 INFO MemoryStore: Block broadcast_348 stored as values in memory (estimated size 102.6 KiB, free 363.1 MiB)
26/01/12 02:54:25 INFO MemoryStore: Block broadcast_348_piece0 stored as bytes in memory (estimated size 36.8 KiB, free 363.0 MiB)
26/01/12 02:54:25 INFO BlockManagerInfo: Added broadcast_348_piece0 in memory on 02926ee04bc9:45221 (size: 36.8 KiB, free: 365.7 MiB)
26/01/12 02:54:25 INFO SparkContext: Created broadcast 348 from broadcast at DAGScheduler.scala:1513
26/01/12 02:54:25 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 232 (MapPartitionsRDD[581] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0))
26/01/12 02:54:25 INFO TaskSchedulerImpl: Adding task set 232.0 with 1 tasks resource profile 0
26/01/12 02:54:25 INFO TaskSetManager: Starting task 0.0 in stage 232.0 (TID 395) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4607 bytes) taskResourceAssignments Map()
26/01/12 02:54:25 INFO BlockManagerInfo: Removed broadcast_339_piece0 on 02926ee04bc9:45221 in memory (size: 36.8 KiB, free: 365.8 MiB)
26/01/12 02:54:25 INFO BlockManagerInfo: Removed broadcast_339_piece0 on 172.18.0.5:42453 in memory (size: 36.8 KiB, free: 365.8 MiB)
26/01/12 02:54:25 INFO BlockManagerInfo: Added broadcast_348_piece0 in memory on 172.18.0.5:42453 (size: 36.8 KiB, free: 365.8 MiB)
26/01/12 02:54:25 INFO BlockManagerInfo: Removed broadcast_343_piece0 on 02926ee04bc9:45221 in memory (size: 35.3 KiB, free: 365.8 MiB)
26/01/12 02:54:25 INFO BlockManagerInfo: Removed broadcast_343_piece0 on 172.18.0.5:42453 in memory (size: 35.3 KiB, free: 365.8 MiB)
26/01/12 02:54:25 INFO BlockManagerInfo: Removed broadcast_346_piece0 on 02926ee04bc9:45221 in memory (size: 35.3 KiB, free: 365.8 MiB)
26/01/12 02:54:25 INFO BlockManagerInfo: Removed broadcast_346_piece0 on 172.18.0.5:42453 in memory (size: 35.3 KiB, free: 365.8 MiB)
26/01/12 02:54:25 INFO BlockManagerInfo: Removed broadcast_344_piece0 on 02926ee04bc9:45221 in memory (size: 77.4 KiB, free: 365.9 MiB)
26/01/12 02:54:25 INFO BlockManagerInfo: Removed broadcast_344_piece0 on 172.18.0.5:42453 in memory (size: 77.4 KiB, free: 365.9 MiB)
26/01/12 02:54:25 INFO BlockManagerInfo: Removed broadcast_347_piece0 on 02926ee04bc9:45221 in memory (size: 77.4 KiB, free: 366.0 MiB)
26/01/12 02:54:25 INFO BlockManagerInfo: Removed broadcast_347_piece0 on 172.18.0.5:42453 in memory (size: 77.4 KiB, free: 366.0 MiB)
26/01/12 02:54:25 INFO BlockManagerInfo: Removed broadcast_345_piece0 on 02926ee04bc9:45221 in memory (size: 36.8 KiB, free: 366.0 MiB)
26/01/12 02:54:25 INFO BlockManagerInfo: Removed broadcast_345_piece0 on 172.18.0.5:42453 in memory (size: 36.8 KiB, free: 366.0 MiB)
26/01/12 02:54:25 INFO BlockManagerInfo: Removed broadcast_341_piece0 on 02926ee04bc9:45221 in memory (size: 77.4 KiB, free: 366.1 MiB)
26/01/12 02:54:25 INFO BlockManagerInfo: Removed broadcast_341_piece0 on 172.18.0.5:42453 in memory (size: 77.4 KiB, free: 366.1 MiB)
26/01/12 02:54:25 INFO BlockManagerInfo: Removed broadcast_342_piece0 on 02926ee04bc9:45221 in memory (size: 36.8 KiB, free: 366.1 MiB)
26/01/12 02:54:25 INFO BlockManagerInfo: Removed broadcast_342_piece0 on 172.18.0.5:42453 in memory (size: 36.8 KiB, free: 366.1 MiB)
26/01/12 02:54:25 INFO BlockManagerInfo: Removed broadcast_340_piece0 on 02926ee04bc9:45221 in memory (size: 35.4 KiB, free: 366.2 MiB)
26/01/12 02:54:25 INFO BlockManagerInfo: Removed broadcast_340_piece0 on 172.18.0.5:42453 in memory (size: 35.4 KiB, free: 366.2 MiB)
26/01/12 02:54:25 INFO TaskSetManager: Finished task 0.0 in stage 232.0 (TID 395) in 66 ms on 172.18.0.5 (executor 0) (1/1)
26/01/12 02:54:25 INFO TaskSchedulerImpl: Removed TaskSet 232.0, whose tasks have all completed, from pool 
26/01/12 02:54:25 INFO DAGScheduler: ResultStage 232 (parquet at <unknown>:0) finished in 0.099 s
26/01/12 02:54:25 INFO DAGScheduler: Job 232 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:54:25 INFO TaskSchedulerImpl: Killing all running tasks in stage 232: Stage finished
26/01/12 02:54:25 INFO DAGScheduler: Job 232 finished: parquet at <unknown>:0, took 0.103849 s
26/01/12 02:54:25 INFO FileSourceStrategy: Pushed Filters: 
26/01/12 02:54:25 INFO FileSourceStrategy: Post-Scan Filters: 
26/01/12 02:54:25 INFO FileSourceStrategy: Output Data Schema: struct<VendorID: bigint, tpep_pickup_datetime: timestamp, tpep_dropoff_datetime: timestamp, passenger_count: double, trip_distance: double ... 17 more fields>
26/01/12 02:54:25 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:54:25 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:54:25 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:54:25 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:54:25 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:54:25 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:54:25 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:54:25 INFO CodeGenerator: Code generated in 16.543409 ms
26/01/12 02:54:25 INFO MemoryStore: Block broadcast_349 stored as values in memory (estimated size 358.5 KiB, free 365.1 MiB)
26/01/12 02:54:25 INFO MemoryStore: Block broadcast_349_piece0 stored as bytes in memory (estimated size 35.3 KiB, free 365.1 MiB)
26/01/12 02:54:25 INFO BlockManagerInfo: Added broadcast_349_piece0 in memory on 02926ee04bc9:45221 (size: 35.3 KiB, free: 366.1 MiB)
26/01/12 02:54:25 INFO SparkContext: Created broadcast 349 from parquet at <unknown>:0
26/01/12 02:54:25 INFO FileSourceScanExec: Planning scan with bin packing, max size: 59849845 bytes, open cost is considered as scanning 4194304 bytes.
26/01/12 02:54:25 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 02:54:25 INFO DAGScheduler: Got job 233 (parquet at <unknown>:0) with 2 output partitions
26/01/12 02:54:25 INFO DAGScheduler: Final stage: ResultStage 233 (parquet at <unknown>:0)
26/01/12 02:54:25 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:54:25 INFO DAGScheduler: Missing parents: List()
26/01/12 02:54:25 INFO DAGScheduler: Submitting ResultStage 233 (MapPartitionsRDD[584] at parquet at <unknown>:0), which has no missing parents
26/01/12 02:54:25 INFO MemoryStore: Block broadcast_350 stored as values in memory (estimated size 225.1 KiB, free 364.9 MiB)
26/01/12 02:54:25 INFO MemoryStore: Block broadcast_350_piece0 stored as bytes in memory (estimated size 77.4 KiB, free 364.8 MiB)
26/01/12 02:54:25 INFO BlockManagerInfo: Added broadcast_350_piece0 in memory on 02926ee04bc9:45221 (size: 77.4 KiB, free: 366.0 MiB)
26/01/12 02:54:25 INFO SparkContext: Created broadcast 350 from broadcast at DAGScheduler.scala:1513
26/01/12 02:54:25 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 233 (MapPartitionsRDD[584] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1))
26/01/12 02:54:25 INFO TaskSchedulerImpl: Adding task set 233.0 with 2 tasks resource profile 0
26/01/12 02:54:25 INFO TaskSetManager: Starting task 0.0 in stage 233.0 (TID 396) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:54:25 INFO TaskSetManager: Starting task 1.0 in stage 233.0 (TID 397) (172.18.0.5, executor 0, partition 1, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:54:25 INFO BlockManagerInfo: Added broadcast_350_piece0 in memory on 172.18.0.5:42453 (size: 77.4 KiB, free: 366.1 MiB)
26/01/12 02:54:25 INFO BlockManagerInfo: Added broadcast_349_piece0 in memory on 172.18.0.5:42453 (size: 35.3 KiB, free: 366.0 MiB)
26/01/12 02:54:26 INFO TaskSetManager: Finished task 1.0 in stage 233.0 (TID 397) in 81 ms on 172.18.0.5 (executor 0) (1/2)
26/01/12 02:54:44 INFO TaskSetManager: Finished task 0.0 in stage 233.0 (TID 396) in 18309 ms on 172.18.0.5 (executor 0) (2/2)
26/01/12 02:54:44 INFO TaskSchedulerImpl: Removed TaskSet 233.0, whose tasks have all completed, from pool 
26/01/12 02:54:44 INFO DAGScheduler: ResultStage 233 (parquet at <unknown>:0) finished in 18.332 s
26/01/12 02:54:44 INFO DAGScheduler: Job 233 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:54:44 INFO TaskSchedulerImpl: Killing all running tasks in stage 233: Stage finished
26/01/12 02:54:44 INFO DAGScheduler: Job 233 finished: parquet at <unknown>:0, took 18.338336 s
26/01/12 02:54:44 INFO FileFormatWriter: Start to commit write Job c23187dd-13b4-45b8-a982-6dde717495cf.
26/01/12 02:54:44 INFO FileFormatWriter: Write Job c23187dd-13b4-45b8-a982-6dde717495cf committed. Elapsed time: 32 ms.
26/01/12 02:54:44 INFO FileFormatWriter: Finished processing stats for write job c23187dd-13b4-45b8-a982-6dde717495cf.
Cargando: yellow_tripdata_2018-10.parquet en hdfs://hadoop-namenode:8020/data/nyc/raw/taxi-trips/2018...
26/01/12 02:54:44 INFO InMemoryFileIndex: It took 7 ms to list leaf files for 1 paths.
26/01/12 02:54:44 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 02:54:44 INFO DAGScheduler: Got job 234 (parquet at <unknown>:0) with 1 output partitions
26/01/12 02:54:44 INFO DAGScheduler: Final stage: ResultStage 234 (parquet at <unknown>:0)
26/01/12 02:54:44 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:54:44 INFO DAGScheduler: Missing parents: List()
26/01/12 02:54:44 INFO DAGScheduler: Submitting ResultStage 234 (MapPartitionsRDD[586] at parquet at <unknown>:0), which has no missing parents
26/01/12 02:54:44 INFO MemoryStore: Block broadcast_351 stored as values in memory (estimated size 102.6 KiB, free 364.7 MiB)
26/01/12 02:54:44 INFO MemoryStore: Block broadcast_351_piece0 stored as bytes in memory (estimated size 36.8 KiB, free 364.7 MiB)
26/01/12 02:54:44 INFO BlockManagerInfo: Added broadcast_351_piece0 in memory on 02926ee04bc9:45221 (size: 36.8 KiB, free: 366.0 MiB)
26/01/12 02:54:44 INFO SparkContext: Created broadcast 351 from broadcast at DAGScheduler.scala:1513
26/01/12 02:54:44 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 234 (MapPartitionsRDD[586] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0))
26/01/12 02:54:44 INFO TaskSchedulerImpl: Adding task set 234.0 with 1 tasks resource profile 0
26/01/12 02:54:44 INFO TaskSetManager: Starting task 0.0 in stage 234.0 (TID 398) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4607 bytes) taskResourceAssignments Map()
26/01/12 02:54:44 INFO BlockManagerInfo: Added broadcast_351_piece0 in memory on 172.18.0.5:42453 (size: 36.8 KiB, free: 366.0 MiB)
26/01/12 02:54:44 INFO TaskSetManager: Finished task 0.0 in stage 234.0 (TID 398) in 46 ms on 172.18.0.5 (executor 0) (1/1)
26/01/12 02:54:44 INFO TaskSchedulerImpl: Removed TaskSet 234.0, whose tasks have all completed, from pool 
26/01/12 02:54:44 INFO DAGScheduler: ResultStage 234 (parquet at <unknown>:0) finished in 0.058 s
26/01/12 02:54:44 INFO DAGScheduler: Job 234 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:54:44 INFO TaskSchedulerImpl: Killing all running tasks in stage 234: Stage finished
26/01/12 02:54:44 INFO DAGScheduler: Job 234 finished: parquet at <unknown>:0, took 0.062513 s
26/01/12 02:54:44 INFO FileSourceStrategy: Pushed Filters: 
26/01/12 02:54:44 INFO FileSourceStrategy: Post-Scan Filters: 
26/01/12 02:54:44 INFO FileSourceStrategy: Output Data Schema: struct<VendorID: bigint, tpep_pickup_datetime: timestamp, tpep_dropoff_datetime: timestamp, passenger_count: double, trip_distance: double ... 17 more fields>
26/01/12 02:54:44 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:54:44 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:54:44 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:54:44 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:54:44 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:54:44 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:54:44 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:54:44 INFO MemoryStore: Block broadcast_352 stored as values in memory (estimated size 358.5 KiB, free 364.3 MiB)
26/01/12 02:54:44 INFO MemoryStore: Block broadcast_352_piece0 stored as bytes in memory (estimated size 35.3 KiB, free 364.3 MiB)
26/01/12 02:54:44 INFO BlockManagerInfo: Added broadcast_352_piece0 in memory on 02926ee04bc9:45221 (size: 35.3 KiB, free: 366.0 MiB)
26/01/12 02:54:44 INFO SparkContext: Created broadcast 352 from parquet at <unknown>:0
26/01/12 02:54:44 INFO FileSourceScanExec: Planning scan with bin packing, max size: 65546953 bytes, open cost is considered as scanning 4194304 bytes.
26/01/12 02:54:44 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 02:54:44 INFO DAGScheduler: Got job 235 (parquet at <unknown>:0) with 2 output partitions
26/01/12 02:54:44 INFO DAGScheduler: Final stage: ResultStage 235 (parquet at <unknown>:0)
26/01/12 02:54:44 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:54:44 INFO DAGScheduler: Missing parents: List()
26/01/12 02:54:44 INFO DAGScheduler: Submitting ResultStage 235 (MapPartitionsRDD[589] at parquet at <unknown>:0), which has no missing parents
26/01/12 02:54:44 INFO MemoryStore: Block broadcast_353 stored as values in memory (estimated size 225.1 KiB, free 364.1 MiB)
26/01/12 02:54:44 INFO MemoryStore: Block broadcast_353_piece0 stored as bytes in memory (estimated size 77.4 KiB, free 364.0 MiB)
26/01/12 02:54:44 INFO BlockManagerInfo: Added broadcast_353_piece0 in memory on 02926ee04bc9:45221 (size: 77.4 KiB, free: 365.9 MiB)
26/01/12 02:54:44 INFO SparkContext: Created broadcast 353 from broadcast at DAGScheduler.scala:1513
26/01/12 02:54:44 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 235 (MapPartitionsRDD[589] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1))
26/01/12 02:54:44 INFO TaskSchedulerImpl: Adding task set 235.0 with 2 tasks resource profile 0
26/01/12 02:54:44 INFO TaskSetManager: Starting task 0.0 in stage 235.0 (TID 399) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:54:44 INFO TaskSetManager: Starting task 1.0 in stage 235.0 (TID 400) (172.18.0.5, executor 0, partition 1, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:54:44 INFO BlockManagerInfo: Added broadcast_353_piece0 in memory on 172.18.0.5:42453 (size: 77.4 KiB, free: 365.9 MiB)
26/01/12 02:54:44 INFO BlockManagerInfo: Added broadcast_352_piece0 in memory on 172.18.0.5:42453 (size: 35.3 KiB, free: 365.9 MiB)
26/01/12 02:54:44 INFO TaskSetManager: Finished task 1.0 in stage 235.0 (TID 400) in 53 ms on 172.18.0.5 (executor 0) (1/2)
26/01/12 02:55:05 INFO TaskSetManager: Finished task 0.0 in stage 235.0 (TID 399) in 21076 ms on 172.18.0.5 (executor 0) (2/2)
26/01/12 02:55:05 INFO TaskSchedulerImpl: Removed TaskSet 235.0, whose tasks have all completed, from pool 
26/01/12 02:55:05 INFO DAGScheduler: ResultStage 235 (parquet at <unknown>:0) finished in 21.094 s
26/01/12 02:55:05 INFO DAGScheduler: Job 235 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:55:05 INFO TaskSchedulerImpl: Killing all running tasks in stage 235: Stage finished
26/01/12 02:55:05 INFO DAGScheduler: Job 235 finished: parquet at <unknown>:0, took 21.100588 s
26/01/12 02:55:05 INFO FileFormatWriter: Start to commit write Job 43a58278-9dc1-4ec3-84ab-9ebdf5a1eec2.
26/01/12 02:55:05 INFO FileFormatWriter: Write Job 43a58278-9dc1-4ec3-84ab-9ebdf5a1eec2 committed. Elapsed time: 30 ms.
26/01/12 02:55:05 INFO FileFormatWriter: Finished processing stats for write job 43a58278-9dc1-4ec3-84ab-9ebdf5a1eec2.
Cargando: yellow_tripdata_2018-11.parquet en hdfs://hadoop-namenode:8020/data/nyc/raw/taxi-trips/2018...
26/01/12 02:55:05 INFO InMemoryFileIndex: It took 6 ms to list leaf files for 1 paths.
26/01/12 02:55:05 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 02:55:05 INFO DAGScheduler: Got job 236 (parquet at <unknown>:0) with 1 output partitions
26/01/12 02:55:05 INFO DAGScheduler: Final stage: ResultStage 236 (parquet at <unknown>:0)
26/01/12 02:55:05 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:55:05 INFO DAGScheduler: Missing parents: List()
26/01/12 02:55:05 INFO DAGScheduler: Submitting ResultStage 236 (MapPartitionsRDD[591] at parquet at <unknown>:0), which has no missing parents
26/01/12 02:55:05 INFO MemoryStore: Block broadcast_354 stored as values in memory (estimated size 102.6 KiB, free 363.9 MiB)
26/01/12 02:55:05 INFO MemoryStore: Block broadcast_354_piece0 stored as bytes in memory (estimated size 36.8 KiB, free 363.9 MiB)
26/01/12 02:55:05 INFO BlockManagerInfo: Added broadcast_354_piece0 in memory on 02926ee04bc9:45221 (size: 36.8 KiB, free: 365.9 MiB)
26/01/12 02:55:05 INFO SparkContext: Created broadcast 354 from broadcast at DAGScheduler.scala:1513
26/01/12 02:55:05 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 236 (MapPartitionsRDD[591] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0))
26/01/12 02:55:05 INFO TaskSchedulerImpl: Adding task set 236.0 with 1 tasks resource profile 0
26/01/12 02:55:05 INFO TaskSetManager: Starting task 0.0 in stage 236.0 (TID 401) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4607 bytes) taskResourceAssignments Map()
26/01/12 02:55:05 INFO BlockManagerInfo: Added broadcast_354_piece0 in memory on 172.18.0.5:42453 (size: 36.8 KiB, free: 365.9 MiB)
26/01/12 02:55:05 INFO TaskSetManager: Finished task 0.0 in stage 236.0 (TID 401) in 46 ms on 172.18.0.5 (executor 0) (1/1)
26/01/12 02:55:05 INFO TaskSchedulerImpl: Removed TaskSet 236.0, whose tasks have all completed, from pool 
26/01/12 02:55:05 INFO DAGScheduler: ResultStage 236 (parquet at <unknown>:0) finished in 0.057 s
26/01/12 02:55:05 INFO DAGScheduler: Job 236 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:55:05 INFO TaskSchedulerImpl: Killing all running tasks in stage 236: Stage finished
26/01/12 02:55:05 INFO DAGScheduler: Job 236 finished: parquet at <unknown>:0, took 0.061382 s
26/01/12 02:55:05 INFO FileSourceStrategy: Pushed Filters: 
26/01/12 02:55:05 INFO FileSourceStrategy: Post-Scan Filters: 
26/01/12 02:55:05 INFO FileSourceStrategy: Output Data Schema: struct<VendorID: bigint, tpep_pickup_datetime: timestamp, tpep_dropoff_datetime: timestamp, passenger_count: double, trip_distance: double ... 17 more fields>
26/01/12 02:55:05 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:55:05 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:55:05 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:55:05 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:55:05 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:55:05 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:55:05 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:55:05 INFO MemoryStore: Block broadcast_355 stored as values in memory (estimated size 358.5 KiB, free 363.5 MiB)
26/01/12 02:55:05 INFO MemoryStore: Block broadcast_355_piece0 stored as bytes in memory (estimated size 35.3 KiB, free 363.5 MiB)
26/01/12 02:55:05 INFO BlockManagerInfo: Added broadcast_355_piece0 in memory on 02926ee04bc9:45221 (size: 35.3 KiB, free: 365.8 MiB)
26/01/12 02:55:05 INFO SparkContext: Created broadcast 355 from parquet at <unknown>:0
26/01/12 02:55:05 INFO FileSourceScanExec: Planning scan with bin packing, max size: 60682460 bytes, open cost is considered as scanning 4194304 bytes.
26/01/12 02:55:05 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 02:55:05 INFO DAGScheduler: Got job 237 (parquet at <unknown>:0) with 2 output partitions
26/01/12 02:55:05 INFO DAGScheduler: Final stage: ResultStage 237 (parquet at <unknown>:0)
26/01/12 02:55:05 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:55:05 INFO DAGScheduler: Missing parents: List()
26/01/12 02:55:05 INFO DAGScheduler: Submitting ResultStage 237 (MapPartitionsRDD[594] at parquet at <unknown>:0), which has no missing parents
26/01/12 02:55:05 INFO MemoryStore: Block broadcast_356 stored as values in memory (estimated size 225.1 KiB, free 363.2 MiB)
26/01/12 02:55:05 INFO MemoryStore: Block broadcast_356_piece0 stored as bytes in memory (estimated size 77.4 KiB, free 363.2 MiB)
26/01/12 02:55:05 INFO BlockManagerInfo: Added broadcast_356_piece0 in memory on 02926ee04bc9:45221 (size: 77.4 KiB, free: 365.8 MiB)
26/01/12 02:55:05 INFO SparkContext: Created broadcast 356 from broadcast at DAGScheduler.scala:1513
26/01/12 02:55:05 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 237 (MapPartitionsRDD[594] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1))
26/01/12 02:55:05 INFO TaskSchedulerImpl: Adding task set 237.0 with 2 tasks resource profile 0
26/01/12 02:55:05 INFO TaskSetManager: Starting task 0.0 in stage 237.0 (TID 402) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:55:05 INFO TaskSetManager: Starting task 1.0 in stage 237.0 (TID 403) (172.18.0.5, executor 0, partition 1, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:55:05 INFO BlockManagerInfo: Added broadcast_356_piece0 in memory on 172.18.0.5:42453 (size: 77.4 KiB, free: 365.8 MiB)
26/01/12 02:55:05 INFO BlockManagerInfo: Added broadcast_355_piece0 in memory on 172.18.0.5:42453 (size: 35.3 KiB, free: 365.8 MiB)
26/01/12 02:55:05 INFO TaskSetManager: Finished task 1.0 in stage 237.0 (TID 403) in 53 ms on 172.18.0.5 (executor 0) (1/2)
26/01/12 02:55:24 INFO TaskSetManager: Finished task 0.0 in stage 237.0 (TID 402) in 19102 ms on 172.18.0.5 (executor 0) (2/2)
26/01/12 02:55:24 INFO TaskSchedulerImpl: Removed TaskSet 237.0, whose tasks have all completed, from pool 
26/01/12 02:55:24 INFO DAGScheduler: ResultStage 237 (parquet at <unknown>:0) finished in 19.120 s
26/01/12 02:55:24 INFO DAGScheduler: Job 237 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:55:24 INFO TaskSchedulerImpl: Killing all running tasks in stage 237: Stage finished
26/01/12 02:55:24 INFO DAGScheduler: Job 237 finished: parquet at <unknown>:0, took 19.125711 s
26/01/12 02:55:24 INFO FileFormatWriter: Start to commit write Job b9fae2d6-53d6-4566-b1f2-790129835a53.
26/01/12 02:55:24 INFO FileFormatWriter: Write Job b9fae2d6-53d6-4566-b1f2-790129835a53 committed. Elapsed time: 88 ms.
26/01/12 02:55:24 INFO FileFormatWriter: Finished processing stats for write job b9fae2d6-53d6-4566-b1f2-790129835a53.
Cargando: yellow_tripdata_2018-12.parquet en hdfs://hadoop-namenode:8020/data/nyc/raw/taxi-trips/2018...
26/01/12 02:55:24 INFO InMemoryFileIndex: It took 5 ms to list leaf files for 1 paths.
26/01/12 02:55:24 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 02:55:24 INFO DAGScheduler: Got job 238 (parquet at <unknown>:0) with 1 output partitions
26/01/12 02:55:24 INFO DAGScheduler: Final stage: ResultStage 238 (parquet at <unknown>:0)
26/01/12 02:55:24 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:55:24 INFO DAGScheduler: Missing parents: List()
26/01/12 02:55:24 INFO DAGScheduler: Submitting ResultStage 238 (MapPartitionsRDD[596] at parquet at <unknown>:0), which has no missing parents
26/01/12 02:55:24 INFO MemoryStore: Block broadcast_357 stored as values in memory (estimated size 102.6 KiB, free 363.1 MiB)
26/01/12 02:55:24 INFO MemoryStore: Block broadcast_357_piece0 stored as bytes in memory (estimated size 36.8 KiB, free 363.0 MiB)
26/01/12 02:55:24 INFO BlockManagerInfo: Added broadcast_357_piece0 in memory on 02926ee04bc9:45221 (size: 36.8 KiB, free: 365.7 MiB)
26/01/12 02:55:24 INFO SparkContext: Created broadcast 357 from broadcast at DAGScheduler.scala:1513
26/01/12 02:55:24 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 238 (MapPartitionsRDD[596] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0))
26/01/12 02:55:24 INFO TaskSchedulerImpl: Adding task set 238.0 with 1 tasks resource profile 0
26/01/12 02:55:24 INFO TaskSetManager: Starting task 0.0 in stage 238.0 (TID 404) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4607 bytes) taskResourceAssignments Map()
26/01/12 02:55:25 INFO BlockManagerInfo: Added broadcast_357_piece0 in memory on 172.18.0.5:42453 (size: 36.8 KiB, free: 365.7 MiB)
26/01/12 02:55:25 INFO TaskSetManager: Finished task 0.0 in stage 238.0 (TID 404) in 47 ms on 172.18.0.5 (executor 0) (1/1)
26/01/12 02:55:25 INFO TaskSchedulerImpl: Removed TaskSet 238.0, whose tasks have all completed, from pool 
26/01/12 02:55:25 INFO DAGScheduler: ResultStage 238 (parquet at <unknown>:0) finished in 0.057 s
26/01/12 02:55:25 INFO DAGScheduler: Job 238 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:55:25 INFO TaskSchedulerImpl: Killing all running tasks in stage 238: Stage finished
26/01/12 02:55:25 INFO DAGScheduler: Job 238 finished: parquet at <unknown>:0, took 0.061141 s
26/01/12 02:55:25 INFO FileSourceStrategy: Pushed Filters: 
26/01/12 02:55:25 INFO FileSourceStrategy: Post-Scan Filters: 
26/01/12 02:55:25 INFO FileSourceStrategy: Output Data Schema: struct<VendorID: bigint, tpep_pickup_datetime: timestamp, tpep_dropoff_datetime: timestamp, passenger_count: double, trip_distance: double ... 17 more fields>
26/01/12 02:55:25 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:55:25 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:55:25 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:55:25 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:55:25 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:55:25 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:55:25 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:55:25 INFO MemoryStore: Block broadcast_358 stored as values in memory (estimated size 358.5 KiB, free 362.7 MiB)
26/01/12 02:55:25 INFO BlockManagerInfo: Removed broadcast_357_piece0 on 02926ee04bc9:45221 in memory (size: 36.8 KiB, free: 365.8 MiB)
26/01/12 02:55:25 INFO BlockManagerInfo: Removed broadcast_357_piece0 on 172.18.0.5:42453 in memory (size: 36.8 KiB, free: 365.8 MiB)
26/01/12 02:55:25 INFO BlockManagerInfo: Removed broadcast_355_piece0 on 02926ee04bc9:45221 in memory (size: 35.3 KiB, free: 365.8 MiB)
26/01/12 02:55:25 INFO MemoryStore: Block broadcast_358_piece0 stored as bytes in memory (estimated size 35.3 KiB, free 362.8 MiB)
26/01/12 02:55:25 INFO BlockManagerInfo: Added broadcast_358_piece0 in memory on 02926ee04bc9:45221 (size: 35.3 KiB, free: 365.8 MiB)
26/01/12 02:55:25 INFO BlockManagerInfo: Removed broadcast_355_piece0 on 172.18.0.5:42453 in memory (size: 35.3 KiB, free: 365.8 MiB)
26/01/12 02:55:25 INFO SparkContext: Created broadcast 358 from parquet at <unknown>:0
26/01/12 02:55:25 INFO FileSourceScanExec: Planning scan with bin packing, max size: 61019657 bytes, open cost is considered as scanning 4194304 bytes.
26/01/12 02:55:25 INFO BlockManagerInfo: Removed broadcast_352_piece0 on 02926ee04bc9:45221 in memory (size: 35.3 KiB, free: 365.8 MiB)
26/01/12 02:55:25 INFO BlockManagerInfo: Removed broadcast_352_piece0 on 172.18.0.5:42453 in memory (size: 35.3 KiB, free: 365.8 MiB)
26/01/12 02:55:25 INFO BlockManagerInfo: Removed broadcast_348_piece0 on 02926ee04bc9:45221 in memory (size: 36.8 KiB, free: 365.8 MiB)
26/01/12 02:55:25 INFO BlockManagerInfo: Removed broadcast_348_piece0 on 172.18.0.5:42453 in memory (size: 36.8 KiB, free: 365.9 MiB)
26/01/12 02:55:25 INFO BlockManagerInfo: Removed broadcast_349_piece0 on 02926ee04bc9:45221 in memory (size: 35.3 KiB, free: 365.9 MiB)
26/01/12 02:55:25 INFO BlockManagerInfo: Removed broadcast_349_piece0 on 172.18.0.5:42453 in memory (size: 35.3 KiB, free: 365.9 MiB)
26/01/12 02:55:25 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 02:55:25 INFO DAGScheduler: Got job 239 (parquet at <unknown>:0) with 2 output partitions
26/01/12 02:55:25 INFO DAGScheduler: Final stage: ResultStage 239 (parquet at <unknown>:0)
26/01/12 02:55:25 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:55:25 INFO DAGScheduler: Missing parents: List()
26/01/12 02:55:25 INFO DAGScheduler: Submitting ResultStage 239 (MapPartitionsRDD[599] at parquet at <unknown>:0), which has no missing parents
26/01/12 02:55:25 INFO BlockManagerInfo: Removed broadcast_351_piece0 on 02926ee04bc9:45221 in memory (size: 36.8 KiB, free: 365.9 MiB)
26/01/12 02:55:25 INFO BlockManagerInfo: Removed broadcast_351_piece0 on 172.18.0.5:42453 in memory (size: 36.8 KiB, free: 365.9 MiB)
26/01/12 02:55:25 INFO BlockManagerInfo: Removed broadcast_350_piece0 on 02926ee04bc9:45221 in memory (size: 77.4 KiB, free: 366.0 MiB)
26/01/12 02:55:25 INFO BlockManagerInfo: Removed broadcast_350_piece0 on 172.18.0.5:42453 in memory (size: 77.4 KiB, free: 366.0 MiB)
26/01/12 02:55:25 INFO BlockManagerInfo: Removed broadcast_353_piece0 on 02926ee04bc9:45221 in memory (size: 77.4 KiB, free: 366.0 MiB)
26/01/12 02:55:25 INFO BlockManagerInfo: Removed broadcast_353_piece0 on 172.18.0.5:42453 in memory (size: 77.4 KiB, free: 366.1 MiB)
26/01/12 02:55:25 INFO BlockManagerInfo: Removed broadcast_356_piece0 on 02926ee04bc9:45221 in memory (size: 77.4 KiB, free: 366.1 MiB)
26/01/12 02:55:25 INFO MemoryStore: Block broadcast_359 stored as values in memory (estimated size 225.1 KiB, free 364.9 MiB)
26/01/12 02:55:25 INFO BlockManagerInfo: Removed broadcast_356_piece0 on 172.18.0.5:42453 in memory (size: 77.4 KiB, free: 366.2 MiB)
26/01/12 02:55:25 INFO MemoryStore: Block broadcast_359_piece0 stored as bytes in memory (estimated size 77.4 KiB, free 364.8 MiB)
26/01/12 02:55:25 INFO BlockManagerInfo: Added broadcast_359_piece0 in memory on 02926ee04bc9:45221 (size: 77.4 KiB, free: 366.0 MiB)
26/01/12 02:55:25 INFO SparkContext: Created broadcast 359 from broadcast at DAGScheduler.scala:1513
26/01/12 02:55:25 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 239 (MapPartitionsRDD[599] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1))
26/01/12 02:55:25 INFO TaskSchedulerImpl: Adding task set 239.0 with 2 tasks resource profile 0
26/01/12 02:55:25 INFO BlockManagerInfo: Removed broadcast_354_piece0 on 02926ee04bc9:45221 in memory (size: 36.8 KiB, free: 366.1 MiB)
26/01/12 02:55:25 INFO TaskSetManager: Starting task 0.0 in stage 239.0 (TID 405) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:55:25 INFO BlockManagerInfo: Removed broadcast_354_piece0 on 172.18.0.5:42453 in memory (size: 36.8 KiB, free: 366.2 MiB)
26/01/12 02:55:25 INFO TaskSetManager: Starting task 1.0 in stage 239.0 (TID 406) (172.18.0.5, executor 0, partition 1, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:55:25 INFO BlockManagerInfo: Added broadcast_359_piece0 in memory on 172.18.0.5:42453 (size: 77.4 KiB, free: 366.1 MiB)
26/01/12 02:55:25 INFO BlockManagerInfo: Added broadcast_358_piece0 in memory on 172.18.0.5:42453 (size: 35.3 KiB, free: 366.1 MiB)
26/01/12 02:55:25 INFO TaskSetManager: Finished task 1.0 in stage 239.0 (TID 406) in 51 ms on 172.18.0.5 (executor 0) (1/2)
26/01/12 02:55:44 INFO TaskSetManager: Finished task 0.0 in stage 239.0 (TID 405) in 19833 ms on 172.18.0.5 (executor 0) (2/2)
26/01/12 02:55:44 INFO TaskSchedulerImpl: Removed TaskSet 239.0, whose tasks have all completed, from pool 
26/01/12 02:55:44 INFO DAGScheduler: ResultStage 239 (parquet at <unknown>:0) finished in 19.855 s
26/01/12 02:55:44 INFO DAGScheduler: Job 239 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:55:44 INFO TaskSchedulerImpl: Killing all running tasks in stage 239: Stage finished
26/01/12 02:55:44 INFO DAGScheduler: Job 239 finished: parquet at <unknown>:0, took 19.861810 s
26/01/12 02:55:44 INFO FileFormatWriter: Start to commit write Job 15ed9d67-b81b-4bd6-b475-ff52ac60dafe.
26/01/12 02:55:45 INFO FileFormatWriter: Write Job 15ed9d67-b81b-4bd6-b475-ff52ac60dafe committed. Elapsed time: 40 ms.
26/01/12 02:55:45 INFO FileFormatWriter: Finished processing stats for write job 15ed9d67-b81b-4bd6-b475-ff52ac60dafe.
Cargando: yellow_tripdata_2019-01.parquet en hdfs://hadoop-namenode:8020/data/nyc/raw/taxi-trips/2019...
26/01/12 02:55:45 INFO InMemoryFileIndex: It took 5 ms to list leaf files for 1 paths.
26/01/12 02:55:45 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 02:55:45 INFO DAGScheduler: Got job 240 (parquet at <unknown>:0) with 1 output partitions
26/01/12 02:55:45 INFO DAGScheduler: Final stage: ResultStage 240 (parquet at <unknown>:0)
26/01/12 02:55:45 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:55:45 INFO DAGScheduler: Missing parents: List()
26/01/12 02:55:45 INFO DAGScheduler: Submitting ResultStage 240 (MapPartitionsRDD[601] at parquet at <unknown>:0), which has no missing parents
26/01/12 02:55:45 INFO MemoryStore: Block broadcast_360 stored as values in memory (estimated size 102.6 KiB, free 364.8 MiB)
26/01/12 02:55:45 INFO MemoryStore: Block broadcast_360_piece0 stored as bytes in memory (estimated size 36.8 KiB, free 364.8 MiB)
26/01/12 02:55:45 INFO BlockManagerInfo: Added broadcast_360_piece0 in memory on 02926ee04bc9:45221 (size: 36.8 KiB, free: 366.0 MiB)
26/01/12 02:55:45 INFO SparkContext: Created broadcast 360 from broadcast at DAGScheduler.scala:1513
26/01/12 02:55:45 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 240 (MapPartitionsRDD[601] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0))
26/01/12 02:55:45 INFO TaskSchedulerImpl: Adding task set 240.0 with 1 tasks resource profile 0
26/01/12 02:55:45 INFO TaskSetManager: Starting task 0.0 in stage 240.0 (TID 407) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4607 bytes) taskResourceAssignments Map()
26/01/12 02:55:45 INFO BlockManagerInfo: Added broadcast_360_piece0 in memory on 172.18.0.5:42453 (size: 36.8 KiB, free: 366.0 MiB)
26/01/12 02:55:45 INFO TaskSetManager: Finished task 0.0 in stage 240.0 (TID 407) in 46 ms on 172.18.0.5 (executor 0) (1/1)
26/01/12 02:55:45 INFO TaskSchedulerImpl: Removed TaskSet 240.0, whose tasks have all completed, from pool 
26/01/12 02:55:45 INFO DAGScheduler: ResultStage 240 (parquet at <unknown>:0) finished in 0.059 s
26/01/12 02:55:45 INFO DAGScheduler: Job 240 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:55:45 INFO TaskSchedulerImpl: Killing all running tasks in stage 240: Stage finished
26/01/12 02:55:45 INFO DAGScheduler: Job 240 finished: parquet at <unknown>:0, took 0.064177 s
26/01/12 02:55:45 INFO FileSourceStrategy: Pushed Filters: 
26/01/12 02:55:45 INFO FileSourceStrategy: Post-Scan Filters: 
26/01/12 02:55:45 INFO FileSourceStrategy: Output Data Schema: struct<VendorID: bigint, tpep_pickup_datetime: timestamp, tpep_dropoff_datetime: timestamp, passenger_count: double, trip_distance: double ... 17 more fields>
26/01/12 02:55:45 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:55:45 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:55:45 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:55:45 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:55:45 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:55:45 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:55:45 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:55:45 INFO MemoryStore: Block broadcast_361 stored as values in memory (estimated size 358.5 KiB, free 364.5 MiB)
26/01/12 02:55:45 INFO MemoryStore: Block broadcast_361_piece0 stored as bytes in memory (estimated size 35.3 KiB, free 364.4 MiB)
26/01/12 02:55:45 INFO BlockManagerInfo: Added broadcast_361_piece0 in memory on 02926ee04bc9:45221 (size: 35.3 KiB, free: 366.0 MiB)
26/01/12 02:55:45 INFO SparkContext: Created broadcast 361 from parquet at <unknown>:0
26/01/12 02:55:45 INFO FileSourceScanExec: Planning scan with bin packing, max size: 57316969 bytes, open cost is considered as scanning 4194304 bytes.
26/01/12 02:55:45 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 02:55:45 INFO DAGScheduler: Got job 241 (parquet at <unknown>:0) with 2 output partitions
26/01/12 02:55:45 INFO DAGScheduler: Final stage: ResultStage 241 (parquet at <unknown>:0)
26/01/12 02:55:45 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:55:45 INFO DAGScheduler: Missing parents: List()
26/01/12 02:55:45 INFO DAGScheduler: Submitting ResultStage 241 (MapPartitionsRDD[604] at parquet at <unknown>:0), which has no missing parents
26/01/12 02:55:45 INFO MemoryStore: Block broadcast_362 stored as values in memory (estimated size 225.1 KiB, free 364.2 MiB)
26/01/12 02:55:45 INFO MemoryStore: Block broadcast_362_piece0 stored as bytes in memory (estimated size 77.4 KiB, free 364.1 MiB)
26/01/12 02:55:45 INFO BlockManagerInfo: Added broadcast_362_piece0 in memory on 02926ee04bc9:45221 (size: 77.4 KiB, free: 365.9 MiB)
26/01/12 02:55:45 INFO SparkContext: Created broadcast 362 from broadcast at DAGScheduler.scala:1513
26/01/12 02:55:45 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 241 (MapPartitionsRDD[604] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1))
26/01/12 02:55:45 INFO TaskSchedulerImpl: Adding task set 241.0 with 2 tasks resource profile 0
26/01/12 02:55:45 INFO TaskSetManager: Starting task 0.0 in stage 241.0 (TID 408) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:55:45 INFO TaskSetManager: Starting task 1.0 in stage 241.0 (TID 409) (172.18.0.5, executor 0, partition 1, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:55:45 INFO BlockManagerInfo: Added broadcast_362_piece0 in memory on 172.18.0.5:42453 (size: 77.4 KiB, free: 366.0 MiB)
26/01/12 02:55:45 INFO BlockManagerInfo: Added broadcast_361_piece0 in memory on 172.18.0.5:42453 (size: 35.3 KiB, free: 365.9 MiB)
26/01/12 02:55:45 INFO TaskSetManager: Finished task 1.0 in stage 241.0 (TID 409) in 51 ms on 172.18.0.5 (executor 0) (1/2)
26/01/12 02:56:03 INFO TaskSetManager: Finished task 0.0 in stage 241.0 (TID 408) in 18038 ms on 172.18.0.5 (executor 0) (2/2)
26/01/12 02:56:03 INFO TaskSchedulerImpl: Removed TaskSet 241.0, whose tasks have all completed, from pool 
26/01/12 02:56:03 INFO DAGScheduler: ResultStage 241 (parquet at <unknown>:0) finished in 18.069 s
26/01/12 02:56:03 INFO DAGScheduler: Job 241 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:56:03 INFO TaskSchedulerImpl: Killing all running tasks in stage 241: Stage finished
26/01/12 02:56:03 INFO DAGScheduler: Job 241 finished: parquet at <unknown>:0, took 18.078212 s
26/01/12 02:56:03 INFO FileFormatWriter: Start to commit write Job 0a17c771-933a-4d8f-b57e-6a8244971328.
26/01/12 02:56:03 INFO FileFormatWriter: Write Job 0a17c771-933a-4d8f-b57e-6a8244971328 committed. Elapsed time: 34 ms.
26/01/12 02:56:03 INFO FileFormatWriter: Finished processing stats for write job 0a17c771-933a-4d8f-b57e-6a8244971328.
Cargando: yellow_tripdata_2019-02.parquet en hdfs://hadoop-namenode:8020/data/nyc/raw/taxi-trips/2019...
26/01/12 02:56:03 INFO InMemoryFileIndex: It took 6 ms to list leaf files for 1 paths.
26/01/12 02:56:03 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 02:56:03 INFO DAGScheduler: Got job 242 (parquet at <unknown>:0) with 1 output partitions
26/01/12 02:56:03 INFO DAGScheduler: Final stage: ResultStage 242 (parquet at <unknown>:0)
26/01/12 02:56:03 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:56:03 INFO DAGScheduler: Missing parents: List()
26/01/12 02:56:03 INFO DAGScheduler: Submitting ResultStage 242 (MapPartitionsRDD[606] at parquet at <unknown>:0), which has no missing parents
26/01/12 02:56:03 INFO MemoryStore: Block broadcast_363 stored as values in memory (estimated size 102.6 KiB, free 364.0 MiB)
26/01/12 02:56:03 INFO MemoryStore: Block broadcast_363_piece0 stored as bytes in memory (estimated size 36.8 KiB, free 364.0 MiB)
26/01/12 02:56:03 INFO BlockManagerInfo: Added broadcast_363_piece0 in memory on 02926ee04bc9:45221 (size: 36.8 KiB, free: 365.9 MiB)
26/01/12 02:56:03 INFO SparkContext: Created broadcast 363 from broadcast at DAGScheduler.scala:1513
26/01/12 02:56:03 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 242 (MapPartitionsRDD[606] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0))
26/01/12 02:56:03 INFO TaskSchedulerImpl: Adding task set 242.0 with 1 tasks resource profile 0
26/01/12 02:56:03 INFO TaskSetManager: Starting task 0.0 in stage 242.0 (TID 410) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4607 bytes) taskResourceAssignments Map()
26/01/12 02:56:03 INFO BlockManagerInfo: Added broadcast_363_piece0 in memory on 172.18.0.5:42453 (size: 36.8 KiB, free: 365.9 MiB)
26/01/12 02:56:03 INFO TaskSetManager: Finished task 0.0 in stage 242.0 (TID 410) in 53 ms on 172.18.0.5 (executor 0) (1/1)
26/01/12 02:56:03 INFO TaskSchedulerImpl: Removed TaskSet 242.0, whose tasks have all completed, from pool 
26/01/12 02:56:03 INFO DAGScheduler: ResultStage 242 (parquet at <unknown>:0) finished in 0.075 s
26/01/12 02:56:03 INFO DAGScheduler: Job 242 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:56:03 INFO TaskSchedulerImpl: Killing all running tasks in stage 242: Stage finished
26/01/12 02:56:03 INFO DAGScheduler: Job 242 finished: parquet at <unknown>:0, took 0.080516 s
26/01/12 02:56:03 INFO FileSourceStrategy: Pushed Filters: 
26/01/12 02:56:03 INFO FileSourceStrategy: Post-Scan Filters: 
26/01/12 02:56:03 INFO FileSourceStrategy: Output Data Schema: struct<VendorID: bigint, tpep_pickup_datetime: timestamp, tpep_dropoff_datetime: timestamp, passenger_count: double, trip_distance: double ... 17 more fields>
26/01/12 02:56:03 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:56:03 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:56:03 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:56:03 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:56:03 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:56:03 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:56:03 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:56:03 INFO MemoryStore: Block broadcast_364 stored as values in memory (estimated size 358.5 KiB, free 363.6 MiB)
26/01/12 02:56:03 INFO MemoryStore: Block broadcast_364_piece0 stored as bytes in memory (estimated size 35.3 KiB, free 363.6 MiB)
26/01/12 02:56:03 INFO BlockManagerInfo: Added broadcast_364_piece0 in memory on 02926ee04bc9:45221 (size: 35.3 KiB, free: 365.9 MiB)
26/01/12 02:56:03 INFO SparkContext: Created broadcast 364 from parquet at <unknown>:0
26/01/12 02:56:03 INFO FileSourceScanExec: Planning scan with bin packing, max size: 53775164 bytes, open cost is considered as scanning 4194304 bytes.
26/01/12 02:56:03 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 02:56:03 INFO DAGScheduler: Got job 243 (parquet at <unknown>:0) with 2 output partitions
26/01/12 02:56:03 INFO DAGScheduler: Final stage: ResultStage 243 (parquet at <unknown>:0)
26/01/12 02:56:03 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:56:03 INFO DAGScheduler: Missing parents: List()
26/01/12 02:56:03 INFO DAGScheduler: Submitting ResultStage 243 (MapPartitionsRDD[609] at parquet at <unknown>:0), which has no missing parents
26/01/12 02:56:03 INFO MemoryStore: Block broadcast_365 stored as values in memory (estimated size 225.1 KiB, free 363.4 MiB)
26/01/12 02:56:03 INFO MemoryStore: Block broadcast_365_piece0 stored as bytes in memory (estimated size 77.4 KiB, free 363.3 MiB)
26/01/12 02:56:03 INFO BlockManagerInfo: Added broadcast_365_piece0 in memory on 02926ee04bc9:45221 (size: 77.4 KiB, free: 365.8 MiB)
26/01/12 02:56:03 INFO SparkContext: Created broadcast 365 from broadcast at DAGScheduler.scala:1513
26/01/12 02:56:03 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 243 (MapPartitionsRDD[609] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1))
26/01/12 02:56:03 INFO TaskSchedulerImpl: Adding task set 243.0 with 2 tasks resource profile 0
26/01/12 02:56:03 INFO TaskSetManager: Starting task 0.0 in stage 243.0 (TID 411) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:56:03 INFO TaskSetManager: Starting task 1.0 in stage 243.0 (TID 412) (172.18.0.5, executor 0, partition 1, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:56:03 INFO BlockManagerInfo: Added broadcast_365_piece0 in memory on 172.18.0.5:42453 (size: 77.4 KiB, free: 365.8 MiB)
26/01/12 02:56:03 INFO BlockManagerInfo: Added broadcast_364_piece0 in memory on 172.18.0.5:42453 (size: 35.3 KiB, free: 365.8 MiB)
26/01/12 02:56:03 INFO TaskSetManager: Finished task 1.0 in stage 243.0 (TID 412) in 59 ms on 172.18.0.5 (executor 0) (1/2)
26/01/12 02:56:20 INFO TaskSetManager: Finished task 0.0 in stage 243.0 (TID 411) in 17284 ms on 172.18.0.5 (executor 0) (2/2)
26/01/12 02:56:20 INFO TaskSchedulerImpl: Removed TaskSet 243.0, whose tasks have all completed, from pool 
26/01/12 02:56:20 INFO DAGScheduler: ResultStage 243 (parquet at <unknown>:0) finished in 17.321 s
26/01/12 02:56:20 INFO DAGScheduler: Job 243 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:56:20 INFO TaskSchedulerImpl: Killing all running tasks in stage 243: Stage finished
26/01/12 02:56:20 INFO DAGScheduler: Job 243 finished: parquet at <unknown>:0, took 17.326618 s
26/01/12 02:56:20 INFO FileFormatWriter: Start to commit write Job 8594aebe-5f04-45da-8480-1931294e97af.
26/01/12 02:56:20 INFO FileFormatWriter: Write Job 8594aebe-5f04-45da-8480-1931294e97af committed. Elapsed time: 31 ms.
26/01/12 02:56:20 INFO FileFormatWriter: Finished processing stats for write job 8594aebe-5f04-45da-8480-1931294e97af.
Cargando: yellow_tripdata_2019-03.parquet en hdfs://hadoop-namenode:8020/data/nyc/raw/taxi-trips/2019...
26/01/12 02:56:20 INFO InMemoryFileIndex: It took 5 ms to list leaf files for 1 paths.
26/01/12 02:56:20 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 02:56:20 INFO DAGScheduler: Got job 244 (parquet at <unknown>:0) with 1 output partitions
26/01/12 02:56:20 INFO DAGScheduler: Final stage: ResultStage 244 (parquet at <unknown>:0)
26/01/12 02:56:20 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:56:20 INFO DAGScheduler: Missing parents: List()
26/01/12 02:56:20 INFO DAGScheduler: Submitting ResultStage 244 (MapPartitionsRDD[611] at parquet at <unknown>:0), which has no missing parents
26/01/12 02:56:20 INFO MemoryStore: Block broadcast_366 stored as values in memory (estimated size 102.6 KiB, free 363.2 MiB)
26/01/12 02:56:20 INFO MemoryStore: Block broadcast_366_piece0 stored as bytes in memory (estimated size 36.8 KiB, free 363.2 MiB)
26/01/12 02:56:20 INFO BlockManagerInfo: Added broadcast_366_piece0 in memory on 02926ee04bc9:45221 (size: 36.8 KiB, free: 365.8 MiB)
26/01/12 02:56:20 INFO SparkContext: Created broadcast 366 from broadcast at DAGScheduler.scala:1513
26/01/12 02:56:20 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 244 (MapPartitionsRDD[611] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0))
26/01/12 02:56:20 INFO TaskSchedulerImpl: Adding task set 244.0 with 1 tasks resource profile 0
26/01/12 02:56:20 INFO TaskSetManager: Starting task 0.0 in stage 244.0 (TID 413) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4607 bytes) taskResourceAssignments Map()
26/01/12 02:56:20 INFO BlockManagerInfo: Added broadcast_366_piece0 in memory on 172.18.0.5:42453 (size: 36.8 KiB, free: 365.8 MiB)
26/01/12 02:56:21 INFO TaskSetManager: Finished task 0.0 in stage 244.0 (TID 413) in 53 ms on 172.18.0.5 (executor 0) (1/1)
26/01/12 02:56:21 INFO TaskSchedulerImpl: Removed TaskSet 244.0, whose tasks have all completed, from pool 
26/01/12 02:56:21 INFO DAGScheduler: ResultStage 244 (parquet at <unknown>:0) finished in 0.070 s
26/01/12 02:56:21 INFO DAGScheduler: Job 244 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:56:21 INFO TaskSchedulerImpl: Killing all running tasks in stage 244: Stage finished
26/01/12 02:56:21 INFO DAGScheduler: Job 244 finished: parquet at <unknown>:0, took 0.075673 s
26/01/12 02:56:21 INFO FileSourceStrategy: Pushed Filters: 
26/01/12 02:56:21 INFO FileSourceStrategy: Post-Scan Filters: 
26/01/12 02:56:21 INFO FileSourceStrategy: Output Data Schema: struct<VendorID: bigint, tpep_pickup_datetime: timestamp, tpep_dropoff_datetime: timestamp, passenger_count: double, trip_distance: double ... 17 more fields>
26/01/12 02:56:21 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:56:21 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:56:21 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:56:21 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:56:21 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:56:21 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:56:21 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:56:21 INFO MemoryStore: Block broadcast_367 stored as values in memory (estimated size 358.5 KiB, free 362.8 MiB)
26/01/12 02:56:21 INFO MemoryStore: Block broadcast_367_piece0 stored as bytes in memory (estimated size 35.3 KiB, free 362.8 MiB)
26/01/12 02:56:21 INFO BlockManagerInfo: Added broadcast_367_piece0 in memory on 02926ee04bc9:45221 (size: 35.3 KiB, free: 365.7 MiB)
26/01/12 02:56:21 INFO SparkContext: Created broadcast 367 from parquet at <unknown>:0
26/01/12 02:56:21 INFO FileSourceScanExec: Planning scan with bin packing, max size: 60105838 bytes, open cost is considered as scanning 4194304 bytes.
26/01/12 02:56:21 INFO BlockManagerInfo: Removed broadcast_359_piece0 on 02926ee04bc9:45221 in memory (size: 77.4 KiB, free: 365.8 MiB)
26/01/12 02:56:21 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 02:56:21 INFO BlockManagerInfo: Removed broadcast_359_piece0 on 172.18.0.5:42453 in memory (size: 77.4 KiB, free: 365.8 MiB)
26/01/12 02:56:21 INFO DAGScheduler: Got job 245 (parquet at <unknown>:0) with 2 output partitions
26/01/12 02:56:21 INFO DAGScheduler: Final stage: ResultStage 245 (parquet at <unknown>:0)
26/01/12 02:56:21 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:56:21 INFO DAGScheduler: Missing parents: List()
26/01/12 02:56:21 INFO DAGScheduler: Submitting ResultStage 245 (MapPartitionsRDD[614] at parquet at <unknown>:0), which has no missing parents
26/01/12 02:56:21 INFO BlockManagerInfo: Removed broadcast_364_piece0 on 02926ee04bc9:45221 in memory (size: 35.3 KiB, free: 365.8 MiB)
26/01/12 02:56:21 INFO BlockManagerInfo: Removed broadcast_364_piece0 on 172.18.0.5:42453 in memory (size: 35.3 KiB, free: 365.9 MiB)
26/01/12 02:56:21 INFO BlockManagerInfo: Removed broadcast_365_piece0 on 02926ee04bc9:45221 in memory (size: 77.4 KiB, free: 365.9 MiB)
26/01/12 02:56:21 INFO BlockManagerInfo: Removed broadcast_365_piece0 on 172.18.0.5:42453 in memory (size: 77.4 KiB, free: 365.9 MiB)
26/01/12 02:56:21 INFO BlockManagerInfo: Removed broadcast_360_piece0 on 02926ee04bc9:45221 in memory (size: 36.8 KiB, free: 365.9 MiB)
26/01/12 02:56:21 INFO BlockManagerInfo: Removed broadcast_360_piece0 on 172.18.0.5:42453 in memory (size: 36.8 KiB, free: 366.0 MiB)
26/01/12 02:56:21 INFO BlockManagerInfo: Removed broadcast_363_piece0 on 02926ee04bc9:45221 in memory (size: 36.8 KiB, free: 366.0 MiB)
26/01/12 02:56:21 INFO BlockManagerInfo: Removed broadcast_363_piece0 on 172.18.0.5:42453 in memory (size: 36.8 KiB, free: 366.0 MiB)
26/01/12 02:56:21 INFO MemoryStore: Block broadcast_368 stored as values in memory (estimated size 225.1 KiB, free 363.8 MiB)
26/01/12 02:56:21 INFO BlockManagerInfo: Removed broadcast_366_piece0 on 02926ee04bc9:45221 in memory (size: 36.8 KiB, free: 366.0 MiB)
26/01/12 02:56:21 INFO MemoryStore: Block broadcast_368_piece0 stored as bytes in memory (estimated size 77.4 KiB, free 363.8 MiB)
26/01/12 02:56:21 INFO BlockManagerInfo: Added broadcast_368_piece0 in memory on 02926ee04bc9:45221 (size: 77.4 KiB, free: 365.9 MiB)
26/01/12 02:56:21 INFO BlockManagerInfo: Removed broadcast_366_piece0 on 172.18.0.5:42453 in memory (size: 36.8 KiB, free: 366.0 MiB)
26/01/12 02:56:21 INFO SparkContext: Created broadcast 368 from broadcast at DAGScheduler.scala:1513
26/01/12 02:56:21 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 245 (MapPartitionsRDD[614] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1))
26/01/12 02:56:21 INFO TaskSchedulerImpl: Adding task set 245.0 with 2 tasks resource profile 0
26/01/12 02:56:21 INFO TaskSetManager: Starting task 0.0 in stage 245.0 (TID 414) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:56:21 INFO TaskSetManager: Starting task 1.0 in stage 245.0 (TID 415) (172.18.0.5, executor 0, partition 1, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:56:21 INFO BlockManagerInfo: Removed broadcast_361_piece0 on 02926ee04bc9:45221 in memory (size: 35.3 KiB, free: 366.0 MiB)
26/01/12 02:56:21 INFO BlockManagerInfo: Removed broadcast_361_piece0 on 172.18.0.5:42453 in memory (size: 35.3 KiB, free: 366.1 MiB)
26/01/12 02:56:21 INFO BlockManagerInfo: Removed broadcast_362_piece0 on 02926ee04bc9:45221 in memory (size: 77.4 KiB, free: 366.0 MiB)
26/01/12 02:56:21 INFO BlockManagerInfo: Added broadcast_368_piece0 in memory on 172.18.0.5:42453 (size: 77.4 KiB, free: 366.0 MiB)
26/01/12 02:56:21 INFO BlockManagerInfo: Removed broadcast_362_piece0 on 172.18.0.5:42453 in memory (size: 77.4 KiB, free: 366.1 MiB)
26/01/12 02:56:21 INFO BlockManagerInfo: Removed broadcast_358_piece0 on 02926ee04bc9:45221 in memory (size: 35.3 KiB, free: 366.1 MiB)
26/01/12 02:56:21 INFO BlockManagerInfo: Removed broadcast_358_piece0 on 172.18.0.5:42453 in memory (size: 35.3 KiB, free: 366.1 MiB)
26/01/12 02:56:21 INFO BlockManagerInfo: Added broadcast_367_piece0 in memory on 172.18.0.5:42453 (size: 35.3 KiB, free: 366.1 MiB)
26/01/12 02:56:21 INFO TaskSetManager: Finished task 1.0 in stage 245.0 (TID 415) in 65 ms on 172.18.0.5 (executor 0) (1/2)
26/01/12 02:56:40 INFO TaskSetManager: Finished task 0.0 in stage 245.0 (TID 414) in 19549 ms on 172.18.0.5 (executor 0) (2/2)
26/01/12 02:56:40 INFO TaskSchedulerImpl: Removed TaskSet 245.0, whose tasks have all completed, from pool 
26/01/12 02:56:40 INFO DAGScheduler: ResultStage 245 (parquet at <unknown>:0) finished in 19.583 s
26/01/12 02:56:40 INFO DAGScheduler: Job 245 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:56:40 INFO TaskSchedulerImpl: Killing all running tasks in stage 245: Stage finished
26/01/12 02:56:40 INFO DAGScheduler: Job 245 finished: parquet at <unknown>:0, took 19.589256 s
26/01/12 02:56:40 INFO FileFormatWriter: Start to commit write Job b305e30d-26df-45fb-8cfb-4a6a6e002d10.
26/01/12 02:56:40 INFO FileFormatWriter: Write Job b305e30d-26df-45fb-8cfb-4a6a6e002d10 committed. Elapsed time: 32 ms.
26/01/12 02:56:40 INFO FileFormatWriter: Finished processing stats for write job b305e30d-26df-45fb-8cfb-4a6a6e002d10.
Cargando: yellow_tripdata_2019-04.parquet en hdfs://hadoop-namenode:8020/data/nyc/raw/taxi-trips/2019...
26/01/12 02:56:40 INFO InMemoryFileIndex: It took 7 ms to list leaf files for 1 paths.
26/01/12 02:56:40 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 02:56:40 INFO DAGScheduler: Got job 246 (parquet at <unknown>:0) with 1 output partitions
26/01/12 02:56:40 INFO DAGScheduler: Final stage: ResultStage 246 (parquet at <unknown>:0)
26/01/12 02:56:40 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:56:40 INFO DAGScheduler: Missing parents: List()
26/01/12 02:56:40 INFO DAGScheduler: Submitting ResultStage 246 (MapPartitionsRDD[616] at parquet at <unknown>:0), which has no missing parents
26/01/12 02:56:40 INFO MemoryStore: Block broadcast_369 stored as values in memory (estimated size 102.6 KiB, free 364.8 MiB)
26/01/12 02:56:40 INFO MemoryStore: Block broadcast_369_piece0 stored as bytes in memory (estimated size 36.8 KiB, free 364.8 MiB)
26/01/12 02:56:40 INFO BlockManagerInfo: Added broadcast_369_piece0 in memory on 02926ee04bc9:45221 (size: 36.8 KiB, free: 366.0 MiB)
26/01/12 02:56:40 INFO SparkContext: Created broadcast 369 from broadcast at DAGScheduler.scala:1513
26/01/12 02:56:40 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 246 (MapPartitionsRDD[616] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0))
26/01/12 02:56:40 INFO TaskSchedulerImpl: Adding task set 246.0 with 1 tasks resource profile 0
26/01/12 02:56:40 INFO TaskSetManager: Starting task 0.0 in stage 246.0 (TID 416) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4607 bytes) taskResourceAssignments Map()
26/01/12 02:56:40 INFO BlockManagerInfo: Added broadcast_369_piece0 in memory on 172.18.0.5:42453 (size: 36.8 KiB, free: 366.0 MiB)
26/01/12 02:56:40 INFO TaskSetManager: Finished task 0.0 in stage 246.0 (TID 416) in 48 ms on 172.18.0.5 (executor 0) (1/1)
26/01/12 02:56:40 INFO TaskSchedulerImpl: Removed TaskSet 246.0, whose tasks have all completed, from pool 
26/01/12 02:56:40 INFO DAGScheduler: ResultStage 246 (parquet at <unknown>:0) finished in 0.060 s
26/01/12 02:56:40 INFO DAGScheduler: Job 246 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:56:40 INFO TaskSchedulerImpl: Killing all running tasks in stage 246: Stage finished
26/01/12 02:56:40 INFO DAGScheduler: Job 246 finished: parquet at <unknown>:0, took 0.064603 s
26/01/12 02:56:40 INFO FileSourceStrategy: Pushed Filters: 
26/01/12 02:56:40 INFO FileSourceStrategy: Post-Scan Filters: 
26/01/12 02:56:40 INFO FileSourceStrategy: Output Data Schema: struct<VendorID: bigint, tpep_pickup_datetime: timestamp, tpep_dropoff_datetime: timestamp, passenger_count: double, trip_distance: double ... 17 more fields>
26/01/12 02:56:40 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:56:40 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:56:40 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:56:40 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:56:40 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:56:40 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:56:40 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:56:40 INFO MemoryStore: Block broadcast_370 stored as values in memory (estimated size 358.5 KiB, free 364.5 MiB)
26/01/12 02:56:40 INFO MemoryStore: Block broadcast_370_piece0 stored as bytes in memory (estimated size 35.3 KiB, free 364.4 MiB)
26/01/12 02:56:40 INFO BlockManagerInfo: Added broadcast_370_piece0 in memory on 02926ee04bc9:45221 (size: 35.3 KiB, free: 366.0 MiB)
26/01/12 02:56:40 INFO SparkContext: Created broadcast 370 from parquet at <unknown>:0
26/01/12 02:56:40 INFO FileSourceScanExec: Planning scan with bin packing, max size: 57166720 bytes, open cost is considered as scanning 4194304 bytes.
26/01/12 02:56:40 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 02:56:40 INFO DAGScheduler: Got job 247 (parquet at <unknown>:0) with 2 output partitions
26/01/12 02:56:40 INFO DAGScheduler: Final stage: ResultStage 247 (parquet at <unknown>:0)
26/01/12 02:56:40 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:56:40 INFO DAGScheduler: Missing parents: List()
26/01/12 02:56:40 INFO DAGScheduler: Submitting ResultStage 247 (MapPartitionsRDD[619] at parquet at <unknown>:0), which has no missing parents
26/01/12 02:56:40 INFO MemoryStore: Block broadcast_371 stored as values in memory (estimated size 225.1 KiB, free 364.2 MiB)
26/01/12 02:56:40 INFO MemoryStore: Block broadcast_371_piece0 stored as bytes in memory (estimated size 77.4 KiB, free 364.1 MiB)
26/01/12 02:56:40 INFO BlockManagerInfo: Added broadcast_371_piece0 in memory on 02926ee04bc9:45221 (size: 77.4 KiB, free: 365.9 MiB)
26/01/12 02:56:40 INFO SparkContext: Created broadcast 371 from broadcast at DAGScheduler.scala:1513
26/01/12 02:56:40 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 247 (MapPartitionsRDD[619] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1))
26/01/12 02:56:40 INFO TaskSchedulerImpl: Adding task set 247.0 with 2 tasks resource profile 0
26/01/12 02:56:40 INFO TaskSetManager: Starting task 0.0 in stage 247.0 (TID 417) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:56:40 INFO TaskSetManager: Starting task 1.0 in stage 247.0 (TID 418) (172.18.0.5, executor 0, partition 1, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:56:40 INFO BlockManagerInfo: Added broadcast_371_piece0 in memory on 172.18.0.5:42453 (size: 77.4 KiB, free: 366.0 MiB)
26/01/12 02:56:40 INFO BlockManagerInfo: Added broadcast_370_piece0 in memory on 172.18.0.5:42453 (size: 35.3 KiB, free: 365.9 MiB)
26/01/12 02:56:41 INFO TaskSetManager: Finished task 1.0 in stage 247.0 (TID 418) in 54 ms on 172.18.0.5 (executor 0) (1/2)
26/01/12 02:56:59 INFO TaskSetManager: Finished task 0.0 in stage 247.0 (TID 417) in 18308 ms on 172.18.0.5 (executor 0) (2/2)
26/01/12 02:56:59 INFO TaskSchedulerImpl: Removed TaskSet 247.0, whose tasks have all completed, from pool 
26/01/12 02:56:59 INFO DAGScheduler: ResultStage 247 (parquet at <unknown>:0) finished in 18.327 s
26/01/12 02:56:59 INFO DAGScheduler: Job 247 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:56:59 INFO TaskSchedulerImpl: Killing all running tasks in stage 247: Stage finished
26/01/12 02:56:59 INFO DAGScheduler: Job 247 finished: parquet at <unknown>:0, took 18.332622 s
26/01/12 02:56:59 INFO FileFormatWriter: Start to commit write Job 9baeb6ee-852a-4876-b08d-9ac42f50796f.
26/01/12 02:56:59 INFO FileFormatWriter: Write Job 9baeb6ee-852a-4876-b08d-9ac42f50796f committed. Elapsed time: 33 ms.
26/01/12 02:56:59 INFO FileFormatWriter: Finished processing stats for write job 9baeb6ee-852a-4876-b08d-9ac42f50796f.
Cargando: yellow_tripdata_2019-05.parquet en hdfs://hadoop-namenode:8020/data/nyc/raw/taxi-trips/2019...
26/01/12 02:56:59 INFO InMemoryFileIndex: It took 5 ms to list leaf files for 1 paths.
26/01/12 02:56:59 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 02:56:59 INFO DAGScheduler: Got job 248 (parquet at <unknown>:0) with 1 output partitions
26/01/12 02:56:59 INFO DAGScheduler: Final stage: ResultStage 248 (parquet at <unknown>:0)
26/01/12 02:56:59 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:56:59 INFO DAGScheduler: Missing parents: List()
26/01/12 02:56:59 INFO DAGScheduler: Submitting ResultStage 248 (MapPartitionsRDD[621] at parquet at <unknown>:0), which has no missing parents
26/01/12 02:56:59 INFO MemoryStore: Block broadcast_372 stored as values in memory (estimated size 102.6 KiB, free 364.0 MiB)
26/01/12 02:56:59 INFO MemoryStore: Block broadcast_372_piece0 stored as bytes in memory (estimated size 36.8 KiB, free 364.0 MiB)
26/01/12 02:56:59 INFO BlockManagerInfo: Added broadcast_372_piece0 in memory on 02926ee04bc9:45221 (size: 36.8 KiB, free: 365.9 MiB)
26/01/12 02:56:59 INFO SparkContext: Created broadcast 372 from broadcast at DAGScheduler.scala:1513
26/01/12 02:56:59 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 248 (MapPartitionsRDD[621] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0))
26/01/12 02:56:59 INFO TaskSchedulerImpl: Adding task set 248.0 with 1 tasks resource profile 0
26/01/12 02:56:59 INFO TaskSetManager: Starting task 0.0 in stage 248.0 (TID 419) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4607 bytes) taskResourceAssignments Map()
26/01/12 02:56:59 INFO BlockManagerInfo: Added broadcast_372_piece0 in memory on 172.18.0.5:42453 (size: 36.8 KiB, free: 365.9 MiB)
26/01/12 02:56:59 INFO TaskSetManager: Finished task 0.0 in stage 248.0 (TID 419) in 46 ms on 172.18.0.5 (executor 0) (1/1)
26/01/12 02:56:59 INFO TaskSchedulerImpl: Removed TaskSet 248.0, whose tasks have all completed, from pool 
26/01/12 02:56:59 INFO DAGScheduler: ResultStage 248 (parquet at <unknown>:0) finished in 0.058 s
26/01/12 02:56:59 INFO DAGScheduler: Job 248 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:56:59 INFO TaskSchedulerImpl: Killing all running tasks in stage 248: Stage finished
26/01/12 02:56:59 INFO DAGScheduler: Job 248 finished: parquet at <unknown>:0, took 0.062229 s
26/01/12 02:56:59 INFO FileSourceStrategy: Pushed Filters: 
26/01/12 02:56:59 INFO FileSourceStrategy: Post-Scan Filters: 
26/01/12 02:56:59 INFO FileSourceStrategy: Output Data Schema: struct<VendorID: bigint, tpep_pickup_datetime: timestamp, tpep_dropoff_datetime: timestamp, passenger_count: double, trip_distance: double ... 17 more fields>
26/01/12 02:56:59 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:56:59 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:56:59 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:56:59 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:56:59 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:56:59 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:56:59 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:56:59 INFO MemoryStore: Block broadcast_373 stored as values in memory (estimated size 358.5 KiB, free 363.6 MiB)
26/01/12 02:56:59 INFO MemoryStore: Block broadcast_373_piece0 stored as bytes in memory (estimated size 35.3 KiB, free 363.6 MiB)
26/01/12 02:56:59 INFO BlockManagerInfo: Added broadcast_373_piece0 in memory on 02926ee04bc9:45221 (size: 35.3 KiB, free: 365.9 MiB)
26/01/12 02:56:59 INFO SparkContext: Created broadcast 373 from parquet at <unknown>:0
26/01/12 02:56:59 INFO FileSourceScanExec: Planning scan with bin packing, max size: 57836623 bytes, open cost is considered as scanning 4194304 bytes.
26/01/12 02:56:59 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 02:56:59 INFO DAGScheduler: Got job 249 (parquet at <unknown>:0) with 2 output partitions
26/01/12 02:56:59 INFO DAGScheduler: Final stage: ResultStage 249 (parquet at <unknown>:0)
26/01/12 02:56:59 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:56:59 INFO DAGScheduler: Missing parents: List()
26/01/12 02:56:59 INFO DAGScheduler: Submitting ResultStage 249 (MapPartitionsRDD[624] at parquet at <unknown>:0), which has no missing parents
26/01/12 02:56:59 INFO MemoryStore: Block broadcast_374 stored as values in memory (estimated size 225.1 KiB, free 363.4 MiB)
26/01/12 02:56:59 INFO MemoryStore: Block broadcast_374_piece0 stored as bytes in memory (estimated size 77.4 KiB, free 363.3 MiB)
26/01/12 02:56:59 INFO BlockManagerInfo: Added broadcast_374_piece0 in memory on 02926ee04bc9:45221 (size: 77.4 KiB, free: 365.8 MiB)
26/01/12 02:56:59 INFO SparkContext: Created broadcast 374 from broadcast at DAGScheduler.scala:1513
26/01/12 02:56:59 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 249 (MapPartitionsRDD[624] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1))
26/01/12 02:56:59 INFO TaskSchedulerImpl: Adding task set 249.0 with 2 tasks resource profile 0
26/01/12 02:56:59 INFO TaskSetManager: Starting task 0.0 in stage 249.0 (TID 420) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:56:59 INFO TaskSetManager: Starting task 1.0 in stage 249.0 (TID 421) (172.18.0.5, executor 0, partition 1, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:56:59 INFO BlockManagerInfo: Added broadcast_374_piece0 in memory on 172.18.0.5:42453 (size: 77.4 KiB, free: 365.8 MiB)
26/01/12 02:56:59 INFO BlockManagerInfo: Added broadcast_373_piece0 in memory on 172.18.0.5:42453 (size: 35.3 KiB, free: 365.8 MiB)
26/01/12 02:56:59 INFO TaskSetManager: Finished task 1.0 in stage 249.0 (TID 421) in 53 ms on 172.18.0.5 (executor 0) (1/2)
26/01/12 02:57:16 INFO TaskSetManager: Finished task 0.0 in stage 249.0 (TID 420) in 17459 ms on 172.18.0.5 (executor 0) (2/2)
26/01/12 02:57:16 INFO TaskSchedulerImpl: Removed TaskSet 249.0, whose tasks have all completed, from pool 
26/01/12 02:57:16 INFO DAGScheduler: ResultStage 249 (parquet at <unknown>:0) finished in 17.478 s
26/01/12 02:57:16 INFO DAGScheduler: Job 249 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:57:16 INFO TaskSchedulerImpl: Killing all running tasks in stage 249: Stage finished
26/01/12 02:57:16 INFO DAGScheduler: Job 249 finished: parquet at <unknown>:0, took 17.485390 s
26/01/12 02:57:16 INFO FileFormatWriter: Start to commit write Job f71d9a86-68b7-4ca5-9af6-a6d270a07fc4.
26/01/12 02:57:16 INFO FileFormatWriter: Write Job f71d9a86-68b7-4ca5-9af6-a6d270a07fc4 committed. Elapsed time: 33 ms.
26/01/12 02:57:16 INFO FileFormatWriter: Finished processing stats for write job f71d9a86-68b7-4ca5-9af6-a6d270a07fc4.
Cargando: yellow_tripdata_2019-06.parquet en hdfs://hadoop-namenode:8020/data/nyc/raw/taxi-trips/2019...
26/01/12 02:57:17 INFO InMemoryFileIndex: It took 6 ms to list leaf files for 1 paths.
26/01/12 02:57:17 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 02:57:17 INFO DAGScheduler: Got job 250 (parquet at <unknown>:0) with 1 output partitions
26/01/12 02:57:17 INFO DAGScheduler: Final stage: ResultStage 250 (parquet at <unknown>:0)
26/01/12 02:57:17 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:57:17 INFO DAGScheduler: Missing parents: List()
26/01/12 02:57:17 INFO DAGScheduler: Submitting ResultStage 250 (MapPartitionsRDD[626] at parquet at <unknown>:0), which has no missing parents
26/01/12 02:57:17 INFO MemoryStore: Block broadcast_375 stored as values in memory (estimated size 102.6 KiB, free 363.2 MiB)
26/01/12 02:57:17 INFO MemoryStore: Block broadcast_375_piece0 stored as bytes in memory (estimated size 36.8 KiB, free 363.2 MiB)
26/01/12 02:57:17 INFO BlockManagerInfo: Added broadcast_375_piece0 in memory on 02926ee04bc9:45221 (size: 36.8 KiB, free: 365.8 MiB)
26/01/12 02:57:17 INFO SparkContext: Created broadcast 375 from broadcast at DAGScheduler.scala:1513
26/01/12 02:57:17 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 250 (MapPartitionsRDD[626] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0))
26/01/12 02:57:17 INFO TaskSchedulerImpl: Adding task set 250.0 with 1 tasks resource profile 0
26/01/12 02:57:17 INFO TaskSetManager: Starting task 0.0 in stage 250.0 (TID 422) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4607 bytes) taskResourceAssignments Map()
26/01/12 02:57:17 INFO BlockManagerInfo: Added broadcast_375_piece0 in memory on 172.18.0.5:42453 (size: 36.8 KiB, free: 365.8 MiB)
26/01/12 02:57:17 INFO TaskSetManager: Finished task 0.0 in stage 250.0 (TID 422) in 49 ms on 172.18.0.5 (executor 0) (1/1)
26/01/12 02:57:17 INFO TaskSchedulerImpl: Removed TaskSet 250.0, whose tasks have all completed, from pool 
26/01/12 02:57:17 INFO DAGScheduler: ResultStage 250 (parquet at <unknown>:0) finished in 0.061 s
26/01/12 02:57:17 INFO DAGScheduler: Job 250 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:57:17 INFO TaskSchedulerImpl: Killing all running tasks in stage 250: Stage finished
26/01/12 02:57:17 INFO DAGScheduler: Job 250 finished: parquet at <unknown>:0, took 0.066749 s
26/01/12 02:57:17 INFO FileSourceStrategy: Pushed Filters: 
26/01/12 02:57:17 INFO FileSourceStrategy: Post-Scan Filters: 
26/01/12 02:57:17 INFO FileSourceStrategy: Output Data Schema: struct<VendorID: bigint, tpep_pickup_datetime: timestamp, tpep_dropoff_datetime: timestamp, passenger_count: double, trip_distance: double ... 17 more fields>
26/01/12 02:57:17 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:57:17 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:57:17 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:57:17 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:57:17 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:57:17 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:57:17 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:57:17 INFO MemoryStore: Block broadcast_376 stored as values in memory (estimated size 358.5 KiB, free 362.8 MiB)
26/01/12 02:57:17 INFO MemoryStore: Block broadcast_376_piece0 stored as bytes in memory (estimated size 35.3 KiB, free 362.8 MiB)
26/01/12 02:57:17 INFO BlockManagerInfo: Added broadcast_376_piece0 in memory on 02926ee04bc9:45221 (size: 35.3 KiB, free: 365.7 MiB)
26/01/12 02:57:17 INFO SparkContext: Created broadcast 376 from parquet at <unknown>:0
26/01/12 02:57:17 INFO FileSourceScanExec: Planning scan with bin packing, max size: 53548824 bytes, open cost is considered as scanning 4194304 bytes.
26/01/12 02:57:17 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 02:57:17 INFO DAGScheduler: Got job 251 (parquet at <unknown>:0) with 2 output partitions
26/01/12 02:57:17 INFO DAGScheduler: Final stage: ResultStage 251 (parquet at <unknown>:0)
26/01/12 02:57:17 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:57:17 INFO DAGScheduler: Missing parents: List()
26/01/12 02:57:17 INFO DAGScheduler: Submitting ResultStage 251 (MapPartitionsRDD[629] at parquet at <unknown>:0), which has no missing parents
26/01/12 02:57:17 INFO MemoryStore: Block broadcast_377 stored as values in memory (estimated size 225.1 KiB, free 362.6 MiB)
26/01/12 02:57:17 INFO MemoryStore: Block broadcast_377_piece0 stored as bytes in memory (estimated size 77.4 KiB, free 362.5 MiB)
26/01/12 02:57:17 INFO BlockManagerInfo: Added broadcast_377_piece0 in memory on 02926ee04bc9:45221 (size: 77.4 KiB, free: 365.6 MiB)
26/01/12 02:57:17 INFO SparkContext: Created broadcast 377 from broadcast at DAGScheduler.scala:1513
26/01/12 02:57:17 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 251 (MapPartitionsRDD[629] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1))
26/01/12 02:57:17 INFO TaskSchedulerImpl: Adding task set 251.0 with 2 tasks resource profile 0
26/01/12 02:57:17 INFO TaskSetManager: Starting task 0.0 in stage 251.0 (TID 423) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:57:17 INFO TaskSetManager: Starting task 1.0 in stage 251.0 (TID 424) (172.18.0.5, executor 0, partition 1, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:57:17 INFO BlockManagerInfo: Removed broadcast_368_piece0 on 02926ee04bc9:45221 in memory (size: 77.4 KiB, free: 365.7 MiB)
26/01/12 02:57:17 INFO BlockManagerInfo: Removed broadcast_368_piece0 on 172.18.0.5:42453 in memory (size: 77.4 KiB, free: 365.8 MiB)
26/01/12 02:57:17 INFO BlockManagerInfo: Removed broadcast_375_piece0 on 02926ee04bc9:45221 in memory (size: 36.8 KiB, free: 365.8 MiB)
26/01/12 02:57:17 INFO BlockManagerInfo: Added broadcast_377_piece0 in memory on 172.18.0.5:42453 (size: 77.4 KiB, free: 365.8 MiB)
26/01/12 02:57:17 INFO BlockManagerInfo: Removed broadcast_375_piece0 on 172.18.0.5:42453 in memory (size: 36.8 KiB, free: 365.8 MiB)
26/01/12 02:57:17 INFO BlockManagerInfo: Removed broadcast_371_piece0 on 02926ee04bc9:45221 in memory (size: 77.4 KiB, free: 365.8 MiB)
26/01/12 02:57:17 INFO BlockManagerInfo: Removed broadcast_371_piece0 on 172.18.0.5:42453 in memory (size: 77.4 KiB, free: 365.9 MiB)
26/01/12 02:57:17 INFO BlockManagerInfo: Removed broadcast_370_piece0 on 02926ee04bc9:45221 in memory (size: 35.3 KiB, free: 365.9 MiB)
26/01/12 02:57:17 INFO BlockManagerInfo: Removed broadcast_370_piece0 on 172.18.0.5:42453 in memory (size: 35.3 KiB, free: 365.9 MiB)
26/01/12 02:57:17 INFO BlockManagerInfo: Removed broadcast_369_piece0 on 02926ee04bc9:45221 in memory (size: 36.8 KiB, free: 365.9 MiB)
26/01/12 02:57:17 INFO BlockManagerInfo: Added broadcast_376_piece0 in memory on 172.18.0.5:42453 (size: 35.3 KiB, free: 365.9 MiB)
26/01/12 02:57:17 INFO BlockManagerInfo: Removed broadcast_369_piece0 on 172.18.0.5:42453 in memory (size: 36.8 KiB, free: 365.9 MiB)
26/01/12 02:57:17 INFO BlockManagerInfo: Removed broadcast_367_piece0 on 02926ee04bc9:45221 in memory (size: 35.3 KiB, free: 365.9 MiB)
26/01/12 02:57:17 INFO BlockManagerInfo: Removed broadcast_367_piece0 on 172.18.0.5:42453 in memory (size: 35.3 KiB, free: 365.9 MiB)
26/01/12 02:57:17 INFO BlockManagerInfo: Removed broadcast_373_piece0 on 02926ee04bc9:45221 in memory (size: 35.3 KiB, free: 366.0 MiB)
26/01/12 02:57:17 INFO BlockManagerInfo: Removed broadcast_373_piece0 on 172.18.0.5:42453 in memory (size: 35.3 KiB, free: 366.0 MiB)
26/01/12 02:57:17 INFO BlockManagerInfo: Removed broadcast_372_piece0 on 02926ee04bc9:45221 in memory (size: 36.8 KiB, free: 366.0 MiB)
26/01/12 02:57:17 INFO BlockManagerInfo: Removed broadcast_372_piece0 on 172.18.0.5:42453 in memory (size: 36.8 KiB, free: 366.0 MiB)
26/01/12 02:57:17 INFO BlockManagerInfo: Removed broadcast_374_piece0 on 02926ee04bc9:45221 in memory (size: 77.4 KiB, free: 366.1 MiB)
26/01/12 02:57:17 INFO BlockManagerInfo: Removed broadcast_374_piece0 on 172.18.0.5:42453 in memory (size: 77.4 KiB, free: 366.1 MiB)
26/01/12 02:57:17 INFO TaskSetManager: Finished task 1.0 in stage 251.0 (TID 424) in 79 ms on 172.18.0.5 (executor 0) (1/2)
26/01/12 02:57:34 INFO TaskSetManager: Finished task 0.0 in stage 251.0 (TID 423) in 17091 ms on 172.18.0.5 (executor 0) (2/2)
26/01/12 02:57:34 INFO TaskSchedulerImpl: Removed TaskSet 251.0, whose tasks have all completed, from pool 
26/01/12 02:57:34 INFO DAGScheduler: ResultStage 251 (parquet at <unknown>:0) finished in 17.131 s
26/01/12 02:57:34 INFO DAGScheduler: Job 251 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:57:34 INFO TaskSchedulerImpl: Killing all running tasks in stage 251: Stage finished
26/01/12 02:57:34 INFO DAGScheduler: Job 251 finished: parquet at <unknown>:0, took 17.139048 s
26/01/12 02:57:34 INFO FileFormatWriter: Start to commit write Job 505728e1-511b-4016-b1cc-00db64722ea2.
26/01/12 02:57:34 INFO FileFormatWriter: Write Job 505728e1-511b-4016-b1cc-00db64722ea2 committed. Elapsed time: 34 ms.
26/01/12 02:57:34 INFO FileFormatWriter: Finished processing stats for write job 505728e1-511b-4016-b1cc-00db64722ea2.
Cargando: yellow_tripdata_2019-07.parquet en hdfs://hadoop-namenode:8020/data/nyc/raw/taxi-trips/2019...
26/01/12 02:57:34 INFO InMemoryFileIndex: It took 6 ms to list leaf files for 1 paths.
26/01/12 02:57:34 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 02:57:34 INFO DAGScheduler: Got job 252 (parquet at <unknown>:0) with 1 output partitions
26/01/12 02:57:34 INFO DAGScheduler: Final stage: ResultStage 252 (parquet at <unknown>:0)
26/01/12 02:57:34 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:57:34 INFO DAGScheduler: Missing parents: List()
26/01/12 02:57:34 INFO DAGScheduler: Submitting ResultStage 252 (MapPartitionsRDD[631] at parquet at <unknown>:0), which has no missing parents
26/01/12 02:57:34 INFO MemoryStore: Block broadcast_378 stored as values in memory (estimated size 102.6 KiB, free 364.8 MiB)
26/01/12 02:57:34 INFO MemoryStore: Block broadcast_378_piece0 stored as bytes in memory (estimated size 36.8 KiB, free 364.8 MiB)
26/01/12 02:57:34 INFO BlockManagerInfo: Added broadcast_378_piece0 in memory on 02926ee04bc9:45221 (size: 36.8 KiB, free: 366.0 MiB)
26/01/12 02:57:34 INFO SparkContext: Created broadcast 378 from broadcast at DAGScheduler.scala:1513
26/01/12 02:57:34 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 252 (MapPartitionsRDD[631] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0))
26/01/12 02:57:34 INFO TaskSchedulerImpl: Adding task set 252.0 with 1 tasks resource profile 0
26/01/12 02:57:34 INFO TaskSetManager: Starting task 0.0 in stage 252.0 (TID 425) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4607 bytes) taskResourceAssignments Map()
26/01/12 02:57:34 INFO BlockManagerInfo: Added broadcast_378_piece0 in memory on 172.18.0.5:42453 (size: 36.8 KiB, free: 366.0 MiB)
26/01/12 02:57:34 INFO TaskSetManager: Finished task 0.0 in stage 252.0 (TID 425) in 48 ms on 172.18.0.5 (executor 0) (1/1)
26/01/12 02:57:34 INFO TaskSchedulerImpl: Removed TaskSet 252.0, whose tasks have all completed, from pool 
26/01/12 02:57:34 INFO DAGScheduler: ResultStage 252 (parquet at <unknown>:0) finished in 0.061 s
26/01/12 02:57:34 INFO DAGScheduler: Job 252 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:57:34 INFO TaskSchedulerImpl: Killing all running tasks in stage 252: Stage finished
26/01/12 02:57:34 INFO DAGScheduler: Job 252 finished: parquet at <unknown>:0, took 0.065555 s
26/01/12 02:57:34 INFO FileSourceStrategy: Pushed Filters: 
26/01/12 02:57:34 INFO FileSourceStrategy: Post-Scan Filters: 
26/01/12 02:57:34 INFO FileSourceStrategy: Output Data Schema: struct<VendorID: bigint, tpep_pickup_datetime: timestamp, tpep_dropoff_datetime: timestamp, passenger_count: double, trip_distance: double ... 17 more fields>
26/01/12 02:57:34 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:57:34 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:57:34 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:57:34 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:57:34 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:57:34 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:57:34 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:57:34 INFO MemoryStore: Block broadcast_379 stored as values in memory (estimated size 358.5 KiB, free 364.5 MiB)
26/01/12 02:57:34 INFO MemoryStore: Block broadcast_379_piece0 stored as bytes in memory (estimated size 35.3 KiB, free 364.4 MiB)
26/01/12 02:57:34 INFO BlockManagerInfo: Added broadcast_379_piece0 in memory on 02926ee04bc9:45221 (size: 35.3 KiB, free: 366.0 MiB)
26/01/12 02:57:34 INFO SparkContext: Created broadcast 379 from parquet at <unknown>:0
26/01/12 02:57:34 INFO FileSourceScanExec: Planning scan with bin packing, max size: 49035823 bytes, open cost is considered as scanning 4194304 bytes.
26/01/12 02:57:34 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 02:57:34 INFO DAGScheduler: Got job 253 (parquet at <unknown>:0) with 2 output partitions
26/01/12 02:57:34 INFO DAGScheduler: Final stage: ResultStage 253 (parquet at <unknown>:0)
26/01/12 02:57:34 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:57:34 INFO DAGScheduler: Missing parents: List()
26/01/12 02:57:34 INFO DAGScheduler: Submitting ResultStage 253 (MapPartitionsRDD[634] at parquet at <unknown>:0), which has no missing parents
26/01/12 02:57:34 INFO MemoryStore: Block broadcast_380 stored as values in memory (estimated size 225.1 KiB, free 364.2 MiB)
26/01/12 02:57:34 INFO MemoryStore: Block broadcast_380_piece0 stored as bytes in memory (estimated size 77.4 KiB, free 364.1 MiB)
26/01/12 02:57:34 INFO BlockManagerInfo: Added broadcast_380_piece0 in memory on 02926ee04bc9:45221 (size: 77.4 KiB, free: 365.9 MiB)
26/01/12 02:57:34 INFO SparkContext: Created broadcast 380 from broadcast at DAGScheduler.scala:1513
26/01/12 02:57:34 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 253 (MapPartitionsRDD[634] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1))
26/01/12 02:57:34 INFO TaskSchedulerImpl: Adding task set 253.0 with 2 tasks resource profile 0
26/01/12 02:57:34 INFO TaskSetManager: Starting task 0.0 in stage 253.0 (TID 426) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:57:34 INFO TaskSetManager: Starting task 1.0 in stage 253.0 (TID 427) (172.18.0.5, executor 0, partition 1, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:57:34 INFO BlockManagerInfo: Added broadcast_380_piece0 in memory on 172.18.0.5:42453 (size: 77.4 KiB, free: 366.0 MiB)
26/01/12 02:57:34 INFO BlockManagerInfo: Added broadcast_379_piece0 in memory on 172.18.0.5:42453 (size: 35.3 KiB, free: 365.9 MiB)
26/01/12 02:57:34 INFO TaskSetManager: Finished task 1.0 in stage 253.0 (TID 427) in 51 ms on 172.18.0.5 (executor 0) (1/2)
26/01/12 02:57:49 INFO TaskSetManager: Finished task 0.0 in stage 253.0 (TID 426) in 15072 ms on 172.18.0.5 (executor 0) (2/2)
26/01/12 02:57:49 INFO TaskSchedulerImpl: Removed TaskSet 253.0, whose tasks have all completed, from pool 
26/01/12 02:57:49 INFO DAGScheduler: ResultStage 253 (parquet at <unknown>:0) finished in 15.092 s
26/01/12 02:57:49 INFO DAGScheduler: Job 253 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:57:49 INFO TaskSchedulerImpl: Killing all running tasks in stage 253: Stage finished
26/01/12 02:57:49 INFO DAGScheduler: Job 253 finished: parquet at <unknown>:0, took 15.098142 s
26/01/12 02:57:49 INFO FileFormatWriter: Start to commit write Job 16617e09-eb5f-4111-a7b0-0423cce8e51d.
26/01/12 02:57:49 INFO FileFormatWriter: Write Job 16617e09-eb5f-4111-a7b0-0423cce8e51d committed. Elapsed time: 33 ms.
26/01/12 02:57:49 INFO FileFormatWriter: Finished processing stats for write job 16617e09-eb5f-4111-a7b0-0423cce8e51d.
Cargando: yellow_tripdata_2019-08.parquet en hdfs://hadoop-namenode:8020/data/nyc/raw/taxi-trips/2019...
26/01/12 02:57:49 INFO InMemoryFileIndex: It took 7 ms to list leaf files for 1 paths.
26/01/12 02:57:49 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 02:57:49 INFO DAGScheduler: Got job 254 (parquet at <unknown>:0) with 1 output partitions
26/01/12 02:57:49 INFO DAGScheduler: Final stage: ResultStage 254 (parquet at <unknown>:0)
26/01/12 02:57:49 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:57:49 INFO DAGScheduler: Missing parents: List()
26/01/12 02:57:49 INFO DAGScheduler: Submitting ResultStage 254 (MapPartitionsRDD[636] at parquet at <unknown>:0), which has no missing parents
26/01/12 02:57:49 INFO MemoryStore: Block broadcast_381 stored as values in memory (estimated size 102.6 KiB, free 364.0 MiB)
26/01/12 02:57:49 INFO MemoryStore: Block broadcast_381_piece0 stored as bytes in memory (estimated size 36.8 KiB, free 364.0 MiB)
26/01/12 02:57:49 INFO BlockManagerInfo: Added broadcast_381_piece0 in memory on 02926ee04bc9:45221 (size: 36.8 KiB, free: 365.9 MiB)
26/01/12 02:57:49 INFO SparkContext: Created broadcast 381 from broadcast at DAGScheduler.scala:1513
26/01/12 02:57:49 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 254 (MapPartitionsRDD[636] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0))
26/01/12 02:57:49 INFO TaskSchedulerImpl: Adding task set 254.0 with 1 tasks resource profile 0
26/01/12 02:57:49 INFO TaskSetManager: Starting task 0.0 in stage 254.0 (TID 428) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4607 bytes) taskResourceAssignments Map()
26/01/12 02:57:49 INFO BlockManagerInfo: Added broadcast_381_piece0 in memory on 172.18.0.5:42453 (size: 36.8 KiB, free: 365.9 MiB)
26/01/12 02:57:49 INFO TaskSetManager: Finished task 0.0 in stage 254.0 (TID 428) in 47 ms on 172.18.0.5 (executor 0) (1/1)
26/01/12 02:57:49 INFO TaskSchedulerImpl: Removed TaskSet 254.0, whose tasks have all completed, from pool 
26/01/12 02:57:49 INFO DAGScheduler: ResultStage 254 (parquet at <unknown>:0) finished in 0.059 s
26/01/12 02:57:49 INFO DAGScheduler: Job 254 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:57:49 INFO TaskSchedulerImpl: Killing all running tasks in stage 254: Stage finished
26/01/12 02:57:49 INFO DAGScheduler: Job 254 finished: parquet at <unknown>:0, took 0.063701 s
26/01/12 02:57:49 INFO FileSourceStrategy: Pushed Filters: 
26/01/12 02:57:49 INFO FileSourceStrategy: Post-Scan Filters: 
26/01/12 02:57:49 INFO FileSourceStrategy: Output Data Schema: struct<VendorID: bigint, tpep_pickup_datetime: timestamp, tpep_dropoff_datetime: timestamp, passenger_count: double, trip_distance: double ... 17 more fields>
26/01/12 02:57:49 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:57:49 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:57:49 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:57:49 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:57:49 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:57:49 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:57:49 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:57:49 INFO MemoryStore: Block broadcast_382 stored as values in memory (estimated size 358.5 KiB, free 363.6 MiB)
26/01/12 02:57:49 INFO MemoryStore: Block broadcast_382_piece0 stored as bytes in memory (estimated size 35.3 KiB, free 363.6 MiB)
26/01/12 02:57:49 INFO BlockManagerInfo: Added broadcast_382_piece0 in memory on 02926ee04bc9:45221 (size: 35.3 KiB, free: 365.9 MiB)
26/01/12 02:57:49 INFO SparkContext: Created broadcast 382 from parquet at <unknown>:0
26/01/12 02:57:49 INFO FileSourceScanExec: Planning scan with bin packing, max size: 47096989 bytes, open cost is considered as scanning 4194304 bytes.
26/01/12 02:57:49 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 02:57:49 INFO DAGScheduler: Got job 255 (parquet at <unknown>:0) with 2 output partitions
26/01/12 02:57:49 INFO DAGScheduler: Final stage: ResultStage 255 (parquet at <unknown>:0)
26/01/12 02:57:49 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:57:49 INFO DAGScheduler: Missing parents: List()
26/01/12 02:57:49 INFO DAGScheduler: Submitting ResultStage 255 (MapPartitionsRDD[639] at parquet at <unknown>:0), which has no missing parents
26/01/12 02:57:49 INFO MemoryStore: Block broadcast_383 stored as values in memory (estimated size 225.1 KiB, free 363.4 MiB)
26/01/12 02:57:49 INFO MemoryStore: Block broadcast_383_piece0 stored as bytes in memory (estimated size 77.4 KiB, free 363.3 MiB)
26/01/12 02:57:49 INFO BlockManagerInfo: Added broadcast_383_piece0 in memory on 02926ee04bc9:45221 (size: 77.4 KiB, free: 365.8 MiB)
26/01/12 02:57:49 INFO SparkContext: Created broadcast 383 from broadcast at DAGScheduler.scala:1513
26/01/12 02:57:49 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 255 (MapPartitionsRDD[639] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1))
26/01/12 02:57:49 INFO TaskSchedulerImpl: Adding task set 255.0 with 2 tasks resource profile 0
26/01/12 02:57:49 INFO TaskSetManager: Starting task 0.0 in stage 255.0 (TID 429) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:57:49 INFO TaskSetManager: Starting task 1.0 in stage 255.0 (TID 430) (172.18.0.5, executor 0, partition 1, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:57:49 INFO BlockManagerInfo: Added broadcast_383_piece0 in memory on 172.18.0.5:42453 (size: 77.4 KiB, free: 365.8 MiB)
26/01/12 02:57:49 INFO BlockManagerInfo: Added broadcast_382_piece0 in memory on 172.18.0.5:42453 (size: 35.3 KiB, free: 365.8 MiB)
26/01/12 02:57:49 INFO TaskSetManager: Finished task 1.0 in stage 255.0 (TID 430) in 63 ms on 172.18.0.5 (executor 0) (1/2)
26/01/12 02:58:04 INFO TaskSetManager: Finished task 0.0 in stage 255.0 (TID 429) in 14810 ms on 172.18.0.5 (executor 0) (2/2)
26/01/12 02:58:04 INFO TaskSchedulerImpl: Removed TaskSet 255.0, whose tasks have all completed, from pool 
26/01/12 02:58:04 INFO DAGScheduler: ResultStage 255 (parquet at <unknown>:0) finished in 14.831 s
26/01/12 02:58:04 INFO DAGScheduler: Job 255 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:58:04 INFO TaskSchedulerImpl: Killing all running tasks in stage 255: Stage finished
26/01/12 02:58:04 INFO DAGScheduler: Job 255 finished: parquet at <unknown>:0, took 14.838306 s
26/01/12 02:58:04 INFO FileFormatWriter: Start to commit write Job 6dd16b0e-ae55-4478-aecd-22da7dfb002d.
26/01/12 02:58:04 INFO FileFormatWriter: Write Job 6dd16b0e-ae55-4478-aecd-22da7dfb002d committed. Elapsed time: 34 ms.
26/01/12 02:58:04 INFO FileFormatWriter: Finished processing stats for write job 6dd16b0e-ae55-4478-aecd-22da7dfb002d.
Cargando: yellow_tripdata_2019-09.parquet en hdfs://hadoop-namenode:8020/data/nyc/raw/taxi-trips/2019...
26/01/12 02:58:04 INFO InMemoryFileIndex: It took 7 ms to list leaf files for 1 paths.
26/01/12 02:58:04 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 02:58:04 INFO DAGScheduler: Got job 256 (parquet at <unknown>:0) with 1 output partitions
26/01/12 02:58:04 INFO DAGScheduler: Final stage: ResultStage 256 (parquet at <unknown>:0)
26/01/12 02:58:04 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:58:04 INFO DAGScheduler: Missing parents: List()
26/01/12 02:58:04 INFO DAGScheduler: Submitting ResultStage 256 (MapPartitionsRDD[641] at parquet at <unknown>:0), which has no missing parents
26/01/12 02:58:04 INFO MemoryStore: Block broadcast_384 stored as values in memory (estimated size 102.6 KiB, free 363.2 MiB)
26/01/12 02:58:04 INFO MemoryStore: Block broadcast_384_piece0 stored as bytes in memory (estimated size 36.8 KiB, free 363.2 MiB)
26/01/12 02:58:04 INFO BlockManagerInfo: Added broadcast_384_piece0 in memory on 02926ee04bc9:45221 (size: 36.8 KiB, free: 365.8 MiB)
26/01/12 02:58:04 INFO SparkContext: Created broadcast 384 from broadcast at DAGScheduler.scala:1513
26/01/12 02:58:04 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 256 (MapPartitionsRDD[641] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0))
26/01/12 02:58:04 INFO TaskSchedulerImpl: Adding task set 256.0 with 1 tasks resource profile 0
26/01/12 02:58:04 INFO TaskSetManager: Starting task 0.0 in stage 256.0 (TID 431) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4607 bytes) taskResourceAssignments Map()
26/01/12 02:58:04 INFO BlockManagerInfo: Added broadcast_384_piece0 in memory on 172.18.0.5:42453 (size: 36.8 KiB, free: 365.8 MiB)
26/01/12 02:58:04 INFO TaskSetManager: Finished task 0.0 in stage 256.0 (TID 431) in 45 ms on 172.18.0.5 (executor 0) (1/1)
26/01/12 02:58:04 INFO TaskSchedulerImpl: Removed TaskSet 256.0, whose tasks have all completed, from pool 
26/01/12 02:58:04 INFO DAGScheduler: ResultStage 256 (parquet at <unknown>:0) finished in 0.057 s
26/01/12 02:58:04 INFO DAGScheduler: Job 256 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:58:04 INFO TaskSchedulerImpl: Killing all running tasks in stage 256: Stage finished
26/01/12 02:58:04 INFO DAGScheduler: Job 256 finished: parquet at <unknown>:0, took 0.061747 s
26/01/12 02:58:04 INFO FileSourceStrategy: Pushed Filters: 
26/01/12 02:58:04 INFO FileSourceStrategy: Post-Scan Filters: 
26/01/12 02:58:04 INFO FileSourceStrategy: Output Data Schema: struct<VendorID: bigint, tpep_pickup_datetime: timestamp, tpep_dropoff_datetime: timestamp, passenger_count: double, trip_distance: double ... 17 more fields>
26/01/12 02:58:04 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:58:04 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:58:04 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:58:04 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:58:04 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:58:04 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:58:04 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:58:04 INFO MemoryStore: Block broadcast_385 stored as values in memory (estimated size 358.5 KiB, free 362.8 MiB)
26/01/12 02:58:04 INFO MemoryStore: Block broadcast_385_piece0 stored as bytes in memory (estimated size 35.3 KiB, free 362.8 MiB)
26/01/12 02:58:04 INFO BlockManagerInfo: Added broadcast_385_piece0 in memory on 02926ee04bc9:45221 (size: 35.3 KiB, free: 365.7 MiB)
26/01/12 02:58:04 INFO SparkContext: Created broadcast 385 from parquet at <unknown>:0
26/01/12 02:58:04 INFO FileSourceScanExec: Planning scan with bin packing, max size: 50652314 bytes, open cost is considered as scanning 4194304 bytes.
26/01/12 02:58:04 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 02:58:04 INFO DAGScheduler: Got job 257 (parquet at <unknown>:0) with 2 output partitions
26/01/12 02:58:04 INFO DAGScheduler: Final stage: ResultStage 257 (parquet at <unknown>:0)
26/01/12 02:58:04 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:58:04 INFO DAGScheduler: Missing parents: List()
26/01/12 02:58:04 INFO DAGScheduler: Submitting ResultStage 257 (MapPartitionsRDD[644] at parquet at <unknown>:0), which has no missing parents
26/01/12 02:58:04 INFO MemoryStore: Block broadcast_386 stored as values in memory (estimated size 225.1 KiB, free 362.6 MiB)
26/01/12 02:58:04 INFO MemoryStore: Block broadcast_386_piece0 stored as bytes in memory (estimated size 77.4 KiB, free 362.5 MiB)
26/01/12 02:58:04 INFO BlockManagerInfo: Added broadcast_386_piece0 in memory on 02926ee04bc9:45221 (size: 77.4 KiB, free: 365.6 MiB)
26/01/12 02:58:04 INFO SparkContext: Created broadcast 386 from broadcast at DAGScheduler.scala:1513
26/01/12 02:58:04 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 257 (MapPartitionsRDD[644] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1))
26/01/12 02:58:04 INFO TaskSchedulerImpl: Adding task set 257.0 with 2 tasks resource profile 0
26/01/12 02:58:04 INFO TaskSetManager: Starting task 0.0 in stage 257.0 (TID 432) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:58:04 INFO TaskSetManager: Starting task 1.0 in stage 257.0 (TID 433) (172.18.0.5, executor 0, partition 1, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:58:04 INFO BlockManagerInfo: Removed broadcast_378_piece0 on 02926ee04bc9:45221 in memory (size: 36.8 KiB, free: 365.7 MiB)
26/01/12 02:58:04 INFO BlockManagerInfo: Removed broadcast_378_piece0 on 172.18.0.5:42453 in memory (size: 36.8 KiB, free: 365.8 MiB)
26/01/12 02:58:04 INFO BlockManagerInfo: Added broadcast_386_piece0 in memory on 172.18.0.5:42453 (size: 77.4 KiB, free: 365.7 MiB)
26/01/12 02:58:04 INFO BlockManagerInfo: Removed broadcast_380_piece0 on 02926ee04bc9:45221 in memory (size: 77.4 KiB, free: 365.8 MiB)
26/01/12 02:58:04 INFO BlockManagerInfo: Removed broadcast_380_piece0 on 172.18.0.5:42453 in memory (size: 77.4 KiB, free: 365.8 MiB)
26/01/12 02:58:04 INFO BlockManagerInfo: Removed broadcast_383_piece0 on 02926ee04bc9:45221 in memory (size: 77.4 KiB, free: 365.8 MiB)
26/01/12 02:58:04 INFO BlockManagerInfo: Removed broadcast_383_piece0 on 172.18.0.5:42453 in memory (size: 77.4 KiB, free: 365.9 MiB)
26/01/12 02:58:04 INFO BlockManagerInfo: Removed broadcast_381_piece0 on 02926ee04bc9:45221 in memory (size: 36.8 KiB, free: 365.9 MiB)
26/01/12 02:58:04 INFO BlockManagerInfo: Removed broadcast_381_piece0 on 172.18.0.5:42453 in memory (size: 36.8 KiB, free: 365.9 MiB)
26/01/12 02:58:04 INFO BlockManagerInfo: Removed broadcast_376_piece0 on 02926ee04bc9:45221 in memory (size: 35.3 KiB, free: 365.9 MiB)
26/01/12 02:58:04 INFO BlockManagerInfo: Removed broadcast_376_piece0 on 172.18.0.5:42453 in memory (size: 35.3 KiB, free: 365.9 MiB)
26/01/12 02:58:04 INFO BlockManagerInfo: Added broadcast_385_piece0 in memory on 172.18.0.5:42453 (size: 35.3 KiB, free: 365.9 MiB)
26/01/12 02:58:04 INFO BlockManagerInfo: Removed broadcast_384_piece0 on 02926ee04bc9:45221 in memory (size: 36.8 KiB, free: 365.9 MiB)
26/01/12 02:58:04 INFO BlockManagerInfo: Removed broadcast_384_piece0 on 172.18.0.5:42453 in memory (size: 36.8 KiB, free: 365.9 MiB)
26/01/12 02:58:04 INFO BlockManagerInfo: Removed broadcast_377_piece0 on 02926ee04bc9:45221 in memory (size: 77.4 KiB, free: 366.0 MiB)
26/01/12 02:58:04 INFO BlockManagerInfo: Removed broadcast_377_piece0 on 172.18.0.5:42453 in memory (size: 77.4 KiB, free: 366.0 MiB)
26/01/12 02:58:04 INFO BlockManagerInfo: Removed broadcast_382_piece0 on 02926ee04bc9:45221 in memory (size: 35.3 KiB, free: 366.0 MiB)
26/01/12 02:58:04 INFO BlockManagerInfo: Removed broadcast_382_piece0 on 172.18.0.5:42453 in memory (size: 35.3 KiB, free: 366.0 MiB)
26/01/12 02:58:04 INFO BlockManagerInfo: Removed broadcast_379_piece0 on 02926ee04bc9:45221 in memory (size: 35.3 KiB, free: 366.1 MiB)
26/01/12 02:58:04 INFO BlockManagerInfo: Removed broadcast_379_piece0 on 172.18.0.5:42453 in memory (size: 35.3 KiB, free: 366.1 MiB)
26/01/12 02:58:04 INFO TaskSetManager: Finished task 1.0 in stage 257.0 (TID 433) in 76 ms on 172.18.0.5 (executor 0) (1/2)
26/01/12 02:58:21 INFO TaskSetManager: Finished task 0.0 in stage 257.0 (TID 432) in 17125 ms on 172.18.0.5 (executor 0) (2/2)
26/01/12 02:58:21 INFO TaskSchedulerImpl: Removed TaskSet 257.0, whose tasks have all completed, from pool 
26/01/12 02:58:21 INFO DAGScheduler: ResultStage 257 (parquet at <unknown>:0) finished in 17.165 s
26/01/12 02:58:21 INFO DAGScheduler: Job 257 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:58:21 INFO TaskSchedulerImpl: Killing all running tasks in stage 257: Stage finished
26/01/12 02:58:21 INFO DAGScheduler: Job 257 finished: parquet at <unknown>:0, took 17.170268 s
26/01/12 02:58:21 INFO FileFormatWriter: Start to commit write Job 8f954a99-1d3e-4b60-8d12-ee516d75a7cc.
26/01/12 02:58:22 INFO FileFormatWriter: Write Job 8f954a99-1d3e-4b60-8d12-ee516d75a7cc committed. Elapsed time: 47 ms.
26/01/12 02:58:22 INFO FileFormatWriter: Finished processing stats for write job 8f954a99-1d3e-4b60-8d12-ee516d75a7cc.
Cargando: yellow_tripdata_2019-10.parquet en hdfs://hadoop-namenode:8020/data/nyc/raw/taxi-trips/2019...
26/01/12 02:58:22 INFO InMemoryFileIndex: It took 7 ms to list leaf files for 1 paths.
26/01/12 02:58:22 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 02:58:22 INFO DAGScheduler: Got job 258 (parquet at <unknown>:0) with 1 output partitions
26/01/12 02:58:22 INFO DAGScheduler: Final stage: ResultStage 258 (parquet at <unknown>:0)
26/01/12 02:58:22 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:58:22 INFO DAGScheduler: Missing parents: List()
26/01/12 02:58:22 INFO DAGScheduler: Submitting ResultStage 258 (MapPartitionsRDD[646] at parquet at <unknown>:0), which has no missing parents
26/01/12 02:58:22 INFO MemoryStore: Block broadcast_387 stored as values in memory (estimated size 102.6 KiB, free 364.8 MiB)
26/01/12 02:58:22 INFO MemoryStore: Block broadcast_387_piece0 stored as bytes in memory (estimated size 36.8 KiB, free 364.8 MiB)
26/01/12 02:58:22 INFO BlockManagerInfo: Added broadcast_387_piece0 in memory on 02926ee04bc9:45221 (size: 36.8 KiB, free: 366.0 MiB)
26/01/12 02:58:22 INFO SparkContext: Created broadcast 387 from broadcast at DAGScheduler.scala:1513
26/01/12 02:58:22 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 258 (MapPartitionsRDD[646] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0))
26/01/12 02:58:22 INFO TaskSchedulerImpl: Adding task set 258.0 with 1 tasks resource profile 0
26/01/12 02:58:22 INFO TaskSetManager: Starting task 0.0 in stage 258.0 (TID 434) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4607 bytes) taskResourceAssignments Map()
26/01/12 02:58:22 INFO BlockManagerInfo: Added broadcast_387_piece0 in memory on 172.18.0.5:42453 (size: 36.8 KiB, free: 366.0 MiB)
26/01/12 02:58:22 INFO TaskSetManager: Finished task 0.0 in stage 258.0 (TID 434) in 45 ms on 172.18.0.5 (executor 0) (1/1)
26/01/12 02:58:22 INFO TaskSchedulerImpl: Removed TaskSet 258.0, whose tasks have all completed, from pool 
26/01/12 02:58:22 INFO DAGScheduler: ResultStage 258 (parquet at <unknown>:0) finished in 0.058 s
26/01/12 02:58:22 INFO DAGScheduler: Job 258 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:58:22 INFO TaskSchedulerImpl: Killing all running tasks in stage 258: Stage finished
26/01/12 02:58:22 INFO DAGScheduler: Job 258 finished: parquet at <unknown>:0, took 0.060291 s
26/01/12 02:58:22 INFO FileSourceStrategy: Pushed Filters: 
26/01/12 02:58:22 INFO FileSourceStrategy: Post-Scan Filters: 
26/01/12 02:58:22 INFO FileSourceStrategy: Output Data Schema: struct<VendorID: bigint, tpep_pickup_datetime: timestamp, tpep_dropoff_datetime: timestamp, passenger_count: double, trip_distance: double ... 17 more fields>
26/01/12 02:58:22 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:58:22 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:58:22 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:58:22 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:58:22 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:58:22 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:58:22 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:58:22 INFO MemoryStore: Block broadcast_388 stored as values in memory (estimated size 358.5 KiB, free 364.5 MiB)
26/01/12 02:58:22 INFO MemoryStore: Block broadcast_388_piece0 stored as bytes in memory (estimated size 35.3 KiB, free 364.4 MiB)
26/01/12 02:58:22 INFO BlockManagerInfo: Added broadcast_388_piece0 in memory on 02926ee04bc9:45221 (size: 35.3 KiB, free: 366.0 MiB)
26/01/12 02:58:22 INFO SparkContext: Created broadcast 388 from parquet at <unknown>:0
26/01/12 02:58:22 INFO FileSourceScanExec: Planning scan with bin packing, max size: 55243838 bytes, open cost is considered as scanning 4194304 bytes.
26/01/12 02:58:22 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 02:58:22 INFO DAGScheduler: Got job 259 (parquet at <unknown>:0) with 2 output partitions
26/01/12 02:58:22 INFO DAGScheduler: Final stage: ResultStage 259 (parquet at <unknown>:0)
26/01/12 02:58:22 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:58:22 INFO DAGScheduler: Missing parents: List()
26/01/12 02:58:22 INFO DAGScheduler: Submitting ResultStage 259 (MapPartitionsRDD[649] at parquet at <unknown>:0), which has no missing parents
26/01/12 02:58:22 INFO MemoryStore: Block broadcast_389 stored as values in memory (estimated size 225.1 KiB, free 364.2 MiB)
26/01/12 02:58:22 INFO MemoryStore: Block broadcast_389_piece0 stored as bytes in memory (estimated size 77.4 KiB, free 364.1 MiB)
26/01/12 02:58:22 INFO BlockManagerInfo: Added broadcast_389_piece0 in memory on 02926ee04bc9:45221 (size: 77.4 KiB, free: 365.9 MiB)
26/01/12 02:58:22 INFO SparkContext: Created broadcast 389 from broadcast at DAGScheduler.scala:1513
26/01/12 02:58:22 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 259 (MapPartitionsRDD[649] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1))
26/01/12 02:58:22 INFO TaskSchedulerImpl: Adding task set 259.0 with 2 tasks resource profile 0
26/01/12 02:58:22 INFO TaskSetManager: Starting task 0.0 in stage 259.0 (TID 435) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:58:22 INFO TaskSetManager: Starting task 1.0 in stage 259.0 (TID 436) (172.18.0.5, executor 0, partition 1, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:58:22 INFO BlockManagerInfo: Added broadcast_389_piece0 in memory on 172.18.0.5:42453 (size: 77.4 KiB, free: 366.0 MiB)
26/01/12 02:58:22 INFO BlockManagerInfo: Added broadcast_388_piece0 in memory on 172.18.0.5:42453 (size: 35.3 KiB, free: 365.9 MiB)
26/01/12 02:58:22 INFO TaskSetManager: Finished task 1.0 in stage 259.0 (TID 436) in 47 ms on 172.18.0.5 (executor 0) (1/2)
26/01/12 02:58:39 INFO TaskSetManager: Finished task 0.0 in stage 259.0 (TID 435) in 17508 ms on 172.18.0.5 (executor 0) (2/2)
26/01/12 02:58:39 INFO TaskSchedulerImpl: Removed TaskSet 259.0, whose tasks have all completed, from pool 
26/01/12 02:58:39 INFO DAGScheduler: ResultStage 259 (parquet at <unknown>:0) finished in 17.527 s
26/01/12 02:58:39 INFO DAGScheduler: Job 259 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:58:39 INFO TaskSchedulerImpl: Killing all running tasks in stage 259: Stage finished
26/01/12 02:58:39 INFO DAGScheduler: Job 259 finished: parquet at <unknown>:0, took 17.533476 s
26/01/12 02:58:39 INFO FileFormatWriter: Start to commit write Job ef9d0915-1b1a-44be-be23-c6581a4770fd.
26/01/12 02:58:39 INFO FileFormatWriter: Write Job ef9d0915-1b1a-44be-be23-c6581a4770fd committed. Elapsed time: 35 ms.
26/01/12 02:58:39 INFO FileFormatWriter: Finished processing stats for write job ef9d0915-1b1a-44be-be23-c6581a4770fd.
Cargando: yellow_tripdata_2019-11.parquet en hdfs://hadoop-namenode:8020/data/nyc/raw/taxi-trips/2019...
26/01/12 02:58:39 INFO InMemoryFileIndex: It took 7 ms to list leaf files for 1 paths.
26/01/12 02:58:39 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 02:58:39 INFO DAGScheduler: Got job 260 (parquet at <unknown>:0) with 1 output partitions
26/01/12 02:58:39 INFO DAGScheduler: Final stage: ResultStage 260 (parquet at <unknown>:0)
26/01/12 02:58:39 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:58:39 INFO DAGScheduler: Missing parents: List()
26/01/12 02:58:39 INFO DAGScheduler: Submitting ResultStage 260 (MapPartitionsRDD[651] at parquet at <unknown>:0), which has no missing parents
26/01/12 02:58:39 INFO MemoryStore: Block broadcast_390 stored as values in memory (estimated size 102.6 KiB, free 364.0 MiB)
26/01/12 02:58:39 INFO MemoryStore: Block broadcast_390_piece0 stored as bytes in memory (estimated size 36.8 KiB, free 364.0 MiB)
26/01/12 02:58:39 INFO BlockManagerInfo: Added broadcast_390_piece0 in memory on 02926ee04bc9:45221 (size: 36.8 KiB, free: 365.9 MiB)
26/01/12 02:58:39 INFO SparkContext: Created broadcast 390 from broadcast at DAGScheduler.scala:1513
26/01/12 02:58:39 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 260 (MapPartitionsRDD[651] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0))
26/01/12 02:58:39 INFO TaskSchedulerImpl: Adding task set 260.0 with 1 tasks resource profile 0
26/01/12 02:58:39 INFO TaskSetManager: Starting task 0.0 in stage 260.0 (TID 437) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4607 bytes) taskResourceAssignments Map()
26/01/12 02:58:39 INFO BlockManagerInfo: Added broadcast_390_piece0 in memory on 172.18.0.5:42453 (size: 36.8 KiB, free: 365.9 MiB)
26/01/12 02:58:39 INFO TaskSetManager: Finished task 0.0 in stage 260.0 (TID 437) in 43 ms on 172.18.0.5 (executor 0) (1/1)
26/01/12 02:58:39 INFO TaskSchedulerImpl: Removed TaskSet 260.0, whose tasks have all completed, from pool 
26/01/12 02:58:39 INFO DAGScheduler: ResultStage 260 (parquet at <unknown>:0) finished in 0.056 s
26/01/12 02:58:39 INFO DAGScheduler: Job 260 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:58:39 INFO TaskSchedulerImpl: Killing all running tasks in stage 260: Stage finished
26/01/12 02:58:39 INFO DAGScheduler: Job 260 finished: parquet at <unknown>:0, took 0.060723 s
26/01/12 02:58:39 INFO FileSourceStrategy: Pushed Filters: 
26/01/12 02:58:39 INFO FileSourceStrategy: Post-Scan Filters: 
26/01/12 02:58:39 INFO FileSourceStrategy: Output Data Schema: struct<VendorID: bigint, tpep_pickup_datetime: timestamp, tpep_dropoff_datetime: timestamp, passenger_count: double, trip_distance: double ... 17 more fields>
26/01/12 02:58:39 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:58:39 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:58:39 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:58:39 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:58:39 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:58:39 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:58:39 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:58:39 INFO MemoryStore: Block broadcast_391 stored as values in memory (estimated size 358.5 KiB, free 363.6 MiB)
26/01/12 02:58:39 INFO MemoryStore: Block broadcast_391_piece0 stored as bytes in memory (estimated size 35.3 KiB, free 363.6 MiB)
26/01/12 02:58:39 INFO BlockManagerInfo: Added broadcast_391_piece0 in memory on 02926ee04bc9:45221 (size: 35.3 KiB, free: 365.9 MiB)
26/01/12 02:58:39 INFO SparkContext: Created broadcast 391 from parquet at <unknown>:0
26/01/12 02:58:39 INFO FileSourceScanExec: Planning scan with bin packing, max size: 52533643 bytes, open cost is considered as scanning 4194304 bytes.
26/01/12 02:58:39 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 02:58:39 INFO DAGScheduler: Got job 261 (parquet at <unknown>:0) with 2 output partitions
26/01/12 02:58:39 INFO DAGScheduler: Final stage: ResultStage 261 (parquet at <unknown>:0)
26/01/12 02:58:39 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:58:39 INFO DAGScheduler: Missing parents: List()
26/01/12 02:58:39 INFO DAGScheduler: Submitting ResultStage 261 (MapPartitionsRDD[654] at parquet at <unknown>:0), which has no missing parents
26/01/12 02:58:39 INFO MemoryStore: Block broadcast_392 stored as values in memory (estimated size 225.1 KiB, free 363.4 MiB)
26/01/12 02:58:39 INFO MemoryStore: Block broadcast_392_piece0 stored as bytes in memory (estimated size 77.4 KiB, free 363.3 MiB)
26/01/12 02:58:39 INFO BlockManagerInfo: Added broadcast_392_piece0 in memory on 02926ee04bc9:45221 (size: 77.4 KiB, free: 365.8 MiB)
26/01/12 02:58:39 INFO SparkContext: Created broadcast 392 from broadcast at DAGScheduler.scala:1513
26/01/12 02:58:39 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 261 (MapPartitionsRDD[654] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1))
26/01/12 02:58:39 INFO TaskSchedulerImpl: Adding task set 261.0 with 2 tasks resource profile 0
26/01/12 02:58:39 INFO TaskSetManager: Starting task 0.0 in stage 261.0 (TID 438) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:58:39 INFO TaskSetManager: Starting task 1.0 in stage 261.0 (TID 439) (172.18.0.5, executor 0, partition 1, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:58:39 INFO BlockManagerInfo: Added broadcast_392_piece0 in memory on 172.18.0.5:42453 (size: 77.4 KiB, free: 365.8 MiB)
26/01/12 02:58:39 INFO BlockManagerInfo: Added broadcast_391_piece0 in memory on 172.18.0.5:42453 (size: 35.3 KiB, free: 365.8 MiB)
26/01/12 02:58:40 INFO TaskSetManager: Finished task 1.0 in stage 261.0 (TID 439) in 50 ms on 172.18.0.5 (executor 0) (1/2)
26/01/12 02:58:56 INFO TaskSetManager: Finished task 0.0 in stage 261.0 (TID 438) in 16859 ms on 172.18.0.5 (executor 0) (2/2)
26/01/12 02:58:56 INFO TaskSchedulerImpl: Removed TaskSet 261.0, whose tasks have all completed, from pool 
26/01/12 02:58:56 INFO DAGScheduler: ResultStage 261 (parquet at <unknown>:0) finished in 16.880 s
26/01/12 02:58:56 INFO DAGScheduler: Job 261 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:58:56 INFO TaskSchedulerImpl: Killing all running tasks in stage 261: Stage finished
26/01/12 02:58:56 INFO DAGScheduler: Job 261 finished: parquet at <unknown>:0, took 16.884619 s
26/01/12 02:58:56 INFO FileFormatWriter: Start to commit write Job 6c0f29b4-42fd-4fa7-a9d9-a689fd8d7cad.
26/01/12 02:58:56 INFO FileFormatWriter: Write Job 6c0f29b4-42fd-4fa7-a9d9-a689fd8d7cad committed. Elapsed time: 31 ms.
26/01/12 02:58:56 INFO FileFormatWriter: Finished processing stats for write job 6c0f29b4-42fd-4fa7-a9d9-a689fd8d7cad.
Cargando: yellow_tripdata_2019-12.parquet en hdfs://hadoop-namenode:8020/data/nyc/raw/taxi-trips/2019...
26/01/12 02:58:56 INFO InMemoryFileIndex: It took 7 ms to list leaf files for 1 paths.
26/01/12 02:58:56 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 02:58:56 INFO DAGScheduler: Got job 262 (parquet at <unknown>:0) with 1 output partitions
26/01/12 02:58:56 INFO DAGScheduler: Final stage: ResultStage 262 (parquet at <unknown>:0)
26/01/12 02:58:56 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:58:56 INFO DAGScheduler: Missing parents: List()
26/01/12 02:58:56 INFO DAGScheduler: Submitting ResultStage 262 (MapPartitionsRDD[656] at parquet at <unknown>:0), which has no missing parents
26/01/12 02:58:56 INFO MemoryStore: Block broadcast_393 stored as values in memory (estimated size 102.6 KiB, free 363.2 MiB)
26/01/12 02:58:56 INFO MemoryStore: Block broadcast_393_piece0 stored as bytes in memory (estimated size 36.8 KiB, free 363.2 MiB)
26/01/12 02:58:56 INFO BlockManagerInfo: Added broadcast_393_piece0 in memory on 02926ee04bc9:45221 (size: 36.8 KiB, free: 365.8 MiB)
26/01/12 02:58:56 INFO SparkContext: Created broadcast 393 from broadcast at DAGScheduler.scala:1513
26/01/12 02:58:56 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 262 (MapPartitionsRDD[656] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0))
26/01/12 02:58:56 INFO TaskSchedulerImpl: Adding task set 262.0 with 1 tasks resource profile 0
26/01/12 02:58:56 INFO TaskSetManager: Starting task 0.0 in stage 262.0 (TID 440) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4607 bytes) taskResourceAssignments Map()
26/01/12 02:58:56 INFO BlockManagerInfo: Added broadcast_393_piece0 in memory on 172.18.0.5:42453 (size: 36.8 KiB, free: 365.8 MiB)
26/01/12 02:58:56 INFO TaskSetManager: Finished task 0.0 in stage 262.0 (TID 440) in 47 ms on 172.18.0.5 (executor 0) (1/1)
26/01/12 02:58:56 INFO TaskSchedulerImpl: Removed TaskSet 262.0, whose tasks have all completed, from pool 
26/01/12 02:58:56 INFO DAGScheduler: ResultStage 262 (parquet at <unknown>:0) finished in 0.059 s
26/01/12 02:58:56 INFO DAGScheduler: Job 262 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:58:56 INFO TaskSchedulerImpl: Killing all running tasks in stage 262: Stage finished
26/01/12 02:58:56 INFO DAGScheduler: Job 262 finished: parquet at <unknown>:0, took 0.062473 s
26/01/12 02:58:56 INFO FileSourceStrategy: Pushed Filters: 
26/01/12 02:58:56 INFO FileSourceStrategy: Post-Scan Filters: 
26/01/12 02:58:56 INFO FileSourceStrategy: Output Data Schema: struct<VendorID: bigint, tpep_pickup_datetime: timestamp, tpep_dropoff_datetime: timestamp, passenger_count: double, trip_distance: double ... 17 more fields>
26/01/12 02:58:56 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:58:56 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:58:56 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:58:56 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:58:56 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:58:56 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:58:56 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:58:56 INFO MemoryStore: Block broadcast_394 stored as values in memory (estimated size 358.5 KiB, free 362.8 MiB)
26/01/12 02:58:56 INFO MemoryStore: Block broadcast_394_piece0 stored as bytes in memory (estimated size 35.3 KiB, free 362.8 MiB)
26/01/12 02:58:56 INFO BlockManagerInfo: Added broadcast_394_piece0 in memory on 02926ee04bc9:45221 (size: 35.3 KiB, free: 365.7 MiB)
26/01/12 02:58:57 INFO SparkContext: Created broadcast 394 from parquet at <unknown>:0
26/01/12 02:58:57 INFO FileSourceScanExec: Planning scan with bin packing, max size: 52619540 bytes, open cost is considered as scanning 4194304 bytes.
26/01/12 02:58:57 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 02:58:57 INFO DAGScheduler: Got job 263 (parquet at <unknown>:0) with 2 output partitions
26/01/12 02:58:57 INFO DAGScheduler: Final stage: ResultStage 263 (parquet at <unknown>:0)
26/01/12 02:58:57 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:58:57 INFO DAGScheduler: Missing parents: List()
26/01/12 02:58:57 INFO DAGScheduler: Submitting ResultStage 263 (MapPartitionsRDD[659] at parquet at <unknown>:0), which has no missing parents
26/01/12 02:58:57 INFO MemoryStore: Block broadcast_395 stored as values in memory (estimated size 225.1 KiB, free 362.6 MiB)
26/01/12 02:58:57 INFO MemoryStore: Block broadcast_395_piece0 stored as bytes in memory (estimated size 77.4 KiB, free 362.5 MiB)
26/01/12 02:58:57 INFO BlockManagerInfo: Added broadcast_395_piece0 in memory on 02926ee04bc9:45221 (size: 77.4 KiB, free: 365.6 MiB)
26/01/12 02:58:57 INFO SparkContext: Created broadcast 395 from broadcast at DAGScheduler.scala:1513
26/01/12 02:58:57 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 263 (MapPartitionsRDD[659] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1))
26/01/12 02:58:57 INFO TaskSchedulerImpl: Adding task set 263.0 with 2 tasks resource profile 0
26/01/12 02:58:57 INFO BlockManagerInfo: Removed broadcast_389_piece0 on 02926ee04bc9:45221 in memory (size: 77.4 KiB, free: 365.7 MiB)
26/01/12 02:58:57 INFO TaskSetManager: Starting task 0.0 in stage 263.0 (TID 441) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:58:57 INFO BlockManagerInfo: Removed broadcast_389_piece0 on 172.18.0.5:42453 in memory (size: 77.4 KiB, free: 365.8 MiB)
26/01/12 02:58:57 INFO TaskSetManager: Starting task 1.0 in stage 263.0 (TID 442) (172.18.0.5, executor 0, partition 1, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:58:57 INFO BlockManagerInfo: Removed broadcast_387_piece0 on 02926ee04bc9:45221 in memory (size: 36.8 KiB, free: 365.8 MiB)
26/01/12 02:58:57 INFO BlockManagerInfo: Removed broadcast_387_piece0 on 172.18.0.5:42453 in memory (size: 36.8 KiB, free: 365.9 MiB)
26/01/12 02:58:57 INFO BlockManagerInfo: Added broadcast_395_piece0 in memory on 172.18.0.5:42453 (size: 77.4 KiB, free: 365.8 MiB)
26/01/12 02:58:57 INFO BlockManagerInfo: Removed broadcast_391_piece0 on 02926ee04bc9:45221 in memory (size: 35.3 KiB, free: 365.8 MiB)
26/01/12 02:58:57 INFO BlockManagerInfo: Removed broadcast_391_piece0 on 172.18.0.5:42453 in memory (size: 35.3 KiB, free: 365.8 MiB)
26/01/12 02:58:57 INFO BlockManagerInfo: Removed broadcast_388_piece0 on 02926ee04bc9:45221 in memory (size: 35.3 KiB, free: 365.8 MiB)
26/01/12 02:58:57 INFO BlockManagerInfo: Removed broadcast_388_piece0 on 172.18.0.5:42453 in memory (size: 35.3 KiB, free: 365.9 MiB)
26/01/12 02:58:57 INFO BlockManagerInfo: Removed broadcast_390_piece0 on 02926ee04bc9:45221 in memory (size: 36.8 KiB, free: 365.9 MiB)
26/01/12 02:58:57 INFO BlockManagerInfo: Removed broadcast_390_piece0 on 172.18.0.5:42453 in memory (size: 36.8 KiB, free: 365.9 MiB)
26/01/12 02:58:57 INFO BlockManagerInfo: Added broadcast_394_piece0 in memory on 172.18.0.5:42453 (size: 35.3 KiB, free: 365.9 MiB)
26/01/12 02:58:57 INFO BlockManagerInfo: Removed broadcast_393_piece0 on 02926ee04bc9:45221 in memory (size: 36.8 KiB, free: 365.9 MiB)
26/01/12 02:58:57 INFO BlockManagerInfo: Removed broadcast_393_piece0 on 172.18.0.5:42453 in memory (size: 36.8 KiB, free: 365.9 MiB)
26/01/12 02:58:57 INFO BlockManagerInfo: Removed broadcast_386_piece0 on 02926ee04bc9:45221 in memory (size: 77.4 KiB, free: 366.0 MiB)
26/01/12 02:58:57 INFO BlockManagerInfo: Removed broadcast_386_piece0 on 172.18.0.5:42453 in memory (size: 77.4 KiB, free: 366.0 MiB)
26/01/12 02:58:57 INFO BlockManagerInfo: Removed broadcast_385_piece0 on 02926ee04bc9:45221 in memory (size: 35.3 KiB, free: 366.0 MiB)
26/01/12 02:58:57 INFO BlockManagerInfo: Removed broadcast_385_piece0 on 172.18.0.5:42453 in memory (size: 35.3 KiB, free: 366.0 MiB)
26/01/12 02:58:57 INFO BlockManagerInfo: Removed broadcast_392_piece0 on 02926ee04bc9:45221 in memory (size: 77.4 KiB, free: 366.1 MiB)
26/01/12 02:58:57 INFO BlockManagerInfo: Removed broadcast_392_piece0 on 172.18.0.5:42453 in memory (size: 77.4 KiB, free: 366.1 MiB)
26/01/12 02:58:57 INFO TaskSetManager: Finished task 1.0 in stage 263.0 (TID 442) in 62 ms on 172.18.0.5 (executor 0) (1/2)
26/01/12 02:59:13 INFO TaskSetManager: Finished task 0.0 in stage 263.0 (TID 441) in 16751 ms on 172.18.0.5 (executor 0) (2/2)
26/01/12 02:59:13 INFO TaskSchedulerImpl: Removed TaskSet 263.0, whose tasks have all completed, from pool 
26/01/12 02:59:13 INFO DAGScheduler: ResultStage 263 (parquet at <unknown>:0) finished in 16.798 s
26/01/12 02:59:13 INFO DAGScheduler: Job 263 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:59:13 INFO TaskSchedulerImpl: Killing all running tasks in stage 263: Stage finished
26/01/12 02:59:13 INFO DAGScheduler: Job 263 finished: parquet at <unknown>:0, took 16.805666 s
26/01/12 02:59:13 INFO FileFormatWriter: Start to commit write Job 49faa0e8-a904-4461-a3be-d0ed0e164602.
26/01/12 02:59:13 INFO FileFormatWriter: Write Job 49faa0e8-a904-4461-a3be-d0ed0e164602 committed. Elapsed time: 32 ms.
26/01/12 02:59:13 INFO FileFormatWriter: Finished processing stats for write job 49faa0e8-a904-4461-a3be-d0ed0e164602.
Cargando: yellow_tripdata_2020-01.parquet en hdfs://hadoop-namenode:8020/data/nyc/raw/taxi-trips/2020...
26/01/12 02:59:13 INFO InMemoryFileIndex: It took 6 ms to list leaf files for 1 paths.
26/01/12 02:59:13 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 02:59:13 INFO DAGScheduler: Got job 264 (parquet at <unknown>:0) with 1 output partitions
26/01/12 02:59:13 INFO DAGScheduler: Final stage: ResultStage 264 (parquet at <unknown>:0)
26/01/12 02:59:13 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:59:13 INFO DAGScheduler: Missing parents: List()
26/01/12 02:59:13 INFO DAGScheduler: Submitting ResultStage 264 (MapPartitionsRDD[661] at parquet at <unknown>:0), which has no missing parents
26/01/12 02:59:13 INFO MemoryStore: Block broadcast_396 stored as values in memory (estimated size 102.6 KiB, free 364.8 MiB)
26/01/12 02:59:13 INFO MemoryStore: Block broadcast_396_piece0 stored as bytes in memory (estimated size 36.8 KiB, free 364.8 MiB)
26/01/12 02:59:13 INFO BlockManagerInfo: Added broadcast_396_piece0 in memory on 02926ee04bc9:45221 (size: 36.8 KiB, free: 366.0 MiB)
26/01/12 02:59:13 INFO SparkContext: Created broadcast 396 from broadcast at DAGScheduler.scala:1513
26/01/12 02:59:13 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 264 (MapPartitionsRDD[661] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0))
26/01/12 02:59:13 INFO TaskSchedulerImpl: Adding task set 264.0 with 1 tasks resource profile 0
26/01/12 02:59:13 INFO TaskSetManager: Starting task 0.0 in stage 264.0 (TID 443) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4607 bytes) taskResourceAssignments Map()
26/01/12 02:59:13 INFO BlockManagerInfo: Added broadcast_396_piece0 in memory on 172.18.0.5:42453 (size: 36.8 KiB, free: 366.0 MiB)
26/01/12 02:59:13 INFO TaskSetManager: Finished task 0.0 in stage 264.0 (TID 443) in 47 ms on 172.18.0.5 (executor 0) (1/1)
26/01/12 02:59:13 INFO TaskSchedulerImpl: Removed TaskSet 264.0, whose tasks have all completed, from pool 
26/01/12 02:59:13 INFO DAGScheduler: ResultStage 264 (parquet at <unknown>:0) finished in 0.059 s
26/01/12 02:59:13 INFO DAGScheduler: Job 264 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:59:13 INFO TaskSchedulerImpl: Killing all running tasks in stage 264: Stage finished
26/01/12 02:59:13 INFO DAGScheduler: Job 264 finished: parquet at <unknown>:0, took 0.063203 s
26/01/12 02:59:13 INFO FileSourceStrategy: Pushed Filters: 
26/01/12 02:59:13 INFO FileSourceStrategy: Post-Scan Filters: 
26/01/12 02:59:13 INFO FileSourceStrategy: Output Data Schema: struct<VendorID: bigint, tpep_pickup_datetime: timestamp, tpep_dropoff_datetime: timestamp, passenger_count: double, trip_distance: double ... 17 more fields>
26/01/12 02:59:13 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:59:13 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:59:13 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:59:13 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:59:13 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:59:13 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:59:13 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:59:13 INFO MemoryStore: Block broadcast_397 stored as values in memory (estimated size 358.5 KiB, free 364.5 MiB)
26/01/12 02:59:13 INFO MemoryStore: Block broadcast_397_piece0 stored as bytes in memory (estimated size 35.3 KiB, free 364.4 MiB)
26/01/12 02:59:13 INFO BlockManagerInfo: Added broadcast_397_piece0 in memory on 02926ee04bc9:45221 (size: 35.3 KiB, free: 366.0 MiB)
26/01/12 02:59:13 INFO SparkContext: Created broadcast 397 from parquet at <unknown>:0
26/01/12 02:59:13 INFO FileSourceScanExec: Planning scan with bin packing, max size: 48878581 bytes, open cost is considered as scanning 4194304 bytes.
26/01/12 02:59:14 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 02:59:14 INFO DAGScheduler: Got job 265 (parquet at <unknown>:0) with 2 output partitions
26/01/12 02:59:14 INFO DAGScheduler: Final stage: ResultStage 265 (parquet at <unknown>:0)
26/01/12 02:59:14 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:59:14 INFO DAGScheduler: Missing parents: List()
26/01/12 02:59:14 INFO DAGScheduler: Submitting ResultStage 265 (MapPartitionsRDD[664] at parquet at <unknown>:0), which has no missing parents
26/01/12 02:59:14 INFO MemoryStore: Block broadcast_398 stored as values in memory (estimated size 225.1 KiB, free 364.2 MiB)
26/01/12 02:59:14 INFO MemoryStore: Block broadcast_398_piece0 stored as bytes in memory (estimated size 77.4 KiB, free 364.1 MiB)
26/01/12 02:59:14 INFO BlockManagerInfo: Added broadcast_398_piece0 in memory on 02926ee04bc9:45221 (size: 77.4 KiB, free: 365.9 MiB)
26/01/12 02:59:14 INFO SparkContext: Created broadcast 398 from broadcast at DAGScheduler.scala:1513
26/01/12 02:59:14 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 265 (MapPartitionsRDD[664] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1))
26/01/12 02:59:14 INFO TaskSchedulerImpl: Adding task set 265.0 with 2 tasks resource profile 0
26/01/12 02:59:14 INFO TaskSetManager: Starting task 0.0 in stage 265.0 (TID 444) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:59:14 INFO TaskSetManager: Starting task 1.0 in stage 265.0 (TID 445) (172.18.0.5, executor 0, partition 1, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:59:14 INFO BlockManagerInfo: Added broadcast_398_piece0 in memory on 172.18.0.5:42453 (size: 77.4 KiB, free: 366.0 MiB)
26/01/12 02:59:14 INFO BlockManagerInfo: Added broadcast_397_piece0 in memory on 172.18.0.5:42453 (size: 35.3 KiB, free: 365.9 MiB)
26/01/12 02:59:14 INFO TaskSetManager: Finished task 1.0 in stage 265.0 (TID 445) in 53 ms on 172.18.0.5 (executor 0) (1/2)
26/01/12 02:59:28 INFO TaskSetManager: Finished task 0.0 in stage 265.0 (TID 444) in 14837 ms on 172.18.0.5 (executor 0) (2/2)
26/01/12 02:59:28 INFO TaskSchedulerImpl: Removed TaskSet 265.0, whose tasks have all completed, from pool 
26/01/12 02:59:28 INFO DAGScheduler: ResultStage 265 (parquet at <unknown>:0) finished in 14.858 s
26/01/12 02:59:28 INFO DAGScheduler: Job 265 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:59:28 INFO TaskSchedulerImpl: Killing all running tasks in stage 265: Stage finished
26/01/12 02:59:28 INFO DAGScheduler: Job 265 finished: parquet at <unknown>:0, took 14.862563 s
26/01/12 02:59:28 INFO FileFormatWriter: Start to commit write Job ef2584c4-a059-49b4-ad93-d8c7044227a2.
26/01/12 02:59:28 INFO FileFormatWriter: Write Job ef2584c4-a059-49b4-ad93-d8c7044227a2 committed. Elapsed time: 30 ms.
26/01/12 02:59:28 INFO FileFormatWriter: Finished processing stats for write job ef2584c4-a059-49b4-ad93-d8c7044227a2.
Cargando: yellow_tripdata_2020-02.parquet en hdfs://hadoop-namenode:8020/data/nyc/raw/taxi-trips/2020...
26/01/12 02:59:28 INFO InMemoryFileIndex: It took 7 ms to list leaf files for 1 paths.
26/01/12 02:59:28 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 02:59:28 INFO DAGScheduler: Got job 266 (parquet at <unknown>:0) with 1 output partitions
26/01/12 02:59:28 INFO DAGScheduler: Final stage: ResultStage 266 (parquet at <unknown>:0)
26/01/12 02:59:28 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:59:28 INFO DAGScheduler: Missing parents: List()
26/01/12 02:59:28 INFO DAGScheduler: Submitting ResultStage 266 (MapPartitionsRDD[666] at parquet at <unknown>:0), which has no missing parents
26/01/12 02:59:28 INFO MemoryStore: Block broadcast_399 stored as values in memory (estimated size 102.6 KiB, free 364.0 MiB)
26/01/12 02:59:28 INFO MemoryStore: Block broadcast_399_piece0 stored as bytes in memory (estimated size 36.8 KiB, free 364.0 MiB)
26/01/12 02:59:28 INFO BlockManagerInfo: Added broadcast_399_piece0 in memory on 02926ee04bc9:45221 (size: 36.8 KiB, free: 365.9 MiB)
26/01/12 02:59:28 INFO SparkContext: Created broadcast 399 from broadcast at DAGScheduler.scala:1513
26/01/12 02:59:28 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 266 (MapPartitionsRDD[666] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0))
26/01/12 02:59:28 INFO TaskSchedulerImpl: Adding task set 266.0 with 1 tasks resource profile 0
26/01/12 02:59:28 INFO TaskSetManager: Starting task 0.0 in stage 266.0 (TID 446) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4607 bytes) taskResourceAssignments Map()
26/01/12 02:59:28 INFO BlockManagerInfo: Added broadcast_399_piece0 in memory on 172.18.0.5:42453 (size: 36.8 KiB, free: 365.9 MiB)
26/01/12 02:59:29 INFO TaskSetManager: Finished task 0.0 in stage 266.0 (TID 446) in 44 ms on 172.18.0.5 (executor 0) (1/1)
26/01/12 02:59:29 INFO TaskSchedulerImpl: Removed TaskSet 266.0, whose tasks have all completed, from pool 
26/01/12 02:59:29 INFO DAGScheduler: ResultStage 266 (parquet at <unknown>:0) finished in 0.055 s
26/01/12 02:59:29 INFO DAGScheduler: Job 266 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:59:29 INFO TaskSchedulerImpl: Killing all running tasks in stage 266: Stage finished
26/01/12 02:59:29 INFO DAGScheduler: Job 266 finished: parquet at <unknown>:0, took 0.059864 s
26/01/12 02:59:29 INFO FileSourceStrategy: Pushed Filters: 
26/01/12 02:59:29 INFO FileSourceStrategy: Post-Scan Filters: 
26/01/12 02:59:29 INFO FileSourceStrategy: Output Data Schema: struct<VendorID: bigint, tpep_pickup_datetime: timestamp, tpep_dropoff_datetime: timestamp, passenger_count: double, trip_distance: double ... 17 more fields>
26/01/12 02:59:29 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:59:29 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:59:29 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:59:29 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:59:29 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:59:29 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:59:29 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:59:29 INFO MemoryStore: Block broadcast_400 stored as values in memory (estimated size 358.5 KiB, free 363.6 MiB)
26/01/12 02:59:29 INFO MemoryStore: Block broadcast_400_piece0 stored as bytes in memory (estimated size 35.3 KiB, free 363.6 MiB)
26/01/12 02:59:29 INFO BlockManagerInfo: Added broadcast_400_piece0 in memory on 02926ee04bc9:45221 (size: 35.3 KiB, free: 365.9 MiB)
26/01/12 02:59:29 INFO SparkContext: Created broadcast 400 from parquet at <unknown>:0
26/01/12 02:59:29 INFO FileSourceScanExec: Planning scan with bin packing, max size: 48164592 bytes, open cost is considered as scanning 4194304 bytes.
26/01/12 02:59:29 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 02:59:29 INFO DAGScheduler: Got job 267 (parquet at <unknown>:0) with 2 output partitions
26/01/12 02:59:29 INFO DAGScheduler: Final stage: ResultStage 267 (parquet at <unknown>:0)
26/01/12 02:59:29 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:59:29 INFO DAGScheduler: Missing parents: List()
26/01/12 02:59:29 INFO DAGScheduler: Submitting ResultStage 267 (MapPartitionsRDD[669] at parquet at <unknown>:0), which has no missing parents
26/01/12 02:59:29 INFO MemoryStore: Block broadcast_401 stored as values in memory (estimated size 225.1 KiB, free 363.4 MiB)
26/01/12 02:59:29 INFO MemoryStore: Block broadcast_401_piece0 stored as bytes in memory (estimated size 77.4 KiB, free 363.3 MiB)
26/01/12 02:59:29 INFO BlockManagerInfo: Added broadcast_401_piece0 in memory on 02926ee04bc9:45221 (size: 77.4 KiB, free: 365.8 MiB)
26/01/12 02:59:29 INFO SparkContext: Created broadcast 401 from broadcast at DAGScheduler.scala:1513
26/01/12 02:59:29 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 267 (MapPartitionsRDD[669] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1))
26/01/12 02:59:29 INFO TaskSchedulerImpl: Adding task set 267.0 with 2 tasks resource profile 0
26/01/12 02:59:29 INFO TaskSetManager: Starting task 0.0 in stage 267.0 (TID 447) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:59:29 INFO TaskSetManager: Starting task 1.0 in stage 267.0 (TID 448) (172.18.0.5, executor 0, partition 1, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:59:29 INFO BlockManagerInfo: Added broadcast_401_piece0 in memory on 172.18.0.5:42453 (size: 77.4 KiB, free: 365.8 MiB)
26/01/12 02:59:29 INFO BlockManagerInfo: Added broadcast_400_piece0 in memory on 172.18.0.5:42453 (size: 35.3 KiB, free: 365.8 MiB)
26/01/12 02:59:29 INFO TaskSetManager: Finished task 1.0 in stage 267.0 (TID 448) in 54 ms on 172.18.0.5 (executor 0) (1/2)
26/01/12 02:59:43 INFO TaskSetManager: Finished task 0.0 in stage 267.0 (TID 447) in 14799 ms on 172.18.0.5 (executor 0) (2/2)
26/01/12 02:59:43 INFO TaskSchedulerImpl: Removed TaskSet 267.0, whose tasks have all completed, from pool 
26/01/12 02:59:43 INFO DAGScheduler: ResultStage 267 (parquet at <unknown>:0) finished in 14.819 s
26/01/12 02:59:43 INFO DAGScheduler: Job 267 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:59:43 INFO TaskSchedulerImpl: Killing all running tasks in stage 267: Stage finished
26/01/12 02:59:43 INFO DAGScheduler: Job 267 finished: parquet at <unknown>:0, took 14.825580 s
26/01/12 02:59:43 INFO FileFormatWriter: Start to commit write Job 5480de5a-0e72-480d-9ebf-142c5e25d1fb.
26/01/12 02:59:43 INFO FileFormatWriter: Write Job 5480de5a-0e72-480d-9ebf-142c5e25d1fb committed. Elapsed time: 30 ms.
26/01/12 02:59:43 INFO FileFormatWriter: Finished processing stats for write job 5480de5a-0e72-480d-9ebf-142c5e25d1fb.
Cargando: yellow_tripdata_2020-03.parquet en hdfs://hadoop-namenode:8020/data/nyc/raw/taxi-trips/2020...
26/01/12 02:59:43 INFO InMemoryFileIndex: It took 8 ms to list leaf files for 1 paths.
26/01/12 02:59:43 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 02:59:43 INFO DAGScheduler: Got job 268 (parquet at <unknown>:0) with 1 output partitions
26/01/12 02:59:43 INFO DAGScheduler: Final stage: ResultStage 268 (parquet at <unknown>:0)
26/01/12 02:59:43 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:59:43 INFO DAGScheduler: Missing parents: List()
26/01/12 02:59:43 INFO DAGScheduler: Submitting ResultStage 268 (MapPartitionsRDD[671] at parquet at <unknown>:0), which has no missing parents
26/01/12 02:59:43 INFO MemoryStore: Block broadcast_402 stored as values in memory (estimated size 102.6 KiB, free 363.2 MiB)
26/01/12 02:59:43 INFO MemoryStore: Block broadcast_402_piece0 stored as bytes in memory (estimated size 36.8 KiB, free 363.2 MiB)
26/01/12 02:59:43 INFO BlockManagerInfo: Added broadcast_402_piece0 in memory on 02926ee04bc9:45221 (size: 36.8 KiB, free: 365.8 MiB)
26/01/12 02:59:43 INFO SparkContext: Created broadcast 402 from broadcast at DAGScheduler.scala:1513
26/01/12 02:59:43 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 268 (MapPartitionsRDD[671] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0))
26/01/12 02:59:43 INFO TaskSchedulerImpl: Adding task set 268.0 with 1 tasks resource profile 0
26/01/12 02:59:43 INFO TaskSetManager: Starting task 0.0 in stage 268.0 (TID 449) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4607 bytes) taskResourceAssignments Map()
26/01/12 02:59:43 INFO BlockManagerInfo: Added broadcast_402_piece0 in memory on 172.18.0.5:42453 (size: 36.8 KiB, free: 365.8 MiB)
26/01/12 02:59:44 INFO TaskSetManager: Finished task 0.0 in stage 268.0 (TID 449) in 46 ms on 172.18.0.5 (executor 0) (1/1)
26/01/12 02:59:44 INFO TaskSchedulerImpl: Removed TaskSet 268.0, whose tasks have all completed, from pool 
26/01/12 02:59:44 INFO DAGScheduler: ResultStage 268 (parquet at <unknown>:0) finished in 0.056 s
26/01/12 02:59:44 INFO DAGScheduler: Job 268 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:59:44 INFO TaskSchedulerImpl: Killing all running tasks in stage 268: Stage finished
26/01/12 02:59:44 INFO DAGScheduler: Job 268 finished: parquet at <unknown>:0, took 0.059305 s
26/01/12 02:59:44 INFO FileSourceStrategy: Pushed Filters: 
26/01/12 02:59:44 INFO FileSourceStrategy: Post-Scan Filters: 
26/01/12 02:59:44 INFO FileSourceStrategy: Output Data Schema: struct<VendorID: bigint, tpep_pickup_datetime: timestamp, tpep_dropoff_datetime: timestamp, passenger_count: double, trip_distance: double ... 17 more fields>
26/01/12 02:59:44 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:59:44 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:59:44 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:59:44 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:59:44 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:59:44 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:59:44 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:59:44 INFO MemoryStore: Block broadcast_403 stored as values in memory (estimated size 358.5 KiB, free 362.8 MiB)
26/01/12 02:59:44 INFO MemoryStore: Block broadcast_403_piece0 stored as bytes in memory (estimated size 35.3 KiB, free 362.8 MiB)
26/01/12 02:59:44 INFO BlockManagerInfo: Added broadcast_403_piece0 in memory on 02926ee04bc9:45221 (size: 35.3 KiB, free: 365.7 MiB)
26/01/12 02:59:44 INFO SparkContext: Created broadcast 403 from parquet at <unknown>:0
26/01/12 02:59:44 INFO FileSourceScanExec: Planning scan with bin packing, max size: 24318447 bytes, open cost is considered as scanning 4194304 bytes.
26/01/12 02:59:44 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 02:59:44 INFO DAGScheduler: Got job 269 (parquet at <unknown>:0) with 2 output partitions
26/01/12 02:59:44 INFO DAGScheduler: Final stage: ResultStage 269 (parquet at <unknown>:0)
26/01/12 02:59:44 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:59:44 INFO DAGScheduler: Missing parents: List()
26/01/12 02:59:44 INFO DAGScheduler: Submitting ResultStage 269 (MapPartitionsRDD[674] at parquet at <unknown>:0), which has no missing parents
26/01/12 02:59:44 INFO MemoryStore: Block broadcast_404 stored as values in memory (estimated size 225.1 KiB, free 362.6 MiB)
26/01/12 02:59:44 INFO MemoryStore: Block broadcast_404_piece0 stored as bytes in memory (estimated size 77.4 KiB, free 362.5 MiB)
26/01/12 02:59:44 INFO BlockManagerInfo: Added broadcast_404_piece0 in memory on 02926ee04bc9:45221 (size: 77.4 KiB, free: 365.6 MiB)
26/01/12 02:59:44 INFO SparkContext: Created broadcast 404 from broadcast at DAGScheduler.scala:1513
26/01/12 02:59:44 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 269 (MapPartitionsRDD[674] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1))
26/01/12 02:59:44 INFO TaskSchedulerImpl: Adding task set 269.0 with 2 tasks resource profile 0
26/01/12 02:59:44 INFO BlockManagerInfo: Removed broadcast_399_piece0 on 02926ee04bc9:45221 in memory (size: 36.8 KiB, free: 365.7 MiB)
26/01/12 02:59:44 INFO TaskSetManager: Starting task 0.0 in stage 269.0 (TID 450) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:59:44 INFO TaskSetManager: Starting task 1.0 in stage 269.0 (TID 451) (172.18.0.5, executor 0, partition 1, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:59:44 INFO BlockManagerInfo: Removed broadcast_399_piece0 on 172.18.0.5:42453 in memory (size: 36.8 KiB, free: 365.8 MiB)
26/01/12 02:59:44 INFO BlockManagerInfo: Removed broadcast_395_piece0 on 02926ee04bc9:45221 in memory (size: 77.4 KiB, free: 365.8 MiB)
26/01/12 02:59:44 INFO BlockManagerInfo: Removed broadcast_395_piece0 on 172.18.0.5:42453 in memory (size: 77.4 KiB, free: 365.9 MiB)
26/01/12 02:59:44 INFO BlockManagerInfo: Added broadcast_404_piece0 in memory on 172.18.0.5:42453 (size: 77.4 KiB, free: 365.8 MiB)
26/01/12 02:59:44 INFO BlockManagerInfo: Removed broadcast_394_piece0 on 02926ee04bc9:45221 in memory (size: 35.3 KiB, free: 365.8 MiB)
26/01/12 02:59:44 INFO BlockManagerInfo: Removed broadcast_394_piece0 on 172.18.0.5:42453 in memory (size: 35.3 KiB, free: 365.8 MiB)
26/01/12 02:59:44 INFO BlockManagerInfo: Removed broadcast_400_piece0 on 02926ee04bc9:45221 in memory (size: 35.3 KiB, free: 365.8 MiB)
26/01/12 02:59:44 INFO BlockManagerInfo: Removed broadcast_400_piece0 on 172.18.0.5:42453 in memory (size: 35.3 KiB, free: 365.9 MiB)
26/01/12 02:59:44 INFO BlockManagerInfo: Added broadcast_403_piece0 in memory on 172.18.0.5:42453 (size: 35.3 KiB, free: 365.8 MiB)
26/01/12 02:59:44 INFO BlockManagerInfo: Removed broadcast_402_piece0 on 02926ee04bc9:45221 in memory (size: 36.8 KiB, free: 365.9 MiB)
26/01/12 02:59:44 INFO BlockManagerInfo: Removed broadcast_402_piece0 on 172.18.0.5:42453 in memory (size: 36.8 KiB, free: 365.9 MiB)
26/01/12 02:59:44 INFO BlockManagerInfo: Removed broadcast_401_piece0 on 02926ee04bc9:45221 in memory (size: 77.4 KiB, free: 365.9 MiB)
26/01/12 02:59:44 INFO BlockManagerInfo: Removed broadcast_401_piece0 on 172.18.0.5:42453 in memory (size: 77.4 KiB, free: 365.9 MiB)
26/01/12 02:59:44 INFO BlockManagerInfo: Removed broadcast_397_piece0 on 02926ee04bc9:45221 in memory (size: 35.3 KiB, free: 366.0 MiB)
26/01/12 02:59:44 INFO BlockManagerInfo: Removed broadcast_397_piece0 on 172.18.0.5:42453 in memory (size: 35.3 KiB, free: 366.0 MiB)
26/01/12 02:59:44 INFO BlockManagerInfo: Removed broadcast_398_piece0 on 02926ee04bc9:45221 in memory (size: 77.4 KiB, free: 366.0 MiB)
26/01/12 02:59:44 INFO BlockManagerInfo: Removed broadcast_398_piece0 on 172.18.0.5:42453 in memory (size: 77.4 KiB, free: 366.0 MiB)
26/01/12 02:59:44 INFO BlockManagerInfo: Removed broadcast_396_piece0 on 02926ee04bc9:45221 in memory (size: 36.8 KiB, free: 366.1 MiB)
26/01/12 02:59:44 INFO BlockManagerInfo: Removed broadcast_396_piece0 on 172.18.0.5:42453 in memory (size: 36.8 KiB, free: 366.1 MiB)
26/01/12 02:59:44 INFO TaskSetManager: Finished task 1.0 in stage 269.0 (TID 451) in 63 ms on 172.18.0.5 (executor 0) (1/2)
26/01/12 02:59:51 INFO TaskSetManager: Finished task 0.0 in stage 269.0 (TID 450) in 7646 ms on 172.18.0.5 (executor 0) (2/2)
26/01/12 02:59:51 INFO TaskSchedulerImpl: Removed TaskSet 269.0, whose tasks have all completed, from pool 
26/01/12 02:59:51 INFO DAGScheduler: ResultStage 269 (parquet at <unknown>:0) finished in 7.688 s
26/01/12 02:59:51 INFO DAGScheduler: Job 269 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:59:51 INFO TaskSchedulerImpl: Killing all running tasks in stage 269: Stage finished
26/01/12 02:59:51 INFO DAGScheduler: Job 269 finished: parquet at <unknown>:0, took 7.693246 s
26/01/12 02:59:51 INFO FileFormatWriter: Start to commit write Job f674bd58-2d2b-46d8-b38c-7a9d8cdd0b20.
26/01/12 02:59:51 INFO FileFormatWriter: Write Job f674bd58-2d2b-46d8-b38c-7a9d8cdd0b20 committed. Elapsed time: 31 ms.
26/01/12 02:59:51 INFO FileFormatWriter: Finished processing stats for write job f674bd58-2d2b-46d8-b38c-7a9d8cdd0b20.
Cargando: yellow_tripdata_2020-04.parquet en hdfs://hadoop-namenode:8020/data/nyc/raw/taxi-trips/2020...
26/01/12 02:59:51 INFO InMemoryFileIndex: It took 7 ms to list leaf files for 1 paths.
26/01/12 02:59:51 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 02:59:51 INFO DAGScheduler: Got job 270 (parquet at <unknown>:0) with 1 output partitions
26/01/12 02:59:51 INFO DAGScheduler: Final stage: ResultStage 270 (parquet at <unknown>:0)
26/01/12 02:59:51 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:59:51 INFO DAGScheduler: Missing parents: List()
26/01/12 02:59:51 INFO DAGScheduler: Submitting ResultStage 270 (MapPartitionsRDD[676] at parquet at <unknown>:0), which has no missing parents
26/01/12 02:59:51 INFO MemoryStore: Block broadcast_405 stored as values in memory (estimated size 102.6 KiB, free 364.8 MiB)
26/01/12 02:59:51 INFO MemoryStore: Block broadcast_405_piece0 stored as bytes in memory (estimated size 36.8 KiB, free 364.8 MiB)
26/01/12 02:59:51 INFO BlockManagerInfo: Added broadcast_405_piece0 in memory on 02926ee04bc9:45221 (size: 36.8 KiB, free: 366.0 MiB)
26/01/12 02:59:51 INFO SparkContext: Created broadcast 405 from broadcast at DAGScheduler.scala:1513
26/01/12 02:59:51 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 270 (MapPartitionsRDD[676] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0))
26/01/12 02:59:51 INFO TaskSchedulerImpl: Adding task set 270.0 with 1 tasks resource profile 0
26/01/12 02:59:51 INFO TaskSetManager: Starting task 0.0 in stage 270.0 (TID 452) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4607 bytes) taskResourceAssignments Map()
26/01/12 02:59:51 INFO BlockManagerInfo: Added broadcast_405_piece0 in memory on 172.18.0.5:42453 (size: 36.8 KiB, free: 366.0 MiB)
26/01/12 02:59:51 INFO TaskSetManager: Finished task 0.0 in stage 270.0 (TID 452) in 43 ms on 172.18.0.5 (executor 0) (1/1)
26/01/12 02:59:51 INFO TaskSchedulerImpl: Removed TaskSet 270.0, whose tasks have all completed, from pool 
26/01/12 02:59:51 INFO DAGScheduler: ResultStage 270 (parquet at <unknown>:0) finished in 0.054 s
26/01/12 02:59:51 INFO DAGScheduler: Job 270 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:59:51 INFO TaskSchedulerImpl: Killing all running tasks in stage 270: Stage finished
26/01/12 02:59:51 INFO DAGScheduler: Job 270 finished: parquet at <unknown>:0, took 0.057687 s
26/01/12 02:59:51 INFO FileSourceStrategy: Pushed Filters: 
26/01/12 02:59:51 INFO FileSourceStrategy: Post-Scan Filters: 
26/01/12 02:59:51 INFO FileSourceStrategy: Output Data Schema: struct<VendorID: bigint, tpep_pickup_datetime: timestamp, tpep_dropoff_datetime: timestamp, passenger_count: double, trip_distance: double ... 17 more fields>
26/01/12 02:59:51 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:59:51 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:59:51 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:59:51 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:59:51 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:59:51 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:59:51 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:59:51 INFO MemoryStore: Block broadcast_406 stored as values in memory (estimated size 358.5 KiB, free 364.5 MiB)
26/01/12 02:59:51 INFO MemoryStore: Block broadcast_406_piece0 stored as bytes in memory (estimated size 35.3 KiB, free 364.4 MiB)
26/01/12 02:59:51 INFO BlockManagerInfo: Added broadcast_406_piece0 in memory on 02926ee04bc9:45221 (size: 35.3 KiB, free: 366.0 MiB)
26/01/12 02:59:51 INFO SparkContext: Created broadcast 406 from parquet at <unknown>:0
26/01/12 02:59:51 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4318462 bytes, open cost is considered as scanning 4194304 bytes.
26/01/12 02:59:51 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 02:59:51 INFO DAGScheduler: Got job 271 (parquet at <unknown>:0) with 2 output partitions
26/01/12 02:59:51 INFO DAGScheduler: Final stage: ResultStage 271 (parquet at <unknown>:0)
26/01/12 02:59:51 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:59:51 INFO DAGScheduler: Missing parents: List()
26/01/12 02:59:51 INFO DAGScheduler: Submitting ResultStage 271 (MapPartitionsRDD[679] at parquet at <unknown>:0), which has no missing parents
26/01/12 02:59:51 INFO MemoryStore: Block broadcast_407 stored as values in memory (estimated size 225.1 KiB, free 364.2 MiB)
26/01/12 02:59:51 INFO MemoryStore: Block broadcast_407_piece0 stored as bytes in memory (estimated size 77.4 KiB, free 364.1 MiB)
26/01/12 02:59:51 INFO BlockManagerInfo: Added broadcast_407_piece0 in memory on 02926ee04bc9:45221 (size: 77.4 KiB, free: 365.9 MiB)
26/01/12 02:59:51 INFO SparkContext: Created broadcast 407 from broadcast at DAGScheduler.scala:1513
26/01/12 02:59:51 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 271 (MapPartitionsRDD[679] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1))
26/01/12 02:59:51 INFO TaskSchedulerImpl: Adding task set 271.0 with 2 tasks resource profile 0
26/01/12 02:59:51 INFO TaskSetManager: Starting task 0.0 in stage 271.0 (TID 453) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:59:51 INFO TaskSetManager: Starting task 1.0 in stage 271.0 (TID 454) (172.18.0.5, executor 0, partition 1, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:59:51 INFO BlockManagerInfo: Added broadcast_407_piece0 in memory on 172.18.0.5:42453 (size: 77.4 KiB, free: 366.0 MiB)
26/01/12 02:59:52 INFO BlockManagerInfo: Added broadcast_406_piece0 in memory on 172.18.0.5:42453 (size: 35.3 KiB, free: 365.9 MiB)
26/01/12 02:59:52 INFO TaskSetManager: Finished task 1.0 in stage 271.0 (TID 454) in 52 ms on 172.18.0.5 (executor 0) (1/2)
26/01/12 02:59:53 INFO TaskSetManager: Finished task 0.0 in stage 271.0 (TID 453) in 1183 ms on 172.18.0.5 (executor 0) (2/2)
26/01/12 02:59:53 INFO TaskSchedulerImpl: Removed TaskSet 271.0, whose tasks have all completed, from pool 
26/01/12 02:59:53 INFO DAGScheduler: ResultStage 271 (parquet at <unknown>:0) finished in 1.209 s
26/01/12 02:59:53 INFO DAGScheduler: Job 271 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:59:53 INFO TaskSchedulerImpl: Killing all running tasks in stage 271: Stage finished
26/01/12 02:59:53 INFO DAGScheduler: Job 271 finished: parquet at <unknown>:0, took 1.213953 s
26/01/12 02:59:53 INFO FileFormatWriter: Start to commit write Job c766f8d6-fc06-4a55-a73b-fdf2f82205a5.
26/01/12 02:59:53 INFO FileFormatWriter: Write Job c766f8d6-fc06-4a55-a73b-fdf2f82205a5 committed. Elapsed time: 27 ms.
26/01/12 02:59:53 INFO FileFormatWriter: Finished processing stats for write job c766f8d6-fc06-4a55-a73b-fdf2f82205a5.
Cargando: yellow_tripdata_2020-05.parquet en hdfs://hadoop-namenode:8020/data/nyc/raw/taxi-trips/2020...
26/01/12 02:59:53 INFO InMemoryFileIndex: It took 5 ms to list leaf files for 1 paths.
26/01/12 02:59:53 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 02:59:53 INFO DAGScheduler: Got job 272 (parquet at <unknown>:0) with 1 output partitions
26/01/12 02:59:53 INFO DAGScheduler: Final stage: ResultStage 272 (parquet at <unknown>:0)
26/01/12 02:59:53 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:59:53 INFO DAGScheduler: Missing parents: List()
26/01/12 02:59:53 INFO DAGScheduler: Submitting ResultStage 272 (MapPartitionsRDD[681] at parquet at <unknown>:0), which has no missing parents
26/01/12 02:59:53 INFO MemoryStore: Block broadcast_408 stored as values in memory (estimated size 102.6 KiB, free 364.0 MiB)
26/01/12 02:59:53 INFO MemoryStore: Block broadcast_408_piece0 stored as bytes in memory (estimated size 36.8 KiB, free 364.0 MiB)
26/01/12 02:59:53 INFO BlockManagerInfo: Added broadcast_408_piece0 in memory on 02926ee04bc9:45221 (size: 36.8 KiB, free: 365.9 MiB)
26/01/12 02:59:53 INFO SparkContext: Created broadcast 408 from broadcast at DAGScheduler.scala:1513
26/01/12 02:59:53 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 272 (MapPartitionsRDD[681] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0))
26/01/12 02:59:53 INFO TaskSchedulerImpl: Adding task set 272.0 with 1 tasks resource profile 0
26/01/12 02:59:53 INFO TaskSetManager: Starting task 0.0 in stage 272.0 (TID 455) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4607 bytes) taskResourceAssignments Map()
26/01/12 02:59:53 INFO BlockManagerInfo: Added broadcast_408_piece0 in memory on 172.18.0.5:42453 (size: 36.8 KiB, free: 365.9 MiB)
26/01/12 02:59:53 INFO TaskSetManager: Finished task 0.0 in stage 272.0 (TID 455) in 46 ms on 172.18.0.5 (executor 0) (1/1)
26/01/12 02:59:53 INFO TaskSchedulerImpl: Removed TaskSet 272.0, whose tasks have all completed, from pool 
26/01/12 02:59:53 INFO DAGScheduler: ResultStage 272 (parquet at <unknown>:0) finished in 0.060 s
26/01/12 02:59:53 INFO DAGScheduler: Job 272 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:59:53 INFO TaskSchedulerImpl: Killing all running tasks in stage 272: Stage finished
26/01/12 02:59:53 INFO DAGScheduler: Job 272 finished: parquet at <unknown>:0, took 0.063236 s
26/01/12 02:59:53 INFO FileSourceStrategy: Pushed Filters: 
26/01/12 02:59:53 INFO FileSourceStrategy: Post-Scan Filters: 
26/01/12 02:59:53 INFO FileSourceStrategy: Output Data Schema: struct<VendorID: bigint, tpep_pickup_datetime: timestamp, tpep_dropoff_datetime: timestamp, passenger_count: double, trip_distance: double ... 17 more fields>
26/01/12 02:59:53 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:59:53 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:59:53 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:59:53 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:59:53 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:59:53 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:59:53 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:59:53 INFO MemoryStore: Block broadcast_409 stored as values in memory (estimated size 358.5 KiB, free 363.6 MiB)
26/01/12 02:59:53 INFO MemoryStore: Block broadcast_409_piece0 stored as bytes in memory (estimated size 35.3 KiB, free 363.6 MiB)
26/01/12 02:59:53 INFO BlockManagerInfo: Added broadcast_409_piece0 in memory on 02926ee04bc9:45221 (size: 35.3 KiB, free: 365.9 MiB)
26/01/12 02:59:53 INFO SparkContext: Created broadcast 409 from parquet at <unknown>:0
26/01/12 02:59:53 INFO FileSourceScanExec: Planning scan with bin packing, max size: 5212084 bytes, open cost is considered as scanning 4194304 bytes.
26/01/12 02:59:53 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 02:59:53 INFO DAGScheduler: Got job 273 (parquet at <unknown>:0) with 2 output partitions
26/01/12 02:59:53 INFO DAGScheduler: Final stage: ResultStage 273 (parquet at <unknown>:0)
26/01/12 02:59:53 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:59:53 INFO DAGScheduler: Missing parents: List()
26/01/12 02:59:53 INFO DAGScheduler: Submitting ResultStage 273 (MapPartitionsRDD[684] at parquet at <unknown>:0), which has no missing parents
26/01/12 02:59:53 INFO MemoryStore: Block broadcast_410 stored as values in memory (estimated size 225.1 KiB, free 363.4 MiB)
26/01/12 02:59:53 INFO MemoryStore: Block broadcast_410_piece0 stored as bytes in memory (estimated size 77.4 KiB, free 363.3 MiB)
26/01/12 02:59:53 INFO BlockManagerInfo: Added broadcast_410_piece0 in memory on 02926ee04bc9:45221 (size: 77.4 KiB, free: 365.8 MiB)
26/01/12 02:59:53 INFO SparkContext: Created broadcast 410 from broadcast at DAGScheduler.scala:1513
26/01/12 02:59:53 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 273 (MapPartitionsRDD[684] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1))
26/01/12 02:59:53 INFO TaskSchedulerImpl: Adding task set 273.0 with 2 tasks resource profile 0
26/01/12 02:59:53 INFO TaskSetManager: Starting task 0.0 in stage 273.0 (TID 456) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:59:53 INFO TaskSetManager: Starting task 1.0 in stage 273.0 (TID 457) (172.18.0.5, executor 0, partition 1, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:59:53 INFO BlockManagerInfo: Added broadcast_410_piece0 in memory on 172.18.0.5:42453 (size: 77.4 KiB, free: 365.8 MiB)
26/01/12 02:59:53 INFO BlockManagerInfo: Added broadcast_409_piece0 in memory on 172.18.0.5:42453 (size: 35.3 KiB, free: 365.8 MiB)
26/01/12 02:59:53 INFO TaskSetManager: Finished task 1.0 in stage 273.0 (TID 457) in 54 ms on 172.18.0.5 (executor 0) (1/2)
26/01/12 02:59:54 INFO TaskSetManager: Finished task 0.0 in stage 273.0 (TID 456) in 1417 ms on 172.18.0.5 (executor 0) (2/2)
26/01/12 02:59:54 INFO TaskSchedulerImpl: Removed TaskSet 273.0, whose tasks have all completed, from pool 
26/01/12 02:59:54 INFO DAGScheduler: ResultStage 273 (parquet at <unknown>:0) finished in 1.438 s
26/01/12 02:59:54 INFO DAGScheduler: Job 273 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:59:54 INFO TaskSchedulerImpl: Killing all running tasks in stage 273: Stage finished
26/01/12 02:59:54 INFO DAGScheduler: Job 273 finished: parquet at <unknown>:0, took 1.442912 s
26/01/12 02:59:54 INFO FileFormatWriter: Start to commit write Job e4299d0c-1957-4ad6-aab0-fdb1cf914009.
26/01/12 02:59:54 INFO FileFormatWriter: Write Job e4299d0c-1957-4ad6-aab0-fdb1cf914009 committed. Elapsed time: 28 ms.
26/01/12 02:59:54 INFO FileFormatWriter: Finished processing stats for write job e4299d0c-1957-4ad6-aab0-fdb1cf914009.
Cargando: yellow_tripdata_2020-06.parquet en hdfs://hadoop-namenode:8020/data/nyc/raw/taxi-trips/2020...
26/01/12 02:59:54 INFO InMemoryFileIndex: It took 6 ms to list leaf files for 1 paths.
26/01/12 02:59:54 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 02:59:54 INFO DAGScheduler: Got job 274 (parquet at <unknown>:0) with 1 output partitions
26/01/12 02:59:54 INFO DAGScheduler: Final stage: ResultStage 274 (parquet at <unknown>:0)
26/01/12 02:59:54 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:59:54 INFO DAGScheduler: Missing parents: List()
26/01/12 02:59:54 INFO DAGScheduler: Submitting ResultStage 274 (MapPartitionsRDD[686] at parquet at <unknown>:0), which has no missing parents
26/01/12 02:59:54 INFO MemoryStore: Block broadcast_411 stored as values in memory (estimated size 102.6 KiB, free 363.2 MiB)
26/01/12 02:59:54 INFO MemoryStore: Block broadcast_411_piece0 stored as bytes in memory (estimated size 36.8 KiB, free 363.2 MiB)
26/01/12 02:59:54 INFO BlockManagerInfo: Added broadcast_411_piece0 in memory on 02926ee04bc9:45221 (size: 36.8 KiB, free: 365.8 MiB)
26/01/12 02:59:54 INFO SparkContext: Created broadcast 411 from broadcast at DAGScheduler.scala:1513
26/01/12 02:59:54 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 274 (MapPartitionsRDD[686] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0))
26/01/12 02:59:54 INFO TaskSchedulerImpl: Adding task set 274.0 with 1 tasks resource profile 0
26/01/12 02:59:54 INFO TaskSetManager: Starting task 0.0 in stage 274.0 (TID 458) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4607 bytes) taskResourceAssignments Map()
26/01/12 02:59:54 INFO BlockManagerInfo: Added broadcast_411_piece0 in memory on 172.18.0.5:42453 (size: 36.8 KiB, free: 365.8 MiB)
26/01/12 02:59:54 INFO TaskSetManager: Finished task 0.0 in stage 274.0 (TID 458) in 49 ms on 172.18.0.5 (executor 0) (1/1)
26/01/12 02:59:54 INFO TaskSchedulerImpl: Removed TaskSet 274.0, whose tasks have all completed, from pool 
26/01/12 02:59:54 INFO DAGScheduler: ResultStage 274 (parquet at <unknown>:0) finished in 0.060 s
26/01/12 02:59:54 INFO DAGScheduler: Job 274 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:59:54 INFO TaskSchedulerImpl: Killing all running tasks in stage 274: Stage finished
26/01/12 02:59:54 INFO DAGScheduler: Job 274 finished: parquet at <unknown>:0, took 0.063351 s
26/01/12 02:59:54 INFO FileSourceStrategy: Pushed Filters: 
26/01/12 02:59:54 INFO FileSourceStrategy: Post-Scan Filters: 
26/01/12 02:59:54 INFO FileSourceStrategy: Output Data Schema: struct<VendorID: bigint, tpep_pickup_datetime: timestamp, tpep_dropoff_datetime: timestamp, passenger_count: double, trip_distance: double ... 17 more fields>
26/01/12 02:59:54 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:59:54 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:59:54 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:59:54 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:59:54 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:59:54 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:59:54 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:59:54 INFO MemoryStore: Block broadcast_412 stored as values in memory (estimated size 358.5 KiB, free 362.8 MiB)
26/01/12 02:59:54 INFO MemoryStore: Block broadcast_412_piece0 stored as bytes in memory (estimated size 35.3 KiB, free 362.8 MiB)
26/01/12 02:59:54 INFO BlockManagerInfo: Added broadcast_412_piece0 in memory on 02926ee04bc9:45221 (size: 35.3 KiB, free: 365.7 MiB)
26/01/12 02:59:54 INFO SparkContext: Created broadcast 412 from parquet at <unknown>:0
26/01/12 02:59:54 INFO FileSourceScanExec: Planning scan with bin packing, max size: 6849831 bytes, open cost is considered as scanning 4194304 bytes.
26/01/12 02:59:55 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 02:59:55 INFO DAGScheduler: Got job 275 (parquet at <unknown>:0) with 2 output partitions
26/01/12 02:59:55 INFO DAGScheduler: Final stage: ResultStage 275 (parquet at <unknown>:0)
26/01/12 02:59:55 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:59:55 INFO DAGScheduler: Missing parents: List()
26/01/12 02:59:55 INFO DAGScheduler: Submitting ResultStage 275 (MapPartitionsRDD[689] at parquet at <unknown>:0), which has no missing parents
26/01/12 02:59:55 INFO BlockManagerInfo: Removed broadcast_406_piece0 on 02926ee04bc9:45221 in memory (size: 35.3 KiB, free: 365.8 MiB)
26/01/12 02:59:55 INFO BlockManagerInfo: Removed broadcast_406_piece0 on 172.18.0.5:42453 in memory (size: 35.3 KiB, free: 365.8 MiB)
26/01/12 02:59:55 INFO BlockManagerInfo: Removed broadcast_404_piece0 on 02926ee04bc9:45221 in memory (size: 77.4 KiB, free: 365.8 MiB)
26/01/12 02:59:55 INFO BlockManagerInfo: Removed broadcast_404_piece0 on 172.18.0.5:42453 in memory (size: 77.4 KiB, free: 365.9 MiB)
26/01/12 02:59:55 INFO MemoryStore: Block broadcast_413 stored as values in memory (estimated size 225.1 KiB, free 363.2 MiB)
26/01/12 02:59:55 INFO BlockManagerInfo: Removed broadcast_411_piece0 on 02926ee04bc9:45221 in memory (size: 36.8 KiB, free: 365.9 MiB)
26/01/12 02:59:55 INFO BlockManagerInfo: Removed broadcast_411_piece0 on 172.18.0.5:42453 in memory (size: 36.8 KiB, free: 365.9 MiB)
26/01/12 02:59:55 INFO MemoryStore: Block broadcast_413_piece0 stored as bytes in memory (estimated size 77.4 KiB, free 363.3 MiB)
26/01/12 02:59:55 INFO BlockManagerInfo: Added broadcast_413_piece0 in memory on 02926ee04bc9:45221 (size: 77.4 KiB, free: 365.8 MiB)
26/01/12 02:59:55 INFO SparkContext: Created broadcast 413 from broadcast at DAGScheduler.scala:1513
26/01/12 02:59:55 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 275 (MapPartitionsRDD[689] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1))
26/01/12 02:59:55 INFO TaskSchedulerImpl: Adding task set 275.0 with 2 tasks resource profile 0
26/01/12 02:59:55 INFO TaskSetManager: Starting task 0.0 in stage 275.0 (TID 459) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:59:55 INFO TaskSetManager: Starting task 1.0 in stage 275.0 (TID 460) (172.18.0.5, executor 0, partition 1, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:59:55 INFO BlockManagerInfo: Removed broadcast_409_piece0 on 02926ee04bc9:45221 in memory (size: 35.3 KiB, free: 365.8 MiB)
26/01/12 02:59:55 INFO BlockManagerInfo: Removed broadcast_409_piece0 on 172.18.0.5:42453 in memory (size: 35.3 KiB, free: 365.9 MiB)
26/01/12 02:59:55 INFO BlockManagerInfo: Removed broadcast_408_piece0 on 02926ee04bc9:45221 in memory (size: 36.8 KiB, free: 365.9 MiB)
26/01/12 02:59:55 INFO BlockManagerInfo: Removed broadcast_408_piece0 on 172.18.0.5:42453 in memory (size: 36.8 KiB, free: 366.0 MiB)
26/01/12 02:59:55 INFO BlockManagerInfo: Added broadcast_413_piece0 in memory on 172.18.0.5:42453 (size: 77.4 KiB, free: 365.9 MiB)
26/01/12 02:59:55 INFO BlockManagerInfo: Removed broadcast_407_piece0 on 02926ee04bc9:45221 in memory (size: 77.4 KiB, free: 365.9 MiB)
26/01/12 02:59:55 INFO BlockManagerInfo: Removed broadcast_407_piece0 on 172.18.0.5:42453 in memory (size: 77.4 KiB, free: 366.0 MiB)
26/01/12 02:59:55 INFO BlockManagerInfo: Removed broadcast_410_piece0 on 02926ee04bc9:45221 in memory (size: 77.4 KiB, free: 366.0 MiB)
26/01/12 02:59:55 INFO BlockManagerInfo: Removed broadcast_410_piece0 on 172.18.0.5:42453 in memory (size: 77.4 KiB, free: 366.0 MiB)
26/01/12 02:59:55 INFO BlockManagerInfo: Removed broadcast_405_piece0 on 02926ee04bc9:45221 in memory (size: 36.8 KiB, free: 366.0 MiB)
26/01/12 02:59:55 INFO BlockManagerInfo: Removed broadcast_405_piece0 on 172.18.0.5:42453 in memory (size: 36.8 KiB, free: 366.1 MiB)
26/01/12 02:59:55 INFO BlockManagerInfo: Removed broadcast_403_piece0 on 02926ee04bc9:45221 in memory (size: 35.3 KiB, free: 366.1 MiB)
26/01/12 02:59:55 INFO BlockManagerInfo: Added broadcast_412_piece0 in memory on 172.18.0.5:42453 (size: 35.3 KiB, free: 366.0 MiB)
26/01/12 02:59:55 INFO BlockManagerInfo: Removed broadcast_403_piece0 on 172.18.0.5:42453 in memory (size: 35.3 KiB, free: 366.1 MiB)
26/01/12 02:59:55 INFO TaskSetManager: Finished task 1.0 in stage 275.0 (TID 460) in 56 ms on 172.18.0.5 (executor 0) (1/2)
26/01/12 02:59:56 INFO TaskSetManager: Finished task 0.0 in stage 275.0 (TID 459) in 1499 ms on 172.18.0.5 (executor 0) (2/2)
26/01/12 02:59:56 INFO TaskSchedulerImpl: Removed TaskSet 275.0, whose tasks have all completed, from pool 
26/01/12 02:59:56 INFO DAGScheduler: ResultStage 275 (parquet at <unknown>:0) finished in 1.526 s
26/01/12 02:59:56 INFO DAGScheduler: Job 275 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:59:56 INFO TaskSchedulerImpl: Killing all running tasks in stage 275: Stage finished
26/01/12 02:59:56 INFO DAGScheduler: Job 275 finished: parquet at <unknown>:0, took 1.529685 s
26/01/12 02:59:56 INFO FileFormatWriter: Start to commit write Job b23155ed-0f33-43ed-afcb-154716975096.
26/01/12 02:59:56 INFO FileFormatWriter: Write Job b23155ed-0f33-43ed-afcb-154716975096 committed. Elapsed time: 25 ms.
26/01/12 02:59:56 INFO FileFormatWriter: Finished processing stats for write job b23155ed-0f33-43ed-afcb-154716975096.
Cargando: yellow_tripdata_2020-07.parquet en hdfs://hadoop-namenode:8020/data/nyc/raw/taxi-trips/2020...
26/01/12 02:59:56 INFO InMemoryFileIndex: It took 6 ms to list leaf files for 1 paths.
26/01/12 02:59:56 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 02:59:56 INFO DAGScheduler: Got job 276 (parquet at <unknown>:0) with 1 output partitions
26/01/12 02:59:56 INFO DAGScheduler: Final stage: ResultStage 276 (parquet at <unknown>:0)
26/01/12 02:59:56 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:59:56 INFO DAGScheduler: Missing parents: List()
26/01/12 02:59:56 INFO DAGScheduler: Submitting ResultStage 276 (MapPartitionsRDD[691] at parquet at <unknown>:0), which has no missing parents
26/01/12 02:59:56 INFO MemoryStore: Block broadcast_414 stored as values in memory (estimated size 102.6 KiB, free 364.8 MiB)
26/01/12 02:59:56 INFO MemoryStore: Block broadcast_414_piece0 stored as bytes in memory (estimated size 36.8 KiB, free 364.8 MiB)
26/01/12 02:59:56 INFO BlockManagerInfo: Added broadcast_414_piece0 in memory on 02926ee04bc9:45221 (size: 36.8 KiB, free: 366.0 MiB)
26/01/12 02:59:56 INFO SparkContext: Created broadcast 414 from broadcast at DAGScheduler.scala:1513
26/01/12 02:59:56 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 276 (MapPartitionsRDD[691] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0))
26/01/12 02:59:56 INFO TaskSchedulerImpl: Adding task set 276.0 with 1 tasks resource profile 0
26/01/12 02:59:56 INFO TaskSetManager: Starting task 0.0 in stage 276.0 (TID 461) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4607 bytes) taskResourceAssignments Map()
26/01/12 02:59:56 INFO BlockManagerInfo: Added broadcast_414_piece0 in memory on 172.18.0.5:42453 (size: 36.8 KiB, free: 366.0 MiB)
26/01/12 02:59:56 INFO TaskSetManager: Finished task 0.0 in stage 276.0 (TID 461) in 46 ms on 172.18.0.5 (executor 0) (1/1)
26/01/12 02:59:56 INFO TaskSchedulerImpl: Removed TaskSet 276.0, whose tasks have all completed, from pool 
26/01/12 02:59:56 INFO DAGScheduler: ResultStage 276 (parquet at <unknown>:0) finished in 0.056 s
26/01/12 02:59:56 INFO DAGScheduler: Job 276 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:59:56 INFO TaskSchedulerImpl: Killing all running tasks in stage 276: Stage finished
26/01/12 02:59:56 INFO DAGScheduler: Job 276 finished: parquet at <unknown>:0, took 0.059387 s
26/01/12 02:59:56 INFO FileSourceStrategy: Pushed Filters: 
26/01/12 02:59:56 INFO FileSourceStrategy: Post-Scan Filters: 
26/01/12 02:59:56 INFO FileSourceStrategy: Output Data Schema: struct<VendorID: bigint, tpep_pickup_datetime: timestamp, tpep_dropoff_datetime: timestamp, passenger_count: double, trip_distance: double ... 17 more fields>
26/01/12 02:59:56 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:59:56 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:59:56 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:59:56 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:59:56 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:59:56 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:59:56 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:59:56 INFO MemoryStore: Block broadcast_415 stored as values in memory (estimated size 358.5 KiB, free 364.5 MiB)
26/01/12 02:59:56 INFO MemoryStore: Block broadcast_415_piece0 stored as bytes in memory (estimated size 35.3 KiB, free 364.4 MiB)
26/01/12 02:59:56 INFO BlockManagerInfo: Added broadcast_415_piece0 in memory on 02926ee04bc9:45221 (size: 35.3 KiB, free: 366.0 MiB)
26/01/12 02:59:56 INFO SparkContext: Created broadcast 415 from parquet at <unknown>:0
26/01/12 02:59:56 INFO FileSourceScanExec: Planning scan with bin packing, max size: 8791041 bytes, open cost is considered as scanning 4194304 bytes.
26/01/12 02:59:56 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 02:59:56 INFO DAGScheduler: Got job 277 (parquet at <unknown>:0) with 2 output partitions
26/01/12 02:59:56 INFO DAGScheduler: Final stage: ResultStage 277 (parquet at <unknown>:0)
26/01/12 02:59:56 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:59:56 INFO DAGScheduler: Missing parents: List()
26/01/12 02:59:56 INFO DAGScheduler: Submitting ResultStage 277 (MapPartitionsRDD[694] at parquet at <unknown>:0), which has no missing parents
26/01/12 02:59:56 INFO MemoryStore: Block broadcast_416 stored as values in memory (estimated size 225.1 KiB, free 364.2 MiB)
26/01/12 02:59:56 INFO MemoryStore: Block broadcast_416_piece0 stored as bytes in memory (estimated size 77.4 KiB, free 364.1 MiB)
26/01/12 02:59:56 INFO BlockManagerInfo: Added broadcast_416_piece0 in memory on 02926ee04bc9:45221 (size: 77.4 KiB, free: 365.9 MiB)
26/01/12 02:59:56 INFO SparkContext: Created broadcast 416 from broadcast at DAGScheduler.scala:1513
26/01/12 02:59:56 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 277 (MapPartitionsRDD[694] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1))
26/01/12 02:59:56 INFO TaskSchedulerImpl: Adding task set 277.0 with 2 tasks resource profile 0
26/01/12 02:59:56 INFO TaskSetManager: Starting task 0.0 in stage 277.0 (TID 462) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:59:56 INFO TaskSetManager: Starting task 1.0 in stage 277.0 (TID 463) (172.18.0.5, executor 0, partition 1, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:59:56 INFO BlockManagerInfo: Added broadcast_416_piece0 in memory on 172.18.0.5:42453 (size: 77.4 KiB, free: 366.0 MiB)
26/01/12 02:59:56 INFO BlockManagerInfo: Added broadcast_415_piece0 in memory on 172.18.0.5:42453 (size: 35.3 KiB, free: 365.9 MiB)
26/01/12 02:59:56 INFO TaskSetManager: Finished task 1.0 in stage 277.0 (TID 463) in 49 ms on 172.18.0.5 (executor 0) (1/2)
26/01/12 02:59:59 INFO TaskSetManager: Finished task 0.0 in stage 277.0 (TID 462) in 2467 ms on 172.18.0.5 (executor 0) (2/2)
26/01/12 02:59:59 INFO TaskSchedulerImpl: Removed TaskSet 277.0, whose tasks have all completed, from pool 
26/01/12 02:59:59 INFO DAGScheduler: ResultStage 277 (parquet at <unknown>:0) finished in 2.488 s
26/01/12 02:59:59 INFO DAGScheduler: Job 277 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:59:59 INFO TaskSchedulerImpl: Killing all running tasks in stage 277: Stage finished
26/01/12 02:59:59 INFO DAGScheduler: Job 277 finished: parquet at <unknown>:0, took 2.491514 s
26/01/12 02:59:59 INFO FileFormatWriter: Start to commit write Job c62cc319-d760-40f8-8a2a-efe4d9770905.
26/01/12 02:59:59 INFO FileFormatWriter: Write Job c62cc319-d760-40f8-8a2a-efe4d9770905 committed. Elapsed time: 24 ms.
26/01/12 02:59:59 INFO FileFormatWriter: Finished processing stats for write job c62cc319-d760-40f8-8a2a-efe4d9770905.
Cargando: yellow_tripdata_2020-08.parquet en hdfs://hadoop-namenode:8020/data/nyc/raw/taxi-trips/2020...
26/01/12 02:59:59 INFO InMemoryFileIndex: It took 6 ms to list leaf files for 1 paths.
26/01/12 02:59:59 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 02:59:59 INFO DAGScheduler: Got job 278 (parquet at <unknown>:0) with 1 output partitions
26/01/12 02:59:59 INFO DAGScheduler: Final stage: ResultStage 278 (parquet at <unknown>:0)
26/01/12 02:59:59 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:59:59 INFO DAGScheduler: Missing parents: List()
26/01/12 02:59:59 INFO DAGScheduler: Submitting ResultStage 278 (MapPartitionsRDD[696] at parquet at <unknown>:0), which has no missing parents
26/01/12 02:59:59 INFO MemoryStore: Block broadcast_417 stored as values in memory (estimated size 102.6 KiB, free 364.0 MiB)
26/01/12 02:59:59 INFO MemoryStore: Block broadcast_417_piece0 stored as bytes in memory (estimated size 36.8 KiB, free 364.0 MiB)
26/01/12 02:59:59 INFO BlockManagerInfo: Added broadcast_417_piece0 in memory on 02926ee04bc9:45221 (size: 36.8 KiB, free: 365.9 MiB)
26/01/12 02:59:59 INFO SparkContext: Created broadcast 417 from broadcast at DAGScheduler.scala:1513
26/01/12 02:59:59 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 278 (MapPartitionsRDD[696] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0))
26/01/12 02:59:59 INFO TaskSchedulerImpl: Adding task set 278.0 with 1 tasks resource profile 0
26/01/12 02:59:59 INFO TaskSetManager: Starting task 0.0 in stage 278.0 (TID 464) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4607 bytes) taskResourceAssignments Map()
26/01/12 02:59:59 INFO BlockManagerInfo: Added broadcast_417_piece0 in memory on 172.18.0.5:42453 (size: 36.8 KiB, free: 365.9 MiB)
26/01/12 02:59:59 INFO TaskSetManager: Finished task 0.0 in stage 278.0 (TID 464) in 44 ms on 172.18.0.5 (executor 0) (1/1)
26/01/12 02:59:59 INFO TaskSchedulerImpl: Removed TaskSet 278.0, whose tasks have all completed, from pool 
26/01/12 02:59:59 INFO DAGScheduler: ResultStage 278 (parquet at <unknown>:0) finished in 0.055 s
26/01/12 02:59:59 INFO DAGScheduler: Job 278 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 02:59:59 INFO TaskSchedulerImpl: Killing all running tasks in stage 278: Stage finished
26/01/12 02:59:59 INFO DAGScheduler: Job 278 finished: parquet at <unknown>:0, took 0.057058 s
26/01/12 02:59:59 INFO FileSourceStrategy: Pushed Filters: 
26/01/12 02:59:59 INFO FileSourceStrategy: Post-Scan Filters: 
26/01/12 02:59:59 INFO FileSourceStrategy: Output Data Schema: struct<VendorID: bigint, tpep_pickup_datetime: timestamp, tpep_dropoff_datetime: timestamp, passenger_count: double, trip_distance: double ... 17 more fields>
26/01/12 02:59:59 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:59:59 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:59:59 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:59:59 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:59:59 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 02:59:59 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 02:59:59 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 02:59:59 INFO CodeGenerator: Code generated in 16.222921 ms
26/01/12 02:59:59 INFO MemoryStore: Block broadcast_418 stored as values in memory (estimated size 358.5 KiB, free 363.6 MiB)
26/01/12 02:59:59 INFO MemoryStore: Block broadcast_418_piece0 stored as bytes in memory (estimated size 35.4 KiB, free 363.6 MiB)
26/01/12 02:59:59 INFO BlockManagerInfo: Added broadcast_418_piece0 in memory on 02926ee04bc9:45221 (size: 35.4 KiB, free: 365.9 MiB)
26/01/12 02:59:59 INFO SparkContext: Created broadcast 418 from parquet at <unknown>:0
26/01/12 02:59:59 INFO FileSourceScanExec: Planning scan with bin packing, max size: 10397883 bytes, open cost is considered as scanning 4194304 bytes.
26/01/12 02:59:59 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 02:59:59 INFO DAGScheduler: Got job 279 (parquet at <unknown>:0) with 2 output partitions
26/01/12 02:59:59 INFO DAGScheduler: Final stage: ResultStage 279 (parquet at <unknown>:0)
26/01/12 02:59:59 INFO DAGScheduler: Parents of final stage: List()
26/01/12 02:59:59 INFO DAGScheduler: Missing parents: List()
26/01/12 02:59:59 INFO DAGScheduler: Submitting ResultStage 279 (MapPartitionsRDD[699] at parquet at <unknown>:0), which has no missing parents
26/01/12 02:59:59 INFO MemoryStore: Block broadcast_419 stored as values in memory (estimated size 225.0 KiB, free 363.4 MiB)
26/01/12 02:59:59 INFO MemoryStore: Block broadcast_419_piece0 stored as bytes in memory (estimated size 77.3 KiB, free 363.3 MiB)
26/01/12 02:59:59 INFO BlockManagerInfo: Added broadcast_419_piece0 in memory on 02926ee04bc9:45221 (size: 77.3 KiB, free: 365.8 MiB)
26/01/12 02:59:59 INFO SparkContext: Created broadcast 419 from broadcast at DAGScheduler.scala:1513
26/01/12 02:59:59 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 279 (MapPartitionsRDD[699] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1))
26/01/12 02:59:59 INFO TaskSchedulerImpl: Adding task set 279.0 with 2 tasks resource profile 0
26/01/12 02:59:59 INFO TaskSetManager: Starting task 0.0 in stage 279.0 (TID 465) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:59:59 INFO TaskSetManager: Starting task 1.0 in stage 279.0 (TID 466) (172.18.0.5, executor 0, partition 1, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 02:59:59 INFO BlockManagerInfo: Added broadcast_419_piece0 in memory on 172.18.0.5:42453 (size: 77.3 KiB, free: 365.8 MiB)
26/01/12 02:59:59 INFO BlockManagerInfo: Added broadcast_418_piece0 in memory on 172.18.0.5:42453 (size: 35.4 KiB, free: 365.8 MiB)
26/01/12 02:59:59 INFO TaskSetManager: Finished task 1.0 in stage 279.0 (TID 466) in 77 ms on 172.18.0.5 (executor 0) (1/2)
26/01/12 03:00:02 INFO TaskSetManager: Finished task 0.0 in stage 279.0 (TID 465) in 2816 ms on 172.18.0.5 (executor 0) (2/2)
26/01/12 03:00:02 INFO TaskSchedulerImpl: Removed TaskSet 279.0, whose tasks have all completed, from pool 
26/01/12 03:00:02 INFO DAGScheduler: ResultStage 279 (parquet at <unknown>:0) finished in 2.841 s
26/01/12 03:00:02 INFO DAGScheduler: Job 279 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 03:00:02 INFO TaskSchedulerImpl: Killing all running tasks in stage 279: Stage finished
26/01/12 03:00:02 INFO DAGScheduler: Job 279 finished: parquet at <unknown>:0, took 2.845048 s
26/01/12 03:00:02 INFO FileFormatWriter: Start to commit write Job ffde5102-2c3a-4529-8637-3dd0175f4d60.
26/01/12 03:00:02 INFO FileFormatWriter: Write Job ffde5102-2c3a-4529-8637-3dd0175f4d60 committed. Elapsed time: 19 ms.
26/01/12 03:00:02 INFO FileFormatWriter: Finished processing stats for write job ffde5102-2c3a-4529-8637-3dd0175f4d60.
Cargando: yellow_tripdata_2020-09.parquet en hdfs://hadoop-namenode:8020/data/nyc/raw/taxi-trips/2020...
26/01/12 03:00:02 INFO InMemoryFileIndex: It took 5 ms to list leaf files for 1 paths.
26/01/12 03:00:02 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 03:00:02 INFO DAGScheduler: Got job 280 (parquet at <unknown>:0) with 1 output partitions
26/01/12 03:00:02 INFO DAGScheduler: Final stage: ResultStage 280 (parquet at <unknown>:0)
26/01/12 03:00:02 INFO DAGScheduler: Parents of final stage: List()
26/01/12 03:00:02 INFO DAGScheduler: Missing parents: List()
26/01/12 03:00:02 INFO DAGScheduler: Submitting ResultStage 280 (MapPartitionsRDD[701] at parquet at <unknown>:0), which has no missing parents
26/01/12 03:00:02 INFO MemoryStore: Block broadcast_420 stored as values in memory (estimated size 102.6 KiB, free 363.2 MiB)
26/01/12 03:00:02 INFO MemoryStore: Block broadcast_420_piece0 stored as bytes in memory (estimated size 36.8 KiB, free 363.2 MiB)
26/01/12 03:00:02 INFO BlockManagerInfo: Added broadcast_420_piece0 in memory on 02926ee04bc9:45221 (size: 36.8 KiB, free: 365.8 MiB)
26/01/12 03:00:02 INFO SparkContext: Created broadcast 420 from broadcast at DAGScheduler.scala:1513
26/01/12 03:00:02 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 280 (MapPartitionsRDD[701] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0))
26/01/12 03:00:02 INFO TaskSchedulerImpl: Adding task set 280.0 with 1 tasks resource profile 0
26/01/12 03:00:02 INFO TaskSetManager: Starting task 0.0 in stage 280.0 (TID 467) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4607 bytes) taskResourceAssignments Map()
26/01/12 03:00:02 INFO BlockManagerInfo: Added broadcast_420_piece0 in memory on 172.18.0.5:42453 (size: 36.8 KiB, free: 365.8 MiB)
26/01/12 03:00:02 INFO TaskSetManager: Finished task 0.0 in stage 280.0 (TID 467) in 44 ms on 172.18.0.5 (executor 0) (1/1)
26/01/12 03:00:02 INFO TaskSchedulerImpl: Removed TaskSet 280.0, whose tasks have all completed, from pool 
26/01/12 03:00:02 INFO DAGScheduler: ResultStage 280 (parquet at <unknown>:0) finished in 0.054 s
26/01/12 03:00:02 INFO DAGScheduler: Job 280 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 03:00:02 INFO TaskSchedulerImpl: Killing all running tasks in stage 280: Stage finished
26/01/12 03:00:02 INFO DAGScheduler: Job 280 finished: parquet at <unknown>:0, took 0.056803 s
26/01/12 03:00:02 INFO FileSourceStrategy: Pushed Filters: 
26/01/12 03:00:02 INFO FileSourceStrategy: Post-Scan Filters: 
26/01/12 03:00:02 INFO FileSourceStrategy: Output Data Schema: struct<VendorID: bigint, tpep_pickup_datetime: timestamp, tpep_dropoff_datetime: timestamp, passenger_count: double, trip_distance: double ... 17 more fields>
26/01/12 03:00:02 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 03:00:02 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 03:00:02 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 03:00:02 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 03:00:02 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 03:00:02 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 03:00:02 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 03:00:02 INFO MemoryStore: Block broadcast_421 stored as values in memory (estimated size 358.5 KiB, free 362.8 MiB)
26/01/12 03:00:02 INFO MemoryStore: Block broadcast_421_piece0 stored as bytes in memory (estimated size 35.4 KiB, free 362.8 MiB)
26/01/12 03:00:02 INFO BlockManagerInfo: Added broadcast_421_piece0 in memory on 02926ee04bc9:45221 (size: 35.4 KiB, free: 365.7 MiB)
26/01/12 03:00:02 INFO SparkContext: Created broadcast 421 from parquet at <unknown>:0
26/01/12 03:00:02 INFO FileSourceScanExec: Planning scan with bin packing, max size: 12788121 bytes, open cost is considered as scanning 4194304 bytes.
26/01/12 03:00:02 INFO BlockManagerInfo: Removed broadcast_420_piece0 on 172.18.0.5:42453 in memory (size: 36.8 KiB, free: 365.8 MiB)
26/01/12 03:00:02 INFO BlockManagerInfo: Removed broadcast_420_piece0 on 02926ee04bc9:45221 in memory (size: 36.8 KiB, free: 365.8 MiB)
26/01/12 03:00:02 INFO BlockManagerInfo: Removed broadcast_414_piece0 on 02926ee04bc9:45221 in memory (size: 36.8 KiB, free: 365.8 MiB)
26/01/12 03:00:02 INFO BlockManagerInfo: Removed broadcast_414_piece0 on 172.18.0.5:42453 in memory (size: 36.8 KiB, free: 365.8 MiB)
26/01/12 03:00:02 INFO BlockManagerInfo: Removed broadcast_417_piece0 on 02926ee04bc9:45221 in memory (size: 36.8 KiB, free: 365.8 MiB)
26/01/12 03:00:02 INFO BlockManagerInfo: Removed broadcast_417_piece0 on 172.18.0.5:42453 in memory (size: 36.8 KiB, free: 365.9 MiB)
26/01/12 03:00:02 INFO BlockManagerInfo: Removed broadcast_415_piece0 on 02926ee04bc9:45221 in memory (size: 35.3 KiB, free: 365.9 MiB)
26/01/12 03:00:02 INFO BlockManagerInfo: Removed broadcast_415_piece0 on 172.18.0.5:42453 in memory (size: 35.3 KiB, free: 365.9 MiB)
26/01/12 03:00:02 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 03:00:02 INFO DAGScheduler: Got job 281 (parquet at <unknown>:0) with 2 output partitions
26/01/12 03:00:02 INFO DAGScheduler: Final stage: ResultStage 281 (parquet at <unknown>:0)
26/01/12 03:00:02 INFO DAGScheduler: Parents of final stage: List()
26/01/12 03:00:02 INFO DAGScheduler: Missing parents: List()
26/01/12 03:00:02 INFO DAGScheduler: Submitting ResultStage 281 (MapPartitionsRDD[704] at parquet at <unknown>:0), which has no missing parents
26/01/12 03:00:02 INFO BlockManagerInfo: Removed broadcast_419_piece0 on 02926ee04bc9:45221 in memory (size: 77.3 KiB, free: 365.9 MiB)
26/01/12 03:00:02 INFO BlockManagerInfo: Removed broadcast_419_piece0 on 172.18.0.5:42453 in memory (size: 77.3 KiB, free: 366.0 MiB)
26/01/12 03:00:02 INFO BlockManagerInfo: Removed broadcast_413_piece0 on 02926ee04bc9:45221 in memory (size: 77.4 KiB, free: 366.0 MiB)
26/01/12 03:00:02 INFO BlockManagerInfo: Removed broadcast_413_piece0 on 172.18.0.5:42453 in memory (size: 77.4 KiB, free: 366.0 MiB)
26/01/12 03:00:02 INFO BlockManagerInfo: Removed broadcast_412_piece0 on 02926ee04bc9:45221 in memory (size: 35.3 KiB, free: 366.0 MiB)
26/01/12 03:00:02 INFO BlockManagerInfo: Removed broadcast_412_piece0 on 172.18.0.5:42453 in memory (size: 35.3 KiB, free: 366.1 MiB)
26/01/12 03:00:02 INFO BlockManagerInfo: Removed broadcast_416_piece0 on 02926ee04bc9:45221 in memory (size: 77.4 KiB, free: 366.1 MiB)
26/01/12 03:00:02 INFO MemoryStore: Block broadcast_422 stored as values in memory (estimated size 225.0 KiB, free 364.4 MiB)
26/01/12 03:00:02 INFO BlockManagerInfo: Removed broadcast_416_piece0 on 172.18.0.5:42453 in memory (size: 77.4 KiB, free: 366.2 MiB)
26/01/12 03:00:02 INFO MemoryStore: Block broadcast_422_piece0 stored as bytes in memory (estimated size 77.3 KiB, free 364.6 MiB)
26/01/12 03:00:02 INFO BlockManagerInfo: Added broadcast_422_piece0 in memory on 02926ee04bc9:45221 (size: 77.3 KiB, free: 366.0 MiB)
26/01/12 03:00:02 INFO SparkContext: Created broadcast 422 from broadcast at DAGScheduler.scala:1513
26/01/12 03:00:02 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 281 (MapPartitionsRDD[704] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1))
26/01/12 03:00:02 INFO TaskSchedulerImpl: Adding task set 281.0 with 2 tasks resource profile 0
26/01/12 03:00:02 INFO BlockManagerInfo: Removed broadcast_418_piece0 on 02926ee04bc9:45221 in memory (size: 35.4 KiB, free: 366.1 MiB)
26/01/12 03:00:02 INFO TaskSetManager: Starting task 0.0 in stage 281.0 (TID 468) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 03:00:02 INFO TaskSetManager: Starting task 1.0 in stage 281.0 (TID 469) (172.18.0.5, executor 0, partition 1, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 03:00:02 INFO BlockManagerInfo: Removed broadcast_418_piece0 on 172.18.0.5:42453 in memory (size: 35.4 KiB, free: 366.2 MiB)
26/01/12 03:00:02 INFO BlockManagerInfo: Added broadcast_422_piece0 in memory on 172.18.0.5:42453 (size: 77.3 KiB, free: 366.1 MiB)
26/01/12 03:00:02 INFO BlockManagerInfo: Added broadcast_421_piece0 in memory on 172.18.0.5:42453 (size: 35.4 KiB, free: 366.1 MiB)
26/01/12 03:00:02 INFO TaskSetManager: Finished task 1.0 in stage 281.0 (TID 469) in 57 ms on 172.18.0.5 (executor 0) (1/2)
26/01/12 03:00:05 INFO TaskSetManager: Finished task 0.0 in stage 281.0 (TID 468) in 3527 ms on 172.18.0.5 (executor 0) (2/2)
26/01/12 03:00:05 INFO TaskSchedulerImpl: Removed TaskSet 281.0, whose tasks have all completed, from pool 
26/01/12 03:00:05 INFO DAGScheduler: ResultStage 281 (parquet at <unknown>:0) finished in 3.549 s
26/01/12 03:00:05 INFO DAGScheduler: Job 281 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 03:00:05 INFO TaskSchedulerImpl: Killing all running tasks in stage 281: Stage finished
26/01/12 03:00:05 INFO DAGScheduler: Job 281 finished: parquet at <unknown>:0, took 3.552813 s
26/01/12 03:00:05 INFO FileFormatWriter: Start to commit write Job 15f63205-5ae5-41f0-b0be-58be0c2aaf29.
26/01/12 03:00:06 INFO FileFormatWriter: Write Job 15f63205-5ae5-41f0-b0be-58be0c2aaf29 committed. Elapsed time: 26 ms.
26/01/12 03:00:06 INFO FileFormatWriter: Finished processing stats for write job 15f63205-5ae5-41f0-b0be-58be0c2aaf29.
Cargando: yellow_tripdata_2020-10.parquet en hdfs://hadoop-namenode:8020/data/nyc/raw/taxi-trips/2020...
26/01/12 03:00:06 INFO InMemoryFileIndex: It took 6 ms to list leaf files for 1 paths.
26/01/12 03:00:06 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 03:00:06 INFO DAGScheduler: Got job 282 (parquet at <unknown>:0) with 1 output partitions
26/01/12 03:00:06 INFO DAGScheduler: Final stage: ResultStage 282 (parquet at <unknown>:0)
26/01/12 03:00:06 INFO DAGScheduler: Parents of final stage: List()
26/01/12 03:00:06 INFO DAGScheduler: Missing parents: List()
26/01/12 03:00:06 INFO DAGScheduler: Submitting ResultStage 282 (MapPartitionsRDD[706] at parquet at <unknown>:0), which has no missing parents
26/01/12 03:00:06 INFO MemoryStore: Block broadcast_423 stored as values in memory (estimated size 102.6 KiB, free 364.8 MiB)
26/01/12 03:00:06 INFO MemoryStore: Block broadcast_423_piece0 stored as bytes in memory (estimated size 36.8 KiB, free 364.8 MiB)
26/01/12 03:00:06 INFO BlockManagerInfo: Added broadcast_423_piece0 in memory on 02926ee04bc9:45221 (size: 36.8 KiB, free: 366.0 MiB)
26/01/12 03:00:06 INFO SparkContext: Created broadcast 423 from broadcast at DAGScheduler.scala:1513
26/01/12 03:00:06 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 282 (MapPartitionsRDD[706] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0))
26/01/12 03:00:06 INFO TaskSchedulerImpl: Adding task set 282.0 with 1 tasks resource profile 0
26/01/12 03:00:06 INFO TaskSetManager: Starting task 0.0 in stage 282.0 (TID 470) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4607 bytes) taskResourceAssignments Map()
26/01/12 03:00:06 INFO BlockManagerInfo: Added broadcast_423_piece0 in memory on 172.18.0.5:42453 (size: 36.8 KiB, free: 366.0 MiB)
26/01/12 03:00:06 INFO TaskSetManager: Finished task 0.0 in stage 282.0 (TID 470) in 44 ms on 172.18.0.5 (executor 0) (1/1)
26/01/12 03:00:06 INFO TaskSchedulerImpl: Removed TaskSet 282.0, whose tasks have all completed, from pool 
26/01/12 03:00:06 INFO DAGScheduler: ResultStage 282 (parquet at <unknown>:0) finished in 0.055 s
26/01/12 03:00:06 INFO DAGScheduler: Job 282 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 03:00:06 INFO TaskSchedulerImpl: Killing all running tasks in stage 282: Stage finished
26/01/12 03:00:06 INFO DAGScheduler: Job 282 finished: parquet at <unknown>:0, took 0.058128 s
26/01/12 03:00:06 INFO FileSourceStrategy: Pushed Filters: 
26/01/12 03:00:06 INFO FileSourceStrategy: Post-Scan Filters: 
26/01/12 03:00:06 INFO FileSourceStrategy: Output Data Schema: struct<VendorID: bigint, tpep_pickup_datetime: timestamp, tpep_dropoff_datetime: timestamp, passenger_count: double, trip_distance: double ... 17 more fields>
26/01/12 03:00:06 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 03:00:06 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 03:00:06 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 03:00:06 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 03:00:06 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 03:00:06 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 03:00:06 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 03:00:06 INFO MemoryStore: Block broadcast_424 stored as values in memory (estimated size 358.5 KiB, free 364.5 MiB)
26/01/12 03:00:06 INFO MemoryStore: Block broadcast_424_piece0 stored as bytes in memory (estimated size 35.3 KiB, free 364.4 MiB)
26/01/12 03:00:06 INFO BlockManagerInfo: Added broadcast_424_piece0 in memory on 02926ee04bc9:45221 (size: 35.3 KiB, free: 366.0 MiB)
26/01/12 03:00:06 INFO SparkContext: Created broadcast 424 from parquet at <unknown>:0
26/01/12 03:00:06 INFO FileSourceScanExec: Planning scan with bin packing, max size: 15250590 bytes, open cost is considered as scanning 4194304 bytes.
26/01/12 03:00:06 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 03:00:06 INFO DAGScheduler: Got job 283 (parquet at <unknown>:0) with 2 output partitions
26/01/12 03:00:06 INFO DAGScheduler: Final stage: ResultStage 283 (parquet at <unknown>:0)
26/01/12 03:00:06 INFO DAGScheduler: Parents of final stage: List()
26/01/12 03:00:06 INFO DAGScheduler: Missing parents: List()
26/01/12 03:00:06 INFO DAGScheduler: Submitting ResultStage 283 (MapPartitionsRDD[709] at parquet at <unknown>:0), which has no missing parents
26/01/12 03:00:06 INFO MemoryStore: Block broadcast_425 stored as values in memory (estimated size 225.1 KiB, free 364.2 MiB)
26/01/12 03:00:06 INFO MemoryStore: Block broadcast_425_piece0 stored as bytes in memory (estimated size 77.4 KiB, free 364.1 MiB)
26/01/12 03:00:06 INFO BlockManagerInfo: Added broadcast_425_piece0 in memory on 02926ee04bc9:45221 (size: 77.4 KiB, free: 365.9 MiB)
26/01/12 03:00:06 INFO SparkContext: Created broadcast 425 from broadcast at DAGScheduler.scala:1513
26/01/12 03:00:06 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 283 (MapPartitionsRDD[709] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1))
26/01/12 03:00:06 INFO TaskSchedulerImpl: Adding task set 283.0 with 2 tasks resource profile 0
26/01/12 03:00:06 INFO TaskSetManager: Starting task 0.0 in stage 283.0 (TID 471) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 03:00:06 INFO TaskSetManager: Starting task 1.0 in stage 283.0 (TID 472) (172.18.0.5, executor 0, partition 1, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 03:00:06 INFO BlockManagerInfo: Added broadcast_425_piece0 in memory on 172.18.0.5:42453 (size: 77.4 KiB, free: 366.0 MiB)
26/01/12 03:00:06 INFO BlockManagerInfo: Added broadcast_424_piece0 in memory on 172.18.0.5:42453 (size: 35.3 KiB, free: 365.9 MiB)
26/01/12 03:00:06 INFO TaskSetManager: Finished task 1.0 in stage 283.0 (TID 472) in 51 ms on 172.18.0.5 (executor 0) (1/2)
26/01/12 03:00:10 INFO TaskSetManager: Finished task 0.0 in stage 283.0 (TID 471) in 4424 ms on 172.18.0.5 (executor 0) (2/2)
26/01/12 03:00:10 INFO TaskSchedulerImpl: Removed TaskSet 283.0, whose tasks have all completed, from pool 
26/01/12 03:00:10 INFO DAGScheduler: ResultStage 283 (parquet at <unknown>:0) finished in 4.440 s
26/01/12 03:00:10 INFO DAGScheduler: Job 283 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 03:00:10 INFO TaskSchedulerImpl: Killing all running tasks in stage 283: Stage finished
26/01/12 03:00:10 INFO DAGScheduler: Job 283 finished: parquet at <unknown>:0, took 4.443944 s
26/01/12 03:00:10 INFO FileFormatWriter: Start to commit write Job 8805a542-d8fa-4500-9d8f-4b841cf88306.
26/01/12 03:00:10 INFO FileFormatWriter: Write Job 8805a542-d8fa-4500-9d8f-4b841cf88306 committed. Elapsed time: 28 ms.
26/01/12 03:00:10 INFO FileFormatWriter: Finished processing stats for write job 8805a542-d8fa-4500-9d8f-4b841cf88306.
Cargando: yellow_tripdata_2020-11.parquet en hdfs://hadoop-namenode:8020/data/nyc/raw/taxi-trips/2020...
26/01/12 03:00:10 INFO InMemoryFileIndex: It took 7 ms to list leaf files for 1 paths.
26/01/12 03:00:10 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 03:00:10 INFO DAGScheduler: Got job 284 (parquet at <unknown>:0) with 1 output partitions
26/01/12 03:00:10 INFO DAGScheduler: Final stage: ResultStage 284 (parquet at <unknown>:0)
26/01/12 03:00:10 INFO DAGScheduler: Parents of final stage: List()
26/01/12 03:00:10 INFO DAGScheduler: Missing parents: List()
26/01/12 03:00:10 INFO DAGScheduler: Submitting ResultStage 284 (MapPartitionsRDD[711] at parquet at <unknown>:0), which has no missing parents
26/01/12 03:00:10 INFO MemoryStore: Block broadcast_426 stored as values in memory (estimated size 102.6 KiB, free 364.0 MiB)
26/01/12 03:00:10 INFO MemoryStore: Block broadcast_426_piece0 stored as bytes in memory (estimated size 36.8 KiB, free 364.0 MiB)
26/01/12 03:00:10 INFO BlockManagerInfo: Added broadcast_426_piece0 in memory on 02926ee04bc9:45221 (size: 36.8 KiB, free: 365.9 MiB)
26/01/12 03:00:10 INFO SparkContext: Created broadcast 426 from broadcast at DAGScheduler.scala:1513
26/01/12 03:00:10 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 284 (MapPartitionsRDD[711] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0))
26/01/12 03:00:10 INFO TaskSchedulerImpl: Adding task set 284.0 with 1 tasks resource profile 0
26/01/12 03:00:10 INFO TaskSetManager: Starting task 0.0 in stage 284.0 (TID 473) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4607 bytes) taskResourceAssignments Map()
26/01/12 03:00:10 INFO BlockManagerInfo: Added broadcast_426_piece0 in memory on 172.18.0.5:42453 (size: 36.8 KiB, free: 365.9 MiB)
26/01/12 03:00:10 INFO TaskSetManager: Finished task 0.0 in stage 284.0 (TID 473) in 46 ms on 172.18.0.5 (executor 0) (1/1)
26/01/12 03:00:10 INFO TaskSchedulerImpl: Removed TaskSet 284.0, whose tasks have all completed, from pool 
26/01/12 03:00:10 INFO DAGScheduler: ResultStage 284 (parquet at <unknown>:0) finished in 0.059 s
26/01/12 03:00:10 INFO DAGScheduler: Job 284 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 03:00:10 INFO TaskSchedulerImpl: Killing all running tasks in stage 284: Stage finished
26/01/12 03:00:10 INFO DAGScheduler: Job 284 finished: parquet at <unknown>:0, took 0.062665 s
26/01/12 03:00:10 INFO FileSourceStrategy: Pushed Filters: 
26/01/12 03:00:10 INFO FileSourceStrategy: Post-Scan Filters: 
26/01/12 03:00:10 INFO FileSourceStrategy: Output Data Schema: struct<VendorID: bigint, tpep_pickup_datetime: timestamp, tpep_dropoff_datetime: timestamp, passenger_count: double, trip_distance: double ... 17 more fields>
26/01/12 03:00:10 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 03:00:10 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 03:00:10 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 03:00:10 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 03:00:10 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 03:00:10 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 03:00:10 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 03:00:10 INFO MemoryStore: Block broadcast_427 stored as values in memory (estimated size 358.5 KiB, free 363.6 MiB)
26/01/12 03:00:10 INFO MemoryStore: Block broadcast_427_piece0 stored as bytes in memory (estimated size 35.4 KiB, free 363.6 MiB)
26/01/12 03:00:10 INFO BlockManagerInfo: Added broadcast_427_piece0 in memory on 02926ee04bc9:45221 (size: 35.4 KiB, free: 365.9 MiB)
26/01/12 03:00:10 INFO SparkContext: Created broadcast 427 from parquet at <unknown>:0
26/01/12 03:00:10 INFO FileSourceScanExec: Planning scan with bin packing, max size: 13888836 bytes, open cost is considered as scanning 4194304 bytes.
26/01/12 03:00:10 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 03:00:10 INFO DAGScheduler: Got job 285 (parquet at <unknown>:0) with 2 output partitions
26/01/12 03:00:10 INFO DAGScheduler: Final stage: ResultStage 285 (parquet at <unknown>:0)
26/01/12 03:00:10 INFO DAGScheduler: Parents of final stage: List()
26/01/12 03:00:10 INFO DAGScheduler: Missing parents: List()
26/01/12 03:00:10 INFO DAGScheduler: Submitting ResultStage 285 (MapPartitionsRDD[714] at parquet at <unknown>:0), which has no missing parents
26/01/12 03:00:10 INFO MemoryStore: Block broadcast_428 stored as values in memory (estimated size 225.0 KiB, free 363.4 MiB)
26/01/12 03:00:10 INFO MemoryStore: Block broadcast_428_piece0 stored as bytes in memory (estimated size 77.3 KiB, free 363.3 MiB)
26/01/12 03:00:10 INFO BlockManagerInfo: Added broadcast_428_piece0 in memory on 02926ee04bc9:45221 (size: 77.3 KiB, free: 365.8 MiB)
26/01/12 03:00:10 INFO SparkContext: Created broadcast 428 from broadcast at DAGScheduler.scala:1513
26/01/12 03:00:10 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 285 (MapPartitionsRDD[714] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1))
26/01/12 03:00:10 INFO TaskSchedulerImpl: Adding task set 285.0 with 2 tasks resource profile 0
26/01/12 03:00:10 INFO TaskSetManager: Starting task 0.0 in stage 285.0 (TID 474) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 03:00:10 INFO TaskSetManager: Starting task 1.0 in stage 285.0 (TID 475) (172.18.0.5, executor 0, partition 1, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 03:00:10 INFO BlockManagerInfo: Added broadcast_428_piece0 in memory on 172.18.0.5:42453 (size: 77.3 KiB, free: 365.8 MiB)
26/01/12 03:00:10 INFO BlockManagerInfo: Added broadcast_427_piece0 in memory on 172.18.0.5:42453 (size: 35.4 KiB, free: 365.8 MiB)
26/01/12 03:00:10 INFO TaskSetManager: Finished task 1.0 in stage 285.0 (TID 475) in 51 ms on 172.18.0.5 (executor 0) (1/2)
26/01/12 03:00:14 INFO TaskSetManager: Finished task 0.0 in stage 285.0 (TID 474) in 4110 ms on 172.18.0.5 (executor 0) (2/2)
26/01/12 03:00:14 INFO TaskSchedulerImpl: Removed TaskSet 285.0, whose tasks have all completed, from pool 
26/01/12 03:00:14 INFO DAGScheduler: ResultStage 285 (parquet at <unknown>:0) finished in 4.128 s
26/01/12 03:00:14 INFO DAGScheduler: Job 285 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 03:00:14 INFO TaskSchedulerImpl: Killing all running tasks in stage 285: Stage finished
26/01/12 03:00:14 INFO DAGScheduler: Job 285 finished: parquet at <unknown>:0, took 4.130916 s
26/01/12 03:00:14 INFO FileFormatWriter: Start to commit write Job 4b473fc0-651d-4e18-878d-31d86b034075.
26/01/12 03:00:14 INFO FileFormatWriter: Write Job 4b473fc0-651d-4e18-878d-31d86b034075 committed. Elapsed time: 27 ms.
26/01/12 03:00:14 INFO FileFormatWriter: Finished processing stats for write job 4b473fc0-651d-4e18-878d-31d86b034075.
Cargando: yellow_tripdata_2020-12.parquet en hdfs://hadoop-namenode:8020/data/nyc/raw/taxi-trips/2020...
26/01/12 03:00:15 INFO InMemoryFileIndex: It took 7 ms to list leaf files for 1 paths.
26/01/12 03:00:15 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 03:00:15 INFO DAGScheduler: Got job 286 (parquet at <unknown>:0) with 1 output partitions
26/01/12 03:00:15 INFO DAGScheduler: Final stage: ResultStage 286 (parquet at <unknown>:0)
26/01/12 03:00:15 INFO DAGScheduler: Parents of final stage: List()
26/01/12 03:00:15 INFO DAGScheduler: Missing parents: List()
26/01/12 03:00:15 INFO DAGScheduler: Submitting ResultStage 286 (MapPartitionsRDD[716] at parquet at <unknown>:0), which has no missing parents
26/01/12 03:00:15 INFO MemoryStore: Block broadcast_429 stored as values in memory (estimated size 102.6 KiB, free 363.2 MiB)
26/01/12 03:00:15 INFO MemoryStore: Block broadcast_429_piece0 stored as bytes in memory (estimated size 36.8 KiB, free 363.2 MiB)
26/01/12 03:00:15 INFO BlockManagerInfo: Added broadcast_429_piece0 in memory on 02926ee04bc9:45221 (size: 36.8 KiB, free: 365.8 MiB)
26/01/12 03:00:15 INFO SparkContext: Created broadcast 429 from broadcast at DAGScheduler.scala:1513
26/01/12 03:00:15 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 286 (MapPartitionsRDD[716] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0))
26/01/12 03:00:15 INFO TaskSchedulerImpl: Adding task set 286.0 with 1 tasks resource profile 0
26/01/12 03:00:15 INFO TaskSetManager: Starting task 0.0 in stage 286.0 (TID 476) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4607 bytes) taskResourceAssignments Map()
26/01/12 03:00:15 INFO BlockManagerInfo: Removed broadcast_428_piece0 on 02926ee04bc9:45221 in memory (size: 77.3 KiB, free: 365.8 MiB)
26/01/12 03:00:15 INFO BlockManagerInfo: Removed broadcast_428_piece0 on 172.18.0.5:42453 in memory (size: 77.3 KiB, free: 365.9 MiB)
26/01/12 03:00:15 INFO BlockManagerInfo: Added broadcast_429_piece0 in memory on 172.18.0.5:42453 (size: 36.8 KiB, free: 365.8 MiB)
26/01/12 03:00:15 INFO BlockManagerInfo: Removed broadcast_427_piece0 on 02926ee04bc9:45221 in memory (size: 35.4 KiB, free: 365.9 MiB)
26/01/12 03:00:15 INFO BlockManagerInfo: Removed broadcast_427_piece0 on 172.18.0.5:42453 in memory (size: 35.4 KiB, free: 365.9 MiB)
26/01/12 03:00:15 INFO BlockManagerInfo: Removed broadcast_422_piece0 on 02926ee04bc9:45221 in memory (size: 77.3 KiB, free: 365.9 MiB)
26/01/12 03:00:15 INFO BlockManagerInfo: Removed broadcast_422_piece0 on 172.18.0.5:42453 in memory (size: 77.3 KiB, free: 365.9 MiB)
26/01/12 03:00:15 INFO BlockManagerInfo: Removed broadcast_421_piece0 on 02926ee04bc9:45221 in memory (size: 35.4 KiB, free: 366.0 MiB)
26/01/12 03:00:15 INFO BlockManagerInfo: Removed broadcast_421_piece0 on 172.18.0.5:42453 in memory (size: 35.4 KiB, free: 366.0 MiB)
26/01/12 03:00:15 INFO BlockManagerInfo: Removed broadcast_426_piece0 on 02926ee04bc9:45221 in memory (size: 36.8 KiB, free: 366.0 MiB)
26/01/12 03:00:15 INFO BlockManagerInfo: Removed broadcast_426_piece0 on 172.18.0.5:42453 in memory (size: 36.8 KiB, free: 366.0 MiB)
26/01/12 03:00:15 INFO BlockManagerInfo: Removed broadcast_424_piece0 on 02926ee04bc9:45221 in memory (size: 35.3 KiB, free: 366.0 MiB)
26/01/12 03:00:15 INFO BlockManagerInfo: Removed broadcast_424_piece0 on 172.18.0.5:42453 in memory (size: 35.3 KiB, free: 366.0 MiB)
26/01/12 03:00:15 INFO BlockManagerInfo: Removed broadcast_423_piece0 on 02926ee04bc9:45221 in memory (size: 36.8 KiB, free: 366.1 MiB)
26/01/12 03:00:15 INFO BlockManagerInfo: Removed broadcast_423_piece0 on 172.18.0.5:42453 in memory (size: 36.8 KiB, free: 366.1 MiB)
26/01/12 03:00:15 INFO BlockManagerInfo: Removed broadcast_425_piece0 on 02926ee04bc9:45221 in memory (size: 77.4 KiB, free: 366.2 MiB)
26/01/12 03:00:15 INFO BlockManagerInfo: Removed broadcast_425_piece0 on 172.18.0.5:42453 in memory (size: 77.4 KiB, free: 366.2 MiB)
26/01/12 03:00:15 INFO TaskSetManager: Finished task 0.0 in stage 286.0 (TID 476) in 69 ms on 172.18.0.5 (executor 0) (1/1)
26/01/12 03:00:15 INFO TaskSchedulerImpl: Removed TaskSet 286.0, whose tasks have all completed, from pool 
26/01/12 03:00:15 INFO DAGScheduler: ResultStage 286 (parquet at <unknown>:0) finished in 0.100 s
26/01/12 03:00:15 INFO DAGScheduler: Job 286 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 03:00:15 INFO TaskSchedulerImpl: Killing all running tasks in stage 286: Stage finished
26/01/12 03:00:15 INFO DAGScheduler: Job 286 finished: parquet at <unknown>:0, took 0.103415 s
26/01/12 03:00:15 INFO FileSourceStrategy: Pushed Filters: 
26/01/12 03:00:15 INFO FileSourceStrategy: Post-Scan Filters: 
26/01/12 03:00:15 INFO FileSourceStrategy: Output Data Schema: struct<VendorID: bigint, tpep_pickup_datetime: timestamp, tpep_dropoff_datetime: timestamp, passenger_count: double, trip_distance: double ... 17 more fields>
26/01/12 03:00:15 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 03:00:15 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 03:00:15 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 03:00:15 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 03:00:15 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 03:00:15 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 03:00:15 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 03:00:15 INFO MemoryStore: Block broadcast_430 stored as values in memory (estimated size 358.5 KiB, free 365.1 MiB)
26/01/12 03:00:15 INFO MemoryStore: Block broadcast_430_piece0 stored as bytes in memory (estimated size 35.4 KiB, free 365.1 MiB)
26/01/12 03:00:15 INFO BlockManagerInfo: Added broadcast_430_piece0 in memory on 02926ee04bc9:45221 (size: 35.4 KiB, free: 366.1 MiB)
26/01/12 03:00:15 INFO SparkContext: Created broadcast 430 from parquet at <unknown>:0
26/01/12 03:00:15 INFO FileSourceScanExec: Planning scan with bin packing, max size: 13607170 bytes, open cost is considered as scanning 4194304 bytes.
26/01/12 03:00:15 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 03:00:15 INFO DAGScheduler: Got job 287 (parquet at <unknown>:0) with 2 output partitions
26/01/12 03:00:15 INFO DAGScheduler: Final stage: ResultStage 287 (parquet at <unknown>:0)
26/01/12 03:00:15 INFO DAGScheduler: Parents of final stage: List()
26/01/12 03:00:15 INFO DAGScheduler: Missing parents: List()
26/01/12 03:00:15 INFO DAGScheduler: Submitting ResultStage 287 (MapPartitionsRDD[719] at parquet at <unknown>:0), which has no missing parents
26/01/12 03:00:15 INFO MemoryStore: Block broadcast_431 stored as values in memory (estimated size 225.0 KiB, free 364.9 MiB)
26/01/12 03:00:15 INFO MemoryStore: Block broadcast_431_piece0 stored as bytes in memory (estimated size 77.3 KiB, free 364.8 MiB)
26/01/12 03:00:15 INFO BlockManagerInfo: Added broadcast_431_piece0 in memory on 02926ee04bc9:45221 (size: 77.3 KiB, free: 366.0 MiB)
26/01/12 03:00:15 INFO SparkContext: Created broadcast 431 from broadcast at DAGScheduler.scala:1513
26/01/12 03:00:15 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 287 (MapPartitionsRDD[719] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1))
26/01/12 03:00:15 INFO TaskSchedulerImpl: Adding task set 287.0 with 2 tasks resource profile 0
26/01/12 03:00:15 INFO TaskSetManager: Starting task 0.0 in stage 287.0 (TID 477) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 03:00:15 INFO TaskSetManager: Starting task 1.0 in stage 287.0 (TID 478) (172.18.0.5, executor 0, partition 1, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 03:00:15 INFO BlockManagerInfo: Added broadcast_431_piece0 in memory on 172.18.0.5:42453 (size: 77.3 KiB, free: 366.1 MiB)
26/01/12 03:00:15 INFO BlockManagerInfo: Added broadcast_430_piece0 in memory on 172.18.0.5:42453 (size: 35.4 KiB, free: 366.0 MiB)
26/01/12 03:00:15 INFO TaskSetManager: Finished task 1.0 in stage 287.0 (TID 478) in 48 ms on 172.18.0.5 (executor 0) (1/2)
26/01/12 03:00:19 INFO TaskSetManager: Finished task 0.0 in stage 287.0 (TID 477) in 3877 ms on 172.18.0.5 (executor 0) (2/2)
26/01/12 03:00:19 INFO TaskSchedulerImpl: Removed TaskSet 287.0, whose tasks have all completed, from pool 
26/01/12 03:00:19 INFO DAGScheduler: ResultStage 287 (parquet at <unknown>:0) finished in 3.897 s
26/01/12 03:00:19 INFO DAGScheduler: Job 287 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 03:00:19 INFO TaskSchedulerImpl: Killing all running tasks in stage 287: Stage finished
26/01/12 03:00:19 INFO DAGScheduler: Job 287 finished: parquet at <unknown>:0, took 3.900109 s
26/01/12 03:00:19 INFO FileFormatWriter: Start to commit write Job 397ad33c-1b2f-4b2d-b8a5-d9c623e993ad.
26/01/12 03:00:19 INFO FileFormatWriter: Write Job 397ad33c-1b2f-4b2d-b8a5-d9c623e993ad committed. Elapsed time: 24 ms.
26/01/12 03:00:19 INFO FileFormatWriter: Finished processing stats for write job 397ad33c-1b2f-4b2d-b8a5-d9c623e993ad.
Cargando: yellow_tripdata_2021-01.parquet en hdfs://hadoop-namenode:8020/data/nyc/raw/taxi-trips/2021...
26/01/12 03:00:19 INFO InMemoryFileIndex: It took 6 ms to list leaf files for 1 paths.
26/01/12 03:00:19 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 03:00:19 INFO DAGScheduler: Got job 288 (parquet at <unknown>:0) with 1 output partitions
26/01/12 03:00:19 INFO DAGScheduler: Final stage: ResultStage 288 (parquet at <unknown>:0)
26/01/12 03:00:19 INFO DAGScheduler: Parents of final stage: List()
26/01/12 03:00:19 INFO DAGScheduler: Missing parents: List()
26/01/12 03:00:19 INFO DAGScheduler: Submitting ResultStage 288 (MapPartitionsRDD[721] at parquet at <unknown>:0), which has no missing parents
26/01/12 03:00:19 INFO MemoryStore: Block broadcast_432 stored as values in memory (estimated size 102.6 KiB, free 364.7 MiB)
26/01/12 03:00:19 INFO MemoryStore: Block broadcast_432_piece0 stored as bytes in memory (estimated size 36.8 KiB, free 364.7 MiB)
26/01/12 03:00:19 INFO BlockManagerInfo: Added broadcast_432_piece0 in memory on 02926ee04bc9:45221 (size: 36.8 KiB, free: 366.0 MiB)
26/01/12 03:00:19 INFO SparkContext: Created broadcast 432 from broadcast at DAGScheduler.scala:1513
26/01/12 03:00:19 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 288 (MapPartitionsRDD[721] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0))
26/01/12 03:00:19 INFO TaskSchedulerImpl: Adding task set 288.0 with 1 tasks resource profile 0
26/01/12 03:00:19 INFO TaskSetManager: Starting task 0.0 in stage 288.0 (TID 479) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4607 bytes) taskResourceAssignments Map()
26/01/12 03:00:19 INFO BlockManagerInfo: Added broadcast_432_piece0 in memory on 172.18.0.5:42453 (size: 36.8 KiB, free: 366.0 MiB)
26/01/12 03:00:19 INFO TaskSetManager: Finished task 0.0 in stage 288.0 (TID 479) in 43 ms on 172.18.0.5 (executor 0) (1/1)
26/01/12 03:00:19 INFO TaskSchedulerImpl: Removed TaskSet 288.0, whose tasks have all completed, from pool 
26/01/12 03:00:19 INFO DAGScheduler: ResultStage 288 (parquet at <unknown>:0) finished in 0.054 s
26/01/12 03:00:19 INFO DAGScheduler: Job 288 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 03:00:19 INFO TaskSchedulerImpl: Killing all running tasks in stage 288: Stage finished
26/01/12 03:00:19 INFO DAGScheduler: Job 288 finished: parquet at <unknown>:0, took 0.057063 s
26/01/12 03:00:19 INFO FileSourceStrategy: Pushed Filters: 
26/01/12 03:00:19 INFO FileSourceStrategy: Post-Scan Filters: 
26/01/12 03:00:19 INFO FileSourceStrategy: Output Data Schema: struct<VendorID: bigint, tpep_pickup_datetime: timestamp, tpep_dropoff_datetime: timestamp, passenger_count: double, trip_distance: double ... 17 more fields>
26/01/12 03:00:19 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 03:00:19 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 03:00:19 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 03:00:19 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 03:00:19 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 03:00:19 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 03:00:19 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 03:00:19 INFO MemoryStore: Block broadcast_433 stored as values in memory (estimated size 358.5 KiB, free 364.3 MiB)
26/01/12 03:00:19 INFO MemoryStore: Block broadcast_433_piece0 stored as bytes in memory (estimated size 35.4 KiB, free 364.3 MiB)
26/01/12 03:00:19 INFO BlockManagerInfo: Added broadcast_433_piece0 in memory on 02926ee04bc9:45221 (size: 35.4 KiB, free: 366.0 MiB)
26/01/12 03:00:19 INFO SparkContext: Created broadcast 433 from parquet at <unknown>:0
26/01/12 03:00:19 INFO FileSourceScanExec: Planning scan with bin packing, max size: 12940185 bytes, open cost is considered as scanning 4194304 bytes.
26/01/12 03:00:19 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 03:00:19 INFO DAGScheduler: Got job 289 (parquet at <unknown>:0) with 2 output partitions
26/01/12 03:00:19 INFO DAGScheduler: Final stage: ResultStage 289 (parquet at <unknown>:0)
26/01/12 03:00:19 INFO DAGScheduler: Parents of final stage: List()
26/01/12 03:00:19 INFO DAGScheduler: Missing parents: List()
26/01/12 03:00:19 INFO DAGScheduler: Submitting ResultStage 289 (MapPartitionsRDD[724] at parquet at <unknown>:0), which has no missing parents
26/01/12 03:00:19 INFO MemoryStore: Block broadcast_434 stored as values in memory (estimated size 225.0 KiB, free 364.1 MiB)
26/01/12 03:00:19 INFO MemoryStore: Block broadcast_434_piece0 stored as bytes in memory (estimated size 77.3 KiB, free 364.0 MiB)
26/01/12 03:00:19 INFO BlockManagerInfo: Added broadcast_434_piece0 in memory on 02926ee04bc9:45221 (size: 77.3 KiB, free: 365.9 MiB)
26/01/12 03:00:19 INFO SparkContext: Created broadcast 434 from broadcast at DAGScheduler.scala:1513
26/01/12 03:00:19 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 289 (MapPartitionsRDD[724] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1))
26/01/12 03:00:19 INFO TaskSchedulerImpl: Adding task set 289.0 with 2 tasks resource profile 0
26/01/12 03:00:19 INFO TaskSetManager: Starting task 0.0 in stage 289.0 (TID 480) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 03:00:19 INFO TaskSetManager: Starting task 1.0 in stage 289.0 (TID 481) (172.18.0.5, executor 0, partition 1, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 03:00:19 INFO BlockManagerInfo: Added broadcast_434_piece0 in memory on 172.18.0.5:42453 (size: 77.3 KiB, free: 365.9 MiB)
26/01/12 03:00:19 INFO BlockManagerInfo: Added broadcast_433_piece0 in memory on 172.18.0.5:42453 (size: 35.4 KiB, free: 365.9 MiB)
26/01/12 03:00:19 INFO TaskSetManager: Finished task 1.0 in stage 289.0 (TID 481) in 53 ms on 172.18.0.5 (executor 0) (1/2)
26/01/12 03:00:23 INFO TaskSetManager: Finished task 0.0 in stage 289.0 (TID 480) in 3845 ms on 172.18.0.5 (executor 0) (2/2)
26/01/12 03:00:23 INFO TaskSchedulerImpl: Removed TaskSet 289.0, whose tasks have all completed, from pool 
26/01/12 03:00:23 INFO DAGScheduler: ResultStage 289 (parquet at <unknown>:0) finished in 3.861 s
26/01/12 03:00:23 INFO DAGScheduler: Job 289 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 03:00:23 INFO TaskSchedulerImpl: Killing all running tasks in stage 289: Stage finished
26/01/12 03:00:23 INFO DAGScheduler: Job 289 finished: parquet at <unknown>:0, took 3.864905 s
26/01/12 03:00:23 INFO FileFormatWriter: Start to commit write Job 0a977316-daee-40be-af0f-065eb13419cb.
26/01/12 03:00:23 INFO FileFormatWriter: Write Job 0a977316-daee-40be-af0f-065eb13419cb committed. Elapsed time: 23 ms.
26/01/12 03:00:23 INFO FileFormatWriter: Finished processing stats for write job 0a977316-daee-40be-af0f-065eb13419cb.
Cargando: yellow_tripdata_2021-02.parquet en hdfs://hadoop-namenode:8020/data/nyc/raw/taxi-trips/2021...
26/01/12 03:00:23 INFO InMemoryFileIndex: It took 6 ms to list leaf files for 1 paths.
26/01/12 03:00:23 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 03:00:23 INFO DAGScheduler: Got job 290 (parquet at <unknown>:0) with 1 output partitions
26/01/12 03:00:23 INFO DAGScheduler: Final stage: ResultStage 290 (parquet at <unknown>:0)
26/01/12 03:00:23 INFO DAGScheduler: Parents of final stage: List()
26/01/12 03:00:23 INFO DAGScheduler: Missing parents: List()
26/01/12 03:00:23 INFO DAGScheduler: Submitting ResultStage 290 (MapPartitionsRDD[726] at parquet at <unknown>:0), which has no missing parents
26/01/12 03:00:23 INFO MemoryStore: Block broadcast_435 stored as values in memory (estimated size 102.6 KiB, free 363.9 MiB)
26/01/12 03:00:23 INFO MemoryStore: Block broadcast_435_piece0 stored as bytes in memory (estimated size 36.8 KiB, free 363.9 MiB)
26/01/12 03:00:23 INFO BlockManagerInfo: Added broadcast_435_piece0 in memory on 02926ee04bc9:45221 (size: 36.8 KiB, free: 365.9 MiB)
26/01/12 03:00:23 INFO SparkContext: Created broadcast 435 from broadcast at DAGScheduler.scala:1513
26/01/12 03:00:23 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 290 (MapPartitionsRDD[726] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0))
26/01/12 03:00:23 INFO TaskSchedulerImpl: Adding task set 290.0 with 1 tasks resource profile 0
26/01/12 03:00:23 INFO TaskSetManager: Starting task 0.0 in stage 290.0 (TID 482) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4607 bytes) taskResourceAssignments Map()
26/01/12 03:00:23 INFO BlockManagerInfo: Added broadcast_435_piece0 in memory on 172.18.0.5:42453 (size: 36.8 KiB, free: 365.9 MiB)
26/01/12 03:00:23 INFO TaskSetManager: Finished task 0.0 in stage 290.0 (TID 482) in 42 ms on 172.18.0.5 (executor 0) (1/1)
26/01/12 03:00:23 INFO TaskSchedulerImpl: Removed TaskSet 290.0, whose tasks have all completed, from pool 
26/01/12 03:00:23 INFO DAGScheduler: ResultStage 290 (parquet at <unknown>:0) finished in 0.054 s
26/01/12 03:00:23 INFO DAGScheduler: Job 290 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 03:00:23 INFO TaskSchedulerImpl: Killing all running tasks in stage 290: Stage finished
26/01/12 03:00:23 INFO DAGScheduler: Job 290 finished: parquet at <unknown>:0, took 0.057194 s
26/01/12 03:00:23 INFO FileSourceStrategy: Pushed Filters: 
26/01/12 03:00:23 INFO FileSourceStrategy: Post-Scan Filters: 
26/01/12 03:00:23 INFO FileSourceStrategy: Output Data Schema: struct<VendorID: bigint, tpep_pickup_datetime: timestamp, tpep_dropoff_datetime: timestamp, passenger_count: double, trip_distance: double ... 17 more fields>
26/01/12 03:00:23 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 03:00:23 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 03:00:23 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 03:00:23 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 03:00:23 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 03:00:23 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 03:00:23 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 03:00:23 INFO MemoryStore: Block broadcast_436 stored as values in memory (estimated size 358.5 KiB, free 363.5 MiB)
26/01/12 03:00:23 INFO MemoryStore: Block broadcast_436_piece0 stored as bytes in memory (estimated size 35.4 KiB, free 363.5 MiB)
26/01/12 03:00:23 INFO BlockManagerInfo: Added broadcast_436_piece0 in memory on 02926ee04bc9:45221 (size: 35.4 KiB, free: 365.8 MiB)
26/01/12 03:00:23 INFO SparkContext: Created broadcast 436 from parquet at <unknown>:0
26/01/12 03:00:23 INFO FileSourceScanExec: Planning scan with bin packing, max size: 12985781 bytes, open cost is considered as scanning 4194304 bytes.
26/01/12 03:00:23 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 03:00:23 INFO DAGScheduler: Got job 291 (parquet at <unknown>:0) with 2 output partitions
26/01/12 03:00:23 INFO DAGScheduler: Final stage: ResultStage 291 (parquet at <unknown>:0)
26/01/12 03:00:23 INFO DAGScheduler: Parents of final stage: List()
26/01/12 03:00:23 INFO DAGScheduler: Missing parents: List()
26/01/12 03:00:23 INFO DAGScheduler: Submitting ResultStage 291 (MapPartitionsRDD[729] at parquet at <unknown>:0), which has no missing parents
26/01/12 03:00:23 INFO MemoryStore: Block broadcast_437 stored as values in memory (estimated size 225.0 KiB, free 363.2 MiB)
26/01/12 03:00:23 INFO MemoryStore: Block broadcast_437_piece0 stored as bytes in memory (estimated size 77.3 KiB, free 363.2 MiB)
26/01/12 03:00:23 INFO BlockManagerInfo: Added broadcast_437_piece0 in memory on 02926ee04bc9:45221 (size: 77.3 KiB, free: 365.8 MiB)
26/01/12 03:00:23 INFO SparkContext: Created broadcast 437 from broadcast at DAGScheduler.scala:1513
26/01/12 03:00:23 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 291 (MapPartitionsRDD[729] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1))
26/01/12 03:00:23 INFO TaskSchedulerImpl: Adding task set 291.0 with 2 tasks resource profile 0
26/01/12 03:00:23 INFO TaskSetManager: Starting task 0.0 in stage 291.0 (TID 483) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 03:00:23 INFO TaskSetManager: Starting task 1.0 in stage 291.0 (TID 484) (172.18.0.5, executor 0, partition 1, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 03:00:23 INFO BlockManagerInfo: Added broadcast_437_piece0 in memory on 172.18.0.5:42453 (size: 77.3 KiB, free: 365.8 MiB)
26/01/12 03:00:23 INFO BlockManagerInfo: Added broadcast_436_piece0 in memory on 172.18.0.5:42453 (size: 35.4 KiB, free: 365.8 MiB)
26/01/12 03:00:23 INFO TaskSetManager: Finished task 1.0 in stage 291.0 (TID 484) in 57 ms on 172.18.0.5 (executor 0) (1/2)
26/01/12 03:00:27 INFO TaskSetManager: Finished task 0.0 in stage 291.0 (TID 483) in 3758 ms on 172.18.0.5 (executor 0) (2/2)
26/01/12 03:00:27 INFO TaskSchedulerImpl: Removed TaskSet 291.0, whose tasks have all completed, from pool 
26/01/12 03:00:27 INFO DAGScheduler: ResultStage 291 (parquet at <unknown>:0) finished in 3.775 s
26/01/12 03:00:27 INFO DAGScheduler: Job 291 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 03:00:27 INFO TaskSchedulerImpl: Killing all running tasks in stage 291: Stage finished
26/01/12 03:00:27 INFO DAGScheduler: Job 291 finished: parquet at <unknown>:0, took 3.779356 s
26/01/12 03:00:27 INFO FileFormatWriter: Start to commit write Job 767ef439-cfb8-4a2f-ae46-71ffaaeb1eb7.
26/01/12 03:00:27 INFO FileFormatWriter: Write Job 767ef439-cfb8-4a2f-ae46-71ffaaeb1eb7 committed. Elapsed time: 20 ms.
26/01/12 03:00:27 INFO FileFormatWriter: Finished processing stats for write job 767ef439-cfb8-4a2f-ae46-71ffaaeb1eb7.
Cargando: yellow_tripdata_2021-03.parquet en hdfs://hadoop-namenode:8020/data/nyc/raw/taxi-trips/2021...
26/01/12 03:00:27 INFO InMemoryFileIndex: It took 6 ms to list leaf files for 1 paths.
26/01/12 03:00:27 INFO BlockManagerInfo: Removed broadcast_429_piece0 on 02926ee04bc9:45221 in memory (size: 36.8 KiB, free: 365.8 MiB)
26/01/12 03:00:27 INFO BlockManagerInfo: Removed broadcast_429_piece0 on 172.18.0.5:42453 in memory (size: 36.8 KiB, free: 365.8 MiB)
26/01/12 03:00:27 INFO BlockManagerInfo: Removed broadcast_437_piece0 on 02926ee04bc9:45221 in memory (size: 77.3 KiB, free: 365.9 MiB)
26/01/12 03:00:27 INFO BlockManagerInfo: Removed broadcast_437_piece0 on 172.18.0.5:42453 in memory (size: 77.3 KiB, free: 365.9 MiB)
26/01/12 03:00:27 INFO BlockManagerInfo: Removed broadcast_433_piece0 on 02926ee04bc9:45221 in memory (size: 35.4 KiB, free: 365.9 MiB)
26/01/12 03:00:27 INFO BlockManagerInfo: Removed broadcast_433_piece0 on 172.18.0.5:42453 in memory (size: 35.4 KiB, free: 365.9 MiB)
26/01/12 03:00:27 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 03:00:27 INFO DAGScheduler: Got job 292 (parquet at <unknown>:0) with 1 output partitions
26/01/12 03:00:27 INFO DAGScheduler: Final stage: ResultStage 292 (parquet at <unknown>:0)
26/01/12 03:00:27 INFO DAGScheduler: Parents of final stage: List()
26/01/12 03:00:27 INFO DAGScheduler: Missing parents: List()
26/01/12 03:00:27 INFO DAGScheduler: Submitting ResultStage 292 (MapPartitionsRDD[731] at parquet at <unknown>:0), which has no missing parents
26/01/12 03:00:27 INFO BlockManagerInfo: Removed broadcast_431_piece0 on 02926ee04bc9:45221 in memory (size: 77.3 KiB, free: 366.0 MiB)
26/01/12 03:00:27 INFO BlockManagerInfo: Removed broadcast_431_piece0 on 172.18.0.5:42453 in memory (size: 77.3 KiB, free: 366.0 MiB)
26/01/12 03:00:27 INFO BlockManagerInfo: Removed broadcast_435_piece0 on 02926ee04bc9:45221 in memory (size: 36.8 KiB, free: 366.0 MiB)
26/01/12 03:00:27 INFO BlockManagerInfo: Removed broadcast_435_piece0 on 172.18.0.5:42453 in memory (size: 36.8 KiB, free: 366.0 MiB)
26/01/12 03:00:27 INFO BlockManagerInfo: Removed broadcast_432_piece0 on 02926ee04bc9:45221 in memory (size: 36.8 KiB, free: 366.0 MiB)
26/01/12 03:00:27 INFO MemoryStore: Block broadcast_438 stored as values in memory (estimated size 102.6 KiB, free 364.5 MiB)
26/01/12 03:00:27 INFO BlockManagerInfo: Removed broadcast_432_piece0 on 172.18.0.5:42453 in memory (size: 36.8 KiB, free: 366.0 MiB)
26/01/12 03:00:27 INFO MemoryStore: Block broadcast_438_piece0 stored as bytes in memory (estimated size 36.8 KiB, free 364.4 MiB)
26/01/12 03:00:27 INFO BlockManagerInfo: Added broadcast_438_piece0 in memory on 02926ee04bc9:45221 (size: 36.8 KiB, free: 366.0 MiB)
26/01/12 03:00:27 INFO SparkContext: Created broadcast 438 from broadcast at DAGScheduler.scala:1513
26/01/12 03:00:27 INFO BlockManagerInfo: Removed broadcast_434_piece0 on 02926ee04bc9:45221 in memory (size: 77.3 KiB, free: 366.1 MiB)
26/01/12 03:00:27 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 292 (MapPartitionsRDD[731] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0))
26/01/12 03:00:27 INFO TaskSchedulerImpl: Adding task set 292.0 with 1 tasks resource profile 0
26/01/12 03:00:27 INFO BlockManagerInfo: Removed broadcast_434_piece0 on 172.18.0.5:42453 in memory (size: 77.3 KiB, free: 366.1 MiB)
26/01/12 03:00:27 INFO TaskSetManager: Starting task 0.0 in stage 292.0 (TID 485) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4607 bytes) taskResourceAssignments Map()
26/01/12 03:00:27 INFO BlockManagerInfo: Removed broadcast_430_piece0 on 02926ee04bc9:45221 in memory (size: 35.4 KiB, free: 366.1 MiB)
26/01/12 03:00:27 INFO BlockManagerInfo: Removed broadcast_430_piece0 on 172.18.0.5:42453 in memory (size: 35.4 KiB, free: 366.2 MiB)
26/01/12 03:00:27 INFO BlockManagerInfo: Added broadcast_438_piece0 in memory on 172.18.0.5:42453 (size: 36.8 KiB, free: 366.1 MiB)
26/01/12 03:00:27 INFO TaskSetManager: Finished task 0.0 in stage 292.0 (TID 485) in 53 ms on 172.18.0.5 (executor 0) (1/1)
26/01/12 03:00:27 INFO TaskSchedulerImpl: Removed TaskSet 292.0, whose tasks have all completed, from pool 
26/01/12 03:00:27 INFO DAGScheduler: ResultStage 292 (parquet at <unknown>:0) finished in 0.070 s
26/01/12 03:00:27 INFO DAGScheduler: Job 292 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 03:00:27 INFO TaskSchedulerImpl: Killing all running tasks in stage 292: Stage finished
26/01/12 03:00:27 INFO DAGScheduler: Job 292 finished: parquet at <unknown>:0, took 0.074530 s
26/01/12 03:00:27 INFO FileSourceStrategy: Pushed Filters: 
26/01/12 03:00:27 INFO FileSourceStrategy: Post-Scan Filters: 
26/01/12 03:00:27 INFO FileSourceStrategy: Output Data Schema: struct<VendorID: bigint, tpep_pickup_datetime: timestamp, tpep_dropoff_datetime: timestamp, passenger_count: double, trip_distance: double ... 17 more fields>
26/01/12 03:00:27 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 03:00:27 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 03:00:27 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 03:00:27 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 03:00:27 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 03:00:27 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 03:00:27 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 03:00:27 INFO MemoryStore: Block broadcast_439 stored as values in memory (estimated size 358.5 KiB, free 364.7 MiB)
26/01/12 03:00:27 INFO MemoryStore: Block broadcast_439_piece0 stored as bytes in memory (estimated size 35.4 KiB, free 364.7 MiB)
26/01/12 03:00:27 INFO BlockManagerInfo: Added broadcast_439_piece0 in memory on 02926ee04bc9:45221 (size: 35.4 KiB, free: 366.1 MiB)
26/01/12 03:00:27 INFO SparkContext: Created broadcast 439 from parquet at <unknown>:0
26/01/12 03:00:27 INFO FileSourceScanExec: Planning scan with bin packing, max size: 17101078 bytes, open cost is considered as scanning 4194304 bytes.
26/01/12 03:00:27 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 03:00:27 INFO DAGScheduler: Got job 293 (parquet at <unknown>:0) with 2 output partitions
26/01/12 03:00:27 INFO DAGScheduler: Final stage: ResultStage 293 (parquet at <unknown>:0)
26/01/12 03:00:27 INFO DAGScheduler: Parents of final stage: List()
26/01/12 03:00:27 INFO DAGScheduler: Missing parents: List()
26/01/12 03:00:27 INFO DAGScheduler: Submitting ResultStage 293 (MapPartitionsRDD[734] at parquet at <unknown>:0), which has no missing parents
26/01/12 03:00:27 INFO MemoryStore: Block broadcast_440 stored as values in memory (estimated size 225.0 KiB, free 364.5 MiB)
26/01/12 03:00:27 INFO MemoryStore: Block broadcast_440_piece0 stored as bytes in memory (estimated size 77.3 KiB, free 364.4 MiB)
26/01/12 03:00:27 INFO BlockManagerInfo: Added broadcast_440_piece0 in memory on 02926ee04bc9:45221 (size: 77.3 KiB, free: 366.0 MiB)
26/01/12 03:00:27 INFO SparkContext: Created broadcast 440 from broadcast at DAGScheduler.scala:1513
26/01/12 03:00:27 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 293 (MapPartitionsRDD[734] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1))
26/01/12 03:00:27 INFO TaskSchedulerImpl: Adding task set 293.0 with 2 tasks resource profile 0
26/01/12 03:00:27 INFO TaskSetManager: Starting task 0.0 in stage 293.0 (TID 486) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 03:00:27 INFO TaskSetManager: Starting task 1.0 in stage 293.0 (TID 487) (172.18.0.5, executor 0, partition 1, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 03:00:27 INFO BlockManagerInfo: Added broadcast_440_piece0 in memory on 172.18.0.5:42453 (size: 77.3 KiB, free: 366.0 MiB)
26/01/12 03:00:27 INFO BlockManagerInfo: Added broadcast_439_piece0 in memory on 172.18.0.5:42453 (size: 35.4 KiB, free: 366.0 MiB)
26/01/12 03:00:27 INFO TaskSetManager: Finished task 1.0 in stage 293.0 (TID 487) in 58 ms on 172.18.0.5 (executor 0) (1/2)
26/01/12 03:00:31 INFO TaskSetManager: Finished task 0.0 in stage 293.0 (TID 486) in 4655 ms on 172.18.0.5 (executor 0) (2/2)
26/01/12 03:00:31 INFO TaskSchedulerImpl: Removed TaskSet 293.0, whose tasks have all completed, from pool 
26/01/12 03:00:31 INFO DAGScheduler: ResultStage 293 (parquet at <unknown>:0) finished in 4.672 s
26/01/12 03:00:31 INFO DAGScheduler: Job 293 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 03:00:31 INFO TaskSchedulerImpl: Killing all running tasks in stage 293: Stage finished
26/01/12 03:00:31 INFO DAGScheduler: Job 293 finished: parquet at <unknown>:0, took 4.679113 s
26/01/12 03:00:31 INFO FileFormatWriter: Start to commit write Job a174677a-4ace-45d3-a0e5-67d3bc215df3.
26/01/12 03:00:31 INFO FileFormatWriter: Write Job a174677a-4ace-45d3-a0e5-67d3bc215df3 committed. Elapsed time: 26 ms.
26/01/12 03:00:31 INFO FileFormatWriter: Finished processing stats for write job a174677a-4ace-45d3-a0e5-67d3bc215df3.
Cargando: yellow_tripdata_2021-04.parquet en hdfs://hadoop-namenode:8020/data/nyc/raw/taxi-trips/2021...
26/01/12 03:00:32 INFO InMemoryFileIndex: It took 7 ms to list leaf files for 1 paths.
26/01/12 03:00:32 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 03:00:32 INFO DAGScheduler: Got job 294 (parquet at <unknown>:0) with 1 output partitions
26/01/12 03:00:32 INFO DAGScheduler: Final stage: ResultStage 294 (parquet at <unknown>:0)
26/01/12 03:00:32 INFO DAGScheduler: Parents of final stage: List()
26/01/12 03:00:32 INFO DAGScheduler: Missing parents: List()
26/01/12 03:00:32 INFO DAGScheduler: Submitting ResultStage 294 (MapPartitionsRDD[736] at parquet at <unknown>:0), which has no missing parents
26/01/12 03:00:32 INFO MemoryStore: Block broadcast_441 stored as values in memory (estimated size 102.6 KiB, free 364.3 MiB)
26/01/12 03:00:32 INFO MemoryStore: Block broadcast_441_piece0 stored as bytes in memory (estimated size 36.8 KiB, free 364.3 MiB)
26/01/12 03:00:32 INFO BlockManagerInfo: Added broadcast_441_piece0 in memory on 02926ee04bc9:45221 (size: 36.8 KiB, free: 366.0 MiB)
26/01/12 03:00:32 INFO SparkContext: Created broadcast 441 from broadcast at DAGScheduler.scala:1513
26/01/12 03:00:32 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 294 (MapPartitionsRDD[736] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0))
26/01/12 03:00:32 INFO TaskSchedulerImpl: Adding task set 294.0 with 1 tasks resource profile 0
26/01/12 03:00:32 INFO TaskSetManager: Starting task 0.0 in stage 294.0 (TID 488) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4607 bytes) taskResourceAssignments Map()
26/01/12 03:00:32 INFO BlockManagerInfo: Added broadcast_441_piece0 in memory on 172.18.0.5:42453 (size: 36.8 KiB, free: 366.0 MiB)
26/01/12 03:00:32 INFO TaskSetManager: Finished task 0.0 in stage 294.0 (TID 488) in 47 ms on 172.18.0.5 (executor 0) (1/1)
26/01/12 03:00:32 INFO TaskSchedulerImpl: Removed TaskSet 294.0, whose tasks have all completed, from pool 
26/01/12 03:00:32 INFO DAGScheduler: ResultStage 294 (parquet at <unknown>:0) finished in 0.057 s
26/01/12 03:00:32 INFO DAGScheduler: Job 294 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 03:00:32 INFO TaskSchedulerImpl: Killing all running tasks in stage 294: Stage finished
26/01/12 03:00:32 INFO DAGScheduler: Job 294 finished: parquet at <unknown>:0, took 0.060659 s
26/01/12 03:00:32 INFO FileSourceStrategy: Pushed Filters: 
26/01/12 03:00:32 INFO FileSourceStrategy: Post-Scan Filters: 
26/01/12 03:00:32 INFO FileSourceStrategy: Output Data Schema: struct<VendorID: bigint, tpep_pickup_datetime: timestamp, tpep_dropoff_datetime: timestamp, passenger_count: double, trip_distance: double ... 17 more fields>
26/01/12 03:00:32 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 03:00:32 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 03:00:32 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 03:00:32 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 03:00:32 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 03:00:32 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 03:00:32 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 03:00:32 INFO MemoryStore: Block broadcast_442 stored as values in memory (estimated size 358.5 KiB, free 363.9 MiB)
26/01/12 03:00:32 INFO MemoryStore: Block broadcast_442_piece0 stored as bytes in memory (estimated size 35.4 KiB, free 363.9 MiB)
26/01/12 03:00:32 INFO BlockManagerInfo: Added broadcast_442_piece0 in memory on 02926ee04bc9:45221 (size: 35.4 KiB, free: 365.9 MiB)
26/01/12 03:00:32 INFO SparkContext: Created broadcast 442 from parquet at <unknown>:0
26/01/12 03:00:32 INFO FileSourceScanExec: Planning scan with bin packing, max size: 19106432 bytes, open cost is considered as scanning 4194304 bytes.
26/01/12 03:00:32 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 03:00:32 INFO DAGScheduler: Got job 295 (parquet at <unknown>:0) with 2 output partitions
26/01/12 03:00:32 INFO DAGScheduler: Final stage: ResultStage 295 (parquet at <unknown>:0)
26/01/12 03:00:32 INFO DAGScheduler: Parents of final stage: List()
26/01/12 03:00:32 INFO DAGScheduler: Missing parents: List()
26/01/12 03:00:32 INFO DAGScheduler: Submitting ResultStage 295 (MapPartitionsRDD[739] at parquet at <unknown>:0), which has no missing parents
26/01/12 03:00:32 INFO MemoryStore: Block broadcast_443 stored as values in memory (estimated size 225.0 KiB, free 363.7 MiB)
26/01/12 03:00:32 INFO MemoryStore: Block broadcast_443_piece0 stored as bytes in memory (estimated size 77.3 KiB, free 363.6 MiB)
26/01/12 03:00:32 INFO BlockManagerInfo: Added broadcast_443_piece0 in memory on 02926ee04bc9:45221 (size: 77.3 KiB, free: 365.9 MiB)
26/01/12 03:00:32 INFO SparkContext: Created broadcast 443 from broadcast at DAGScheduler.scala:1513
26/01/12 03:00:32 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 295 (MapPartitionsRDD[739] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1))
26/01/12 03:00:32 INFO TaskSchedulerImpl: Adding task set 295.0 with 2 tasks resource profile 0
26/01/12 03:00:32 INFO TaskSetManager: Starting task 0.0 in stage 295.0 (TID 489) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 03:00:32 INFO TaskSetManager: Starting task 1.0 in stage 295.0 (TID 490) (172.18.0.5, executor 0, partition 1, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 03:00:32 INFO BlockManagerInfo: Added broadcast_443_piece0 in memory on 172.18.0.5:42453 (size: 77.3 KiB, free: 365.9 MiB)
26/01/12 03:00:32 INFO BlockManagerInfo: Added broadcast_442_piece0 in memory on 172.18.0.5:42453 (size: 35.4 KiB, free: 365.9 MiB)
26/01/12 03:00:32 INFO TaskSetManager: Finished task 1.0 in stage 295.0 (TID 490) in 47 ms on 172.18.0.5 (executor 0) (1/2)
26/01/12 03:00:37 INFO TaskSetManager: Finished task 0.0 in stage 295.0 (TID 489) in 5726 ms on 172.18.0.5 (executor 0) (2/2)
26/01/12 03:00:37 INFO TaskSchedulerImpl: Removed TaskSet 295.0, whose tasks have all completed, from pool 
26/01/12 03:00:37 INFO DAGScheduler: ResultStage 295 (parquet at <unknown>:0) finished in 5.743 s
26/01/12 03:00:37 INFO DAGScheduler: Job 295 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 03:00:37 INFO TaskSchedulerImpl: Killing all running tasks in stage 295: Stage finished
26/01/12 03:00:37 INFO DAGScheduler: Job 295 finished: parquet at <unknown>:0, took 5.747434 s
26/01/12 03:00:37 INFO FileFormatWriter: Start to commit write Job cdabbe8c-46ca-4013-aaeb-4d8c11726f8f.
26/01/12 03:00:37 INFO FileFormatWriter: Write Job cdabbe8c-46ca-4013-aaeb-4d8c11726f8f committed. Elapsed time: 32 ms.
26/01/12 03:00:37 INFO FileFormatWriter: Finished processing stats for write job cdabbe8c-46ca-4013-aaeb-4d8c11726f8f.
Cargando: yellow_tripdata_2021-05.parquet en hdfs://hadoop-namenode:8020/data/nyc/raw/taxi-trips/2021...
26/01/12 03:00:37 INFO InMemoryFileIndex: It took 8 ms to list leaf files for 1 paths.
26/01/12 03:00:37 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 03:00:37 INFO DAGScheduler: Got job 296 (parquet at <unknown>:0) with 1 output partitions
26/01/12 03:00:37 INFO DAGScheduler: Final stage: ResultStage 296 (parquet at <unknown>:0)
26/01/12 03:00:37 INFO DAGScheduler: Parents of final stage: List()
26/01/12 03:00:37 INFO DAGScheduler: Missing parents: List()
26/01/12 03:00:37 INFO DAGScheduler: Submitting ResultStage 296 (MapPartitionsRDD[741] at parquet at <unknown>:0), which has no missing parents
26/01/12 03:00:37 INFO MemoryStore: Block broadcast_444 stored as values in memory (estimated size 102.6 KiB, free 363.5 MiB)
26/01/12 03:00:37 INFO MemoryStore: Block broadcast_444_piece0 stored as bytes in memory (estimated size 36.8 KiB, free 363.5 MiB)
26/01/12 03:00:37 INFO BlockManagerInfo: Added broadcast_444_piece0 in memory on 02926ee04bc9:45221 (size: 36.8 KiB, free: 365.8 MiB)
26/01/12 03:00:37 INFO SparkContext: Created broadcast 444 from broadcast at DAGScheduler.scala:1513
26/01/12 03:00:37 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 296 (MapPartitionsRDD[741] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0))
26/01/12 03:00:37 INFO TaskSchedulerImpl: Adding task set 296.0 with 1 tasks resource profile 0
26/01/12 03:00:37 INFO TaskSetManager: Starting task 0.0 in stage 296.0 (TID 491) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4607 bytes) taskResourceAssignments Map()
26/01/12 03:00:37 INFO BlockManagerInfo: Added broadcast_444_piece0 in memory on 172.18.0.5:42453 (size: 36.8 KiB, free: 365.8 MiB)
26/01/12 03:00:38 INFO TaskSetManager: Finished task 0.0 in stage 296.0 (TID 491) in 45 ms on 172.18.0.5 (executor 0) (1/1)
26/01/12 03:00:38 INFO TaskSchedulerImpl: Removed TaskSet 296.0, whose tasks have all completed, from pool 
26/01/12 03:00:38 INFO DAGScheduler: ResultStage 296 (parquet at <unknown>:0) finished in 0.057 s
26/01/12 03:00:38 INFO DAGScheduler: Job 296 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 03:00:38 INFO TaskSchedulerImpl: Killing all running tasks in stage 296: Stage finished
26/01/12 03:00:38 INFO DAGScheduler: Job 296 finished: parquet at <unknown>:0, took 0.060189 s
26/01/12 03:00:38 INFO FileSourceStrategy: Pushed Filters: 
26/01/12 03:00:38 INFO FileSourceStrategy: Post-Scan Filters: 
26/01/12 03:00:38 INFO FileSourceStrategy: Output Data Schema: struct<VendorID: bigint, tpep_pickup_datetime: timestamp, tpep_dropoff_datetime: timestamp, passenger_count: double, trip_distance: double ... 17 more fields>
26/01/12 03:00:38 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 03:00:38 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 03:00:38 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 03:00:38 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 03:00:38 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 03:00:38 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 03:00:38 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 03:00:38 INFO MemoryStore: Block broadcast_445 stored as values in memory (estimated size 358.5 KiB, free 363.1 MiB)
26/01/12 03:00:38 INFO MemoryStore: Block broadcast_445_piece0 stored as bytes in memory (estimated size 35.4 KiB, free 363.1 MiB)
26/01/12 03:00:38 INFO BlockManagerInfo: Added broadcast_445_piece0 in memory on 02926ee04bc9:45221 (size: 35.4 KiB, free: 365.8 MiB)
26/01/12 03:00:38 INFO SparkContext: Created broadcast 445 from parquet at <unknown>:0
26/01/12 03:00:38 INFO FileSourceScanExec: Planning scan with bin packing, max size: 21468993 bytes, open cost is considered as scanning 4194304 bytes.
26/01/12 03:00:38 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 03:00:38 INFO DAGScheduler: Got job 297 (parquet at <unknown>:0) with 2 output partitions
26/01/12 03:00:38 INFO DAGScheduler: Final stage: ResultStage 297 (parquet at <unknown>:0)
26/01/12 03:00:38 INFO DAGScheduler: Parents of final stage: List()
26/01/12 03:00:38 INFO DAGScheduler: Missing parents: List()
26/01/12 03:00:38 INFO DAGScheduler: Submitting ResultStage 297 (MapPartitionsRDD[744] at parquet at <unknown>:0), which has no missing parents
26/01/12 03:00:38 INFO BlockManagerInfo: Removed broadcast_436_piece0 on 02926ee04bc9:45221 in memory (size: 35.4 KiB, free: 365.8 MiB)
26/01/12 03:00:38 INFO BlockManagerInfo: Removed broadcast_436_piece0 on 172.18.0.5:42453 in memory (size: 35.4 KiB, free: 365.9 MiB)
26/01/12 03:00:38 INFO BlockManagerInfo: Removed broadcast_439_piece0 on 02926ee04bc9:45221 in memory (size: 35.4 KiB, free: 365.9 MiB)
26/01/12 03:00:38 INFO BlockManagerInfo: Removed broadcast_439_piece0 on 172.18.0.5:42453 in memory (size: 35.4 KiB, free: 365.9 MiB)
26/01/12 03:00:38 INFO BlockManagerInfo: Removed broadcast_438_piece0 on 02926ee04bc9:45221 in memory (size: 36.8 KiB, free: 365.9 MiB)
26/01/12 03:00:38 INFO BlockManagerInfo: Removed broadcast_438_piece0 on 172.18.0.5:42453 in memory (size: 36.8 KiB, free: 365.9 MiB)
26/01/12 03:00:38 INFO MemoryStore: Block broadcast_446 stored as values in memory (estimated size 225.0 KiB, free 363.8 MiB)
26/01/12 03:00:38 INFO MemoryStore: Block broadcast_446_piece0 stored as bytes in memory (estimated size 77.3 KiB, free 363.7 MiB)
26/01/12 03:00:38 INFO BlockManagerInfo: Removed broadcast_441_piece0 on 02926ee04bc9:45221 in memory (size: 36.8 KiB, free: 365.9 MiB)
26/01/12 03:00:38 INFO BlockManagerInfo: Added broadcast_446_piece0 in memory on 02926ee04bc9:45221 (size: 77.3 KiB, free: 365.9 MiB)
26/01/12 03:00:38 INFO BlockManagerInfo: Removed broadcast_441_piece0 on 172.18.0.5:42453 in memory (size: 36.8 KiB, free: 366.0 MiB)
26/01/12 03:00:38 INFO SparkContext: Created broadcast 446 from broadcast at DAGScheduler.scala:1513
26/01/12 03:00:38 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 297 (MapPartitionsRDD[744] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1))
26/01/12 03:00:38 INFO TaskSchedulerImpl: Adding task set 297.0 with 2 tasks resource profile 0
26/01/12 03:00:38 INFO TaskSetManager: Starting task 0.0 in stage 297.0 (TID 492) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 03:00:38 INFO BlockManagerInfo: Removed broadcast_440_piece0 on 02926ee04bc9:45221 in memory (size: 77.3 KiB, free: 365.9 MiB)
26/01/12 03:00:38 INFO TaskSetManager: Starting task 1.0 in stage 297.0 (TID 493) (172.18.0.5, executor 0, partition 1, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 03:00:38 INFO BlockManagerInfo: Removed broadcast_440_piece0 on 172.18.0.5:42453 in memory (size: 77.3 KiB, free: 366.0 MiB)
26/01/12 03:00:38 INFO BlockManagerInfo: Removed broadcast_443_piece0 on 02926ee04bc9:45221 in memory (size: 77.3 KiB, free: 366.0 MiB)
26/01/12 03:00:38 INFO BlockManagerInfo: Removed broadcast_443_piece0 on 172.18.0.5:42453 in memory (size: 77.3 KiB, free: 366.1 MiB)
26/01/12 03:00:38 INFO BlockManagerInfo: Added broadcast_446_piece0 in memory on 172.18.0.5:42453 (size: 77.3 KiB, free: 366.0 MiB)
26/01/12 03:00:38 INFO BlockManagerInfo: Removed broadcast_442_piece0 on 02926ee04bc9:45221 in memory (size: 35.4 KiB, free: 366.0 MiB)
26/01/12 03:00:38 INFO BlockManagerInfo: Removed broadcast_442_piece0 on 172.18.0.5:42453 in memory (size: 35.4 KiB, free: 366.1 MiB)
26/01/12 03:00:38 INFO BlockManagerInfo: Removed broadcast_444_piece0 on 02926ee04bc9:45221 in memory (size: 36.8 KiB, free: 366.1 MiB)
26/01/12 03:00:38 INFO BlockManagerInfo: Removed broadcast_444_piece0 on 172.18.0.5:42453 in memory (size: 36.8 KiB, free: 366.1 MiB)
26/01/12 03:00:38 INFO BlockManagerInfo: Added broadcast_445_piece0 in memory on 172.18.0.5:42453 (size: 35.4 KiB, free: 366.1 MiB)
26/01/12 03:00:38 INFO TaskSetManager: Finished task 1.0 in stage 297.0 (TID 493) in 57 ms on 172.18.0.5 (executor 0) (1/2)
26/01/12 03:00:45 INFO TaskSetManager: Finished task 0.0 in stage 297.0 (TID 492) in 7016 ms on 172.18.0.5 (executor 0) (2/2)
26/01/12 03:00:45 INFO TaskSchedulerImpl: Removed TaskSet 297.0, whose tasks have all completed, from pool 
26/01/12 03:00:45 INFO DAGScheduler: ResultStage 297 (parquet at <unknown>:0) finished in 7.042 s
26/01/12 03:00:45 INFO DAGScheduler: Job 297 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 03:00:45 INFO TaskSchedulerImpl: Killing all running tasks in stage 297: Stage finished
26/01/12 03:00:45 INFO DAGScheduler: Job 297 finished: parquet at <unknown>:0, took 7.045937 s
26/01/12 03:00:45 INFO FileFormatWriter: Start to commit write Job 972b025b-3f0d-4502-87f2-909fc1612e85.
26/01/12 03:00:45 INFO FileFormatWriter: Write Job 972b025b-3f0d-4502-87f2-909fc1612e85 committed. Elapsed time: 25 ms.
26/01/12 03:00:45 INFO FileFormatWriter: Finished processing stats for write job 972b025b-3f0d-4502-87f2-909fc1612e85.
Cargando: yellow_tripdata_2021-06.parquet en hdfs://hadoop-namenode:8020/data/nyc/raw/taxi-trips/2021...
26/01/12 03:00:45 INFO InMemoryFileIndex: It took 4 ms to list leaf files for 1 paths.
26/01/12 03:00:45 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 03:00:45 INFO DAGScheduler: Got job 298 (parquet at <unknown>:0) with 1 output partitions
26/01/12 03:00:45 INFO DAGScheduler: Final stage: ResultStage 298 (parquet at <unknown>:0)
26/01/12 03:00:45 INFO DAGScheduler: Parents of final stage: List()
26/01/12 03:00:45 INFO DAGScheduler: Missing parents: List()
26/01/12 03:00:45 INFO DAGScheduler: Submitting ResultStage 298 (MapPartitionsRDD[746] at parquet at <unknown>:0), which has no missing parents
26/01/12 03:00:45 INFO MemoryStore: Block broadcast_447 stored as values in memory (estimated size 102.6 KiB, free 364.8 MiB)
26/01/12 03:00:45 INFO MemoryStore: Block broadcast_447_piece0 stored as bytes in memory (estimated size 36.8 KiB, free 364.8 MiB)
26/01/12 03:00:45 INFO BlockManagerInfo: Added broadcast_447_piece0 in memory on 02926ee04bc9:45221 (size: 36.8 KiB, free: 366.0 MiB)
26/01/12 03:00:45 INFO SparkContext: Created broadcast 447 from broadcast at DAGScheduler.scala:1513
26/01/12 03:00:45 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 298 (MapPartitionsRDD[746] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0))
26/01/12 03:00:45 INFO TaskSchedulerImpl: Adding task set 298.0 with 1 tasks resource profile 0
26/01/12 03:00:45 INFO TaskSetManager: Starting task 0.0 in stage 298.0 (TID 494) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4607 bytes) taskResourceAssignments Map()
26/01/12 03:00:45 INFO BlockManagerInfo: Added broadcast_447_piece0 in memory on 172.18.0.5:42453 (size: 36.8 KiB, free: 366.0 MiB)
26/01/12 03:00:45 INFO TaskSetManager: Finished task 0.0 in stage 298.0 (TID 494) in 46 ms on 172.18.0.5 (executor 0) (1/1)
26/01/12 03:00:45 INFO TaskSchedulerImpl: Removed TaskSet 298.0, whose tasks have all completed, from pool 
26/01/12 03:00:45 INFO DAGScheduler: ResultStage 298 (parquet at <unknown>:0) finished in 0.057 s
26/01/12 03:00:45 INFO DAGScheduler: Job 298 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 03:00:45 INFO TaskSchedulerImpl: Killing all running tasks in stage 298: Stage finished
26/01/12 03:00:45 INFO DAGScheduler: Job 298 finished: parquet at <unknown>:0, took 0.060690 s
26/01/12 03:00:45 INFO FileSourceStrategy: Pushed Filters: 
26/01/12 03:00:45 INFO FileSourceStrategy: Post-Scan Filters: 
26/01/12 03:00:45 INFO FileSourceStrategy: Output Data Schema: struct<VendorID: bigint, tpep_pickup_datetime: timestamp, tpep_dropoff_datetime: timestamp, passenger_count: double, trip_distance: double ... 17 more fields>
26/01/12 03:00:45 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 03:00:45 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 03:00:45 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 03:00:45 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 03:00:45 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 03:00:45 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 03:00:45 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 03:00:45 INFO MemoryStore: Block broadcast_448 stored as values in memory (estimated size 358.5 KiB, free 364.5 MiB)
26/01/12 03:00:45 INFO MemoryStore: Block broadcast_448_piece0 stored as bytes in memory (estimated size 35.4 KiB, free 364.4 MiB)
26/01/12 03:00:45 INFO BlockManagerInfo: Added broadcast_448_piece0 in memory on 02926ee04bc9:45221 (size: 35.4 KiB, free: 366.0 MiB)
26/01/12 03:00:45 INFO SparkContext: Created broadcast 448 from parquet at <unknown>:0
26/01/12 03:00:45 INFO FileSourceScanExec: Planning scan with bin packing, max size: 24132948 bytes, open cost is considered as scanning 4194304 bytes.
26/01/12 03:00:45 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 03:00:45 INFO DAGScheduler: Got job 299 (parquet at <unknown>:0) with 2 output partitions
26/01/12 03:00:45 INFO DAGScheduler: Final stage: ResultStage 299 (parquet at <unknown>:0)
26/01/12 03:00:45 INFO DAGScheduler: Parents of final stage: List()
26/01/12 03:00:45 INFO DAGScheduler: Missing parents: List()
26/01/12 03:00:45 INFO DAGScheduler: Submitting ResultStage 299 (MapPartitionsRDD[749] at parquet at <unknown>:0), which has no missing parents
26/01/12 03:00:45 INFO MemoryStore: Block broadcast_449 stored as values in memory (estimated size 225.0 KiB, free 364.2 MiB)
26/01/12 03:00:45 INFO MemoryStore: Block broadcast_449_piece0 stored as bytes in memory (estimated size 77.3 KiB, free 364.1 MiB)
26/01/12 03:00:45 INFO BlockManagerInfo: Added broadcast_449_piece0 in memory on 02926ee04bc9:45221 (size: 77.3 KiB, free: 365.9 MiB)
26/01/12 03:00:45 INFO SparkContext: Created broadcast 449 from broadcast at DAGScheduler.scala:1513
26/01/12 03:00:45 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 299 (MapPartitionsRDD[749] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1))
26/01/12 03:00:45 INFO TaskSchedulerImpl: Adding task set 299.0 with 2 tasks resource profile 0
26/01/12 03:00:45 INFO TaskSetManager: Starting task 0.0 in stage 299.0 (TID 495) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 03:00:45 INFO TaskSetManager: Starting task 1.0 in stage 299.0 (TID 496) (172.18.0.5, executor 0, partition 1, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 03:00:45 INFO BlockManagerInfo: Added broadcast_449_piece0 in memory on 172.18.0.5:42453 (size: 77.3 KiB, free: 366.0 MiB)
26/01/12 03:00:45 INFO BlockManagerInfo: Added broadcast_448_piece0 in memory on 172.18.0.5:42453 (size: 35.4 KiB, free: 365.9 MiB)
26/01/12 03:00:45 INFO TaskSetManager: Finished task 1.0 in stage 299.0 (TID 496) in 51 ms on 172.18.0.5 (executor 0) (1/2)
26/01/12 03:00:53 INFO TaskSetManager: Finished task 0.0 in stage 299.0 (TID 495) in 7752 ms on 172.18.0.5 (executor 0) (2/2)
26/01/12 03:00:53 INFO TaskSchedulerImpl: Removed TaskSet 299.0, whose tasks have all completed, from pool 
26/01/12 03:00:53 INFO DAGScheduler: ResultStage 299 (parquet at <unknown>:0) finished in 7.770 s
26/01/12 03:00:53 INFO DAGScheduler: Job 299 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 03:00:53 INFO TaskSchedulerImpl: Killing all running tasks in stage 299: Stage finished
26/01/12 03:00:53 INFO DAGScheduler: Job 299 finished: parquet at <unknown>:0, took 7.774153 s
26/01/12 03:00:53 INFO FileFormatWriter: Start to commit write Job 8d406d0c-cb63-477a-8e5a-68d0ae3d32f7.
26/01/12 03:00:53 INFO FileFormatWriter: Write Job 8d406d0c-cb63-477a-8e5a-68d0ae3d32f7 committed. Elapsed time: 27 ms.
26/01/12 03:00:53 INFO FileFormatWriter: Finished processing stats for write job 8d406d0c-cb63-477a-8e5a-68d0ae3d32f7.
Cargando: yellow_tripdata_2021-07.parquet en hdfs://hadoop-namenode:8020/data/nyc/raw/taxi-trips/2021...
26/01/12 03:00:53 INFO InMemoryFileIndex: It took 7 ms to list leaf files for 1 paths.
26/01/12 03:00:53 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 03:00:53 INFO DAGScheduler: Got job 300 (parquet at <unknown>:0) with 1 output partitions
26/01/12 03:00:53 INFO DAGScheduler: Final stage: ResultStage 300 (parquet at <unknown>:0)
26/01/12 03:00:53 INFO DAGScheduler: Parents of final stage: List()
26/01/12 03:00:53 INFO DAGScheduler: Missing parents: List()
26/01/12 03:00:53 INFO DAGScheduler: Submitting ResultStage 300 (MapPartitionsRDD[751] at parquet at <unknown>:0), which has no missing parents
26/01/12 03:00:53 INFO MemoryStore: Block broadcast_450 stored as values in memory (estimated size 102.6 KiB, free 364.0 MiB)
26/01/12 03:00:53 INFO MemoryStore: Block broadcast_450_piece0 stored as bytes in memory (estimated size 36.8 KiB, free 364.0 MiB)
26/01/12 03:00:53 INFO BlockManagerInfo: Added broadcast_450_piece0 in memory on 02926ee04bc9:45221 (size: 36.8 KiB, free: 365.9 MiB)
26/01/12 03:00:53 INFO SparkContext: Created broadcast 450 from broadcast at DAGScheduler.scala:1513
26/01/12 03:00:53 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 300 (MapPartitionsRDD[751] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0))
26/01/12 03:00:53 INFO TaskSchedulerImpl: Adding task set 300.0 with 1 tasks resource profile 0
26/01/12 03:00:53 INFO TaskSetManager: Starting task 0.0 in stage 300.0 (TID 497) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4607 bytes) taskResourceAssignments Map()
26/01/12 03:00:53 INFO BlockManagerInfo: Added broadcast_450_piece0 in memory on 172.18.0.5:42453 (size: 36.8 KiB, free: 365.9 MiB)
26/01/12 03:00:53 INFO TaskSetManager: Finished task 0.0 in stage 300.0 (TID 497) in 41 ms on 172.18.0.5 (executor 0) (1/1)
26/01/12 03:00:53 INFO TaskSchedulerImpl: Removed TaskSet 300.0, whose tasks have all completed, from pool 
26/01/12 03:00:53 INFO DAGScheduler: ResultStage 300 (parquet at <unknown>:0) finished in 0.052 s
26/01/12 03:00:53 INFO DAGScheduler: Job 300 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 03:00:53 INFO TaskSchedulerImpl: Killing all running tasks in stage 300: Stage finished
26/01/12 03:00:53 INFO DAGScheduler: Job 300 finished: parquet at <unknown>:0, took 0.055883 s
26/01/12 03:00:53 INFO FileSourceStrategy: Pushed Filters: 
26/01/12 03:00:53 INFO FileSourceStrategy: Post-Scan Filters: 
26/01/12 03:00:53 INFO FileSourceStrategy: Output Data Schema: struct<VendorID: bigint, tpep_pickup_datetime: timestamp, tpep_dropoff_datetime: timestamp, passenger_count: double, trip_distance: double ... 17 more fields>
26/01/12 03:00:53 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 03:00:53 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 03:00:53 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 03:00:53 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 03:00:53 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 03:00:53 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 03:00:53 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 03:00:53 INFO MemoryStore: Block broadcast_451 stored as values in memory (estimated size 358.5 KiB, free 363.6 MiB)
26/01/12 03:00:53 INFO MemoryStore: Block broadcast_451_piece0 stored as bytes in memory (estimated size 35.4 KiB, free 363.6 MiB)
26/01/12 03:00:53 INFO BlockManagerInfo: Added broadcast_451_piece0 in memory on 02926ee04bc9:45221 (size: 35.4 KiB, free: 365.9 MiB)
26/01/12 03:00:53 INFO SparkContext: Created broadcast 451 from parquet at <unknown>:0
26/01/12 03:00:53 INFO FileSourceScanExec: Planning scan with bin packing, max size: 23945997 bytes, open cost is considered as scanning 4194304 bytes.
26/01/12 03:00:53 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 03:00:53 INFO DAGScheduler: Got job 301 (parquet at <unknown>:0) with 2 output partitions
26/01/12 03:00:53 INFO DAGScheduler: Final stage: ResultStage 301 (parquet at <unknown>:0)
26/01/12 03:00:53 INFO DAGScheduler: Parents of final stage: List()
26/01/12 03:00:53 INFO DAGScheduler: Missing parents: List()
26/01/12 03:00:53 INFO DAGScheduler: Submitting ResultStage 301 (MapPartitionsRDD[754] at parquet at <unknown>:0), which has no missing parents
26/01/12 03:00:53 INFO MemoryStore: Block broadcast_452 stored as values in memory (estimated size 225.0 KiB, free 363.4 MiB)
26/01/12 03:00:53 INFO MemoryStore: Block broadcast_452_piece0 stored as bytes in memory (estimated size 77.3 KiB, free 363.3 MiB)
26/01/12 03:00:53 INFO BlockManagerInfo: Added broadcast_452_piece0 in memory on 02926ee04bc9:45221 (size: 77.3 KiB, free: 365.8 MiB)
26/01/12 03:00:53 INFO SparkContext: Created broadcast 452 from broadcast at DAGScheduler.scala:1513
26/01/12 03:00:53 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 301 (MapPartitionsRDD[754] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1))
26/01/12 03:00:53 INFO TaskSchedulerImpl: Adding task set 301.0 with 2 tasks resource profile 0
26/01/12 03:00:53 INFO TaskSetManager: Starting task 0.0 in stage 301.0 (TID 498) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 03:00:53 INFO TaskSetManager: Starting task 1.0 in stage 301.0 (TID 499) (172.18.0.5, executor 0, partition 1, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 03:00:53 INFO BlockManagerInfo: Added broadcast_452_piece0 in memory on 172.18.0.5:42453 (size: 77.3 KiB, free: 365.8 MiB)
26/01/12 03:00:53 INFO BlockManagerInfo: Added broadcast_451_piece0 in memory on 172.18.0.5:42453 (size: 35.4 KiB, free: 365.8 MiB)
26/01/12 03:00:53 INFO TaskSetManager: Finished task 1.0 in stage 301.0 (TID 499) in 52 ms on 172.18.0.5 (executor 0) (1/2)
26/01/12 03:01:00 INFO TaskSetManager: Finished task 0.0 in stage 301.0 (TID 498) in 7166 ms on 172.18.0.5 (executor 0) (2/2)
26/01/12 03:01:00 INFO TaskSchedulerImpl: Removed TaskSet 301.0, whose tasks have all completed, from pool 
26/01/12 03:01:00 INFO DAGScheduler: ResultStage 301 (parquet at <unknown>:0) finished in 7.182 s
26/01/12 03:01:00 INFO DAGScheduler: Job 301 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 03:01:00 INFO TaskSchedulerImpl: Killing all running tasks in stage 301: Stage finished
26/01/12 03:01:00 INFO DAGScheduler: Job 301 finished: parquet at <unknown>:0, took 7.187341 s
26/01/12 03:01:00 INFO FileFormatWriter: Start to commit write Job 641bf55c-208c-46b3-a0c2-376e8ffe9ecd.
26/01/12 03:01:00 INFO FileFormatWriter: Write Job 641bf55c-208c-46b3-a0c2-376e8ffe9ecd committed. Elapsed time: 25 ms.
26/01/12 03:01:00 INFO FileFormatWriter: Finished processing stats for write job 641bf55c-208c-46b3-a0c2-376e8ffe9ecd.
Cargando: yellow_tripdata_2021-08.parquet en hdfs://hadoop-namenode:8020/data/nyc/raw/taxi-trips/2021...
26/01/12 03:01:00 INFO InMemoryFileIndex: It took 6 ms to list leaf files for 1 paths.
26/01/12 03:01:00 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 03:01:00 INFO DAGScheduler: Got job 302 (parquet at <unknown>:0) with 1 output partitions
26/01/12 03:01:00 INFO DAGScheduler: Final stage: ResultStage 302 (parquet at <unknown>:0)
26/01/12 03:01:00 INFO DAGScheduler: Parents of final stage: List()
26/01/12 03:01:00 INFO DAGScheduler: Missing parents: List()
26/01/12 03:01:00 INFO DAGScheduler: Submitting ResultStage 302 (MapPartitionsRDD[756] at parquet at <unknown>:0), which has no missing parents
26/01/12 03:01:00 INFO MemoryStore: Block broadcast_453 stored as values in memory (estimated size 102.6 KiB, free 363.2 MiB)
26/01/12 03:01:00 INFO MemoryStore: Block broadcast_453_piece0 stored as bytes in memory (estimated size 36.8 KiB, free 363.2 MiB)
26/01/12 03:01:00 INFO BlockManagerInfo: Added broadcast_453_piece0 in memory on 02926ee04bc9:45221 (size: 36.8 KiB, free: 365.8 MiB)
26/01/12 03:01:00 INFO SparkContext: Created broadcast 453 from broadcast at DAGScheduler.scala:1513
26/01/12 03:01:00 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 302 (MapPartitionsRDD[756] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0))
26/01/12 03:01:00 INFO TaskSchedulerImpl: Adding task set 302.0 with 1 tasks resource profile 0
26/01/12 03:01:00 INFO TaskSetManager: Starting task 0.0 in stage 302.0 (TID 500) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4607 bytes) taskResourceAssignments Map()
26/01/12 03:01:00 INFO BlockManagerInfo: Added broadcast_453_piece0 in memory on 172.18.0.5:42453 (size: 36.8 KiB, free: 365.8 MiB)
26/01/12 03:01:00 INFO TaskSetManager: Finished task 0.0 in stage 302.0 (TID 500) in 56 ms on 172.18.0.5 (executor 0) (1/1)
26/01/12 03:01:00 INFO TaskSchedulerImpl: Removed TaskSet 302.0, whose tasks have all completed, from pool 
26/01/12 03:01:00 INFO DAGScheduler: ResultStage 302 (parquet at <unknown>:0) finished in 0.073 s
26/01/12 03:01:00 INFO DAGScheduler: Job 302 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 03:01:00 INFO TaskSchedulerImpl: Killing all running tasks in stage 302: Stage finished
26/01/12 03:01:00 INFO DAGScheduler: Job 302 finished: parquet at <unknown>:0, took 0.077013 s
26/01/12 03:01:00 INFO BlockManagerInfo: Removed broadcast_450_piece0 on 02926ee04bc9:45221 in memory (size: 36.8 KiB, free: 365.8 MiB)
26/01/12 03:01:00 INFO BlockManagerInfo: Removed broadcast_450_piece0 on 172.18.0.5:42453 in memory (size: 36.8 KiB, free: 365.8 MiB)
26/01/12 03:01:00 INFO FileSourceStrategy: Pushed Filters: 
26/01/12 03:01:00 INFO FileSourceStrategy: Post-Scan Filters: 
26/01/12 03:01:00 INFO FileSourceStrategy: Output Data Schema: struct<VendorID: bigint, tpep_pickup_datetime: timestamp, tpep_dropoff_datetime: timestamp, passenger_count: double, trip_distance: double ... 17 more fields>
26/01/12 03:01:00 INFO BlockManagerInfo: Removed broadcast_449_piece0 on 02926ee04bc9:45221 in memory (size: 77.3 KiB, free: 365.9 MiB)
26/01/12 03:01:00 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 03:01:00 INFO BlockManagerInfo: Removed broadcast_449_piece0 on 172.18.0.5:42453 in memory (size: 77.3 KiB, free: 365.9 MiB)
26/01/12 03:01:00 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 03:01:00 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 03:01:00 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 03:01:00 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 03:01:00 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 03:01:00 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 03:01:00 INFO BlockManagerInfo: Removed broadcast_448_piece0 on 02926ee04bc9:45221 in memory (size: 35.4 KiB, free: 365.9 MiB)
26/01/12 03:01:00 INFO BlockManagerInfo: Removed broadcast_448_piece0 on 172.18.0.5:42453 in memory (size: 35.4 KiB, free: 365.9 MiB)
26/01/12 03:01:00 INFO BlockManagerInfo: Removed broadcast_453_piece0 on 02926ee04bc9:45221 in memory (size: 36.8 KiB, free: 365.9 MiB)
26/01/12 03:01:00 INFO BlockManagerInfo: Removed broadcast_453_piece0 on 172.18.0.5:42453 in memory (size: 36.8 KiB, free: 365.9 MiB)
26/01/12 03:01:00 INFO MemoryStore: Block broadcast_454 stored as values in memory (estimated size 358.5 KiB, free 363.8 MiB)
26/01/12 03:01:00 INFO BlockManagerInfo: Removed broadcast_447_piece0 on 02926ee04bc9:45221 in memory (size: 36.8 KiB, free: 366.0 MiB)
26/01/12 03:01:00 INFO BlockManagerInfo: Removed broadcast_447_piece0 on 172.18.0.5:42453 in memory (size: 36.8 KiB, free: 366.0 MiB)
26/01/12 03:01:00 INFO BlockManagerInfo: Removed broadcast_445_piece0 on 02926ee04bc9:45221 in memory (size: 35.4 KiB, free: 366.0 MiB)
26/01/12 03:01:00 INFO BlockManagerInfo: Removed broadcast_445_piece0 on 172.18.0.5:42453 in memory (size: 35.4 KiB, free: 366.0 MiB)
26/01/12 03:01:00 INFO MemoryStore: Block broadcast_454_piece0 stored as bytes in memory (estimated size 35.4 KiB, free 364.3 MiB)
26/01/12 03:01:00 INFO BlockManagerInfo: Added broadcast_454_piece0 in memory on 02926ee04bc9:45221 (size: 35.4 KiB, free: 366.0 MiB)
26/01/12 03:01:00 INFO SparkContext: Created broadcast 454 from parquet at <unknown>:0
26/01/12 03:01:00 INFO FileSourceScanExec: Planning scan with bin packing, max size: 23810105 bytes, open cost is considered as scanning 4194304 bytes.
26/01/12 03:01:00 INFO BlockManagerInfo: Removed broadcast_446_piece0 on 02926ee04bc9:45221 in memory (size: 77.3 KiB, free: 366.0 MiB)
26/01/12 03:01:00 INFO BlockManagerInfo: Removed broadcast_446_piece0 on 172.18.0.5:42453 in memory (size: 77.3 KiB, free: 366.1 MiB)
26/01/12 03:01:00 INFO BlockManagerInfo: Removed broadcast_452_piece0 on 02926ee04bc9:45221 in memory (size: 77.3 KiB, free: 366.1 MiB)
26/01/12 03:01:00 INFO BlockManagerInfo: Removed broadcast_452_piece0 on 172.18.0.5:42453 in memory (size: 77.3 KiB, free: 366.2 MiB)
26/01/12 03:01:00 INFO BlockManagerInfo: Removed broadcast_451_piece0 on 02926ee04bc9:45221 in memory (size: 35.4 KiB, free: 366.2 MiB)
26/01/12 03:01:00 INFO BlockManagerInfo: Removed broadcast_451_piece0 on 172.18.0.5:42453 in memory (size: 35.4 KiB, free: 366.2 MiB)
26/01/12 03:01:00 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 03:01:00 INFO DAGScheduler: Got job 303 (parquet at <unknown>:0) with 2 output partitions
26/01/12 03:01:00 INFO DAGScheduler: Final stage: ResultStage 303 (parquet at <unknown>:0)
26/01/12 03:01:00 INFO DAGScheduler: Parents of final stage: List()
26/01/12 03:01:00 INFO DAGScheduler: Missing parents: List()
26/01/12 03:01:00 INFO DAGScheduler: Submitting ResultStage 303 (MapPartitionsRDD[759] at parquet at <unknown>:0), which has no missing parents
26/01/12 03:01:00 INFO MemoryStore: Block broadcast_455 stored as values in memory (estimated size 225.0 KiB, free 365.0 MiB)
26/01/12 03:01:00 INFO MemoryStore: Block broadcast_455_piece0 stored as bytes in memory (estimated size 77.3 KiB, free 364.9 MiB)
26/01/12 03:01:00 INFO BlockManagerInfo: Added broadcast_455_piece0 in memory on 02926ee04bc9:45221 (size: 77.3 KiB, free: 366.1 MiB)
26/01/12 03:01:00 INFO SparkContext: Created broadcast 455 from broadcast at DAGScheduler.scala:1513
26/01/12 03:01:00 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 303 (MapPartitionsRDD[759] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1))
26/01/12 03:01:00 INFO TaskSchedulerImpl: Adding task set 303.0 with 2 tasks resource profile 0
26/01/12 03:01:00 INFO TaskSetManager: Starting task 0.0 in stage 303.0 (TID 501) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 03:01:00 INFO TaskSetManager: Starting task 1.0 in stage 303.0 (TID 502) (172.18.0.5, executor 0, partition 1, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 03:01:00 INFO BlockManagerInfo: Added broadcast_455_piece0 in memory on 172.18.0.5:42453 (size: 77.3 KiB, free: 366.1 MiB)
26/01/12 03:01:00 INFO BlockManagerInfo: Added broadcast_454_piece0 in memory on 172.18.0.5:42453 (size: 35.4 KiB, free: 366.1 MiB)
26/01/12 03:01:00 INFO TaskSetManager: Finished task 1.0 in stage 303.0 (TID 502) in 48 ms on 172.18.0.5 (executor 0) (1/2)
26/01/12 03:01:07 INFO TaskSetManager: Finished task 0.0 in stage 303.0 (TID 501) in 7087 ms on 172.18.0.5 (executor 0) (2/2)
26/01/12 03:01:07 INFO TaskSchedulerImpl: Removed TaskSet 303.0, whose tasks have all completed, from pool 
26/01/12 03:01:07 INFO DAGScheduler: ResultStage 303 (parquet at <unknown>:0) finished in 7.105 s
26/01/12 03:01:07 INFO DAGScheduler: Job 303 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 03:01:07 INFO TaskSchedulerImpl: Killing all running tasks in stage 303: Stage finished
26/01/12 03:01:07 INFO DAGScheduler: Job 303 finished: parquet at <unknown>:0, took 7.108870 s
26/01/12 03:01:07 INFO FileFormatWriter: Start to commit write Job 490889fe-95e8-44b7-8114-8a9a64b038b4.
26/01/12 03:01:07 INFO FileFormatWriter: Write Job 490889fe-95e8-44b7-8114-8a9a64b038b4 committed. Elapsed time: 27 ms.
26/01/12 03:01:07 INFO FileFormatWriter: Finished processing stats for write job 490889fe-95e8-44b7-8114-8a9a64b038b4.
Cargando: yellow_tripdata_2021-09.parquet en hdfs://hadoop-namenode:8020/data/nyc/raw/taxi-trips/2021...
26/01/12 03:01:07 INFO InMemoryFileIndex: It took 6 ms to list leaf files for 1 paths.
26/01/12 03:01:07 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 03:01:07 INFO DAGScheduler: Got job 304 (parquet at <unknown>:0) with 1 output partitions
26/01/12 03:01:07 INFO DAGScheduler: Final stage: ResultStage 304 (parquet at <unknown>:0)
26/01/12 03:01:07 INFO DAGScheduler: Parents of final stage: List()
26/01/12 03:01:07 INFO DAGScheduler: Missing parents: List()
26/01/12 03:01:07 INFO DAGScheduler: Submitting ResultStage 304 (MapPartitionsRDD[761] at parquet at <unknown>:0), which has no missing parents
26/01/12 03:01:07 INFO MemoryStore: Block broadcast_456 stored as values in memory (estimated size 102.6 KiB, free 364.8 MiB)
26/01/12 03:01:07 INFO MemoryStore: Block broadcast_456_piece0 stored as bytes in memory (estimated size 36.8 KiB, free 364.8 MiB)
26/01/12 03:01:07 INFO BlockManagerInfo: Added broadcast_456_piece0 in memory on 02926ee04bc9:45221 (size: 36.8 KiB, free: 366.0 MiB)
26/01/12 03:01:07 INFO SparkContext: Created broadcast 456 from broadcast at DAGScheduler.scala:1513
26/01/12 03:01:07 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 304 (MapPartitionsRDD[761] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0))
26/01/12 03:01:07 INFO TaskSchedulerImpl: Adding task set 304.0 with 1 tasks resource profile 0
26/01/12 03:01:07 INFO TaskSetManager: Starting task 0.0 in stage 304.0 (TID 503) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4607 bytes) taskResourceAssignments Map()
26/01/12 03:01:07 INFO BlockManagerInfo: Added broadcast_456_piece0 in memory on 172.18.0.5:42453 (size: 36.8 KiB, free: 366.0 MiB)
26/01/12 03:01:07 INFO TaskSetManager: Finished task 0.0 in stage 304.0 (TID 503) in 48 ms on 172.18.0.5 (executor 0) (1/1)
26/01/12 03:01:07 INFO TaskSchedulerImpl: Removed TaskSet 304.0, whose tasks have all completed, from pool 
26/01/12 03:01:07 INFO DAGScheduler: ResultStage 304 (parquet at <unknown>:0) finished in 0.058 s
26/01/12 03:01:07 INFO DAGScheduler: Job 304 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 03:01:07 INFO TaskSchedulerImpl: Killing all running tasks in stage 304: Stage finished
26/01/12 03:01:07 INFO DAGScheduler: Job 304 finished: parquet at <unknown>:0, took 0.060884 s
26/01/12 03:01:07 INFO FileSourceStrategy: Pushed Filters: 
26/01/12 03:01:07 INFO FileSourceStrategy: Post-Scan Filters: 
26/01/12 03:01:07 INFO FileSourceStrategy: Output Data Schema: struct<VendorID: bigint, tpep_pickup_datetime: timestamp, tpep_dropoff_datetime: timestamp, passenger_count: double, trip_distance: double ... 17 more fields>
26/01/12 03:01:07 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 03:01:07 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 03:01:07 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 03:01:07 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 03:01:07 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 03:01:07 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 03:01:07 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 03:01:07 INFO MemoryStore: Block broadcast_457 stored as values in memory (estimated size 358.5 KiB, free 364.5 MiB)
26/01/12 03:01:07 INFO MemoryStore: Block broadcast_457_piece0 stored as bytes in memory (estimated size 35.4 KiB, free 364.4 MiB)
26/01/12 03:01:07 INFO BlockManagerInfo: Added broadcast_457_piece0 in memory on 02926ee04bc9:45221 (size: 35.4 KiB, free: 366.0 MiB)
26/01/12 03:01:07 INFO SparkContext: Created broadcast 457 from parquet at <unknown>:0
26/01/12 03:01:07 INFO FileSourceScanExec: Planning scan with bin packing, max size: 25160093 bytes, open cost is considered as scanning 4194304 bytes.
26/01/12 03:01:07 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 03:01:07 INFO DAGScheduler: Got job 305 (parquet at <unknown>:0) with 2 output partitions
26/01/12 03:01:07 INFO DAGScheduler: Final stage: ResultStage 305 (parquet at <unknown>:0)
26/01/12 03:01:07 INFO DAGScheduler: Parents of final stage: List()
26/01/12 03:01:07 INFO DAGScheduler: Missing parents: List()
26/01/12 03:01:07 INFO DAGScheduler: Submitting ResultStage 305 (MapPartitionsRDD[764] at parquet at <unknown>:0), which has no missing parents
26/01/12 03:01:07 INFO MemoryStore: Block broadcast_458 stored as values in memory (estimated size 225.0 KiB, free 364.2 MiB)
26/01/12 03:01:07 INFO MemoryStore: Block broadcast_458_piece0 stored as bytes in memory (estimated size 77.3 KiB, free 364.1 MiB)
26/01/12 03:01:07 INFO BlockManagerInfo: Added broadcast_458_piece0 in memory on 02926ee04bc9:45221 (size: 77.3 KiB, free: 365.9 MiB)
26/01/12 03:01:07 INFO SparkContext: Created broadcast 458 from broadcast at DAGScheduler.scala:1513
26/01/12 03:01:08 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 305 (MapPartitionsRDD[764] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1))
26/01/12 03:01:08 INFO TaskSchedulerImpl: Adding task set 305.0 with 2 tasks resource profile 0
26/01/12 03:01:08 INFO TaskSetManager: Starting task 0.0 in stage 305.0 (TID 504) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 03:01:08 INFO TaskSetManager: Starting task 1.0 in stage 305.0 (TID 505) (172.18.0.5, executor 0, partition 1, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 03:01:08 INFO BlockManagerInfo: Added broadcast_458_piece0 in memory on 172.18.0.5:42453 (size: 77.3 KiB, free: 366.0 MiB)
26/01/12 03:01:08 INFO BlockManagerInfo: Added broadcast_457_piece0 in memory on 172.18.0.5:42453 (size: 35.4 KiB, free: 365.9 MiB)
26/01/12 03:01:08 INFO TaskSetManager: Finished task 1.0 in stage 305.0 (TID 505) in 54 ms on 172.18.0.5 (executor 0) (1/2)
26/01/12 03:01:15 INFO TaskSetManager: Finished task 0.0 in stage 305.0 (TID 504) in 7663 ms on 172.18.0.5 (executor 0) (2/2)
26/01/12 03:01:15 INFO TaskSchedulerImpl: Removed TaskSet 305.0, whose tasks have all completed, from pool 
26/01/12 03:01:15 INFO DAGScheduler: ResultStage 305 (parquet at <unknown>:0) finished in 7.680 s
26/01/12 03:01:15 INFO DAGScheduler: Job 305 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 03:01:15 INFO TaskSchedulerImpl: Killing all running tasks in stage 305: Stage finished
26/01/12 03:01:15 INFO DAGScheduler: Job 305 finished: parquet at <unknown>:0, took 7.684612 s
26/01/12 03:01:15 INFO FileFormatWriter: Start to commit write Job ce705dfa-9f46-4ae6-b66f-d71a692c067e.
26/01/12 03:01:15 INFO FileFormatWriter: Write Job ce705dfa-9f46-4ae6-b66f-d71a692c067e committed. Elapsed time: 28 ms.
26/01/12 03:01:15 INFO FileFormatWriter: Finished processing stats for write job ce705dfa-9f46-4ae6-b66f-d71a692c067e.
Cargando: yellow_tripdata_2021-10.parquet en hdfs://hadoop-namenode:8020/data/nyc/raw/taxi-trips/2021...
26/01/12 03:01:15 INFO InMemoryFileIndex: It took 7 ms to list leaf files for 1 paths.
26/01/12 03:01:15 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 03:01:15 INFO DAGScheduler: Got job 306 (parquet at <unknown>:0) with 1 output partitions
26/01/12 03:01:15 INFO DAGScheduler: Final stage: ResultStage 306 (parquet at <unknown>:0)
26/01/12 03:01:15 INFO DAGScheduler: Parents of final stage: List()
26/01/12 03:01:15 INFO DAGScheduler: Missing parents: List()
26/01/12 03:01:15 INFO DAGScheduler: Submitting ResultStage 306 (MapPartitionsRDD[766] at parquet at <unknown>:0), which has no missing parents
26/01/12 03:01:15 INFO MemoryStore: Block broadcast_459 stored as values in memory (estimated size 102.6 KiB, free 364.0 MiB)
26/01/12 03:01:15 INFO MemoryStore: Block broadcast_459_piece0 stored as bytes in memory (estimated size 36.8 KiB, free 364.0 MiB)
26/01/12 03:01:15 INFO BlockManagerInfo: Added broadcast_459_piece0 in memory on 02926ee04bc9:45221 (size: 36.8 KiB, free: 365.9 MiB)
26/01/12 03:01:15 INFO SparkContext: Created broadcast 459 from broadcast at DAGScheduler.scala:1513
26/01/12 03:01:15 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 306 (MapPartitionsRDD[766] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0))
26/01/12 03:01:15 INFO TaskSchedulerImpl: Adding task set 306.0 with 1 tasks resource profile 0
26/01/12 03:01:15 INFO TaskSetManager: Starting task 0.0 in stage 306.0 (TID 506) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4607 bytes) taskResourceAssignments Map()
26/01/12 03:01:15 INFO BlockManagerInfo: Added broadcast_459_piece0 in memory on 172.18.0.5:42453 (size: 36.8 KiB, free: 365.9 MiB)
26/01/12 03:01:15 INFO TaskSetManager: Finished task 0.0 in stage 306.0 (TID 506) in 52 ms on 172.18.0.5 (executor 0) (1/1)
26/01/12 03:01:15 INFO TaskSchedulerImpl: Removed TaskSet 306.0, whose tasks have all completed, from pool 
26/01/12 03:01:15 INFO DAGScheduler: ResultStage 306 (parquet at <unknown>:0) finished in 0.065 s
26/01/12 03:01:15 INFO DAGScheduler: Job 306 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 03:01:15 INFO TaskSchedulerImpl: Killing all running tasks in stage 306: Stage finished
26/01/12 03:01:15 INFO DAGScheduler: Job 306 finished: parquet at <unknown>:0, took 0.068433 s
26/01/12 03:01:15 INFO FileSourceStrategy: Pushed Filters: 
26/01/12 03:01:15 INFO FileSourceStrategy: Post-Scan Filters: 
26/01/12 03:01:15 INFO FileSourceStrategy: Output Data Schema: struct<VendorID: bigint, tpep_pickup_datetime: timestamp, tpep_dropoff_datetime: timestamp, passenger_count: double, trip_distance: double ... 17 more fields>
26/01/12 03:01:15 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 03:01:15 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 03:01:15 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 03:01:15 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 03:01:15 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 03:01:15 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 03:01:15 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 03:01:15 INFO MemoryStore: Block broadcast_460 stored as values in memory (estimated size 358.5 KiB, free 363.6 MiB)
26/01/12 03:01:15 INFO MemoryStore: Block broadcast_460_piece0 stored as bytes in memory (estimated size 35.4 KiB, free 363.6 MiB)
26/01/12 03:01:15 INFO BlockManagerInfo: Added broadcast_460_piece0 in memory on 02926ee04bc9:45221 (size: 35.4 KiB, free: 365.9 MiB)
26/01/12 03:01:15 INFO SparkContext: Created broadcast 460 from parquet at <unknown>:0
26/01/12 03:01:15 INFO FileSourceScanExec: Planning scan with bin packing, max size: 28740384 bytes, open cost is considered as scanning 4194304 bytes.
26/01/12 03:01:15 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 03:01:15 INFO DAGScheduler: Got job 307 (parquet at <unknown>:0) with 2 output partitions
26/01/12 03:01:15 INFO DAGScheduler: Final stage: ResultStage 307 (parquet at <unknown>:0)
26/01/12 03:01:15 INFO DAGScheduler: Parents of final stage: List()
26/01/12 03:01:15 INFO DAGScheduler: Missing parents: List()
26/01/12 03:01:15 INFO DAGScheduler: Submitting ResultStage 307 (MapPartitionsRDD[769] at parquet at <unknown>:0), which has no missing parents
26/01/12 03:01:15 INFO MemoryStore: Block broadcast_461 stored as values in memory (estimated size 225.0 KiB, free 363.4 MiB)
26/01/12 03:01:15 INFO MemoryStore: Block broadcast_461_piece0 stored as bytes in memory (estimated size 77.3 KiB, free 363.3 MiB)
26/01/12 03:01:15 INFO BlockManagerInfo: Added broadcast_461_piece0 in memory on 02926ee04bc9:45221 (size: 77.3 KiB, free: 365.8 MiB)
26/01/12 03:01:15 INFO SparkContext: Created broadcast 461 from broadcast at DAGScheduler.scala:1513
26/01/12 03:01:15 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 307 (MapPartitionsRDD[769] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1))
26/01/12 03:01:15 INFO TaskSchedulerImpl: Adding task set 307.0 with 2 tasks resource profile 0
26/01/12 03:01:15 INFO TaskSetManager: Starting task 0.0 in stage 307.0 (TID 507) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 03:01:15 INFO TaskSetManager: Starting task 1.0 in stage 307.0 (TID 508) (172.18.0.5, executor 0, partition 1, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 03:01:15 INFO BlockManagerInfo: Added broadcast_461_piece0 in memory on 172.18.0.5:42453 (size: 77.3 KiB, free: 365.8 MiB)
26/01/12 03:01:15 INFO BlockManagerInfo: Removed broadcast_458_piece0 on 02926ee04bc9:45221 in memory (size: 77.3 KiB, free: 365.9 MiB)
26/01/12 03:01:15 INFO BlockManagerInfo: Removed broadcast_458_piece0 on 172.18.0.5:42453 in memory (size: 77.3 KiB, free: 365.9 MiB)
26/01/12 03:01:15 INFO BlockManagerInfo: Removed broadcast_454_piece0 on 02926ee04bc9:45221 in memory (size: 35.4 KiB, free: 365.9 MiB)
26/01/12 03:01:15 INFO BlockManagerInfo: Removed broadcast_454_piece0 on 172.18.0.5:42453 in memory (size: 35.4 KiB, free: 365.9 MiB)
26/01/12 03:01:15 INFO BlockManagerInfo: Removed broadcast_459_piece0 on 02926ee04bc9:45221 in memory (size: 36.8 KiB, free: 365.9 MiB)
26/01/12 03:01:15 INFO BlockManagerInfo: Removed broadcast_459_piece0 on 172.18.0.5:42453 in memory (size: 36.8 KiB, free: 366.0 MiB)
26/01/12 03:01:15 INFO BlockManagerInfo: Added broadcast_460_piece0 in memory on 172.18.0.5:42453 (size: 35.4 KiB, free: 365.9 MiB)
26/01/12 03:01:15 INFO BlockManagerInfo: Removed broadcast_457_piece0 on 02926ee04bc9:45221 in memory (size: 35.4 KiB, free: 366.0 MiB)
26/01/12 03:01:15 INFO BlockManagerInfo: Removed broadcast_457_piece0 on 172.18.0.5:42453 in memory (size: 35.4 KiB, free: 366.0 MiB)
26/01/12 03:01:15 INFO BlockManagerInfo: Removed broadcast_455_piece0 on 02926ee04bc9:45221 in memory (size: 77.3 KiB, free: 366.0 MiB)
26/01/12 03:01:15 INFO BlockManagerInfo: Removed broadcast_455_piece0 on 172.18.0.5:42453 in memory (size: 77.3 KiB, free: 366.0 MiB)
26/01/12 03:01:15 INFO BlockManagerInfo: Removed broadcast_456_piece0 on 02926ee04bc9:45221 in memory (size: 36.8 KiB, free: 366.1 MiB)
26/01/12 03:01:15 INFO BlockManagerInfo: Removed broadcast_456_piece0 on 172.18.0.5:42453 in memory (size: 36.8 KiB, free: 366.1 MiB)
26/01/12 03:01:15 INFO TaskSetManager: Finished task 1.0 in stage 307.0 (TID 508) in 85 ms on 172.18.0.5 (executor 0) (1/2)
26/01/12 03:01:24 INFO TaskSetManager: Finished task 0.0 in stage 307.0 (TID 507) in 8691 ms on 172.18.0.5 (executor 0) (2/2)
26/01/12 03:01:24 INFO TaskSchedulerImpl: Removed TaskSet 307.0, whose tasks have all completed, from pool 
26/01/12 03:01:24 INFO DAGScheduler: ResultStage 307 (parquet at <unknown>:0) finished in 8.708 s
26/01/12 03:01:24 INFO DAGScheduler: Job 307 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 03:01:24 INFO TaskSchedulerImpl: Killing all running tasks in stage 307: Stage finished
26/01/12 03:01:24 INFO DAGScheduler: Job 307 finished: parquet at <unknown>:0, took 8.712511 s
26/01/12 03:01:24 INFO FileFormatWriter: Start to commit write Job 24f4d6d8-36ab-4eec-acf2-c7c095bed993.
26/01/12 03:01:24 INFO FileFormatWriter: Write Job 24f4d6d8-36ab-4eec-acf2-c7c095bed993 committed. Elapsed time: 25 ms.
26/01/12 03:01:24 INFO FileFormatWriter: Finished processing stats for write job 24f4d6d8-36ab-4eec-acf2-c7c095bed993.
Cargando: yellow_tripdata_2021-11.parquet en hdfs://hadoop-namenode:8020/data/nyc/raw/taxi-trips/2021...
26/01/12 03:01:24 INFO InMemoryFileIndex: It took 6 ms to list leaf files for 1 paths.
26/01/12 03:01:24 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 03:01:24 INFO DAGScheduler: Got job 308 (parquet at <unknown>:0) with 1 output partitions
26/01/12 03:01:24 INFO DAGScheduler: Final stage: ResultStage 308 (parquet at <unknown>:0)
26/01/12 03:01:24 INFO DAGScheduler: Parents of final stage: List()
26/01/12 03:01:24 INFO DAGScheduler: Missing parents: List()
26/01/12 03:01:24 INFO DAGScheduler: Submitting ResultStage 308 (MapPartitionsRDD[771] at parquet at <unknown>:0), which has no missing parents
26/01/12 03:01:24 INFO MemoryStore: Block broadcast_462 stored as values in memory (estimated size 102.6 KiB, free 364.8 MiB)
26/01/12 03:01:24 INFO MemoryStore: Block broadcast_462_piece0 stored as bytes in memory (estimated size 36.8 KiB, free 364.8 MiB)
26/01/12 03:01:24 INFO BlockManagerInfo: Added broadcast_462_piece0 in memory on 02926ee04bc9:45221 (size: 36.8 KiB, free: 366.0 MiB)
26/01/12 03:01:24 INFO SparkContext: Created broadcast 462 from broadcast at DAGScheduler.scala:1513
26/01/12 03:01:24 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 308 (MapPartitionsRDD[771] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0))
26/01/12 03:01:24 INFO TaskSchedulerImpl: Adding task set 308.0 with 1 tasks resource profile 0
26/01/12 03:01:24 INFO TaskSetManager: Starting task 0.0 in stage 308.0 (TID 509) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4607 bytes) taskResourceAssignments Map()
26/01/12 03:01:24 INFO BlockManagerInfo: Added broadcast_462_piece0 in memory on 172.18.0.5:42453 (size: 36.8 KiB, free: 366.0 MiB)
26/01/12 03:01:24 INFO TaskSetManager: Finished task 0.0 in stage 308.0 (TID 509) in 47 ms on 172.18.0.5 (executor 0) (1/1)
26/01/12 03:01:24 INFO TaskSchedulerImpl: Removed TaskSet 308.0, whose tasks have all completed, from pool 
26/01/12 03:01:24 INFO DAGScheduler: ResultStage 308 (parquet at <unknown>:0) finished in 0.058 s
26/01/12 03:01:24 INFO DAGScheduler: Job 308 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 03:01:24 INFO TaskSchedulerImpl: Killing all running tasks in stage 308: Stage finished
26/01/12 03:01:24 INFO DAGScheduler: Job 308 finished: parquet at <unknown>:0, took 0.061502 s
26/01/12 03:01:24 INFO FileSourceStrategy: Pushed Filters: 
26/01/12 03:01:24 INFO FileSourceStrategy: Post-Scan Filters: 
26/01/12 03:01:24 INFO FileSourceStrategy: Output Data Schema: struct<VendorID: bigint, tpep_pickup_datetime: timestamp, tpep_dropoff_datetime: timestamp, passenger_count: double, trip_distance: double ... 17 more fields>
26/01/12 03:01:24 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 03:01:24 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 03:01:24 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 03:01:24 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 03:01:24 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 03:01:24 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 03:01:24 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 03:01:24 INFO MemoryStore: Block broadcast_463 stored as values in memory (estimated size 358.5 KiB, free 364.5 MiB)
26/01/12 03:01:24 INFO MemoryStore: Block broadcast_463_piece0 stored as bytes in memory (estimated size 35.4 KiB, free 364.4 MiB)
26/01/12 03:01:24 INFO BlockManagerInfo: Added broadcast_463_piece0 in memory on 02926ee04bc9:45221 (size: 35.4 KiB, free: 366.0 MiB)
26/01/12 03:01:24 INFO SparkContext: Created broadcast 463 from parquet at <unknown>:0
26/01/12 03:01:24 INFO FileSourceScanExec: Planning scan with bin packing, max size: 28647513 bytes, open cost is considered as scanning 4194304 bytes.
26/01/12 03:01:24 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 03:01:24 INFO DAGScheduler: Got job 309 (parquet at <unknown>:0) with 2 output partitions
26/01/12 03:01:24 INFO DAGScheduler: Final stage: ResultStage 309 (parquet at <unknown>:0)
26/01/12 03:01:24 INFO DAGScheduler: Parents of final stage: List()
26/01/12 03:01:24 INFO DAGScheduler: Missing parents: List()
26/01/12 03:01:24 INFO DAGScheduler: Submitting ResultStage 309 (MapPartitionsRDD[774] at parquet at <unknown>:0), which has no missing parents
26/01/12 03:01:24 INFO MemoryStore: Block broadcast_464 stored as values in memory (estimated size 225.0 KiB, free 364.2 MiB)
26/01/12 03:01:24 INFO MemoryStore: Block broadcast_464_piece0 stored as bytes in memory (estimated size 77.3 KiB, free 364.1 MiB)
26/01/12 03:01:24 INFO BlockManagerInfo: Added broadcast_464_piece0 in memory on 02926ee04bc9:45221 (size: 77.3 KiB, free: 365.9 MiB)
26/01/12 03:01:24 INFO SparkContext: Created broadcast 464 from broadcast at DAGScheduler.scala:1513
26/01/12 03:01:24 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 309 (MapPartitionsRDD[774] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1))
26/01/12 03:01:24 INFO TaskSchedulerImpl: Adding task set 309.0 with 2 tasks resource profile 0
26/01/12 03:01:24 INFO TaskSetManager: Starting task 0.0 in stage 309.0 (TID 510) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 03:01:24 INFO TaskSetManager: Starting task 1.0 in stage 309.0 (TID 511) (172.18.0.5, executor 0, partition 1, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 03:01:24 INFO BlockManagerInfo: Added broadcast_464_piece0 in memory on 172.18.0.5:42453 (size: 77.3 KiB, free: 366.0 MiB)
26/01/12 03:01:24 INFO BlockManagerInfo: Added broadcast_463_piece0 in memory on 172.18.0.5:42453 (size: 35.4 KiB, free: 365.9 MiB)
26/01/12 03:01:24 INFO TaskSetManager: Finished task 1.0 in stage 309.0 (TID 511) in 51 ms on 172.18.0.5 (executor 0) (1/2)
26/01/12 03:01:33 INFO TaskSetManager: Finished task 0.0 in stage 309.0 (TID 510) in 8832 ms on 172.18.0.5 (executor 0) (2/2)
26/01/12 03:01:33 INFO TaskSchedulerImpl: Removed TaskSet 309.0, whose tasks have all completed, from pool 
26/01/12 03:01:33 INFO DAGScheduler: ResultStage 309 (parquet at <unknown>:0) finished in 8.850 s
26/01/12 03:01:33 INFO DAGScheduler: Job 309 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 03:01:33 INFO TaskSchedulerImpl: Killing all running tasks in stage 309: Stage finished
26/01/12 03:01:33 INFO DAGScheduler: Job 309 finished: parquet at <unknown>:0, took 8.856928 s
26/01/12 03:01:33 INFO FileFormatWriter: Start to commit write Job 3c622284-a587-4cc0-a1a1-f79639e5f6f9.
26/01/12 03:01:33 INFO FileFormatWriter: Write Job 3c622284-a587-4cc0-a1a1-f79639e5f6f9 committed. Elapsed time: 30 ms.
26/01/12 03:01:33 INFO FileFormatWriter: Finished processing stats for write job 3c622284-a587-4cc0-a1a1-f79639e5f6f9.
Cargando: yellow_tripdata_2021-12.parquet en hdfs://hadoop-namenode:8020/data/nyc/raw/taxi-trips/2021...
26/01/12 03:01:33 INFO InMemoryFileIndex: It took 5 ms to list leaf files for 1 paths.
26/01/12 03:01:33 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 03:01:33 INFO DAGScheduler: Got job 310 (parquet at <unknown>:0) with 1 output partitions
26/01/12 03:01:33 INFO DAGScheduler: Final stage: ResultStage 310 (parquet at <unknown>:0)
26/01/12 03:01:33 INFO DAGScheduler: Parents of final stage: List()
26/01/12 03:01:33 INFO DAGScheduler: Missing parents: List()
26/01/12 03:01:33 INFO DAGScheduler: Submitting ResultStage 310 (MapPartitionsRDD[776] at parquet at <unknown>:0), which has no missing parents
26/01/12 03:01:33 INFO MemoryStore: Block broadcast_465 stored as values in memory (estimated size 102.6 KiB, free 364.0 MiB)
26/01/12 03:01:33 INFO MemoryStore: Block broadcast_465_piece0 stored as bytes in memory (estimated size 36.8 KiB, free 364.0 MiB)
26/01/12 03:01:33 INFO BlockManagerInfo: Added broadcast_465_piece0 in memory on 02926ee04bc9:45221 (size: 36.8 KiB, free: 365.9 MiB)
26/01/12 03:01:33 INFO SparkContext: Created broadcast 465 from broadcast at DAGScheduler.scala:1513
26/01/12 03:01:33 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 310 (MapPartitionsRDD[776] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0))
26/01/12 03:01:33 INFO TaskSchedulerImpl: Adding task set 310.0 with 1 tasks resource profile 0
26/01/12 03:01:33 INFO TaskSetManager: Starting task 0.0 in stage 310.0 (TID 512) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4607 bytes) taskResourceAssignments Map()
26/01/12 03:01:33 INFO BlockManagerInfo: Added broadcast_465_piece0 in memory on 172.18.0.5:42453 (size: 36.8 KiB, free: 365.9 MiB)
26/01/12 03:01:33 INFO TaskSetManager: Finished task 0.0 in stage 310.0 (TID 512) in 44 ms on 172.18.0.5 (executor 0) (1/1)
26/01/12 03:01:33 INFO TaskSchedulerImpl: Removed TaskSet 310.0, whose tasks have all completed, from pool 
26/01/12 03:01:33 INFO DAGScheduler: ResultStage 310 (parquet at <unknown>:0) finished in 0.055 s
26/01/12 03:01:33 INFO DAGScheduler: Job 310 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 03:01:33 INFO TaskSchedulerImpl: Killing all running tasks in stage 310: Stage finished
26/01/12 03:01:33 INFO DAGScheduler: Job 310 finished: parquet at <unknown>:0, took 0.057833 s
26/01/12 03:01:33 INFO FileSourceStrategy: Pushed Filters: 
26/01/12 03:01:33 INFO FileSourceStrategy: Post-Scan Filters: 
26/01/12 03:01:33 INFO FileSourceStrategy: Output Data Schema: struct<VendorID: bigint, tpep_pickup_datetime: timestamp, tpep_dropoff_datetime: timestamp, passenger_count: double, trip_distance: double ... 17 more fields>
26/01/12 03:01:33 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 03:01:33 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 03:01:33 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 03:01:33 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 03:01:33 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 03:01:33 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 03:01:33 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 03:01:33 INFO MemoryStore: Block broadcast_466 stored as values in memory (estimated size 358.5 KiB, free 363.6 MiB)
26/01/12 03:01:33 INFO MemoryStore: Block broadcast_466_piece0 stored as bytes in memory (estimated size 35.4 KiB, free 363.6 MiB)
26/01/12 03:01:33 INFO BlockManagerInfo: Added broadcast_466_piece0 in memory on 02926ee04bc9:45221 (size: 35.4 KiB, free: 365.9 MiB)
26/01/12 03:01:33 INFO SparkContext: Created broadcast 466 from parquet at <unknown>:0
26/01/12 03:01:33 INFO FileSourceScanExec: Planning scan with bin packing, max size: 26916678 bytes, open cost is considered as scanning 4194304 bytes.
26/01/12 03:01:33 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 03:01:33 INFO DAGScheduler: Got job 311 (parquet at <unknown>:0) with 2 output partitions
26/01/12 03:01:33 INFO DAGScheduler: Final stage: ResultStage 311 (parquet at <unknown>:0)
26/01/12 03:01:33 INFO DAGScheduler: Parents of final stage: List()
26/01/12 03:01:33 INFO DAGScheduler: Missing parents: List()
26/01/12 03:01:33 INFO DAGScheduler: Submitting ResultStage 311 (MapPartitionsRDD[779] at parquet at <unknown>:0), which has no missing parents
26/01/12 03:01:33 INFO MemoryStore: Block broadcast_467 stored as values in memory (estimated size 225.0 KiB, free 363.4 MiB)
26/01/12 03:01:33 INFO MemoryStore: Block broadcast_467_piece0 stored as bytes in memory (estimated size 77.3 KiB, free 363.3 MiB)
26/01/12 03:01:33 INFO BlockManagerInfo: Added broadcast_467_piece0 in memory on 02926ee04bc9:45221 (size: 77.3 KiB, free: 365.8 MiB)
26/01/12 03:01:33 INFO SparkContext: Created broadcast 467 from broadcast at DAGScheduler.scala:1513
26/01/12 03:01:33 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 311 (MapPartitionsRDD[779] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1))
26/01/12 03:01:33 INFO TaskSchedulerImpl: Adding task set 311.0 with 2 tasks resource profile 0
26/01/12 03:01:33 INFO TaskSetManager: Starting task 0.0 in stage 311.0 (TID 513) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 03:01:33 INFO TaskSetManager: Starting task 1.0 in stage 311.0 (TID 514) (172.18.0.5, executor 0, partition 1, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 03:01:33 INFO BlockManagerInfo: Added broadcast_467_piece0 in memory on 172.18.0.5:42453 (size: 77.3 KiB, free: 365.8 MiB)
26/01/12 03:01:33 INFO BlockManagerInfo: Added broadcast_466_piece0 in memory on 172.18.0.5:42453 (size: 35.4 KiB, free: 365.8 MiB)
26/01/12 03:01:33 INFO TaskSetManager: Finished task 1.0 in stage 311.0 (TID 514) in 51 ms on 172.18.0.5 (executor 0) (1/2)
26/01/12 03:01:42 INFO TaskSetManager: Finished task 0.0 in stage 311.0 (TID 513) in 8479 ms on 172.18.0.5 (executor 0) (2/2)
26/01/12 03:01:42 INFO TaskSchedulerImpl: Removed TaskSet 311.0, whose tasks have all completed, from pool 
26/01/12 03:01:42 INFO DAGScheduler: ResultStage 311 (parquet at <unknown>:0) finished in 8.496 s
26/01/12 03:01:42 INFO DAGScheduler: Job 311 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 03:01:42 INFO TaskSchedulerImpl: Killing all running tasks in stage 311: Stage finished
26/01/12 03:01:42 INFO DAGScheduler: Job 311 finished: parquet at <unknown>:0, took 8.500945 s
26/01/12 03:01:42 INFO FileFormatWriter: Start to commit write Job 677aa99d-4222-47c4-84f3-cd496ff92ad0.
26/01/12 03:01:42 INFO FileFormatWriter: Write Job 677aa99d-4222-47c4-84f3-cd496ff92ad0 committed. Elapsed time: 23 ms.
26/01/12 03:01:42 INFO FileFormatWriter: Finished processing stats for write job 677aa99d-4222-47c4-84f3-cd496ff92ad0.
Cargando: yellow_tripdata_2022-01.parquet en hdfs://hadoop-namenode:8020/data/nyc/raw/taxi-trips/2022...
26/01/12 03:01:42 INFO InMemoryFileIndex: It took 5 ms to list leaf files for 1 paths.
26/01/12 03:01:42 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 03:01:42 INFO DAGScheduler: Got job 312 (parquet at <unknown>:0) with 1 output partitions
26/01/12 03:01:42 INFO DAGScheduler: Final stage: ResultStage 312 (parquet at <unknown>:0)
26/01/12 03:01:42 INFO DAGScheduler: Parents of final stage: List()
26/01/12 03:01:42 INFO DAGScheduler: Missing parents: List()
26/01/12 03:01:42 INFO DAGScheduler: Submitting ResultStage 312 (MapPartitionsRDD[781] at parquet at <unknown>:0), which has no missing parents
26/01/12 03:01:42 INFO MemoryStore: Block broadcast_468 stored as values in memory (estimated size 102.6 KiB, free 363.2 MiB)
26/01/12 03:01:42 INFO MemoryStore: Block broadcast_468_piece0 stored as bytes in memory (estimated size 36.8 KiB, free 363.2 MiB)
26/01/12 03:01:42 INFO BlockManagerInfo: Added broadcast_468_piece0 in memory on 02926ee04bc9:45221 (size: 36.8 KiB, free: 365.8 MiB)
26/01/12 03:01:42 INFO SparkContext: Created broadcast 468 from broadcast at DAGScheduler.scala:1513
26/01/12 03:01:42 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 312 (MapPartitionsRDD[781] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0))
26/01/12 03:01:42 INFO TaskSchedulerImpl: Adding task set 312.0 with 1 tasks resource profile 0
26/01/12 03:01:42 INFO TaskSetManager: Starting task 0.0 in stage 312.0 (TID 515) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4607 bytes) taskResourceAssignments Map()
26/01/12 03:01:42 INFO BlockManagerInfo: Added broadcast_468_piece0 in memory on 172.18.0.5:42453 (size: 36.8 KiB, free: 365.8 MiB)
26/01/12 03:01:42 INFO TaskSetManager: Finished task 0.0 in stage 312.0 (TID 515) in 47 ms on 172.18.0.5 (executor 0) (1/1)
26/01/12 03:01:42 INFO TaskSchedulerImpl: Removed TaskSet 312.0, whose tasks have all completed, from pool 
26/01/12 03:01:42 INFO DAGScheduler: ResultStage 312 (parquet at <unknown>:0) finished in 0.057 s
26/01/12 03:01:42 INFO DAGScheduler: Job 312 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 03:01:42 INFO TaskSchedulerImpl: Killing all running tasks in stage 312: Stage finished
26/01/12 03:01:42 INFO DAGScheduler: Job 312 finished: parquet at <unknown>:0, took 0.060327 s
26/01/12 03:01:42 INFO FileSourceStrategy: Pushed Filters: 
26/01/12 03:01:42 INFO FileSourceStrategy: Post-Scan Filters: 
26/01/12 03:01:42 INFO FileSourceStrategy: Output Data Schema: struct<VendorID: bigint, tpep_pickup_datetime: timestamp, tpep_dropoff_datetime: timestamp, passenger_count: double, trip_distance: double ... 17 more fields>
26/01/12 03:01:42 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 03:01:42 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 03:01:42 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 03:01:42 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 03:01:42 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 03:01:42 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 03:01:42 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 03:01:42 INFO MemoryStore: Block broadcast_469 stored as values in memory (estimated size 358.5 KiB, free 362.8 MiB)
26/01/12 03:01:42 INFO BlockManagerInfo: Removed broadcast_464_piece0 on 02926ee04bc9:45221 in memory (size: 77.3 KiB, free: 365.8 MiB)
26/01/12 03:01:42 INFO BlockManagerInfo: Removed broadcast_464_piece0 on 172.18.0.5:42453 in memory (size: 77.3 KiB, free: 365.8 MiB)
26/01/12 03:01:42 INFO BlockManagerInfo: Removed broadcast_467_piece0 on 02926ee04bc9:45221 in memory (size: 77.3 KiB, free: 365.9 MiB)
26/01/12 03:01:42 INFO BlockManagerInfo: Removed broadcast_467_piece0 on 172.18.0.5:42453 in memory (size: 77.3 KiB, free: 365.9 MiB)
26/01/12 03:01:42 INFO MemoryStore: Block broadcast_469_piece0 stored as bytes in memory (estimated size 35.4 KiB, free 363.4 MiB)
26/01/12 03:01:42 INFO BlockManagerInfo: Removed broadcast_461_piece0 on 02926ee04bc9:45221 in memory (size: 77.3 KiB, free: 366.0 MiB)
26/01/12 03:01:42 INFO BlockManagerInfo: Added broadcast_469_piece0 in memory on 02926ee04bc9:45221 (size: 35.4 KiB, free: 365.9 MiB)
26/01/12 03:01:42 INFO BlockManagerInfo: Removed broadcast_461_piece0 on 172.18.0.5:42453 in memory (size: 77.3 KiB, free: 366.0 MiB)
26/01/12 03:01:42 INFO SparkContext: Created broadcast 469 from parquet at <unknown>:0
26/01/12 03:01:42 INFO FileSourceScanExec: Planning scan with bin packing, max size: 21167126 bytes, open cost is considered as scanning 4194304 bytes.
26/01/12 03:01:42 INFO BlockManagerInfo: Removed broadcast_460_piece0 on 02926ee04bc9:45221 in memory (size: 35.4 KiB, free: 366.0 MiB)
26/01/12 03:01:42 INFO BlockManagerInfo: Removed broadcast_460_piece0 on 172.18.0.5:42453 in memory (size: 35.4 KiB, free: 366.0 MiB)
26/01/12 03:01:42 INFO BlockManagerInfo: Removed broadcast_463_piece0 on 02926ee04bc9:45221 in memory (size: 35.4 KiB, free: 366.0 MiB)
26/01/12 03:01:42 INFO BlockManagerInfo: Removed broadcast_463_piece0 on 172.18.0.5:42453 in memory (size: 35.4 KiB, free: 366.0 MiB)
26/01/12 03:01:42 INFO BlockManagerInfo: Removed broadcast_468_piece0 on 02926ee04bc9:45221 in memory (size: 36.8 KiB, free: 366.0 MiB)
26/01/12 03:01:42 INFO BlockManagerInfo: Removed broadcast_468_piece0 on 172.18.0.5:42453 in memory (size: 36.8 KiB, free: 366.1 MiB)
26/01/12 03:01:42 INFO BlockManagerInfo: Removed broadcast_466_piece0 on 02926ee04bc9:45221 in memory (size: 35.4 KiB, free: 366.1 MiB)
26/01/12 03:01:42 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 03:01:42 INFO BlockManagerInfo: Removed broadcast_466_piece0 on 172.18.0.5:42453 in memory (size: 35.4 KiB, free: 366.1 MiB)
26/01/12 03:01:42 INFO DAGScheduler: Got job 313 (parquet at <unknown>:0) with 2 output partitions
26/01/12 03:01:42 INFO DAGScheduler: Final stage: ResultStage 313 (parquet at <unknown>:0)
26/01/12 03:01:42 INFO DAGScheduler: Parents of final stage: List()
26/01/12 03:01:42 INFO DAGScheduler: Missing parents: List()
26/01/12 03:01:42 INFO DAGScheduler: Submitting ResultStage 313 (MapPartitionsRDD[784] at parquet at <unknown>:0), which has no missing parents
26/01/12 03:01:42 INFO BlockManagerInfo: Removed broadcast_465_piece0 on 02926ee04bc9:45221 in memory (size: 36.8 KiB, free: 366.1 MiB)
26/01/12 03:01:42 INFO BlockManagerInfo: Removed broadcast_465_piece0 on 172.18.0.5:42453 in memory (size: 36.8 KiB, free: 366.2 MiB)
26/01/12 03:01:42 INFO BlockManagerInfo: Removed broadcast_462_piece0 on 02926ee04bc9:45221 in memory (size: 36.8 KiB, free: 366.2 MiB)
26/01/12 03:01:42 INFO BlockManagerInfo: Removed broadcast_462_piece0 on 172.18.0.5:42453 in memory (size: 36.8 KiB, free: 366.2 MiB)
26/01/12 03:01:42 INFO MemoryStore: Block broadcast_470 stored as values in memory (estimated size 225.0 KiB, free 365.0 MiB)
26/01/12 03:01:42 INFO MemoryStore: Block broadcast_470_piece0 stored as bytes in memory (estimated size 77.3 KiB, free 364.9 MiB)
26/01/12 03:01:42 INFO BlockManagerInfo: Added broadcast_470_piece0 in memory on 02926ee04bc9:45221 (size: 77.3 KiB, free: 366.1 MiB)
26/01/12 03:01:42 INFO SparkContext: Created broadcast 470 from broadcast at DAGScheduler.scala:1513
26/01/12 03:01:42 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 313 (MapPartitionsRDD[784] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1))
26/01/12 03:01:42 INFO TaskSchedulerImpl: Adding task set 313.0 with 2 tasks resource profile 0
26/01/12 03:01:42 INFO TaskSetManager: Starting task 0.0 in stage 313.0 (TID 516) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 03:01:42 INFO TaskSetManager: Starting task 1.0 in stage 313.0 (TID 517) (172.18.0.5, executor 0, partition 1, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 03:01:42 INFO BlockManagerInfo: Added broadcast_470_piece0 in memory on 172.18.0.5:42453 (size: 77.3 KiB, free: 366.1 MiB)
26/01/12 03:01:42 INFO BlockManagerInfo: Added broadcast_469_piece0 in memory on 172.18.0.5:42453 (size: 35.4 KiB, free: 366.1 MiB)
26/01/12 03:01:42 INFO TaskSetManager: Finished task 1.0 in stage 313.0 (TID 517) in 58 ms on 172.18.0.5 (executor 0) (1/2)
26/01/12 03:01:49 INFO TaskSetManager: Finished task 0.0 in stage 313.0 (TID 516) in 6557 ms on 172.18.0.5 (executor 0) (2/2)
26/01/12 03:01:49 INFO TaskSchedulerImpl: Removed TaskSet 313.0, whose tasks have all completed, from pool 
26/01/12 03:01:49 INFO DAGScheduler: ResultStage 313 (parquet at <unknown>:0) finished in 6.580 s
26/01/12 03:01:49 INFO DAGScheduler: Job 313 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 03:01:49 INFO TaskSchedulerImpl: Killing all running tasks in stage 313: Stage finished
26/01/12 03:01:49 INFO DAGScheduler: Job 313 finished: parquet at <unknown>:0, took 6.585688 s
26/01/12 03:01:49 INFO FileFormatWriter: Start to commit write Job 95478105-79be-4f49-af50-19db3283c16b.
26/01/12 03:01:49 INFO FileFormatWriter: Write Job 95478105-79be-4f49-af50-19db3283c16b committed. Elapsed time: 28 ms.
26/01/12 03:01:49 INFO FileFormatWriter: Finished processing stats for write job 95478105-79be-4f49-af50-19db3283c16b.
Cargando: yellow_tripdata_2022-02.parquet en hdfs://hadoop-namenode:8020/data/nyc/raw/taxi-trips/2022...
26/01/12 03:01:49 INFO InMemoryFileIndex: It took 8 ms to list leaf files for 1 paths.
26/01/12 03:01:49 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 03:01:49 INFO DAGScheduler: Got job 314 (parquet at <unknown>:0) with 1 output partitions
26/01/12 03:01:49 INFO DAGScheduler: Final stage: ResultStage 314 (parquet at <unknown>:0)
26/01/12 03:01:49 INFO DAGScheduler: Parents of final stage: List()
26/01/12 03:01:49 INFO DAGScheduler: Missing parents: List()
26/01/12 03:01:49 INFO DAGScheduler: Submitting ResultStage 314 (MapPartitionsRDD[786] at parquet at <unknown>:0), which has no missing parents
26/01/12 03:01:49 INFO MemoryStore: Block broadcast_471 stored as values in memory (estimated size 102.6 KiB, free 364.8 MiB)
26/01/12 03:01:49 INFO MemoryStore: Block broadcast_471_piece0 stored as bytes in memory (estimated size 36.8 KiB, free 364.8 MiB)
26/01/12 03:01:49 INFO BlockManagerInfo: Added broadcast_471_piece0 in memory on 02926ee04bc9:45221 (size: 36.8 KiB, free: 366.0 MiB)
26/01/12 03:01:49 INFO SparkContext: Created broadcast 471 from broadcast at DAGScheduler.scala:1513
26/01/12 03:01:49 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 314 (MapPartitionsRDD[786] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0))
26/01/12 03:01:49 INFO TaskSchedulerImpl: Adding task set 314.0 with 1 tasks resource profile 0
26/01/12 03:01:49 INFO TaskSetManager: Starting task 0.0 in stage 314.0 (TID 518) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4607 bytes) taskResourceAssignments Map()
26/01/12 03:01:49 INFO BlockManagerInfo: Added broadcast_471_piece0 in memory on 172.18.0.5:42453 (size: 36.8 KiB, free: 366.0 MiB)
26/01/12 03:01:49 INFO TaskSetManager: Finished task 0.0 in stage 314.0 (TID 518) in 46 ms on 172.18.0.5 (executor 0) (1/1)
26/01/12 03:01:49 INFO TaskSchedulerImpl: Removed TaskSet 314.0, whose tasks have all completed, from pool 
26/01/12 03:01:49 INFO DAGScheduler: ResultStage 314 (parquet at <unknown>:0) finished in 0.058 s
26/01/12 03:01:49 INFO DAGScheduler: Job 314 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 03:01:49 INFO TaskSchedulerImpl: Killing all running tasks in stage 314: Stage finished
26/01/12 03:01:49 INFO DAGScheduler: Job 314 finished: parquet at <unknown>:0, took 0.061381 s
26/01/12 03:01:49 INFO FileSourceStrategy: Pushed Filters: 
26/01/12 03:01:49 INFO FileSourceStrategy: Post-Scan Filters: 
26/01/12 03:01:49 INFO FileSourceStrategy: Output Data Schema: struct<VendorID: bigint, tpep_pickup_datetime: timestamp, tpep_dropoff_datetime: timestamp, passenger_count: double, trip_distance: double ... 17 more fields>
26/01/12 03:01:49 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 03:01:49 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 03:01:49 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 03:01:49 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 03:01:49 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 03:01:49 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 03:01:49 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 03:01:49 INFO MemoryStore: Block broadcast_472 stored as values in memory (estimated size 358.5 KiB, free 364.5 MiB)
26/01/12 03:01:49 INFO MemoryStore: Block broadcast_472_piece0 stored as bytes in memory (estimated size 35.4 KiB, free 364.4 MiB)
26/01/12 03:01:49 INFO BlockManagerInfo: Added broadcast_472_piece0 in memory on 02926ee04bc9:45221 (size: 35.4 KiB, free: 366.0 MiB)
26/01/12 03:01:49 INFO SparkContext: Created broadcast 472 from parquet at <unknown>:0
26/01/12 03:01:49 INFO FileSourceScanExec: Planning scan with bin packing, max size: 24905408 bytes, open cost is considered as scanning 4194304 bytes.
26/01/12 03:01:49 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 03:01:49 INFO DAGScheduler: Got job 315 (parquet at <unknown>:0) with 2 output partitions
26/01/12 03:01:49 INFO DAGScheduler: Final stage: ResultStage 315 (parquet at <unknown>:0)
26/01/12 03:01:49 INFO DAGScheduler: Parents of final stage: List()
26/01/12 03:01:49 INFO DAGScheduler: Missing parents: List()
26/01/12 03:01:49 INFO DAGScheduler: Submitting ResultStage 315 (MapPartitionsRDD[789] at parquet at <unknown>:0), which has no missing parents
26/01/12 03:01:49 INFO MemoryStore: Block broadcast_473 stored as values in memory (estimated size 225.0 KiB, free 364.2 MiB)
26/01/12 03:01:49 INFO MemoryStore: Block broadcast_473_piece0 stored as bytes in memory (estimated size 77.2 KiB, free 364.1 MiB)
26/01/12 03:01:49 INFO BlockManagerInfo: Added broadcast_473_piece0 in memory on 02926ee04bc9:45221 (size: 77.2 KiB, free: 365.9 MiB)
26/01/12 03:01:49 INFO SparkContext: Created broadcast 473 from broadcast at DAGScheduler.scala:1513
26/01/12 03:01:49 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 315 (MapPartitionsRDD[789] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1))
26/01/12 03:01:49 INFO TaskSchedulerImpl: Adding task set 315.0 with 2 tasks resource profile 0
26/01/12 03:01:49 INFO TaskSetManager: Starting task 0.0 in stage 315.0 (TID 519) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 03:01:49 INFO TaskSetManager: Starting task 1.0 in stage 315.0 (TID 520) (172.18.0.5, executor 0, partition 1, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 03:01:49 INFO BlockManagerInfo: Added broadcast_473_piece0 in memory on 172.18.0.5:42453 (size: 77.2 KiB, free: 366.0 MiB)
26/01/12 03:01:49 INFO BlockManagerInfo: Added broadcast_472_piece0 in memory on 172.18.0.5:42453 (size: 35.4 KiB, free: 365.9 MiB)
26/01/12 03:01:49 INFO TaskSetManager: Finished task 1.0 in stage 315.0 (TID 520) in 50 ms on 172.18.0.5 (executor 0) (1/2)
26/01/12 03:01:56 INFO TaskSetManager: Finished task 0.0 in stage 315.0 (TID 519) in 7638 ms on 172.18.0.5 (executor 0) (2/2)
26/01/12 03:01:56 INFO TaskSchedulerImpl: Removed TaskSet 315.0, whose tasks have all completed, from pool 
26/01/12 03:01:56 INFO DAGScheduler: ResultStage 315 (parquet at <unknown>:0) finished in 7.654 s
26/01/12 03:01:56 INFO DAGScheduler: Job 315 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 03:01:56 INFO TaskSchedulerImpl: Killing all running tasks in stage 315: Stage finished
26/01/12 03:01:56 INFO DAGScheduler: Job 315 finished: parquet at <unknown>:0, took 7.659745 s
26/01/12 03:01:56 INFO FileFormatWriter: Start to commit write Job 3f2427c2-8d2a-4f3c-b65b-f55113ea5ce9.
26/01/12 03:01:56 INFO FileFormatWriter: Write Job 3f2427c2-8d2a-4f3c-b65b-f55113ea5ce9 committed. Elapsed time: 29 ms.
26/01/12 03:01:56 INFO FileFormatWriter: Finished processing stats for write job 3f2427c2-8d2a-4f3c-b65b-f55113ea5ce9.
Cargando: yellow_tripdata_2022-03.parquet en hdfs://hadoop-namenode:8020/data/nyc/raw/taxi-trips/2022...
26/01/12 03:01:57 INFO InMemoryFileIndex: It took 8 ms to list leaf files for 1 paths.
26/01/12 03:01:57 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 03:01:57 INFO DAGScheduler: Got job 316 (parquet at <unknown>:0) with 1 output partitions
26/01/12 03:01:57 INFO DAGScheduler: Final stage: ResultStage 316 (parquet at <unknown>:0)
26/01/12 03:01:57 INFO DAGScheduler: Parents of final stage: List()
26/01/12 03:01:57 INFO DAGScheduler: Missing parents: List()
26/01/12 03:01:57 INFO DAGScheduler: Submitting ResultStage 316 (MapPartitionsRDD[791] at parquet at <unknown>:0), which has no missing parents
26/01/12 03:01:57 INFO MemoryStore: Block broadcast_474 stored as values in memory (estimated size 102.6 KiB, free 364.0 MiB)
26/01/12 03:01:57 INFO MemoryStore: Block broadcast_474_piece0 stored as bytes in memory (estimated size 36.8 KiB, free 364.0 MiB)
26/01/12 03:01:57 INFO BlockManagerInfo: Added broadcast_474_piece0 in memory on 02926ee04bc9:45221 (size: 36.8 KiB, free: 365.9 MiB)
26/01/12 03:01:57 INFO SparkContext: Created broadcast 474 from broadcast at DAGScheduler.scala:1513
26/01/12 03:01:57 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 316 (MapPartitionsRDD[791] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0))
26/01/12 03:01:57 INFO TaskSchedulerImpl: Adding task set 316.0 with 1 tasks resource profile 0
26/01/12 03:01:57 INFO TaskSetManager: Starting task 0.0 in stage 316.0 (TID 521) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4607 bytes) taskResourceAssignments Map()
26/01/12 03:01:57 INFO BlockManagerInfo: Added broadcast_474_piece0 in memory on 172.18.0.5:42453 (size: 36.8 KiB, free: 365.9 MiB)
26/01/12 03:01:57 INFO TaskSetManager: Finished task 0.0 in stage 316.0 (TID 521) in 46 ms on 172.18.0.5 (executor 0) (1/1)
26/01/12 03:01:57 INFO TaskSchedulerImpl: Removed TaskSet 316.0, whose tasks have all completed, from pool 
26/01/12 03:01:57 INFO DAGScheduler: ResultStage 316 (parquet at <unknown>:0) finished in 0.059 s
26/01/12 03:01:57 INFO DAGScheduler: Job 316 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 03:01:57 INFO TaskSchedulerImpl: Killing all running tasks in stage 316: Stage finished
26/01/12 03:01:57 INFO DAGScheduler: Job 316 finished: parquet at <unknown>:0, took 0.062034 s
26/01/12 03:01:57 INFO FileSourceStrategy: Pushed Filters: 
26/01/12 03:01:57 INFO FileSourceStrategy: Post-Scan Filters: 
26/01/12 03:01:57 INFO FileSourceStrategy: Output Data Schema: struct<VendorID: bigint, tpep_pickup_datetime: timestamp, tpep_dropoff_datetime: timestamp, passenger_count: double, trip_distance: double ... 17 more fields>
26/01/12 03:01:57 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 03:01:57 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 03:01:57 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 03:01:57 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 03:01:57 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 03:01:57 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 03:01:57 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 03:01:57 INFO MemoryStore: Block broadcast_475 stored as values in memory (estimated size 358.5 KiB, free 363.6 MiB)
26/01/12 03:01:57 INFO MemoryStore: Block broadcast_475_piece0 stored as bytes in memory (estimated size 35.4 KiB, free 363.6 MiB)
26/01/12 03:01:57 INFO BlockManagerInfo: Added broadcast_475_piece0 in memory on 02926ee04bc9:45221 (size: 35.4 KiB, free: 365.9 MiB)
26/01/12 03:01:57 INFO SparkContext: Created broadcast 475 from parquet at <unknown>:0
26/01/12 03:01:57 INFO FileSourceScanExec: Planning scan with bin packing, max size: 29938336 bytes, open cost is considered as scanning 4194304 bytes.
26/01/12 03:01:57 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 03:01:57 INFO DAGScheduler: Got job 317 (parquet at <unknown>:0) with 2 output partitions
26/01/12 03:01:57 INFO DAGScheduler: Final stage: ResultStage 317 (parquet at <unknown>:0)
26/01/12 03:01:57 INFO DAGScheduler: Parents of final stage: List()
26/01/12 03:01:57 INFO DAGScheduler: Missing parents: List()
26/01/12 03:01:57 INFO DAGScheduler: Submitting ResultStage 317 (MapPartitionsRDD[794] at parquet at <unknown>:0), which has no missing parents
26/01/12 03:01:57 INFO MemoryStore: Block broadcast_476 stored as values in memory (estimated size 225.0 KiB, free 363.4 MiB)
26/01/12 03:01:57 INFO MemoryStore: Block broadcast_476_piece0 stored as bytes in memory (estimated size 77.3 KiB, free 363.3 MiB)
26/01/12 03:01:57 INFO BlockManagerInfo: Added broadcast_476_piece0 in memory on 02926ee04bc9:45221 (size: 77.3 KiB, free: 365.8 MiB)
26/01/12 03:01:57 INFO SparkContext: Created broadcast 476 from broadcast at DAGScheduler.scala:1513
26/01/12 03:01:57 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 317 (MapPartitionsRDD[794] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1))
26/01/12 03:01:57 INFO TaskSchedulerImpl: Adding task set 317.0 with 2 tasks resource profile 0
26/01/12 03:01:57 INFO TaskSetManager: Starting task 0.0 in stage 317.0 (TID 522) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 03:01:57 INFO TaskSetManager: Starting task 1.0 in stage 317.0 (TID 523) (172.18.0.5, executor 0, partition 1, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 03:01:57 INFO BlockManagerInfo: Added broadcast_476_piece0 in memory on 172.18.0.5:42453 (size: 77.3 KiB, free: 365.8 MiB)
26/01/12 03:01:57 INFO BlockManagerInfo: Added broadcast_475_piece0 in memory on 172.18.0.5:42453 (size: 35.4 KiB, free: 365.8 MiB)
26/01/12 03:01:57 INFO TaskSetManager: Finished task 1.0 in stage 317.0 (TID 523) in 53 ms on 172.18.0.5 (executor 0) (1/2)
26/01/12 03:02:06 INFO TaskSetManager: Finished task 0.0 in stage 317.0 (TID 522) in 9445 ms on 172.18.0.5 (executor 0) (2/2)
26/01/12 03:02:06 INFO TaskSchedulerImpl: Removed TaskSet 317.0, whose tasks have all completed, from pool 
26/01/12 03:02:06 INFO DAGScheduler: ResultStage 317 (parquet at <unknown>:0) finished in 9.465 s
26/01/12 03:02:06 INFO DAGScheduler: Job 317 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 03:02:06 INFO TaskSchedulerImpl: Killing all running tasks in stage 317: Stage finished
26/01/12 03:02:06 INFO DAGScheduler: Job 317 finished: parquet at <unknown>:0, took 9.469517 s
26/01/12 03:02:06 INFO FileFormatWriter: Start to commit write Job 4d2f7c08-ee4f-4d82-9cb5-9b5ba2ede6ff.
26/01/12 03:02:06 INFO FileFormatWriter: Write Job 4d2f7c08-ee4f-4d82-9cb5-9b5ba2ede6ff committed. Elapsed time: 24 ms.
26/01/12 03:02:06 INFO FileFormatWriter: Finished processing stats for write job 4d2f7c08-ee4f-4d82-9cb5-9b5ba2ede6ff.
Cargando: yellow_tripdata_2022-04.parquet en hdfs://hadoop-namenode:8020/data/nyc/raw/taxi-trips/2022...
26/01/12 03:02:06 INFO BlockManagerInfo: Removed broadcast_472_piece0 on 02926ee04bc9:45221 in memory (size: 35.4 KiB, free: 365.8 MiB)
26/01/12 03:02:06 INFO BlockManagerInfo: Removed broadcast_472_piece0 on 172.18.0.5:42453 in memory (size: 35.4 KiB, free: 365.8 MiB)
26/01/12 03:02:06 INFO BlockManagerInfo: Removed broadcast_476_piece0 on 02926ee04bc9:45221 in memory (size: 77.3 KiB, free: 365.9 MiB)
26/01/12 03:02:06 INFO BlockManagerInfo: Removed broadcast_476_piece0 on 172.18.0.5:42453 in memory (size: 77.3 KiB, free: 365.9 MiB)
26/01/12 03:02:06 INFO BlockManagerInfo: Removed broadcast_474_piece0 on 02926ee04bc9:45221 in memory (size: 36.8 KiB, free: 365.9 MiB)
26/01/12 03:02:06 INFO BlockManagerInfo: Removed broadcast_474_piece0 on 172.18.0.5:42453 in memory (size: 36.8 KiB, free: 365.9 MiB)
26/01/12 03:02:06 INFO BlockManagerInfo: Removed broadcast_470_piece0 on 02926ee04bc9:45221 in memory (size: 77.3 KiB, free: 366.0 MiB)
26/01/12 03:02:06 INFO BlockManagerInfo: Removed broadcast_470_piece0 on 172.18.0.5:42453 in memory (size: 77.3 KiB, free: 366.0 MiB)
26/01/12 03:02:06 INFO BlockManagerInfo: Removed broadcast_469_piece0 on 02926ee04bc9:45221 in memory (size: 35.4 KiB, free: 366.0 MiB)
26/01/12 03:02:06 INFO BlockManagerInfo: Removed broadcast_469_piece0 on 172.18.0.5:42453 in memory (size: 35.4 KiB, free: 366.0 MiB)
26/01/12 03:02:06 INFO InMemoryFileIndex: It took 10 ms to list leaf files for 1 paths.
26/01/12 03:02:06 INFO BlockManagerInfo: Removed broadcast_471_piece0 on 02926ee04bc9:45221 in memory (size: 36.8 KiB, free: 366.1 MiB)
26/01/12 03:02:06 INFO BlockManagerInfo: Removed broadcast_471_piece0 on 172.18.0.5:42453 in memory (size: 36.8 KiB, free: 366.1 MiB)
26/01/12 03:02:06 INFO BlockManagerInfo: Removed broadcast_473_piece0 on 02926ee04bc9:45221 in memory (size: 77.2 KiB, free: 366.2 MiB)
26/01/12 03:02:06 INFO BlockManagerInfo: Removed broadcast_473_piece0 on 172.18.0.5:42453 in memory (size: 77.2 KiB, free: 366.2 MiB)
26/01/12 03:02:06 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 03:02:06 INFO DAGScheduler: Got job 318 (parquet at <unknown>:0) with 1 output partitions
26/01/12 03:02:06 INFO DAGScheduler: Final stage: ResultStage 318 (parquet at <unknown>:0)
26/01/12 03:02:06 INFO DAGScheduler: Parents of final stage: List()
26/01/12 03:02:06 INFO DAGScheduler: Missing parents: List()
26/01/12 03:02:06 INFO DAGScheduler: Submitting ResultStage 318 (MapPartitionsRDD[796] at parquet at <unknown>:0), which has no missing parents
26/01/12 03:02:06 INFO MemoryStore: Block broadcast_477 stored as values in memory (estimated size 102.6 KiB, free 365.1 MiB)
26/01/12 03:02:06 INFO MemoryStore: Block broadcast_477_piece0 stored as bytes in memory (estimated size 36.8 KiB, free 365.1 MiB)
26/01/12 03:02:06 INFO BlockManagerInfo: Added broadcast_477_piece0 in memory on 02926ee04bc9:45221 (size: 36.8 KiB, free: 366.1 MiB)
26/01/12 03:02:06 INFO SparkContext: Created broadcast 477 from broadcast at DAGScheduler.scala:1513
26/01/12 03:02:06 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 318 (MapPartitionsRDD[796] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0))
26/01/12 03:02:06 INFO TaskSchedulerImpl: Adding task set 318.0 with 1 tasks resource profile 0
26/01/12 03:02:06 INFO TaskSetManager: Starting task 0.0 in stage 318.0 (TID 524) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4607 bytes) taskResourceAssignments Map()
26/01/12 03:02:06 INFO BlockManagerInfo: Added broadcast_477_piece0 in memory on 172.18.0.5:42453 (size: 36.8 KiB, free: 366.1 MiB)
26/01/12 03:02:06 INFO TaskSetManager: Finished task 0.0 in stage 318.0 (TID 524) in 45 ms on 172.18.0.5 (executor 0) (1/1)
26/01/12 03:02:06 INFO TaskSchedulerImpl: Removed TaskSet 318.0, whose tasks have all completed, from pool 
26/01/12 03:02:06 INFO DAGScheduler: ResultStage 318 (parquet at <unknown>:0) finished in 0.057 s
26/01/12 03:02:06 INFO DAGScheduler: Job 318 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 03:02:06 INFO TaskSchedulerImpl: Killing all running tasks in stage 318: Stage finished
26/01/12 03:02:06 INFO DAGScheduler: Job 318 finished: parquet at <unknown>:0, took 0.060995 s
26/01/12 03:02:06 INFO FileSourceStrategy: Pushed Filters: 
26/01/12 03:02:06 INFO FileSourceStrategy: Post-Scan Filters: 
26/01/12 03:02:06 INFO FileSourceStrategy: Output Data Schema: struct<VendorID: bigint, tpep_pickup_datetime: timestamp, tpep_dropoff_datetime: timestamp, passenger_count: double, trip_distance: double ... 17 more fields>
26/01/12 03:02:06 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 03:02:06 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 03:02:06 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 03:02:06 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 03:02:06 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 03:02:06 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 03:02:06 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 03:02:06 INFO MemoryStore: Block broadcast_478 stored as values in memory (estimated size 358.5 KiB, free 364.7 MiB)
26/01/12 03:02:06 INFO MemoryStore: Block broadcast_478_piece0 stored as bytes in memory (estimated size 35.4 KiB, free 364.7 MiB)
26/01/12 03:02:06 INFO BlockManagerInfo: Added broadcast_478_piece0 in memory on 02926ee04bc9:45221 (size: 35.4 KiB, free: 366.1 MiB)
26/01/12 03:02:06 INFO SparkContext: Created broadcast 478 from parquet at <unknown>:0
26/01/12 03:02:06 INFO FileSourceScanExec: Planning scan with bin packing, max size: 29708498 bytes, open cost is considered as scanning 4194304 bytes.
26/01/12 03:02:06 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 03:02:06 INFO DAGScheduler: Got job 319 (parquet at <unknown>:0) with 2 output partitions
26/01/12 03:02:06 INFO DAGScheduler: Final stage: ResultStage 319 (parquet at <unknown>:0)
26/01/12 03:02:06 INFO DAGScheduler: Parents of final stage: List()
26/01/12 03:02:06 INFO DAGScheduler: Missing parents: List()
26/01/12 03:02:06 INFO DAGScheduler: Submitting ResultStage 319 (MapPartitionsRDD[799] at parquet at <unknown>:0), which has no missing parents
26/01/12 03:02:06 INFO MemoryStore: Block broadcast_479 stored as values in memory (estimated size 225.0 KiB, free 364.5 MiB)
26/01/12 03:02:06 INFO MemoryStore: Block broadcast_479_piece0 stored as bytes in memory (estimated size 77.3 KiB, free 364.4 MiB)
26/01/12 03:02:06 INFO BlockManagerInfo: Added broadcast_479_piece0 in memory on 02926ee04bc9:45221 (size: 77.3 KiB, free: 366.0 MiB)
26/01/12 03:02:06 INFO SparkContext: Created broadcast 479 from broadcast at DAGScheduler.scala:1513
26/01/12 03:02:06 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 319 (MapPartitionsRDD[799] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1))
26/01/12 03:02:06 INFO TaskSchedulerImpl: Adding task set 319.0 with 2 tasks resource profile 0
26/01/12 03:02:06 INFO TaskSetManager: Starting task 0.0 in stage 319.0 (TID 525) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 03:02:06 INFO TaskSetManager: Starting task 1.0 in stage 319.0 (TID 526) (172.18.0.5, executor 0, partition 1, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 03:02:06 INFO BlockManagerInfo: Added broadcast_479_piece0 in memory on 172.18.0.5:42453 (size: 77.3 KiB, free: 366.0 MiB)
26/01/12 03:02:06 INFO BlockManagerInfo: Added broadcast_478_piece0 in memory on 172.18.0.5:42453 (size: 35.4 KiB, free: 366.0 MiB)
26/01/12 03:02:06 INFO TaskSetManager: Finished task 1.0 in stage 319.0 (TID 526) in 51 ms on 172.18.0.5 (executor 0) (1/2)
26/01/12 03:02:15 INFO TaskSetManager: Finished task 0.0 in stage 319.0 (TID 525) in 9101 ms on 172.18.0.5 (executor 0) (2/2)
26/01/12 03:02:15 INFO TaskSchedulerImpl: Removed TaskSet 319.0, whose tasks have all completed, from pool 
26/01/12 03:02:15 INFO DAGScheduler: ResultStage 319 (parquet at <unknown>:0) finished in 9.119 s
26/01/12 03:02:15 INFO DAGScheduler: Job 319 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 03:02:15 INFO TaskSchedulerImpl: Killing all running tasks in stage 319: Stage finished
26/01/12 03:02:15 INFO DAGScheduler: Job 319 finished: parquet at <unknown>:0, took 9.123067 s
26/01/12 03:02:15 INFO FileFormatWriter: Start to commit write Job 380b0a56-8ac8-447c-b500-70bb4b4b5a65.
26/01/12 03:02:15 INFO FileFormatWriter: Write Job 380b0a56-8ac8-447c-b500-70bb4b4b5a65 committed. Elapsed time: 26 ms.
26/01/12 03:02:15 INFO FileFormatWriter: Finished processing stats for write job 380b0a56-8ac8-447c-b500-70bb4b4b5a65.
Cargando: yellow_tripdata_2022-05.parquet en hdfs://hadoop-namenode:8020/data/nyc/raw/taxi-trips/2022...
26/01/12 03:02:16 INFO InMemoryFileIndex: It took 7 ms to list leaf files for 1 paths.
26/01/12 03:02:16 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 03:02:16 INFO DAGScheduler: Got job 320 (parquet at <unknown>:0) with 1 output partitions
26/01/12 03:02:16 INFO DAGScheduler: Final stage: ResultStage 320 (parquet at <unknown>:0)
26/01/12 03:02:16 INFO DAGScheduler: Parents of final stage: List()
26/01/12 03:02:16 INFO DAGScheduler: Missing parents: List()
26/01/12 03:02:16 INFO DAGScheduler: Submitting ResultStage 320 (MapPartitionsRDD[801] at parquet at <unknown>:0), which has no missing parents
26/01/12 03:02:16 INFO MemoryStore: Block broadcast_480 stored as values in memory (estimated size 102.6 KiB, free 364.3 MiB)
26/01/12 03:02:16 INFO MemoryStore: Block broadcast_480_piece0 stored as bytes in memory (estimated size 36.8 KiB, free 364.3 MiB)
26/01/12 03:02:16 INFO BlockManagerInfo: Added broadcast_480_piece0 in memory on 02926ee04bc9:45221 (size: 36.8 KiB, free: 366.0 MiB)
26/01/12 03:02:16 INFO SparkContext: Created broadcast 480 from broadcast at DAGScheduler.scala:1513
26/01/12 03:02:16 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 320 (MapPartitionsRDD[801] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0))
26/01/12 03:02:16 INFO TaskSchedulerImpl: Adding task set 320.0 with 1 tasks resource profile 0
26/01/12 03:02:16 INFO TaskSetManager: Starting task 0.0 in stage 320.0 (TID 527) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4607 bytes) taskResourceAssignments Map()
26/01/12 03:02:16 INFO BlockManagerInfo: Added broadcast_480_piece0 in memory on 172.18.0.5:42453 (size: 36.8 KiB, free: 366.0 MiB)
26/01/12 03:02:16 INFO TaskSetManager: Finished task 0.0 in stage 320.0 (TID 527) in 45 ms on 172.18.0.5 (executor 0) (1/1)
26/01/12 03:02:16 INFO TaskSchedulerImpl: Removed TaskSet 320.0, whose tasks have all completed, from pool 
26/01/12 03:02:16 INFO DAGScheduler: ResultStage 320 (parquet at <unknown>:0) finished in 0.056 s
26/01/12 03:02:16 INFO DAGScheduler: Job 320 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 03:02:16 INFO TaskSchedulerImpl: Killing all running tasks in stage 320: Stage finished
26/01/12 03:02:16 INFO DAGScheduler: Job 320 finished: parquet at <unknown>:0, took 0.059183 s
26/01/12 03:02:16 INFO FileSourceStrategy: Pushed Filters: 
26/01/12 03:02:16 INFO FileSourceStrategy: Post-Scan Filters: 
26/01/12 03:02:16 INFO FileSourceStrategy: Output Data Schema: struct<VendorID: bigint, tpep_pickup_datetime: timestamp, tpep_dropoff_datetime: timestamp, passenger_count: double, trip_distance: double ... 17 more fields>
26/01/12 03:02:16 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 03:02:16 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 03:02:16 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 03:02:16 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 03:02:16 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 03:02:16 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 03:02:16 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 03:02:16 INFO MemoryStore: Block broadcast_481 stored as values in memory (estimated size 358.5 KiB, free 363.9 MiB)
26/01/12 03:02:16 INFO MemoryStore: Block broadcast_481_piece0 stored as bytes in memory (estimated size 35.4 KiB, free 363.9 MiB)
26/01/12 03:02:16 INFO BlockManagerInfo: Added broadcast_481_piece0 in memory on 02926ee04bc9:45221 (size: 35.4 KiB, free: 365.9 MiB)
26/01/12 03:02:16 INFO SparkContext: Created broadcast 481 from parquet at <unknown>:0
26/01/12 03:02:16 INFO FileSourceScanExec: Planning scan with bin packing, max size: 29876562 bytes, open cost is considered as scanning 4194304 bytes.
26/01/12 03:02:16 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 03:02:16 INFO DAGScheduler: Got job 321 (parquet at <unknown>:0) with 2 output partitions
26/01/12 03:02:16 INFO DAGScheduler: Final stage: ResultStage 321 (parquet at <unknown>:0)
26/01/12 03:02:16 INFO DAGScheduler: Parents of final stage: List()
26/01/12 03:02:16 INFO DAGScheduler: Missing parents: List()
26/01/12 03:02:16 INFO DAGScheduler: Submitting ResultStage 321 (MapPartitionsRDD[804] at parquet at <unknown>:0), which has no missing parents
26/01/12 03:02:16 INFO MemoryStore: Block broadcast_482 stored as values in memory (estimated size 225.0 KiB, free 363.7 MiB)
26/01/12 03:02:16 INFO MemoryStore: Block broadcast_482_piece0 stored as bytes in memory (estimated size 77.3 KiB, free 363.6 MiB)
26/01/12 03:02:16 INFO BlockManagerInfo: Added broadcast_482_piece0 in memory on 02926ee04bc9:45221 (size: 77.3 KiB, free: 365.9 MiB)
26/01/12 03:02:16 INFO SparkContext: Created broadcast 482 from broadcast at DAGScheduler.scala:1513
26/01/12 03:02:16 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 321 (MapPartitionsRDD[804] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1))
26/01/12 03:02:16 INFO TaskSchedulerImpl: Adding task set 321.0 with 2 tasks resource profile 0
26/01/12 03:02:16 INFO TaskSetManager: Starting task 0.0 in stage 321.0 (TID 528) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 03:02:16 INFO TaskSetManager: Starting task 1.0 in stage 321.0 (TID 529) (172.18.0.5, executor 0, partition 1, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 03:02:16 INFO BlockManagerInfo: Added broadcast_482_piece0 in memory on 172.18.0.5:42453 (size: 77.3 KiB, free: 365.9 MiB)
26/01/12 03:02:16 INFO BlockManagerInfo: Added broadcast_481_piece0 in memory on 172.18.0.5:42453 (size: 35.4 KiB, free: 365.9 MiB)
26/01/12 03:02:16 INFO TaskSetManager: Finished task 1.0 in stage 321.0 (TID 529) in 54 ms on 172.18.0.5 (executor 0) (1/2)
26/01/12 03:02:25 INFO TaskSetManager: Finished task 0.0 in stage 321.0 (TID 528) in 9328 ms on 172.18.0.5 (executor 0) (2/2)
26/01/12 03:02:25 INFO TaskSchedulerImpl: Removed TaskSet 321.0, whose tasks have all completed, from pool 
26/01/12 03:02:25 INFO DAGScheduler: ResultStage 321 (parquet at <unknown>:0) finished in 9.346 s
26/01/12 03:02:25 INFO DAGScheduler: Job 321 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 03:02:25 INFO TaskSchedulerImpl: Killing all running tasks in stage 321: Stage finished
26/01/12 03:02:25 INFO DAGScheduler: Job 321 finished: parquet at <unknown>:0, took 9.350529 s
26/01/12 03:02:25 INFO FileFormatWriter: Start to commit write Job 7a0269ce-f736-45db-afe1-9bbba2b08280.
26/01/12 03:02:25 INFO FileFormatWriter: Write Job 7a0269ce-f736-45db-afe1-9bbba2b08280 committed. Elapsed time: 26 ms.
26/01/12 03:02:25 INFO FileFormatWriter: Finished processing stats for write job 7a0269ce-f736-45db-afe1-9bbba2b08280.
Cargando: yellow_tripdata_2022-06.parquet en hdfs://hadoop-namenode:8020/data/nyc/raw/taxi-trips/2022...
26/01/12 03:02:25 INFO InMemoryFileIndex: It took 6 ms to list leaf files for 1 paths.
26/01/12 03:02:25 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 03:02:25 INFO DAGScheduler: Got job 322 (parquet at <unknown>:0) with 1 output partitions
26/01/12 03:02:25 INFO DAGScheduler: Final stage: ResultStage 322 (parquet at <unknown>:0)
26/01/12 03:02:25 INFO DAGScheduler: Parents of final stage: List()
26/01/12 03:02:25 INFO DAGScheduler: Missing parents: List()
26/01/12 03:02:25 INFO DAGScheduler: Submitting ResultStage 322 (MapPartitionsRDD[806] at parquet at <unknown>:0), which has no missing parents
26/01/12 03:02:25 INFO MemoryStore: Block broadcast_483 stored as values in memory (estimated size 102.6 KiB, free 363.5 MiB)
26/01/12 03:02:25 INFO MemoryStore: Block broadcast_483_piece0 stored as bytes in memory (estimated size 36.8 KiB, free 363.5 MiB)
26/01/12 03:02:25 INFO BlockManagerInfo: Added broadcast_483_piece0 in memory on 02926ee04bc9:45221 (size: 36.8 KiB, free: 365.8 MiB)
26/01/12 03:02:25 INFO SparkContext: Created broadcast 483 from broadcast at DAGScheduler.scala:1513
26/01/12 03:02:25 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 322 (MapPartitionsRDD[806] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0))
26/01/12 03:02:25 INFO TaskSchedulerImpl: Adding task set 322.0 with 1 tasks resource profile 0
26/01/12 03:02:25 INFO TaskSetManager: Starting task 0.0 in stage 322.0 (TID 530) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4607 bytes) taskResourceAssignments Map()
26/01/12 03:02:25 INFO BlockManagerInfo: Added broadcast_483_piece0 in memory on 172.18.0.5:42453 (size: 36.8 KiB, free: 365.8 MiB)
26/01/12 03:02:25 INFO TaskSetManager: Finished task 0.0 in stage 322.0 (TID 530) in 41 ms on 172.18.0.5 (executor 0) (1/1)
26/01/12 03:02:25 INFO TaskSchedulerImpl: Removed TaskSet 322.0, whose tasks have all completed, from pool 
26/01/12 03:02:25 INFO DAGScheduler: ResultStage 322 (parquet at <unknown>:0) finished in 0.052 s
26/01/12 03:02:25 INFO DAGScheduler: Job 322 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 03:02:25 INFO TaskSchedulerImpl: Killing all running tasks in stage 322: Stage finished
26/01/12 03:02:25 INFO DAGScheduler: Job 322 finished: parquet at <unknown>:0, took 0.054775 s
26/01/12 03:02:25 INFO FileSourceStrategy: Pushed Filters: 
26/01/12 03:02:25 INFO FileSourceStrategy: Post-Scan Filters: 
26/01/12 03:02:25 INFO FileSourceStrategy: Output Data Schema: struct<VendorID: bigint, tpep_pickup_datetime: timestamp, tpep_dropoff_datetime: timestamp, passenger_count: double, trip_distance: double ... 17 more fields>
26/01/12 03:02:25 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 03:02:25 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 03:02:25 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 03:02:25 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 03:02:25 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 03:02:25 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 03:02:25 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 03:02:25 INFO BlockManagerInfo: Removed broadcast_479_piece0 on 02926ee04bc9:45221 in memory (size: 77.3 KiB, free: 365.9 MiB)
26/01/12 03:02:25 INFO BlockManagerInfo: Removed broadcast_479_piece0 on 172.18.0.5:42453 in memory (size: 77.3 KiB, free: 365.9 MiB)
26/01/12 03:02:25 INFO MemoryStore: Block broadcast_484 stored as values in memory (estimated size 358.5 KiB, free 363.4 MiB)
26/01/12 03:02:25 INFO BlockManagerInfo: Removed broadcast_480_piece0 on 02926ee04bc9:45221 in memory (size: 36.8 KiB, free: 365.9 MiB)
26/01/12 03:02:25 INFO BlockManagerInfo: Removed broadcast_480_piece0 on 172.18.0.5:42453 in memory (size: 36.8 KiB, free: 365.9 MiB)
26/01/12 03:02:25 INFO MemoryStore: Block broadcast_484_piece0 stored as bytes in memory (estimated size 35.4 KiB, free 363.5 MiB)
26/01/12 03:02:25 INFO BlockManagerInfo: Added broadcast_484_piece0 in memory on 02926ee04bc9:45221 (size: 35.4 KiB, free: 365.9 MiB)
26/01/12 03:02:25 INFO SparkContext: Created broadcast 484 from parquet at <unknown>:0
26/01/12 03:02:25 INFO FileSourceScanExec: Planning scan with bin packing, max size: 29779744 bytes, open cost is considered as scanning 4194304 bytes.
26/01/12 03:02:25 INFO BlockManagerInfo: Removed broadcast_475_piece0 on 02926ee04bc9:45221 in memory (size: 35.4 KiB, free: 365.9 MiB)
26/01/12 03:02:25 INFO BlockManagerInfo: Removed broadcast_475_piece0 on 172.18.0.5:42453 in memory (size: 35.4 KiB, free: 366.0 MiB)
26/01/12 03:02:25 INFO BlockManagerInfo: Removed broadcast_481_piece0 on 02926ee04bc9:45221 in memory (size: 35.4 KiB, free: 366.0 MiB)
26/01/12 03:02:25 INFO BlockManagerInfo: Removed broadcast_481_piece0 on 172.18.0.5:42453 in memory (size: 35.4 KiB, free: 366.0 MiB)
26/01/12 03:02:25 INFO BlockManagerInfo: Removed broadcast_483_piece0 on 02926ee04bc9:45221 in memory (size: 36.8 KiB, free: 366.0 MiB)
26/01/12 03:02:25 INFO BlockManagerInfo: Removed broadcast_483_piece0 on 172.18.0.5:42453 in memory (size: 36.8 KiB, free: 366.0 MiB)
26/01/12 03:02:25 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 03:02:25 INFO BlockManagerInfo: Removed broadcast_477_piece0 on 02926ee04bc9:45221 in memory (size: 36.8 KiB, free: 366.0 MiB)
26/01/12 03:02:25 INFO DAGScheduler: Got job 323 (parquet at <unknown>:0) with 2 output partitions
26/01/12 03:02:25 INFO DAGScheduler: Final stage: ResultStage 323 (parquet at <unknown>:0)
26/01/12 03:02:25 INFO DAGScheduler: Parents of final stage: List()
26/01/12 03:02:25 INFO BlockManagerInfo: Removed broadcast_477_piece0 on 172.18.0.5:42453 in memory (size: 36.8 KiB, free: 366.1 MiB)
26/01/12 03:02:25 INFO DAGScheduler: Missing parents: List()
26/01/12 03:02:25 INFO DAGScheduler: Submitting ResultStage 323 (MapPartitionsRDD[809] at parquet at <unknown>:0), which has no missing parents
26/01/12 03:02:25 INFO BlockManagerInfo: Removed broadcast_478_piece0 on 02926ee04bc9:45221 in memory (size: 35.4 KiB, free: 366.1 MiB)
26/01/12 03:02:25 INFO BlockManagerInfo: Removed broadcast_478_piece0 on 172.18.0.5:42453 in memory (size: 35.4 KiB, free: 366.1 MiB)
26/01/12 03:02:25 INFO BlockManagerInfo: Removed broadcast_482_piece0 on 02926ee04bc9:45221 in memory (size: 77.3 KiB, free: 366.2 MiB)
26/01/12 03:02:25 INFO BlockManagerInfo: Removed broadcast_482_piece0 on 172.18.0.5:42453 in memory (size: 77.3 KiB, free: 366.2 MiB)
26/01/12 03:02:25 INFO MemoryStore: Block broadcast_485 stored as values in memory (estimated size 225.0 KiB, free 365.0 MiB)
26/01/12 03:02:25 INFO MemoryStore: Block broadcast_485_piece0 stored as bytes in memory (estimated size 77.3 KiB, free 364.9 MiB)
26/01/12 03:02:25 INFO BlockManagerInfo: Added broadcast_485_piece0 in memory on 02926ee04bc9:45221 (size: 77.3 KiB, free: 366.1 MiB)
26/01/12 03:02:25 INFO SparkContext: Created broadcast 485 from broadcast at DAGScheduler.scala:1513
26/01/12 03:02:25 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 323 (MapPartitionsRDD[809] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1))
26/01/12 03:02:25 INFO TaskSchedulerImpl: Adding task set 323.0 with 2 tasks resource profile 0
26/01/12 03:02:25 INFO TaskSetManager: Starting task 0.0 in stage 323.0 (TID 531) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 03:02:25 INFO TaskSetManager: Starting task 1.0 in stage 323.0 (TID 532) (172.18.0.5, executor 0, partition 1, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 03:02:25 INFO BlockManagerInfo: Added broadcast_485_piece0 in memory on 172.18.0.5:42453 (size: 77.3 KiB, free: 366.1 MiB)
26/01/12 03:02:25 INFO BlockManagerInfo: Added broadcast_484_piece0 in memory on 172.18.0.5:42453 (size: 35.4 KiB, free: 366.1 MiB)
26/01/12 03:02:25 INFO TaskSetManager: Finished task 1.0 in stage 323.0 (TID 532) in 45 ms on 172.18.0.5 (executor 0) (1/2)
26/01/12 03:02:34 INFO TaskSetManager: Finished task 0.0 in stage 323.0 (TID 531) in 9288 ms on 172.18.0.5 (executor 0) (2/2)
26/01/12 03:02:34 INFO TaskSchedulerImpl: Removed TaskSet 323.0, whose tasks have all completed, from pool 
26/01/12 03:02:34 INFO DAGScheduler: ResultStage 323 (parquet at <unknown>:0) finished in 9.306 s
26/01/12 03:02:34 INFO DAGScheduler: Job 323 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 03:02:34 INFO TaskSchedulerImpl: Killing all running tasks in stage 323: Stage finished
26/01/12 03:02:34 INFO DAGScheduler: Job 323 finished: parquet at <unknown>:0, took 9.313084 s
26/01/12 03:02:34 INFO FileFormatWriter: Start to commit write Job 0308a122-ad08-46c3-b526-fe8bf3d9b45f.
26/01/12 03:02:35 INFO FileFormatWriter: Write Job 0308a122-ad08-46c3-b526-fe8bf3d9b45f committed. Elapsed time: 27 ms.
26/01/12 03:02:35 INFO FileFormatWriter: Finished processing stats for write job 0308a122-ad08-46c3-b526-fe8bf3d9b45f.
Cargando: yellow_tripdata_2022-07.parquet en hdfs://hadoop-namenode:8020/data/nyc/raw/taxi-trips/2022...
26/01/12 03:02:35 INFO InMemoryFileIndex: It took 6 ms to list leaf files for 1 paths.
26/01/12 03:02:35 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 03:02:35 INFO DAGScheduler: Got job 324 (parquet at <unknown>:0) with 1 output partitions
26/01/12 03:02:35 INFO DAGScheduler: Final stage: ResultStage 324 (parquet at <unknown>:0)
26/01/12 03:02:35 INFO DAGScheduler: Parents of final stage: List()
26/01/12 03:02:35 INFO DAGScheduler: Missing parents: List()
26/01/12 03:02:35 INFO DAGScheduler: Submitting ResultStage 324 (MapPartitionsRDD[811] at parquet at <unknown>:0), which has no missing parents
26/01/12 03:02:35 INFO MemoryStore: Block broadcast_486 stored as values in memory (estimated size 102.6 KiB, free 364.8 MiB)
26/01/12 03:02:35 INFO MemoryStore: Block broadcast_486_piece0 stored as bytes in memory (estimated size 36.8 KiB, free 364.8 MiB)
26/01/12 03:02:35 INFO BlockManagerInfo: Added broadcast_486_piece0 in memory on 02926ee04bc9:45221 (size: 36.8 KiB, free: 366.0 MiB)
26/01/12 03:02:35 INFO SparkContext: Created broadcast 486 from broadcast at DAGScheduler.scala:1513
26/01/12 03:02:35 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 324 (MapPartitionsRDD[811] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0))
26/01/12 03:02:35 INFO TaskSchedulerImpl: Adding task set 324.0 with 1 tasks resource profile 0
26/01/12 03:02:35 INFO TaskSetManager: Starting task 0.0 in stage 324.0 (TID 533) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4607 bytes) taskResourceAssignments Map()
26/01/12 03:02:35 INFO BlockManagerInfo: Added broadcast_486_piece0 in memory on 172.18.0.5:42453 (size: 36.8 KiB, free: 366.0 MiB)
26/01/12 03:02:35 INFO TaskSetManager: Finished task 0.0 in stage 324.0 (TID 533) in 44 ms on 172.18.0.5 (executor 0) (1/1)
26/01/12 03:02:35 INFO TaskSchedulerImpl: Removed TaskSet 324.0, whose tasks have all completed, from pool 
26/01/12 03:02:35 INFO DAGScheduler: ResultStage 324 (parquet at <unknown>:0) finished in 0.055 s
26/01/12 03:02:35 INFO DAGScheduler: Job 324 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 03:02:35 INFO TaskSchedulerImpl: Killing all running tasks in stage 324: Stage finished
26/01/12 03:02:35 INFO DAGScheduler: Job 324 finished: parquet at <unknown>:0, took 0.058102 s
26/01/12 03:02:35 INFO FileSourceStrategy: Pushed Filters: 
26/01/12 03:02:35 INFO FileSourceStrategy: Post-Scan Filters: 
26/01/12 03:02:35 INFO FileSourceStrategy: Output Data Schema: struct<VendorID: bigint, tpep_pickup_datetime: timestamp, tpep_dropoff_datetime: timestamp, passenger_count: double, trip_distance: double ... 17 more fields>
26/01/12 03:02:35 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 03:02:35 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 03:02:35 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 03:02:35 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 03:02:35 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 03:02:35 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 03:02:35 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 03:02:35 INFO MemoryStore: Block broadcast_487 stored as values in memory (estimated size 358.5 KiB, free 364.5 MiB)
26/01/12 03:02:35 INFO MemoryStore: Block broadcast_487_piece0 stored as bytes in memory (estimated size 35.4 KiB, free 364.4 MiB)
26/01/12 03:02:35 INFO BlockManagerInfo: Added broadcast_487_piece0 in memory on 02926ee04bc9:45221 (size: 35.4 KiB, free: 366.0 MiB)
26/01/12 03:02:35 INFO SparkContext: Created broadcast 487 from parquet at <unknown>:0
26/01/12 03:02:35 INFO FileSourceScanExec: Planning scan with bin packing, max size: 26781008 bytes, open cost is considered as scanning 4194304 bytes.
26/01/12 03:02:35 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 03:02:35 INFO DAGScheduler: Got job 325 (parquet at <unknown>:0) with 2 output partitions
26/01/12 03:02:35 INFO DAGScheduler: Final stage: ResultStage 325 (parquet at <unknown>:0)
26/01/12 03:02:35 INFO DAGScheduler: Parents of final stage: List()
26/01/12 03:02:35 INFO DAGScheduler: Missing parents: List()
26/01/12 03:02:35 INFO DAGScheduler: Submitting ResultStage 325 (MapPartitionsRDD[814] at parquet at <unknown>:0), which has no missing parents
26/01/12 03:02:35 INFO MemoryStore: Block broadcast_488 stored as values in memory (estimated size 225.0 KiB, free 364.2 MiB)
26/01/12 03:02:35 INFO MemoryStore: Block broadcast_488_piece0 stored as bytes in memory (estimated size 77.3 KiB, free 364.1 MiB)
26/01/12 03:02:35 INFO BlockManagerInfo: Added broadcast_488_piece0 in memory on 02926ee04bc9:45221 (size: 77.3 KiB, free: 365.9 MiB)
26/01/12 03:02:35 INFO SparkContext: Created broadcast 488 from broadcast at DAGScheduler.scala:1513
26/01/12 03:02:35 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 325 (MapPartitionsRDD[814] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1))
26/01/12 03:02:35 INFO TaskSchedulerImpl: Adding task set 325.0 with 2 tasks resource profile 0
26/01/12 03:02:35 INFO TaskSetManager: Starting task 0.0 in stage 325.0 (TID 534) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 03:02:35 INFO TaskSetManager: Starting task 1.0 in stage 325.0 (TID 535) (172.18.0.5, executor 0, partition 1, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 03:02:35 INFO BlockManagerInfo: Added broadcast_488_piece0 in memory on 172.18.0.5:42453 (size: 77.3 KiB, free: 366.0 MiB)
26/01/12 03:02:35 INFO BlockManagerInfo: Added broadcast_487_piece0 in memory on 172.18.0.5:42453 (size: 35.4 KiB, free: 365.9 MiB)
26/01/12 03:02:35 INFO TaskSetManager: Finished task 1.0 in stage 325.0 (TID 535) in 51 ms on 172.18.0.5 (executor 0) (1/2)
26/01/12 03:02:43 INFO TaskSetManager: Finished task 0.0 in stage 325.0 (TID 534) in 8383 ms on 172.18.0.5 (executor 0) (2/2)
26/01/12 03:02:43 INFO TaskSchedulerImpl: Removed TaskSet 325.0, whose tasks have all completed, from pool 
26/01/12 03:02:43 INFO DAGScheduler: ResultStage 325 (parquet at <unknown>:0) finished in 8.400 s
26/01/12 03:02:43 INFO DAGScheduler: Job 325 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 03:02:43 INFO TaskSchedulerImpl: Killing all running tasks in stage 325: Stage finished
26/01/12 03:02:43 INFO DAGScheduler: Job 325 finished: parquet at <unknown>:0, took 8.403019 s
26/01/12 03:02:43 INFO FileFormatWriter: Start to commit write Job cda985b5-e273-492b-aab4-8fe6d6845732.
26/01/12 03:02:43 INFO FileFormatWriter: Write Job cda985b5-e273-492b-aab4-8fe6d6845732 committed. Elapsed time: 25 ms.
26/01/12 03:02:43 INFO FileFormatWriter: Finished processing stats for write job cda985b5-e273-492b-aab4-8fe6d6845732.
Cargando: yellow_tripdata_2022-08.parquet en hdfs://hadoop-namenode:8020/data/nyc/raw/taxi-trips/2022...
26/01/12 03:02:43 INFO InMemoryFileIndex: It took 6 ms to list leaf files for 1 paths.
26/01/12 03:02:43 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 03:02:43 INFO DAGScheduler: Got job 326 (parquet at <unknown>:0) with 1 output partitions
26/01/12 03:02:43 INFO DAGScheduler: Final stage: ResultStage 326 (parquet at <unknown>:0)
26/01/12 03:02:43 INFO DAGScheduler: Parents of final stage: List()
26/01/12 03:02:43 INFO DAGScheduler: Missing parents: List()
26/01/12 03:02:43 INFO DAGScheduler: Submitting ResultStage 326 (MapPartitionsRDD[816] at parquet at <unknown>:0), which has no missing parents
26/01/12 03:02:43 INFO MemoryStore: Block broadcast_489 stored as values in memory (estimated size 102.6 KiB, free 364.0 MiB)
26/01/12 03:02:43 INFO MemoryStore: Block broadcast_489_piece0 stored as bytes in memory (estimated size 36.8 KiB, free 364.0 MiB)
26/01/12 03:02:43 INFO BlockManagerInfo: Added broadcast_489_piece0 in memory on 02926ee04bc9:45221 (size: 36.8 KiB, free: 365.9 MiB)
26/01/12 03:02:43 INFO SparkContext: Created broadcast 489 from broadcast at DAGScheduler.scala:1513
26/01/12 03:02:43 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 326 (MapPartitionsRDD[816] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0))
26/01/12 03:02:43 INFO TaskSchedulerImpl: Adding task set 326.0 with 1 tasks resource profile 0
26/01/12 03:02:43 INFO TaskSetManager: Starting task 0.0 in stage 326.0 (TID 536) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4607 bytes) taskResourceAssignments Map()
26/01/12 03:02:43 INFO BlockManagerInfo: Added broadcast_489_piece0 in memory on 172.18.0.5:42453 (size: 36.8 KiB, free: 365.9 MiB)
26/01/12 03:02:43 INFO TaskSetManager: Finished task 0.0 in stage 326.0 (TID 536) in 38 ms on 172.18.0.5 (executor 0) (1/1)
26/01/12 03:02:43 INFO TaskSchedulerImpl: Removed TaskSet 326.0, whose tasks have all completed, from pool 
26/01/12 03:02:43 INFO DAGScheduler: ResultStage 326 (parquet at <unknown>:0) finished in 0.049 s
26/01/12 03:02:43 INFO DAGScheduler: Job 326 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 03:02:43 INFO TaskSchedulerImpl: Killing all running tasks in stage 326: Stage finished
26/01/12 03:02:43 INFO DAGScheduler: Job 326 finished: parquet at <unknown>:0, took 0.051308 s
26/01/12 03:02:43 INFO FileSourceStrategy: Pushed Filters: 
26/01/12 03:02:43 INFO FileSourceStrategy: Post-Scan Filters: 
26/01/12 03:02:43 INFO FileSourceStrategy: Output Data Schema: struct<VendorID: bigint, tpep_pickup_datetime: timestamp, tpep_dropoff_datetime: timestamp, passenger_count: double, trip_distance: double ... 17 more fields>
26/01/12 03:02:43 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 03:02:43 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 03:02:43 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 03:02:43 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 03:02:43 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 03:02:43 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 03:02:43 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 03:02:43 INFO MemoryStore: Block broadcast_490 stored as values in memory (estimated size 358.5 KiB, free 363.6 MiB)
26/01/12 03:02:43 INFO MemoryStore: Block broadcast_490_piece0 stored as bytes in memory (estimated size 35.4 KiB, free 363.6 MiB)
26/01/12 03:02:43 INFO BlockManagerInfo: Added broadcast_490_piece0 in memory on 02926ee04bc9:45221 (size: 35.4 KiB, free: 365.9 MiB)
26/01/12 03:02:43 INFO SparkContext: Created broadcast 490 from parquet at <unknown>:0
26/01/12 03:02:43 INFO FileSourceScanExec: Planning scan with bin packing, max size: 26955731 bytes, open cost is considered as scanning 4194304 bytes.
26/01/12 03:02:43 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 03:02:43 INFO DAGScheduler: Got job 327 (parquet at <unknown>:0) with 2 output partitions
26/01/12 03:02:43 INFO DAGScheduler: Final stage: ResultStage 327 (parquet at <unknown>:0)
26/01/12 03:02:43 INFO DAGScheduler: Parents of final stage: List()
26/01/12 03:02:43 INFO DAGScheduler: Missing parents: List()
26/01/12 03:02:43 INFO DAGScheduler: Submitting ResultStage 327 (MapPartitionsRDD[819] at parquet at <unknown>:0), which has no missing parents
26/01/12 03:02:43 INFO MemoryStore: Block broadcast_491 stored as values in memory (estimated size 225.0 KiB, free 363.4 MiB)
26/01/12 03:02:43 INFO BlockManagerInfo: Removed broadcast_485_piece0 on 02926ee04bc9:45221 in memory (size: 77.3 KiB, free: 365.9 MiB)
26/01/12 03:02:43 INFO BlockManagerInfo: Removed broadcast_485_piece0 on 172.18.0.5:42453 in memory (size: 77.3 KiB, free: 366.0 MiB)
26/01/12 03:02:43 INFO MemoryStore: Block broadcast_491_piece0 stored as bytes in memory (estimated size 77.3 KiB, free 363.6 MiB)
26/01/12 03:02:43 INFO BlockManagerInfo: Added broadcast_491_piece0 in memory on 02926ee04bc9:45221 (size: 77.3 KiB, free: 365.9 MiB)
26/01/12 03:02:43 INFO SparkContext: Created broadcast 491 from broadcast at DAGScheduler.scala:1513
26/01/12 03:02:43 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 327 (MapPartitionsRDD[819] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1))
26/01/12 03:02:43 INFO TaskSchedulerImpl: Adding task set 327.0 with 2 tasks resource profile 0
26/01/12 03:02:43 INFO TaskSetManager: Starting task 0.0 in stage 327.0 (TID 537) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 03:02:43 INFO BlockManagerInfo: Removed broadcast_484_piece0 on 02926ee04bc9:45221 in memory (size: 35.4 KiB, free: 365.9 MiB)
26/01/12 03:02:43 INFO TaskSetManager: Starting task 1.0 in stage 327.0 (TID 538) (172.18.0.5, executor 0, partition 1, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 03:02:43 INFO BlockManagerInfo: Removed broadcast_484_piece0 on 172.18.0.5:42453 in memory (size: 35.4 KiB, free: 366.0 MiB)
26/01/12 03:02:43 INFO BlockManagerInfo: Removed broadcast_487_piece0 on 02926ee04bc9:45221 in memory (size: 35.4 KiB, free: 365.9 MiB)
26/01/12 03:02:43 INFO BlockManagerInfo: Added broadcast_491_piece0 in memory on 172.18.0.5:42453 (size: 77.3 KiB, free: 365.9 MiB)
26/01/12 03:02:43 INFO BlockManagerInfo: Removed broadcast_487_piece0 on 172.18.0.5:42453 in memory (size: 35.4 KiB, free: 366.0 MiB)
26/01/12 03:02:43 INFO BlockManagerInfo: Removed broadcast_489_piece0 on 02926ee04bc9:45221 in memory (size: 36.8 KiB, free: 366.0 MiB)
26/01/12 03:02:43 INFO BlockManagerInfo: Removed broadcast_489_piece0 on 172.18.0.5:42453 in memory (size: 36.8 KiB, free: 366.0 MiB)
26/01/12 03:02:43 INFO BlockManagerInfo: Removed broadcast_488_piece0 on 02926ee04bc9:45221 in memory (size: 77.3 KiB, free: 366.0 MiB)
26/01/12 03:02:43 INFO BlockManagerInfo: Removed broadcast_488_piece0 on 172.18.0.5:42453 in memory (size: 77.3 KiB, free: 366.1 MiB)
26/01/12 03:02:43 INFO BlockManagerInfo: Added broadcast_490_piece0 in memory on 172.18.0.5:42453 (size: 35.4 KiB, free: 366.0 MiB)
26/01/12 03:02:43 INFO BlockManagerInfo: Removed broadcast_486_piece0 on 02926ee04bc9:45221 in memory (size: 36.8 KiB, free: 366.1 MiB)
26/01/12 03:02:43 INFO BlockManagerInfo: Removed broadcast_486_piece0 on 172.18.0.5:42453 in memory (size: 36.8 KiB, free: 366.1 MiB)
26/01/12 03:02:43 INFO TaskSetManager: Finished task 1.0 in stage 327.0 (TID 538) in 69 ms on 172.18.0.5 (executor 0) (1/2)
26/01/12 03:02:52 INFO TaskSetManager: Finished task 0.0 in stage 327.0 (TID 537) in 8442 ms on 172.18.0.5 (executor 0) (2/2)
26/01/12 03:02:52 INFO TaskSchedulerImpl: Removed TaskSet 327.0, whose tasks have all completed, from pool 
26/01/12 03:02:52 INFO DAGScheduler: ResultStage 327 (parquet at <unknown>:0) finished in 8.478 s
26/01/12 03:02:52 INFO DAGScheduler: Job 327 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 03:02:52 INFO TaskSchedulerImpl: Killing all running tasks in stage 327: Stage finished
26/01/12 03:02:52 INFO DAGScheduler: Job 327 finished: parquet at <unknown>:0, took 8.481779 s
26/01/12 03:02:52 INFO FileFormatWriter: Start to commit write Job bcd2658e-9fad-4f54-949a-2481fe41e5a9.
26/01/12 03:02:52 INFO FileFormatWriter: Write Job bcd2658e-9fad-4f54-949a-2481fe41e5a9 committed. Elapsed time: 24 ms.
26/01/12 03:02:52 INFO FileFormatWriter: Finished processing stats for write job bcd2658e-9fad-4f54-949a-2481fe41e5a9.
Cargando: yellow_tripdata_2022-09.parquet en hdfs://hadoop-namenode:8020/data/nyc/raw/taxi-trips/2022...
26/01/12 03:02:52 INFO InMemoryFileIndex: It took 6 ms to list leaf files for 1 paths.
26/01/12 03:02:52 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 03:02:52 INFO DAGScheduler: Got job 328 (parquet at <unknown>:0) with 1 output partitions
26/01/12 03:02:52 INFO DAGScheduler: Final stage: ResultStage 328 (parquet at <unknown>:0)
26/01/12 03:02:52 INFO DAGScheduler: Parents of final stage: List()
26/01/12 03:02:52 INFO DAGScheduler: Missing parents: List()
26/01/12 03:02:52 INFO DAGScheduler: Submitting ResultStage 328 (MapPartitionsRDD[821] at parquet at <unknown>:0), which has no missing parents
26/01/12 03:02:52 INFO MemoryStore: Block broadcast_492 stored as values in memory (estimated size 102.6 KiB, free 364.8 MiB)
26/01/12 03:02:52 INFO MemoryStore: Block broadcast_492_piece0 stored as bytes in memory (estimated size 36.8 KiB, free 364.8 MiB)
26/01/12 03:02:52 INFO BlockManagerInfo: Added broadcast_492_piece0 in memory on 02926ee04bc9:45221 (size: 36.8 KiB, free: 366.0 MiB)
26/01/12 03:02:52 INFO SparkContext: Created broadcast 492 from broadcast at DAGScheduler.scala:1513
26/01/12 03:02:52 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 328 (MapPartitionsRDD[821] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0))
26/01/12 03:02:52 INFO TaskSchedulerImpl: Adding task set 328.0 with 1 tasks resource profile 0
26/01/12 03:02:52 INFO TaskSetManager: Starting task 0.0 in stage 328.0 (TID 539) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4607 bytes) taskResourceAssignments Map()
26/01/12 03:02:52 INFO BlockManagerInfo: Added broadcast_492_piece0 in memory on 172.18.0.5:42453 (size: 36.8 KiB, free: 366.0 MiB)
26/01/12 03:02:52 INFO TaskSetManager: Finished task 0.0 in stage 328.0 (TID 539) in 50 ms on 172.18.0.5 (executor 0) (1/1)
26/01/12 03:02:52 INFO TaskSchedulerImpl: Removed TaskSet 328.0, whose tasks have all completed, from pool 
26/01/12 03:02:52 INFO DAGScheduler: ResultStage 328 (parquet at <unknown>:0) finished in 0.061 s
26/01/12 03:02:52 INFO DAGScheduler: Job 328 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 03:02:52 INFO TaskSchedulerImpl: Killing all running tasks in stage 328: Stage finished
26/01/12 03:02:52 INFO DAGScheduler: Job 328 finished: parquet at <unknown>:0, took 0.063780 s
26/01/12 03:02:52 INFO FileSourceStrategy: Pushed Filters: 
26/01/12 03:02:52 INFO FileSourceStrategy: Post-Scan Filters: 
26/01/12 03:02:52 INFO FileSourceStrategy: Output Data Schema: struct<VendorID: bigint, tpep_pickup_datetime: timestamp, tpep_dropoff_datetime: timestamp, passenger_count: double, trip_distance: double ... 17 more fields>
26/01/12 03:02:52 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 03:02:52 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 03:02:52 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 03:02:52 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 03:02:52 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 03:02:52 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 03:02:52 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 03:02:52 INFO MemoryStore: Block broadcast_493 stored as values in memory (estimated size 358.5 KiB, free 364.5 MiB)
26/01/12 03:02:52 INFO MemoryStore: Block broadcast_493_piece0 stored as bytes in memory (estimated size 35.4 KiB, free 364.4 MiB)
26/01/12 03:02:52 INFO BlockManagerInfo: Added broadcast_493_piece0 in memory on 02926ee04bc9:45221 (size: 35.4 KiB, free: 366.0 MiB)
26/01/12 03:02:52 INFO SparkContext: Created broadcast 493 from parquet at <unknown>:0
26/01/12 03:02:52 INFO FileSourceScanExec: Planning scan with bin packing, max size: 26907130 bytes, open cost is considered as scanning 4194304 bytes.
26/01/12 03:02:52 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 03:02:52 INFO DAGScheduler: Got job 329 (parquet at <unknown>:0) with 2 output partitions
26/01/12 03:02:52 INFO DAGScheduler: Final stage: ResultStage 329 (parquet at <unknown>:0)
26/01/12 03:02:52 INFO DAGScheduler: Parents of final stage: List()
26/01/12 03:02:52 INFO DAGScheduler: Missing parents: List()
26/01/12 03:02:52 INFO DAGScheduler: Submitting ResultStage 329 (MapPartitionsRDD[824] at parquet at <unknown>:0), which has no missing parents
26/01/12 03:02:52 INFO MemoryStore: Block broadcast_494 stored as values in memory (estimated size 225.0 KiB, free 364.2 MiB)
26/01/12 03:02:52 INFO MemoryStore: Block broadcast_494_piece0 stored as bytes in memory (estimated size 77.3 KiB, free 364.1 MiB)
26/01/12 03:02:52 INFO BlockManagerInfo: Added broadcast_494_piece0 in memory on 02926ee04bc9:45221 (size: 77.3 KiB, free: 365.9 MiB)
26/01/12 03:02:52 INFO SparkContext: Created broadcast 494 from broadcast at DAGScheduler.scala:1513
26/01/12 03:02:52 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 329 (MapPartitionsRDD[824] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1))
26/01/12 03:02:52 INFO TaskSchedulerImpl: Adding task set 329.0 with 2 tasks resource profile 0
26/01/12 03:02:52 INFO TaskSetManager: Starting task 0.0 in stage 329.0 (TID 540) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 03:02:52 INFO TaskSetManager: Starting task 1.0 in stage 329.0 (TID 541) (172.18.0.5, executor 0, partition 1, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 03:02:52 INFO BlockManagerInfo: Added broadcast_494_piece0 in memory on 172.18.0.5:42453 (size: 77.3 KiB, free: 366.0 MiB)
26/01/12 03:02:52 INFO BlockManagerInfo: Added broadcast_493_piece0 in memory on 172.18.0.5:42453 (size: 35.4 KiB, free: 365.9 MiB)
26/01/12 03:02:52 INFO TaskSetManager: Finished task 1.0 in stage 329.0 (TID 541) in 48 ms on 172.18.0.5 (executor 0) (1/2)
26/01/12 03:03:01 INFO TaskSetManager: Finished task 0.0 in stage 329.0 (TID 540) in 8676 ms on 172.18.0.5 (executor 0) (2/2)
26/01/12 03:03:01 INFO TaskSchedulerImpl: Removed TaskSet 329.0, whose tasks have all completed, from pool 
26/01/12 03:03:01 INFO DAGScheduler: ResultStage 329 (parquet at <unknown>:0) finished in 8.692 s
26/01/12 03:03:01 INFO DAGScheduler: Job 329 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 03:03:01 INFO TaskSchedulerImpl: Killing all running tasks in stage 329: Stage finished
26/01/12 03:03:01 INFO DAGScheduler: Job 329 finished: parquet at <unknown>:0, took 8.698797 s
26/01/12 03:03:01 INFO FileFormatWriter: Start to commit write Job 4ad2fd04-e393-4cee-a149-1d942ace78c7.
26/01/12 03:03:01 INFO FileFormatWriter: Write Job 4ad2fd04-e393-4cee-a149-1d942ace78c7 committed. Elapsed time: 23 ms.
26/01/12 03:03:01 INFO FileFormatWriter: Finished processing stats for write job 4ad2fd04-e393-4cee-a149-1d942ace78c7.
Cargando: yellow_tripdata_2022-10.parquet en hdfs://hadoop-namenode:8020/data/nyc/raw/taxi-trips/2022...
26/01/12 03:03:01 INFO InMemoryFileIndex: It took 6 ms to list leaf files for 1 paths.
26/01/12 03:03:01 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 03:03:01 INFO DAGScheduler: Got job 330 (parquet at <unknown>:0) with 1 output partitions
26/01/12 03:03:01 INFO DAGScheduler: Final stage: ResultStage 330 (parquet at <unknown>:0)
26/01/12 03:03:01 INFO DAGScheduler: Parents of final stage: List()
26/01/12 03:03:01 INFO DAGScheduler: Missing parents: List()
26/01/12 03:03:01 INFO DAGScheduler: Submitting ResultStage 330 (MapPartitionsRDD[826] at parquet at <unknown>:0), which has no missing parents
26/01/12 03:03:01 INFO MemoryStore: Block broadcast_495 stored as values in memory (estimated size 102.6 KiB, free 364.0 MiB)
26/01/12 03:03:01 INFO MemoryStore: Block broadcast_495_piece0 stored as bytes in memory (estimated size 36.8 KiB, free 364.0 MiB)
26/01/12 03:03:01 INFO BlockManagerInfo: Added broadcast_495_piece0 in memory on 02926ee04bc9:45221 (size: 36.8 KiB, free: 365.9 MiB)
26/01/12 03:03:01 INFO SparkContext: Created broadcast 495 from broadcast at DAGScheduler.scala:1513
26/01/12 03:03:01 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 330 (MapPartitionsRDD[826] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0))
26/01/12 03:03:01 INFO TaskSchedulerImpl: Adding task set 330.0 with 1 tasks resource profile 0
26/01/12 03:03:01 INFO TaskSetManager: Starting task 0.0 in stage 330.0 (TID 542) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4607 bytes) taskResourceAssignments Map()
26/01/12 03:03:01 INFO BlockManagerInfo: Added broadcast_495_piece0 in memory on 172.18.0.5:42453 (size: 36.8 KiB, free: 365.9 MiB)
26/01/12 03:03:01 INFO TaskSetManager: Finished task 0.0 in stage 330.0 (TID 542) in 46 ms on 172.18.0.5 (executor 0) (1/1)
26/01/12 03:03:01 INFO TaskSchedulerImpl: Removed TaskSet 330.0, whose tasks have all completed, from pool 
26/01/12 03:03:01 INFO DAGScheduler: ResultStage 330 (parquet at <unknown>:0) finished in 0.057 s
26/01/12 03:03:01 INFO DAGScheduler: Job 330 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 03:03:01 INFO TaskSchedulerImpl: Killing all running tasks in stage 330: Stage finished
26/01/12 03:03:01 INFO DAGScheduler: Job 330 finished: parquet at <unknown>:0, took 0.059394 s
26/01/12 03:03:01 INFO FileSourceStrategy: Pushed Filters: 
26/01/12 03:03:01 INFO FileSourceStrategy: Post-Scan Filters: 
26/01/12 03:03:01 INFO FileSourceStrategy: Output Data Schema: struct<VendorID: bigint, tpep_pickup_datetime: timestamp, tpep_dropoff_datetime: timestamp, passenger_count: double, trip_distance: double ... 17 more fields>
26/01/12 03:03:01 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 03:03:01 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 03:03:01 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 03:03:01 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 03:03:01 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 03:03:01 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 03:03:01 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 03:03:01 INFO MemoryStore: Block broadcast_496 stored as values in memory (estimated size 358.5 KiB, free 363.6 MiB)
26/01/12 03:03:01 INFO MemoryStore: Block broadcast_496_piece0 stored as bytes in memory (estimated size 35.4 KiB, free 363.6 MiB)
26/01/12 03:03:01 INFO BlockManagerInfo: Added broadcast_496_piece0 in memory on 02926ee04bc9:45221 (size: 35.4 KiB, free: 365.9 MiB)
26/01/12 03:03:01 INFO SparkContext: Created broadcast 496 from parquet at <unknown>:0
26/01/12 03:03:01 INFO FileSourceScanExec: Planning scan with bin packing, max size: 30628121 bytes, open cost is considered as scanning 4194304 bytes.
26/01/12 03:03:01 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 03:03:01 INFO DAGScheduler: Got job 331 (parquet at <unknown>:0) with 2 output partitions
26/01/12 03:03:01 INFO DAGScheduler: Final stage: ResultStage 331 (parquet at <unknown>:0)
26/01/12 03:03:01 INFO DAGScheduler: Parents of final stage: List()
26/01/12 03:03:01 INFO DAGScheduler: Missing parents: List()
26/01/12 03:03:01 INFO DAGScheduler: Submitting ResultStage 331 (MapPartitionsRDD[829] at parquet at <unknown>:0), which has no missing parents
26/01/12 03:03:01 INFO MemoryStore: Block broadcast_497 stored as values in memory (estimated size 225.0 KiB, free 363.4 MiB)
26/01/12 03:03:01 INFO MemoryStore: Block broadcast_497_piece0 stored as bytes in memory (estimated size 77.3 KiB, free 363.3 MiB)
26/01/12 03:03:01 INFO BlockManagerInfo: Added broadcast_497_piece0 in memory on 02926ee04bc9:45221 (size: 77.3 KiB, free: 365.8 MiB)
26/01/12 03:03:01 INFO SparkContext: Created broadcast 497 from broadcast at DAGScheduler.scala:1513
26/01/12 03:03:01 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 331 (MapPartitionsRDD[829] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1))
26/01/12 03:03:01 INFO TaskSchedulerImpl: Adding task set 331.0 with 2 tasks resource profile 0
26/01/12 03:03:01 INFO TaskSetManager: Starting task 0.0 in stage 331.0 (TID 543) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 03:03:01 INFO TaskSetManager: Starting task 1.0 in stage 331.0 (TID 544) (172.18.0.5, executor 0, partition 1, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 03:03:01 INFO BlockManagerInfo: Added broadcast_497_piece0 in memory on 172.18.0.5:42453 (size: 77.3 KiB, free: 365.8 MiB)
26/01/12 03:03:01 INFO BlockManagerInfo: Added broadcast_496_piece0 in memory on 172.18.0.5:42453 (size: 35.4 KiB, free: 365.8 MiB)
26/01/12 03:03:01 INFO TaskSetManager: Finished task 1.0 in stage 331.0 (TID 544) in 48 ms on 172.18.0.5 (executor 0) (1/2)
26/01/12 03:03:10 INFO TaskSetManager: Finished task 0.0 in stage 331.0 (TID 543) in 9695 ms on 172.18.0.5 (executor 0) (2/2)
26/01/12 03:03:10 INFO TaskSchedulerImpl: Removed TaskSet 331.0, whose tasks have all completed, from pool 
26/01/12 03:03:10 INFO DAGScheduler: ResultStage 331 (parquet at <unknown>:0) finished in 9.713 s
26/01/12 03:03:10 INFO DAGScheduler: Job 331 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 03:03:10 INFO TaskSchedulerImpl: Killing all running tasks in stage 331: Stage finished
26/01/12 03:03:10 INFO DAGScheduler: Job 331 finished: parquet at <unknown>:0, took 9.716801 s
26/01/12 03:03:10 INFO FileFormatWriter: Start to commit write Job 321fde36-8d99-415f-868a-c7062e73581d.
26/01/12 03:03:11 INFO FileFormatWriter: Write Job 321fde36-8d99-415f-868a-c7062e73581d committed. Elapsed time: 25 ms.
26/01/12 03:03:11 INFO FileFormatWriter: Finished processing stats for write job 321fde36-8d99-415f-868a-c7062e73581d.
Cargando: yellow_tripdata_2022-11.parquet en hdfs://hadoop-namenode:8020/data/nyc/raw/taxi-trips/2022...
26/01/12 03:03:11 INFO InMemoryFileIndex: It took 6 ms to list leaf files for 1 paths.
26/01/12 03:03:11 INFO BlockManagerInfo: Removed broadcast_490_piece0 on 02926ee04bc9:45221 in memory (size: 35.4 KiB, free: 365.8 MiB)
26/01/12 03:03:11 INFO BlockManagerInfo: Removed broadcast_490_piece0 on 172.18.0.5:42453 in memory (size: 35.4 KiB, free: 365.8 MiB)
26/01/12 03:03:11 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 03:03:11 INFO DAGScheduler: Got job 332 (parquet at <unknown>:0) with 1 output partitions
26/01/12 03:03:11 INFO DAGScheduler: Final stage: ResultStage 332 (parquet at <unknown>:0)
26/01/12 03:03:11 INFO DAGScheduler: Parents of final stage: List()
26/01/12 03:03:11 INFO DAGScheduler: Missing parents: List()
26/01/12 03:03:11 INFO DAGScheduler: Submitting ResultStage 332 (MapPartitionsRDD[831] at parquet at <unknown>:0), which has no missing parents
26/01/12 03:03:11 INFO BlockManagerInfo: Removed broadcast_491_piece0 on 02926ee04bc9:45221 in memory (size: 77.3 KiB, free: 365.9 MiB)
26/01/12 03:03:11 INFO BlockManagerInfo: Removed broadcast_491_piece0 on 172.18.0.5:42453 in memory (size: 77.3 KiB, free: 365.9 MiB)
26/01/12 03:03:11 INFO BlockManagerInfo: Removed broadcast_495_piece0 on 02926ee04bc9:45221 in memory (size: 36.8 KiB, free: 365.9 MiB)
26/01/12 03:03:11 INFO BlockManagerInfo: Removed broadcast_495_piece0 on 172.18.0.5:42453 in memory (size: 36.8 KiB, free: 365.9 MiB)
26/01/12 03:03:11 INFO MemoryStore: Block broadcast_498 stored as values in memory (estimated size 102.6 KiB, free 364.0 MiB)
26/01/12 03:03:11 INFO MemoryStore: Block broadcast_498_piece0 stored as bytes in memory (estimated size 36.8 KiB, free 364.0 MiB)
26/01/12 03:03:11 INFO BlockManagerInfo: Added broadcast_498_piece0 in memory on 02926ee04bc9:45221 (size: 36.8 KiB, free: 365.9 MiB)
26/01/12 03:03:11 INFO SparkContext: Created broadcast 498 from broadcast at DAGScheduler.scala:1513
26/01/12 03:03:11 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 332 (MapPartitionsRDD[831] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0))
26/01/12 03:03:11 INFO BlockManagerInfo: Removed broadcast_497_piece0 on 02926ee04bc9:45221 in memory (size: 77.3 KiB, free: 366.0 MiB)
26/01/12 03:03:11 INFO TaskSchedulerImpl: Adding task set 332.0 with 1 tasks resource profile 0
26/01/12 03:03:11 INFO BlockManagerInfo: Removed broadcast_497_piece0 on 172.18.0.5:42453 in memory (size: 77.3 KiB, free: 366.0 MiB)
26/01/12 03:03:11 INFO TaskSetManager: Starting task 0.0 in stage 332.0 (TID 545) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4607 bytes) taskResourceAssignments Map()
26/01/12 03:03:11 INFO BlockManagerInfo: Removed broadcast_493_piece0 on 02926ee04bc9:45221 in memory (size: 35.4 KiB, free: 366.0 MiB)
26/01/12 03:03:11 INFO BlockManagerInfo: Removed broadcast_493_piece0 on 172.18.0.5:42453 in memory (size: 35.4 KiB, free: 366.0 MiB)
26/01/12 03:03:11 INFO BlockManagerInfo: Added broadcast_498_piece0 in memory on 172.18.0.5:42453 (size: 36.8 KiB, free: 366.0 MiB)
26/01/12 03:03:11 INFO BlockManagerInfo: Removed broadcast_494_piece0 on 02926ee04bc9:45221 in memory (size: 77.3 KiB, free: 366.1 MiB)
26/01/12 03:03:11 INFO BlockManagerInfo: Removed broadcast_494_piece0 on 172.18.0.5:42453 in memory (size: 77.3 KiB, free: 366.1 MiB)
26/01/12 03:03:11 INFO BlockManagerInfo: Removed broadcast_492_piece0 on 02926ee04bc9:45221 in memory (size: 36.8 KiB, free: 366.1 MiB)
26/01/12 03:03:11 INFO BlockManagerInfo: Removed broadcast_492_piece0 on 172.18.0.5:42453 in memory (size: 36.8 KiB, free: 366.1 MiB)
26/01/12 03:03:11 INFO TaskSetManager: Finished task 0.0 in stage 332.0 (TID 545) in 42 ms on 172.18.0.5 (executor 0) (1/1)
26/01/12 03:03:11 INFO TaskSchedulerImpl: Removed TaskSet 332.0, whose tasks have all completed, from pool 
26/01/12 03:03:11 INFO DAGScheduler: ResultStage 332 (parquet at <unknown>:0) finished in 0.054 s
26/01/12 03:03:11 INFO DAGScheduler: Job 332 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 03:03:11 INFO TaskSchedulerImpl: Killing all running tasks in stage 332: Stage finished
26/01/12 03:03:11 INFO DAGScheduler: Job 332 finished: parquet at <unknown>:0, took 0.057300 s
26/01/12 03:03:11 INFO FileSourceStrategy: Pushed Filters: 
26/01/12 03:03:11 INFO FileSourceStrategy: Post-Scan Filters: 
26/01/12 03:03:11 INFO FileSourceStrategy: Output Data Schema: struct<VendorID: bigint, tpep_pickup_datetime: timestamp, tpep_dropoff_datetime: timestamp, passenger_count: double, trip_distance: double ... 17 more fields>
26/01/12 03:03:11 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 03:03:11 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 03:03:11 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 03:03:11 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 03:03:11 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 03:03:11 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 03:03:11 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 03:03:11 INFO MemoryStore: Block broadcast_499 stored as values in memory (estimated size 358.5 KiB, free 364.7 MiB)
26/01/12 03:03:11 INFO MemoryStore: Block broadcast_499_piece0 stored as bytes in memory (estimated size 35.4 KiB, free 364.7 MiB)
26/01/12 03:03:11 INFO BlockManagerInfo: Added broadcast_499_piece0 in memory on 02926ee04bc9:45221 (size: 35.4 KiB, free: 366.1 MiB)
26/01/12 03:03:11 INFO SparkContext: Created broadcast 499 from parquet at <unknown>:0
26/01/12 03:03:11 INFO FileSourceScanExec: Planning scan with bin packing, max size: 27150467 bytes, open cost is considered as scanning 4194304 bytes.
26/01/12 03:03:11 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 03:03:11 INFO DAGScheduler: Got job 333 (parquet at <unknown>:0) with 2 output partitions
26/01/12 03:03:11 INFO DAGScheduler: Final stage: ResultStage 333 (parquet at <unknown>:0)
26/01/12 03:03:11 INFO DAGScheduler: Parents of final stage: List()
26/01/12 03:03:11 INFO DAGScheduler: Missing parents: List()
26/01/12 03:03:11 INFO DAGScheduler: Submitting ResultStage 333 (MapPartitionsRDD[834] at parquet at <unknown>:0), which has no missing parents
26/01/12 03:03:11 INFO MemoryStore: Block broadcast_500 stored as values in memory (estimated size 225.0 KiB, free 364.5 MiB)
26/01/12 03:03:11 INFO MemoryStore: Block broadcast_500_piece0 stored as bytes in memory (estimated size 77.2 KiB, free 364.4 MiB)
26/01/12 03:03:11 INFO BlockManagerInfo: Added broadcast_500_piece0 in memory on 02926ee04bc9:45221 (size: 77.2 KiB, free: 366.0 MiB)
26/01/12 03:03:11 INFO SparkContext: Created broadcast 500 from broadcast at DAGScheduler.scala:1513
26/01/12 03:03:11 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 333 (MapPartitionsRDD[834] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1))
26/01/12 03:03:11 INFO TaskSchedulerImpl: Adding task set 333.0 with 2 tasks resource profile 0
26/01/12 03:03:11 INFO TaskSetManager: Starting task 0.0 in stage 333.0 (TID 546) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 03:03:11 INFO TaskSetManager: Starting task 1.0 in stage 333.0 (TID 547) (172.18.0.5, executor 0, partition 1, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 03:03:11 INFO BlockManagerInfo: Added broadcast_500_piece0 in memory on 172.18.0.5:42453 (size: 77.2 KiB, free: 366.0 MiB)
26/01/12 03:03:11 INFO BlockManagerInfo: Added broadcast_499_piece0 in memory on 172.18.0.5:42453 (size: 35.4 KiB, free: 366.0 MiB)
26/01/12 03:03:11 INFO TaskSetManager: Finished task 1.0 in stage 333.0 (TID 547) in 55 ms on 172.18.0.5 (executor 0) (1/2)
26/01/12 03:03:19 INFO TaskSetManager: Finished task 0.0 in stage 333.0 (TID 546) in 8320 ms on 172.18.0.5 (executor 0) (2/2)
26/01/12 03:03:19 INFO TaskSchedulerImpl: Removed TaskSet 333.0, whose tasks have all completed, from pool 
26/01/12 03:03:19 INFO DAGScheduler: ResultStage 333 (parquet at <unknown>:0) finished in 8.337 s
26/01/12 03:03:19 INFO DAGScheduler: Job 333 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 03:03:19 INFO TaskSchedulerImpl: Killing all running tasks in stage 333: Stage finished
26/01/12 03:03:19 INFO DAGScheduler: Job 333 finished: parquet at <unknown>:0, took 8.341287 s
26/01/12 03:03:19 INFO FileFormatWriter: Start to commit write Job 7f02b30e-e88a-48c9-a2b1-1441b29b1910.
26/01/12 03:03:19 INFO FileFormatWriter: Write Job 7f02b30e-e88a-48c9-a2b1-1441b29b1910 committed. Elapsed time: 28 ms.
26/01/12 03:03:19 INFO FileFormatWriter: Finished processing stats for write job 7f02b30e-e88a-48c9-a2b1-1441b29b1910.
Cargando: yellow_tripdata_2022-12.parquet en hdfs://hadoop-namenode:8020/data/nyc/raw/taxi-trips/2022...
26/01/12 03:03:19 INFO InMemoryFileIndex: It took 6 ms to list leaf files for 1 paths.
26/01/12 03:03:19 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 03:03:19 INFO DAGScheduler: Got job 334 (parquet at <unknown>:0) with 1 output partitions
26/01/12 03:03:19 INFO DAGScheduler: Final stage: ResultStage 334 (parquet at <unknown>:0)
26/01/12 03:03:19 INFO DAGScheduler: Parents of final stage: List()
26/01/12 03:03:19 INFO DAGScheduler: Missing parents: List()
26/01/12 03:03:19 INFO DAGScheduler: Submitting ResultStage 334 (MapPartitionsRDD[836] at parquet at <unknown>:0), which has no missing parents
26/01/12 03:03:19 INFO MemoryStore: Block broadcast_501 stored as values in memory (estimated size 102.6 KiB, free 364.3 MiB)
26/01/12 03:03:19 INFO MemoryStore: Block broadcast_501_piece0 stored as bytes in memory (estimated size 36.8 KiB, free 364.3 MiB)
26/01/12 03:03:19 INFO BlockManagerInfo: Added broadcast_501_piece0 in memory on 02926ee04bc9:45221 (size: 36.8 KiB, free: 366.0 MiB)
26/01/12 03:03:19 INFO SparkContext: Created broadcast 501 from broadcast at DAGScheduler.scala:1513
26/01/12 03:03:19 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 334 (MapPartitionsRDD[836] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0))
26/01/12 03:03:19 INFO TaskSchedulerImpl: Adding task set 334.0 with 1 tasks resource profile 0
26/01/12 03:03:19 INFO TaskSetManager: Starting task 0.0 in stage 334.0 (TID 548) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4607 bytes) taskResourceAssignments Map()
26/01/12 03:03:19 INFO BlockManagerInfo: Added broadcast_501_piece0 in memory on 172.18.0.5:42453 (size: 36.8 KiB, free: 366.0 MiB)
26/01/12 03:03:19 INFO TaskSetManager: Finished task 0.0 in stage 334.0 (TID 548) in 45 ms on 172.18.0.5 (executor 0) (1/1)
26/01/12 03:03:19 INFO TaskSchedulerImpl: Removed TaskSet 334.0, whose tasks have all completed, from pool 
26/01/12 03:03:19 INFO DAGScheduler: ResultStage 334 (parquet at <unknown>:0) finished in 0.057 s
26/01/12 03:03:19 INFO DAGScheduler: Job 334 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 03:03:19 INFO TaskSchedulerImpl: Killing all running tasks in stage 334: Stage finished
26/01/12 03:03:19 INFO DAGScheduler: Job 334 finished: parquet at <unknown>:0, took 0.059894 s
26/01/12 03:03:19 INFO FileSourceStrategy: Pushed Filters: 
26/01/12 03:03:19 INFO FileSourceStrategy: Post-Scan Filters: 
26/01/12 03:03:19 INFO FileSourceStrategy: Output Data Schema: struct<VendorID: bigint, tpep_pickup_datetime: timestamp, tpep_dropoff_datetime: timestamp, passenger_count: double, trip_distance: double ... 17 more fields>
26/01/12 03:03:19 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 03:03:19 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 03:03:19 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 03:03:19 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 03:03:19 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 03:03:19 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 03:03:19 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 03:03:19 INFO MemoryStore: Block broadcast_502 stored as values in memory (estimated size 358.5 KiB, free 363.9 MiB)
26/01/12 03:03:19 INFO MemoryStore: Block broadcast_502_piece0 stored as bytes in memory (estimated size 35.4 KiB, free 363.9 MiB)
26/01/12 03:03:19 INFO BlockManagerInfo: Added broadcast_502_piece0 in memory on 02926ee04bc9:45221 (size: 35.4 KiB, free: 365.9 MiB)
26/01/12 03:03:19 INFO SparkContext: Created broadcast 502 from parquet at <unknown>:0
26/01/12 03:03:19 INFO FileSourceScanExec: Planning scan with bin packing, max size: 28917521 bytes, open cost is considered as scanning 4194304 bytes.
26/01/12 03:03:19 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 03:03:19 INFO DAGScheduler: Got job 335 (parquet at <unknown>:0) with 2 output partitions
26/01/12 03:03:19 INFO DAGScheduler: Final stage: ResultStage 335 (parquet at <unknown>:0)
26/01/12 03:03:19 INFO DAGScheduler: Parents of final stage: List()
26/01/12 03:03:19 INFO DAGScheduler: Missing parents: List()
26/01/12 03:03:19 INFO DAGScheduler: Submitting ResultStage 335 (MapPartitionsRDD[839] at parquet at <unknown>:0), which has no missing parents
26/01/12 03:03:19 INFO MemoryStore: Block broadcast_503 stored as values in memory (estimated size 225.0 KiB, free 363.7 MiB)
26/01/12 03:03:19 INFO MemoryStore: Block broadcast_503_piece0 stored as bytes in memory (estimated size 77.3 KiB, free 363.6 MiB)
26/01/12 03:03:19 INFO BlockManagerInfo: Added broadcast_503_piece0 in memory on 02926ee04bc9:45221 (size: 77.3 KiB, free: 365.9 MiB)
26/01/12 03:03:19 INFO SparkContext: Created broadcast 503 from broadcast at DAGScheduler.scala:1513
26/01/12 03:03:19 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 335 (MapPartitionsRDD[839] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1))
26/01/12 03:03:19 INFO TaskSchedulerImpl: Adding task set 335.0 with 2 tasks resource profile 0
26/01/12 03:03:19 INFO TaskSetManager: Starting task 0.0 in stage 335.0 (TID 549) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 03:03:19 INFO TaskSetManager: Starting task 1.0 in stage 335.0 (TID 550) (172.18.0.5, executor 0, partition 1, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 03:03:19 INFO BlockManagerInfo: Added broadcast_503_piece0 in memory on 172.18.0.5:42453 (size: 77.3 KiB, free: 365.9 MiB)
26/01/12 03:03:19 INFO BlockManagerInfo: Added broadcast_502_piece0 in memory on 172.18.0.5:42453 (size: 35.4 KiB, free: 365.9 MiB)
26/01/12 03:03:19 INFO TaskSetManager: Finished task 1.0 in stage 335.0 (TID 550) in 61 ms on 172.18.0.5 (executor 0) (1/2)
26/01/12 03:03:28 INFO TaskSetManager: Finished task 0.0 in stage 335.0 (TID 549) in 8782 ms on 172.18.0.5 (executor 0) (2/2)
26/01/12 03:03:28 INFO TaskSchedulerImpl: Removed TaskSet 335.0, whose tasks have all completed, from pool 
26/01/12 03:03:28 INFO DAGScheduler: ResultStage 335 (parquet at <unknown>:0) finished in 8.806 s
26/01/12 03:03:28 INFO DAGScheduler: Job 335 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 03:03:28 INFO TaskSchedulerImpl: Killing all running tasks in stage 335: Stage finished
26/01/12 03:03:28 INFO DAGScheduler: Job 335 finished: parquet at <unknown>:0, took 8.810487 s
26/01/12 03:03:28 INFO FileFormatWriter: Start to commit write Job 4af8fed4-292e-475a-9c1d-656010bc98c3.
26/01/12 03:03:28 INFO FileFormatWriter: Write Job 4af8fed4-292e-475a-9c1d-656010bc98c3 committed. Elapsed time: 30 ms.
26/01/12 03:03:28 INFO FileFormatWriter: Finished processing stats for write job 4af8fed4-292e-475a-9c1d-656010bc98c3.
Cargando: yellow_tripdata_2023-01.parquet en hdfs://hadoop-namenode:8020/data/nyc/raw/taxi-trips/2023...
26/01/12 03:03:28 INFO InMemoryFileIndex: It took 6 ms to list leaf files for 1 paths.
26/01/12 03:03:28 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 03:03:28 INFO DAGScheduler: Got job 336 (parquet at <unknown>:0) with 1 output partitions
26/01/12 03:03:28 INFO DAGScheduler: Final stage: ResultStage 336 (parquet at <unknown>:0)
26/01/12 03:03:28 INFO DAGScheduler: Parents of final stage: List()
26/01/12 03:03:28 INFO DAGScheduler: Missing parents: List()
26/01/12 03:03:28 INFO DAGScheduler: Submitting ResultStage 336 (MapPartitionsRDD[841] at parquet at <unknown>:0), which has no missing parents
26/01/12 03:03:28 INFO MemoryStore: Block broadcast_504 stored as values in memory (estimated size 102.6 KiB, free 363.5 MiB)
26/01/12 03:03:28 INFO MemoryStore: Block broadcast_504_piece0 stored as bytes in memory (estimated size 36.8 KiB, free 363.5 MiB)
26/01/12 03:03:28 INFO BlockManagerInfo: Added broadcast_504_piece0 in memory on 02926ee04bc9:45221 (size: 36.8 KiB, free: 365.8 MiB)
26/01/12 03:03:28 INFO SparkContext: Created broadcast 504 from broadcast at DAGScheduler.scala:1513
26/01/12 03:03:28 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 336 (MapPartitionsRDD[841] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0))
26/01/12 03:03:28 INFO TaskSchedulerImpl: Adding task set 336.0 with 1 tasks resource profile 0
26/01/12 03:03:28 INFO TaskSetManager: Starting task 0.0 in stage 336.0 (TID 551) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4607 bytes) taskResourceAssignments Map()
26/01/12 03:03:28 INFO BlockManagerInfo: Added broadcast_504_piece0 in memory on 172.18.0.5:42453 (size: 36.8 KiB, free: 365.8 MiB)
26/01/12 03:03:28 INFO TaskSetManager: Finished task 0.0 in stage 336.0 (TID 551) in 43 ms on 172.18.0.5 (executor 0) (1/1)
26/01/12 03:03:28 INFO TaskSchedulerImpl: Removed TaskSet 336.0, whose tasks have all completed, from pool 
26/01/12 03:03:28 INFO DAGScheduler: ResultStage 336 (parquet at <unknown>:0) finished in 0.055 s
26/01/12 03:03:28 INFO DAGScheduler: Job 336 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 03:03:28 INFO TaskSchedulerImpl: Killing all running tasks in stage 336: Stage finished
26/01/12 03:03:28 INFO DAGScheduler: Job 336 finished: parquet at <unknown>:0, took 0.059508 s
26/01/12 03:03:28 INFO FileSourceStrategy: Pushed Filters: 
26/01/12 03:03:28 INFO FileSourceStrategy: Post-Scan Filters: 
26/01/12 03:03:28 INFO FileSourceStrategy: Output Data Schema: struct<VendorID: bigint, tpep_pickup_datetime: timestamp, tpep_dropoff_datetime: timestamp, passenger_count: double, trip_distance: double ... 17 more fields>
26/01/12 03:03:28 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 03:03:28 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 03:03:28 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 03:03:28 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 03:03:28 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 03:03:28 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 03:03:28 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 03:03:28 INFO MemoryStore: Block broadcast_505 stored as values in memory (estimated size 358.5 KiB, free 363.1 MiB)
26/01/12 03:03:28 INFO BlockManagerInfo: Removed broadcast_503_piece0 on 02926ee04bc9:45221 in memory (size: 77.3 KiB, free: 365.9 MiB)
26/01/12 03:03:28 INFO BlockManagerInfo: Removed broadcast_503_piece0 on 172.18.0.5:42453 in memory (size: 77.3 KiB, free: 365.9 MiB)
26/01/12 03:03:28 INFO MemoryStore: Block broadcast_505_piece0 stored as bytes in memory (estimated size 35.4 KiB, free 363.5 MiB)
26/01/12 03:03:28 INFO BlockManagerInfo: Removed broadcast_498_piece0 on 02926ee04bc9:45221 in memory (size: 36.8 KiB, free: 365.9 MiB)
26/01/12 03:03:28 INFO BlockManagerInfo: Added broadcast_505_piece0 in memory on 02926ee04bc9:45221 (size: 35.4 KiB, free: 365.9 MiB)
26/01/12 03:03:28 INFO BlockManagerInfo: Removed broadcast_498_piece0 on 172.18.0.5:42453 in memory (size: 36.8 KiB, free: 365.9 MiB)
26/01/12 03:03:28 INFO SparkContext: Created broadcast 505 from parquet at <unknown>:0
26/01/12 03:03:28 INFO FileSourceScanExec: Planning scan with bin packing, max size: 25933837 bytes, open cost is considered as scanning 4194304 bytes.
26/01/12 03:03:28 INFO BlockManagerInfo: Removed broadcast_500_piece0 on 02926ee04bc9:45221 in memory (size: 77.2 KiB, free: 366.0 MiB)
26/01/12 03:03:28 INFO BlockManagerInfo: Removed broadcast_500_piece0 on 172.18.0.5:42453 in memory (size: 77.2 KiB, free: 366.0 MiB)
26/01/12 03:03:28 INFO BlockManagerInfo: Removed broadcast_501_piece0 on 02926ee04bc9:45221 in memory (size: 36.8 KiB, free: 366.0 MiB)
26/01/12 03:03:28 INFO BlockManagerInfo: Removed broadcast_501_piece0 on 172.18.0.5:42453 in memory (size: 36.8 KiB, free: 366.1 MiB)
26/01/12 03:03:28 INFO BlockManagerInfo: Removed broadcast_496_piece0 on 02926ee04bc9:45221 in memory (size: 35.4 KiB, free: 366.1 MiB)
26/01/12 03:03:28 INFO BlockManagerInfo: Removed broadcast_496_piece0 on 172.18.0.5:42453 in memory (size: 35.4 KiB, free: 366.1 MiB)
26/01/12 03:03:28 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 03:03:28 INFO DAGScheduler: Got job 337 (parquet at <unknown>:0) with 2 output partitions
26/01/12 03:03:28 INFO DAGScheduler: Final stage: ResultStage 337 (parquet at <unknown>:0)
26/01/12 03:03:28 INFO DAGScheduler: Parents of final stage: List()
26/01/12 03:03:28 INFO BlockManagerInfo: Removed broadcast_499_piece0 on 02926ee04bc9:45221 in memory (size: 35.4 KiB, free: 366.1 MiB)
26/01/12 03:03:28 INFO DAGScheduler: Missing parents: List()
26/01/12 03:03:28 INFO DAGScheduler: Submitting ResultStage 337 (MapPartitionsRDD[844] at parquet at <unknown>:0), which has no missing parents
26/01/12 03:03:28 INFO BlockManagerInfo: Removed broadcast_499_piece0 on 172.18.0.5:42453 in memory (size: 35.4 KiB, free: 366.1 MiB)
26/01/12 03:03:28 INFO BlockManagerInfo: Removed broadcast_502_piece0 on 02926ee04bc9:45221 in memory (size: 35.4 KiB, free: 366.1 MiB)
26/01/12 03:03:28 INFO BlockManagerInfo: Removed broadcast_502_piece0 on 172.18.0.5:42453 in memory (size: 35.4 KiB, free: 366.2 MiB)
26/01/12 03:03:28 INFO BlockManagerInfo: Removed broadcast_504_piece0 on 02926ee04bc9:45221 in memory (size: 36.8 KiB, free: 366.2 MiB)
26/01/12 03:03:28 INFO BlockManagerInfo: Removed broadcast_504_piece0 on 172.18.0.5:42453 in memory (size: 36.8 KiB, free: 366.2 MiB)
26/01/12 03:03:28 INFO MemoryStore: Block broadcast_506 stored as values in memory (estimated size 225.0 KiB, free 365.0 MiB)
26/01/12 03:03:28 INFO MemoryStore: Block broadcast_506_piece0 stored as bytes in memory (estimated size 77.3 KiB, free 364.9 MiB)
26/01/12 03:03:28 INFO BlockManagerInfo: Added broadcast_506_piece0 in memory on 02926ee04bc9:45221 (size: 77.3 KiB, free: 366.1 MiB)
26/01/12 03:03:28 INFO SparkContext: Created broadcast 506 from broadcast at DAGScheduler.scala:1513
26/01/12 03:03:28 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 337 (MapPartitionsRDD[844] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1))
26/01/12 03:03:28 INFO TaskSchedulerImpl: Adding task set 337.0 with 2 tasks resource profile 0
26/01/12 03:03:28 INFO TaskSetManager: Starting task 0.0 in stage 337.0 (TID 552) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 03:03:28 INFO TaskSetManager: Starting task 1.0 in stage 337.0 (TID 553) (172.18.0.5, executor 0, partition 1, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 03:03:28 INFO BlockManagerInfo: Added broadcast_506_piece0 in memory on 172.18.0.5:42453 (size: 77.3 KiB, free: 366.1 MiB)
26/01/12 03:03:28 INFO BlockManagerInfo: Added broadcast_505_piece0 in memory on 172.18.0.5:42453 (size: 35.4 KiB, free: 366.1 MiB)
26/01/12 03:03:28 INFO TaskSetManager: Finished task 1.0 in stage 337.0 (TID 553) in 51 ms on 172.18.0.5 (executor 0) (1/2)
26/01/12 03:03:37 INFO TaskSetManager: Finished task 0.0 in stage 337.0 (TID 552) in 8545 ms on 172.18.0.5 (executor 0) (2/2)
26/01/12 03:03:37 INFO TaskSchedulerImpl: Removed TaskSet 337.0, whose tasks have all completed, from pool 
26/01/12 03:03:37 INFO DAGScheduler: ResultStage 337 (parquet at <unknown>:0) finished in 8.570 s
26/01/12 03:03:37 INFO DAGScheduler: Job 337 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 03:03:37 INFO TaskSchedulerImpl: Killing all running tasks in stage 337: Stage finished
26/01/12 03:03:37 INFO DAGScheduler: Job 337 finished: parquet at <unknown>:0, took 8.580515 s
26/01/12 03:03:37 INFO FileFormatWriter: Start to commit write Job 0e080a47-05f8-4e21-bb65-31ae71f9a322.
26/01/12 03:03:37 INFO FileFormatWriter: Write Job 0e080a47-05f8-4e21-bb65-31ae71f9a322 committed. Elapsed time: 31 ms.
26/01/12 03:03:37 INFO FileFormatWriter: Finished processing stats for write job 0e080a47-05f8-4e21-bb65-31ae71f9a322.
Cargando: yellow_tripdata_2023-02.parquet en hdfs://hadoop-namenode:8020/data/nyc/raw/taxi-trips/2023...
26/01/12 03:03:37 INFO InMemoryFileIndex: It took 8 ms to list leaf files for 1 paths.
26/01/12 03:03:37 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 03:03:37 INFO DAGScheduler: Got job 338 (parquet at <unknown>:0) with 1 output partitions
26/01/12 03:03:37 INFO DAGScheduler: Final stage: ResultStage 338 (parquet at <unknown>:0)
26/01/12 03:03:37 INFO DAGScheduler: Parents of final stage: List()
26/01/12 03:03:37 INFO DAGScheduler: Missing parents: List()
26/01/12 03:03:37 INFO DAGScheduler: Submitting ResultStage 338 (MapPartitionsRDD[846] at parquet at <unknown>:0), which has no missing parents
26/01/12 03:03:37 INFO MemoryStore: Block broadcast_507 stored as values in memory (estimated size 102.6 KiB, free 364.8 MiB)
26/01/12 03:03:37 INFO MemoryStore: Block broadcast_507_piece0 stored as bytes in memory (estimated size 36.8 KiB, free 364.8 MiB)
26/01/12 03:03:37 INFO BlockManagerInfo: Added broadcast_507_piece0 in memory on 02926ee04bc9:45221 (size: 36.8 KiB, free: 366.0 MiB)
26/01/12 03:03:37 INFO SparkContext: Created broadcast 507 from broadcast at DAGScheduler.scala:1513
26/01/12 03:03:37 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 338 (MapPartitionsRDD[846] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0))
26/01/12 03:03:37 INFO TaskSchedulerImpl: Adding task set 338.0 with 1 tasks resource profile 0
26/01/12 03:03:37 INFO TaskSetManager: Starting task 0.0 in stage 338.0 (TID 554) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4607 bytes) taskResourceAssignments Map()
26/01/12 03:03:37 INFO BlockManagerInfo: Added broadcast_507_piece0 in memory on 172.18.0.5:42453 (size: 36.8 KiB, free: 366.0 MiB)
26/01/12 03:03:37 INFO TaskSetManager: Finished task 0.0 in stage 338.0 (TID 554) in 49 ms on 172.18.0.5 (executor 0) (1/1)
26/01/12 03:03:37 INFO TaskSchedulerImpl: Removed TaskSet 338.0, whose tasks have all completed, from pool 
26/01/12 03:03:37 INFO DAGScheduler: ResultStage 338 (parquet at <unknown>:0) finished in 0.060 s
26/01/12 03:03:37 INFO DAGScheduler: Job 338 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 03:03:37 INFO TaskSchedulerImpl: Killing all running tasks in stage 338: Stage finished
26/01/12 03:03:37 INFO DAGScheduler: Job 338 finished: parquet at <unknown>:0, took 0.062939 s
26/01/12 03:03:37 INFO FileSourceStrategy: Pushed Filters: 
26/01/12 03:03:37 INFO FileSourceStrategy: Post-Scan Filters: 
26/01/12 03:03:37 INFO FileSourceStrategy: Output Data Schema: struct<VendorID: int, tpep_pickup_datetime: timestamp, tpep_dropoff_datetime: timestamp, passenger_count: bigint, trip_distance: double ... 17 more fields>
26/01/12 03:03:37 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 03:03:37 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 03:03:37 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 03:03:37 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 03:03:37 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 03:03:37 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 03:03:37 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 03:03:37 INFO CodeGenerator: Code generated in 14.733538 ms
26/01/12 03:03:37 INFO MemoryStore: Block broadcast_508 stored as values in memory (estimated size 358.5 KiB, free 364.5 MiB)
26/01/12 03:03:37 INFO MemoryStore: Block broadcast_508_piece0 stored as bytes in memory (estimated size 35.3 KiB, free 364.4 MiB)
26/01/12 03:03:37 INFO BlockManagerInfo: Added broadcast_508_piece0 in memory on 02926ee04bc9:45221 (size: 35.3 KiB, free: 366.0 MiB)
26/01/12 03:03:37 INFO SparkContext: Created broadcast 508 from parquet at <unknown>:0
26/01/12 03:03:37 INFO FileSourceScanExec: Planning scan with bin packing, max size: 25971158 bytes, open cost is considered as scanning 4194304 bytes.
26/01/12 03:03:37 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 03:03:37 INFO DAGScheduler: Got job 339 (parquet at <unknown>:0) with 2 output partitions
26/01/12 03:03:37 INFO DAGScheduler: Final stage: ResultStage 339 (parquet at <unknown>:0)
26/01/12 03:03:37 INFO DAGScheduler: Parents of final stage: List()
26/01/12 03:03:37 INFO DAGScheduler: Missing parents: List()
26/01/12 03:03:37 INFO DAGScheduler: Submitting ResultStage 339 (MapPartitionsRDD[849] at parquet at <unknown>:0), which has no missing parents
26/01/12 03:03:37 INFO MemoryStore: Block broadcast_509 stored as values in memory (estimated size 225.1 KiB, free 364.2 MiB)
26/01/12 03:03:37 INFO MemoryStore: Block broadcast_509_piece0 stored as bytes in memory (estimated size 77.5 KiB, free 364.1 MiB)
26/01/12 03:03:37 INFO BlockManagerInfo: Added broadcast_509_piece0 in memory on 02926ee04bc9:45221 (size: 77.5 KiB, free: 365.9 MiB)
26/01/12 03:03:37 INFO SparkContext: Created broadcast 509 from broadcast at DAGScheduler.scala:1513
26/01/12 03:03:37 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 339 (MapPartitionsRDD[849] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1))
26/01/12 03:03:37 INFO TaskSchedulerImpl: Adding task set 339.0 with 2 tasks resource profile 0
26/01/12 03:03:37 INFO TaskSetManager: Starting task 0.0 in stage 339.0 (TID 555) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 03:03:37 INFO TaskSetManager: Starting task 1.0 in stage 339.0 (TID 556) (172.18.0.5, executor 0, partition 1, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 03:03:37 INFO BlockManagerInfo: Added broadcast_509_piece0 in memory on 172.18.0.5:42453 (size: 77.5 KiB, free: 366.0 MiB)
26/01/12 03:03:37 INFO BlockManagerInfo: Added broadcast_508_piece0 in memory on 172.18.0.5:42453 (size: 35.3 KiB, free: 365.9 MiB)
26/01/12 03:03:37 INFO TaskSetManager: Finished task 1.0 in stage 339.0 (TID 556) in 80 ms on 172.18.0.5 (executor 0) (1/2)
26/01/12 03:03:45 INFO TaskSetManager: Finished task 0.0 in stage 339.0 (TID 555) in 7592 ms on 172.18.0.5 (executor 0) (2/2)
26/01/12 03:03:45 INFO TaskSchedulerImpl: Removed TaskSet 339.0, whose tasks have all completed, from pool 
26/01/12 03:03:45 INFO DAGScheduler: ResultStage 339 (parquet at <unknown>:0) finished in 7.610 s
26/01/12 03:03:45 INFO DAGScheduler: Job 339 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 03:03:45 INFO TaskSchedulerImpl: Killing all running tasks in stage 339: Stage finished
26/01/12 03:03:45 INFO DAGScheduler: Job 339 finished: parquet at <unknown>:0, took 7.614028 s
26/01/12 03:03:45 INFO FileFormatWriter: Start to commit write Job 02e16400-77cb-4f1c-b855-e3fd3ad22384.
26/01/12 03:03:45 INFO FileFormatWriter: Write Job 02e16400-77cb-4f1c-b855-e3fd3ad22384 committed. Elapsed time: 16 ms.
26/01/12 03:03:45 INFO FileFormatWriter: Finished processing stats for write job 02e16400-77cb-4f1c-b855-e3fd3ad22384.
Cargando: yellow_tripdata_2023-03.parquet en hdfs://hadoop-namenode:8020/data/nyc/raw/taxi-trips/2023...
26/01/12 03:03:45 INFO InMemoryFileIndex: It took 7 ms to list leaf files for 1 paths.
26/01/12 03:03:45 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 03:03:45 INFO DAGScheduler: Got job 340 (parquet at <unknown>:0) with 1 output partitions
26/01/12 03:03:45 INFO DAGScheduler: Final stage: ResultStage 340 (parquet at <unknown>:0)
26/01/12 03:03:45 INFO DAGScheduler: Parents of final stage: List()
26/01/12 03:03:45 INFO DAGScheduler: Missing parents: List()
26/01/12 03:03:45 INFO DAGScheduler: Submitting ResultStage 340 (MapPartitionsRDD[851] at parquet at <unknown>:0), which has no missing parents
26/01/12 03:03:45 INFO MemoryStore: Block broadcast_510 stored as values in memory (estimated size 102.6 KiB, free 364.0 MiB)
26/01/12 03:03:45 INFO MemoryStore: Block broadcast_510_piece0 stored as bytes in memory (estimated size 36.8 KiB, free 364.0 MiB)
26/01/12 03:03:45 INFO BlockManagerInfo: Added broadcast_510_piece0 in memory on 02926ee04bc9:45221 (size: 36.8 KiB, free: 365.9 MiB)
26/01/12 03:03:45 INFO SparkContext: Created broadcast 510 from broadcast at DAGScheduler.scala:1513
26/01/12 03:03:45 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 340 (MapPartitionsRDD[851] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0))
26/01/12 03:03:45 INFO TaskSchedulerImpl: Adding task set 340.0 with 1 tasks resource profile 0
26/01/12 03:03:45 INFO TaskSetManager: Starting task 0.0 in stage 340.0 (TID 557) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4607 bytes) taskResourceAssignments Map()
26/01/12 03:03:45 INFO BlockManagerInfo: Added broadcast_510_piece0 in memory on 172.18.0.5:42453 (size: 36.8 KiB, free: 365.9 MiB)
26/01/12 03:03:45 INFO TaskSetManager: Finished task 0.0 in stage 340.0 (TID 557) in 43 ms on 172.18.0.5 (executor 0) (1/1)
26/01/12 03:03:45 INFO TaskSchedulerImpl: Removed TaskSet 340.0, whose tasks have all completed, from pool 
26/01/12 03:03:45 INFO DAGScheduler: ResultStage 340 (parquet at <unknown>:0) finished in 0.053 s
26/01/12 03:03:45 INFO DAGScheduler: Job 340 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 03:03:45 INFO TaskSchedulerImpl: Killing all running tasks in stage 340: Stage finished
26/01/12 03:03:45 INFO DAGScheduler: Job 340 finished: parquet at <unknown>:0, took 0.056461 s
26/01/12 03:03:45 INFO FileSourceStrategy: Pushed Filters: 
26/01/12 03:03:45 INFO FileSourceStrategy: Post-Scan Filters: 
26/01/12 03:03:45 INFO FileSourceStrategy: Output Data Schema: struct<VendorID: int, tpep_pickup_datetime: timestamp, tpep_dropoff_datetime: timestamp, passenger_count: bigint, trip_distance: double ... 17 more fields>
26/01/12 03:03:45 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 03:03:45 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 03:03:45 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 03:03:45 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 03:03:45 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 03:03:45 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 03:03:45 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 03:03:45 INFO MemoryStore: Block broadcast_511 stored as values in memory (estimated size 358.5 KiB, free 363.6 MiB)
26/01/12 03:03:45 INFO BlockManagerInfo: Removed broadcast_510_piece0 on 02926ee04bc9:45221 in memory (size: 36.8 KiB, free: 365.9 MiB)
26/01/12 03:03:45 INFO BlockManagerInfo: Removed broadcast_510_piece0 on 172.18.0.5:42453 in memory (size: 36.8 KiB, free: 365.9 MiB)
26/01/12 03:03:45 INFO MemoryStore: Block broadcast_511_piece0 stored as bytes in memory (estimated size 35.3 KiB, free 363.7 MiB)
26/01/12 03:03:45 INFO BlockManagerInfo: Added broadcast_511_piece0 in memory on 02926ee04bc9:45221 (size: 35.3 KiB, free: 365.9 MiB)
26/01/12 03:03:45 INFO SparkContext: Created broadcast 511 from parquet at <unknown>:0
26/01/12 03:03:45 INFO FileSourceScanExec: Planning scan with bin packing, max size: 30161033 bytes, open cost is considered as scanning 4194304 bytes.
26/01/12 03:03:45 INFO BlockManagerInfo: Removed broadcast_507_piece0 on 02926ee04bc9:45221 in memory (size: 36.8 KiB, free: 365.9 MiB)
26/01/12 03:03:45 INFO BlockManagerInfo: Removed broadcast_507_piece0 on 172.18.0.5:42453 in memory (size: 36.8 KiB, free: 366.0 MiB)
26/01/12 03:03:45 INFO BlockManagerInfo: Removed broadcast_508_piece0 on 02926ee04bc9:45221 in memory (size: 35.3 KiB, free: 366.0 MiB)
26/01/12 03:03:45 INFO BlockManagerInfo: Removed broadcast_508_piece0 on 172.18.0.5:42453 in memory (size: 35.3 KiB, free: 366.0 MiB)
26/01/12 03:03:45 INFO BlockManagerInfo: Removed broadcast_506_piece0 on 02926ee04bc9:45221 in memory (size: 77.3 KiB, free: 366.0 MiB)
26/01/12 03:03:45 INFO BlockManagerInfo: Removed broadcast_506_piece0 on 172.18.0.5:42453 in memory (size: 77.3 KiB, free: 366.1 MiB)
26/01/12 03:03:45 INFO BlockManagerInfo: Removed broadcast_509_piece0 on 02926ee04bc9:45221 in memory (size: 77.5 KiB, free: 366.1 MiB)
26/01/12 03:03:45 INFO BlockManagerInfo: Removed broadcast_509_piece0 on 172.18.0.5:42453 in memory (size: 77.5 KiB, free: 366.2 MiB)
26/01/12 03:03:45 INFO BlockManagerInfo: Removed broadcast_505_piece0 on 02926ee04bc9:45221 in memory (size: 35.4 KiB, free: 366.2 MiB)
26/01/12 03:03:45 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 03:03:45 INFO DAGScheduler: Got job 341 (parquet at <unknown>:0) with 2 output partitions
26/01/12 03:03:45 INFO BlockManagerInfo: Removed broadcast_505_piece0 on 172.18.0.5:42453 in memory (size: 35.4 KiB, free: 366.2 MiB)
26/01/12 03:03:45 INFO DAGScheduler: Final stage: ResultStage 341 (parquet at <unknown>:0)
26/01/12 03:03:45 INFO DAGScheduler: Parents of final stage: List()
26/01/12 03:03:45 INFO DAGScheduler: Missing parents: List()
26/01/12 03:03:45 INFO DAGScheduler: Submitting ResultStage 341 (MapPartitionsRDD[854] at parquet at <unknown>:0), which has no missing parents
26/01/12 03:03:45 INFO MemoryStore: Block broadcast_512 stored as values in memory (estimated size 225.1 KiB, free 365.0 MiB)
26/01/12 03:03:45 INFO MemoryStore: Block broadcast_512_piece0 stored as bytes in memory (estimated size 77.5 KiB, free 364.9 MiB)
26/01/12 03:03:45 INFO BlockManagerInfo: Added broadcast_512_piece0 in memory on 02926ee04bc9:45221 (size: 77.5 KiB, free: 366.1 MiB)
26/01/12 03:03:45 INFO SparkContext: Created broadcast 512 from broadcast at DAGScheduler.scala:1513
26/01/12 03:03:45 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 341 (MapPartitionsRDD[854] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1))
26/01/12 03:03:45 INFO TaskSchedulerImpl: Adding task set 341.0 with 2 tasks resource profile 0
26/01/12 03:03:45 INFO TaskSetManager: Starting task 0.0 in stage 341.0 (TID 558) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 03:03:45 INFO TaskSetManager: Starting task 1.0 in stage 341.0 (TID 559) (172.18.0.5, executor 0, partition 1, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 03:03:45 INFO BlockManagerInfo: Added broadcast_512_piece0 in memory on 172.18.0.5:42453 (size: 77.5 KiB, free: 366.1 MiB)
26/01/12 03:03:45 INFO BlockManagerInfo: Added broadcast_511_piece0 in memory on 172.18.0.5:42453 (size: 35.3 KiB, free: 366.1 MiB)
26/01/12 03:03:45 INFO TaskSetManager: Finished task 1.0 in stage 341.0 (TID 559) in 60 ms on 172.18.0.5 (executor 0) (1/2)
26/01/12 03:03:54 INFO TaskSetManager: Finished task 0.0 in stage 341.0 (TID 558) in 8778 ms on 172.18.0.5 (executor 0) (2/2)
26/01/12 03:03:54 INFO TaskSchedulerImpl: Removed TaskSet 341.0, whose tasks have all completed, from pool 
26/01/12 03:03:54 INFO DAGScheduler: ResultStage 341 (parquet at <unknown>:0) finished in 8.799 s
26/01/12 03:03:54 INFO DAGScheduler: Job 341 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 03:03:54 INFO TaskSchedulerImpl: Killing all running tasks in stage 341: Stage finished
26/01/12 03:03:54 INFO DAGScheduler: Job 341 finished: parquet at <unknown>:0, took 8.801915 s
26/01/12 03:03:54 INFO FileFormatWriter: Start to commit write Job 013c2c17-d7f4-40ae-ad67-bdf9f5ed8581.
26/01/12 03:03:54 INFO FileFormatWriter: Write Job 013c2c17-d7f4-40ae-ad67-bdf9f5ed8581 committed. Elapsed time: 25 ms.
26/01/12 03:03:54 INFO FileFormatWriter: Finished processing stats for write job 013c2c17-d7f4-40ae-ad67-bdf9f5ed8581.
Cargando: yellow_tripdata_2023-04.parquet en hdfs://hadoop-namenode:8020/data/nyc/raw/taxi-trips/2023...
26/01/12 03:03:54 INFO InMemoryFileIndex: It took 6 ms to list leaf files for 1 paths.
26/01/12 03:03:54 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 03:03:54 INFO DAGScheduler: Got job 342 (parquet at <unknown>:0) with 1 output partitions
26/01/12 03:03:54 INFO DAGScheduler: Final stage: ResultStage 342 (parquet at <unknown>:0)
26/01/12 03:03:54 INFO DAGScheduler: Parents of final stage: List()
26/01/12 03:03:54 INFO DAGScheduler: Missing parents: List()
26/01/12 03:03:54 INFO DAGScheduler: Submitting ResultStage 342 (MapPartitionsRDD[856] at parquet at <unknown>:0), which has no missing parents
26/01/12 03:03:54 INFO MemoryStore: Block broadcast_513 stored as values in memory (estimated size 102.6 KiB, free 364.8 MiB)
26/01/12 03:03:54 INFO MemoryStore: Block broadcast_513_piece0 stored as bytes in memory (estimated size 36.8 KiB, free 364.8 MiB)
26/01/12 03:03:54 INFO BlockManagerInfo: Added broadcast_513_piece0 in memory on 02926ee04bc9:45221 (size: 36.8 KiB, free: 366.0 MiB)
26/01/12 03:03:54 INFO SparkContext: Created broadcast 513 from broadcast at DAGScheduler.scala:1513
26/01/12 03:03:54 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 342 (MapPartitionsRDD[856] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0))
26/01/12 03:03:54 INFO TaskSchedulerImpl: Adding task set 342.0 with 1 tasks resource profile 0
26/01/12 03:03:54 INFO TaskSetManager: Starting task 0.0 in stage 342.0 (TID 560) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4607 bytes) taskResourceAssignments Map()
26/01/12 03:03:54 INFO BlockManagerInfo: Added broadcast_513_piece0 in memory on 172.18.0.5:42453 (size: 36.8 KiB, free: 366.0 MiB)
26/01/12 03:03:54 INFO TaskSetManager: Finished task 0.0 in stage 342.0 (TID 560) in 46 ms on 172.18.0.5 (executor 0) (1/1)
26/01/12 03:03:54 INFO TaskSchedulerImpl: Removed TaskSet 342.0, whose tasks have all completed, from pool 
26/01/12 03:03:54 INFO DAGScheduler: ResultStage 342 (parquet at <unknown>:0) finished in 0.056 s
26/01/12 03:03:54 INFO DAGScheduler: Job 342 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 03:03:54 INFO TaskSchedulerImpl: Killing all running tasks in stage 342: Stage finished
26/01/12 03:03:54 INFO DAGScheduler: Job 342 finished: parquet at <unknown>:0, took 0.059125 s
26/01/12 03:03:54 INFO FileSourceStrategy: Pushed Filters: 
26/01/12 03:03:54 INFO FileSourceStrategy: Post-Scan Filters: 
26/01/12 03:03:54 INFO FileSourceStrategy: Output Data Schema: struct<VendorID: int, tpep_pickup_datetime: timestamp, tpep_dropoff_datetime: timestamp, passenger_count: bigint, trip_distance: double ... 17 more fields>
26/01/12 03:03:54 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 03:03:54 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 03:03:54 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 03:03:54 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 03:03:54 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 03:03:54 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 03:03:54 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 03:03:54 INFO MemoryStore: Block broadcast_514 stored as values in memory (estimated size 358.5 KiB, free 364.5 MiB)
26/01/12 03:03:54 INFO MemoryStore: Block broadcast_514_piece0 stored as bytes in memory (estimated size 35.3 KiB, free 364.4 MiB)
26/01/12 03:03:54 INFO BlockManagerInfo: Added broadcast_514_piece0 in memory on 02926ee04bc9:45221 (size: 35.3 KiB, free: 366.0 MiB)
26/01/12 03:03:54 INFO SparkContext: Created broadcast 514 from parquet at <unknown>:0
26/01/12 03:03:54 INFO FileSourceScanExec: Planning scan with bin packing, max size: 29208501 bytes, open cost is considered as scanning 4194304 bytes.
26/01/12 03:03:54 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 03:03:54 INFO DAGScheduler: Got job 343 (parquet at <unknown>:0) with 2 output partitions
26/01/12 03:03:54 INFO DAGScheduler: Final stage: ResultStage 343 (parquet at <unknown>:0)
26/01/12 03:03:54 INFO DAGScheduler: Parents of final stage: List()
26/01/12 03:03:54 INFO DAGScheduler: Missing parents: List()
26/01/12 03:03:54 INFO DAGScheduler: Submitting ResultStage 343 (MapPartitionsRDD[859] at parquet at <unknown>:0), which has no missing parents
26/01/12 03:03:54 INFO MemoryStore: Block broadcast_515 stored as values in memory (estimated size 225.1 KiB, free 364.2 MiB)
26/01/12 03:03:54 INFO MemoryStore: Block broadcast_515_piece0 stored as bytes in memory (estimated size 77.5 KiB, free 364.1 MiB)
26/01/12 03:03:54 INFO BlockManagerInfo: Added broadcast_515_piece0 in memory on 02926ee04bc9:45221 (size: 77.5 KiB, free: 365.9 MiB)
26/01/12 03:03:54 INFO SparkContext: Created broadcast 515 from broadcast at DAGScheduler.scala:1513
26/01/12 03:03:54 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 343 (MapPartitionsRDD[859] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1))
26/01/12 03:03:54 INFO TaskSchedulerImpl: Adding task set 343.0 with 2 tasks resource profile 0
26/01/12 03:03:54 INFO TaskSetManager: Starting task 0.0 in stage 343.0 (TID 561) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 03:03:54 INFO TaskSetManager: Starting task 1.0 in stage 343.0 (TID 562) (172.18.0.5, executor 0, partition 1, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 03:03:54 INFO BlockManagerInfo: Added broadcast_515_piece0 in memory on 172.18.0.5:42453 (size: 77.5 KiB, free: 366.0 MiB)
26/01/12 03:03:54 INFO BlockManagerInfo: Added broadcast_514_piece0 in memory on 172.18.0.5:42453 (size: 35.3 KiB, free: 365.9 MiB)
26/01/12 03:03:54 INFO TaskSetManager: Finished task 1.0 in stage 343.0 (TID 562) in 53 ms on 172.18.0.5 (executor 0) (1/2)
26/01/12 03:04:03 INFO TaskSetManager: Finished task 0.0 in stage 343.0 (TID 561) in 8780 ms on 172.18.0.5 (executor 0) (2/2)
26/01/12 03:04:03 INFO TaskSchedulerImpl: Removed TaskSet 343.0, whose tasks have all completed, from pool 
26/01/12 03:04:03 INFO DAGScheduler: ResultStage 343 (parquet at <unknown>:0) finished in 8.797 s
26/01/12 03:04:03 INFO DAGScheduler: Job 343 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 03:04:03 INFO TaskSchedulerImpl: Killing all running tasks in stage 343: Stage finished
26/01/12 03:04:03 INFO DAGScheduler: Job 343 finished: parquet at <unknown>:0, took 8.803370 s
26/01/12 03:04:03 INFO FileFormatWriter: Start to commit write Job 5f2841d5-ff41-4b8a-b440-eb8c9d716b85.
26/01/12 03:04:03 INFO FileFormatWriter: Write Job 5f2841d5-ff41-4b8a-b440-eb8c9d716b85 committed. Elapsed time: 23 ms.
26/01/12 03:04:03 INFO FileFormatWriter: Finished processing stats for write job 5f2841d5-ff41-4b8a-b440-eb8c9d716b85.
Cargando: yellow_tripdata_2023-05.parquet en hdfs://hadoop-namenode:8020/data/nyc/raw/taxi-trips/2023...
26/01/12 03:04:03 INFO InMemoryFileIndex: It took 7 ms to list leaf files for 1 paths.
26/01/12 03:04:03 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 03:04:03 INFO DAGScheduler: Got job 344 (parquet at <unknown>:0) with 1 output partitions
26/01/12 03:04:03 INFO DAGScheduler: Final stage: ResultStage 344 (parquet at <unknown>:0)
26/01/12 03:04:03 INFO DAGScheduler: Parents of final stage: List()
26/01/12 03:04:03 INFO DAGScheduler: Missing parents: List()
26/01/12 03:04:03 INFO DAGScheduler: Submitting ResultStage 344 (MapPartitionsRDD[861] at parquet at <unknown>:0), which has no missing parents
26/01/12 03:04:03 INFO MemoryStore: Block broadcast_516 stored as values in memory (estimated size 102.6 KiB, free 364.0 MiB)
26/01/12 03:04:03 INFO MemoryStore: Block broadcast_516_piece0 stored as bytes in memory (estimated size 36.8 KiB, free 364.0 MiB)
26/01/12 03:04:03 INFO BlockManagerInfo: Added broadcast_516_piece0 in memory on 02926ee04bc9:45221 (size: 36.8 KiB, free: 365.9 MiB)
26/01/12 03:04:03 INFO SparkContext: Created broadcast 516 from broadcast at DAGScheduler.scala:1513
26/01/12 03:04:03 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 344 (MapPartitionsRDD[861] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0))
26/01/12 03:04:03 INFO TaskSchedulerImpl: Adding task set 344.0 with 1 tasks resource profile 0
26/01/12 03:04:03 INFO TaskSetManager: Starting task 0.0 in stage 344.0 (TID 563) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4607 bytes) taskResourceAssignments Map()
26/01/12 03:04:03 INFO BlockManagerInfo: Added broadcast_516_piece0 in memory on 172.18.0.5:42453 (size: 36.8 KiB, free: 365.9 MiB)
26/01/12 03:04:03 INFO TaskSetManager: Finished task 0.0 in stage 344.0 (TID 563) in 44 ms on 172.18.0.5 (executor 0) (1/1)
26/01/12 03:04:03 INFO TaskSchedulerImpl: Removed TaskSet 344.0, whose tasks have all completed, from pool 
26/01/12 03:04:03 INFO DAGScheduler: ResultStage 344 (parquet at <unknown>:0) finished in 0.055 s
26/01/12 03:04:03 INFO DAGScheduler: Job 344 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 03:04:03 INFO TaskSchedulerImpl: Killing all running tasks in stage 344: Stage finished
26/01/12 03:04:03 INFO DAGScheduler: Job 344 finished: parquet at <unknown>:0, took 0.057904 s
26/01/12 03:04:03 INFO FileSourceStrategy: Pushed Filters: 
26/01/12 03:04:03 INFO FileSourceStrategy: Post-Scan Filters: 
26/01/12 03:04:03 INFO FileSourceStrategy: Output Data Schema: struct<VendorID: int, tpep_pickup_datetime: timestamp, tpep_dropoff_datetime: timestamp, passenger_count: bigint, trip_distance: double ... 17 more fields>
26/01/12 03:04:03 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 03:04:03 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 03:04:03 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 03:04:03 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 03:04:03 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 03:04:03 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 03:04:03 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 03:04:03 INFO MemoryStore: Block broadcast_517 stored as values in memory (estimated size 358.5 KiB, free 363.6 MiB)
26/01/12 03:04:03 INFO MemoryStore: Block broadcast_517_piece0 stored as bytes in memory (estimated size 35.3 KiB, free 363.6 MiB)
26/01/12 03:04:03 INFO BlockManagerInfo: Added broadcast_517_piece0 in memory on 02926ee04bc9:45221 (size: 35.3 KiB, free: 365.9 MiB)
26/01/12 03:04:03 INFO SparkContext: Created broadcast 517 from parquet at <unknown>:0
26/01/12 03:04:03 INFO FileSourceScanExec: Planning scan with bin packing, max size: 31424465 bytes, open cost is considered as scanning 4194304 bytes.
26/01/12 03:04:03 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 03:04:03 INFO DAGScheduler: Got job 345 (parquet at <unknown>:0) with 2 output partitions
26/01/12 03:04:03 INFO DAGScheduler: Final stage: ResultStage 345 (parquet at <unknown>:0)
26/01/12 03:04:03 INFO DAGScheduler: Parents of final stage: List()
26/01/12 03:04:03 INFO DAGScheduler: Missing parents: List()
26/01/12 03:04:03 INFO BlockManagerInfo: Removed broadcast_513_piece0 on 02926ee04bc9:45221 in memory (size: 36.8 KiB, free: 365.9 MiB)
26/01/12 03:04:03 INFO DAGScheduler: Submitting ResultStage 345 (MapPartitionsRDD[864] at parquet at <unknown>:0), which has no missing parents
26/01/12 03:04:03 INFO BlockManagerInfo: Removed broadcast_513_piece0 on 172.18.0.5:42453 in memory (size: 36.8 KiB, free: 365.9 MiB)
26/01/12 03:04:03 INFO BlockManagerInfo: Removed broadcast_514_piece0 on 02926ee04bc9:45221 in memory (size: 35.3 KiB, free: 365.9 MiB)
26/01/12 03:04:03 INFO BlockManagerInfo: Removed broadcast_514_piece0 on 172.18.0.5:42453 in memory (size: 35.3 KiB, free: 366.0 MiB)
26/01/12 03:04:03 INFO BlockManagerInfo: Removed broadcast_515_piece0 on 02926ee04bc9:45221 in memory (size: 77.5 KiB, free: 366.0 MiB)
26/01/12 03:04:03 INFO BlockManagerInfo: Removed broadcast_515_piece0 on 172.18.0.5:42453 in memory (size: 77.5 KiB, free: 366.0 MiB)
26/01/12 03:04:03 INFO MemoryStore: Block broadcast_518 stored as values in memory (estimated size 225.1 KiB, free 364.2 MiB)
26/01/12 03:04:03 INFO MemoryStore: Block broadcast_518_piece0 stored as bytes in memory (estimated size 77.5 KiB, free 364.1 MiB)
26/01/12 03:04:03 INFO BlockManagerInfo: Added broadcast_518_piece0 in memory on 02926ee04bc9:45221 (size: 77.5 KiB, free: 365.9 MiB)
26/01/12 03:04:03 INFO SparkContext: Created broadcast 518 from broadcast at DAGScheduler.scala:1513
26/01/12 03:04:03 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 345 (MapPartitionsRDD[864] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1))
26/01/12 03:04:03 INFO TaskSchedulerImpl: Adding task set 345.0 with 2 tasks resource profile 0
26/01/12 03:04:03 INFO BlockManagerInfo: Removed broadcast_512_piece0 on 02926ee04bc9:45221 in memory (size: 77.5 KiB, free: 366.0 MiB)
26/01/12 03:04:03 INFO TaskSetManager: Starting task 0.0 in stage 345.0 (TID 564) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 03:04:03 INFO BlockManagerInfo: Removed broadcast_512_piece0 on 172.18.0.5:42453 in memory (size: 77.5 KiB, free: 366.1 MiB)
26/01/12 03:04:03 INFO TaskSetManager: Starting task 1.0 in stage 345.0 (TID 565) (172.18.0.5, executor 0, partition 1, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 03:04:03 INFO BlockManagerInfo: Removed broadcast_516_piece0 on 02926ee04bc9:45221 in memory (size: 36.8 KiB, free: 366.0 MiB)
26/01/12 03:04:03 INFO BlockManagerInfo: Removed broadcast_516_piece0 on 172.18.0.5:42453 in memory (size: 36.8 KiB, free: 366.2 MiB)
26/01/12 03:04:03 INFO BlockManagerInfo: Added broadcast_518_piece0 in memory on 172.18.0.5:42453 (size: 77.5 KiB, free: 366.1 MiB)
26/01/12 03:04:03 INFO BlockManagerInfo: Removed broadcast_511_piece0 on 02926ee04bc9:45221 in memory (size: 35.3 KiB, free: 366.1 MiB)
26/01/12 03:04:03 INFO BlockManagerInfo: Removed broadcast_511_piece0 on 172.18.0.5:42453 in memory (size: 35.3 KiB, free: 366.1 MiB)
26/01/12 03:04:03 INFO BlockManagerInfo: Added broadcast_517_piece0 in memory on 172.18.0.5:42453 (size: 35.3 KiB, free: 366.1 MiB)
26/01/12 03:04:03 INFO TaskSetManager: Finished task 1.0 in stage 345.0 (TID 565) in 52 ms on 172.18.0.5 (executor 0) (1/2)
26/01/12 03:04:12 INFO TaskSetManager: Finished task 0.0 in stage 345.0 (TID 564) in 9105 ms on 172.18.0.5 (executor 0) (2/2)
26/01/12 03:04:12 INFO TaskSchedulerImpl: Removed TaskSet 345.0, whose tasks have all completed, from pool 
26/01/12 03:04:12 INFO DAGScheduler: ResultStage 345 (parquet at <unknown>:0) finished in 9.127 s
26/01/12 03:04:12 INFO DAGScheduler: Job 345 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 03:04:12 INFO TaskSchedulerImpl: Killing all running tasks in stage 345: Stage finished
26/01/12 03:04:12 INFO DAGScheduler: Job 345 finished: parquet at <unknown>:0, took 9.134015 s
26/01/12 03:04:12 INFO FileFormatWriter: Start to commit write Job 9313587d-acfb-4330-ba29-917d834a05c5.
26/01/12 03:04:12 INFO FileFormatWriter: Write Job 9313587d-acfb-4330-ba29-917d834a05c5 committed. Elapsed time: 22 ms.
26/01/12 03:04:12 INFO FileFormatWriter: Finished processing stats for write job 9313587d-acfb-4330-ba29-917d834a05c5.
Cargando: yellow_tripdata_2023-06.parquet en hdfs://hadoop-namenode:8020/data/nyc/raw/taxi-trips/2023...
26/01/12 03:04:12 INFO InMemoryFileIndex: It took 6 ms to list leaf files for 1 paths.
26/01/12 03:04:12 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 03:04:12 INFO DAGScheduler: Got job 346 (parquet at <unknown>:0) with 1 output partitions
26/01/12 03:04:12 INFO DAGScheduler: Final stage: ResultStage 346 (parquet at <unknown>:0)
26/01/12 03:04:12 INFO DAGScheduler: Parents of final stage: List()
26/01/12 03:04:12 INFO DAGScheduler: Missing parents: List()
26/01/12 03:04:12 INFO DAGScheduler: Submitting ResultStage 346 (MapPartitionsRDD[866] at parquet at <unknown>:0), which has no missing parents
26/01/12 03:04:12 INFO MemoryStore: Block broadcast_519 stored as values in memory (estimated size 102.6 KiB, free 364.8 MiB)
26/01/12 03:04:12 INFO MemoryStore: Block broadcast_519_piece0 stored as bytes in memory (estimated size 36.8 KiB, free 364.8 MiB)
26/01/12 03:04:12 INFO BlockManagerInfo: Added broadcast_519_piece0 in memory on 02926ee04bc9:45221 (size: 36.8 KiB, free: 366.0 MiB)
26/01/12 03:04:12 INFO SparkContext: Created broadcast 519 from broadcast at DAGScheduler.scala:1513
26/01/12 03:04:12 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 346 (MapPartitionsRDD[866] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0))
26/01/12 03:04:12 INFO TaskSchedulerImpl: Adding task set 346.0 with 1 tasks resource profile 0
26/01/12 03:04:12 INFO TaskSetManager: Starting task 0.0 in stage 346.0 (TID 566) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4607 bytes) taskResourceAssignments Map()
26/01/12 03:04:12 INFO BlockManagerInfo: Added broadcast_519_piece0 in memory on 172.18.0.5:42453 (size: 36.8 KiB, free: 366.0 MiB)
26/01/12 03:04:12 INFO TaskSetManager: Finished task 0.0 in stage 346.0 (TID 566) in 42 ms on 172.18.0.5 (executor 0) (1/1)
26/01/12 03:04:12 INFO TaskSchedulerImpl: Removed TaskSet 346.0, whose tasks have all completed, from pool 
26/01/12 03:04:12 INFO DAGScheduler: ResultStage 346 (parquet at <unknown>:0) finished in 0.055 s
26/01/12 03:04:12 INFO DAGScheduler: Job 346 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 03:04:12 INFO TaskSchedulerImpl: Killing all running tasks in stage 346: Stage finished
26/01/12 03:04:12 INFO DAGScheduler: Job 346 finished: parquet at <unknown>:0, took 0.057650 s
26/01/12 03:04:12 INFO FileSourceStrategy: Pushed Filters: 
26/01/12 03:04:12 INFO FileSourceStrategy: Post-Scan Filters: 
26/01/12 03:04:12 INFO FileSourceStrategy: Output Data Schema: struct<VendorID: int, tpep_pickup_datetime: timestamp, tpep_dropoff_datetime: timestamp, passenger_count: bigint, trip_distance: double ... 17 more fields>
26/01/12 03:04:12 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 03:04:12 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 03:04:12 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 03:04:12 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 03:04:12 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 03:04:12 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 03:04:12 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 03:04:12 INFO MemoryStore: Block broadcast_520 stored as values in memory (estimated size 358.5 KiB, free 364.5 MiB)
26/01/12 03:04:12 INFO MemoryStore: Block broadcast_520_piece0 stored as bytes in memory (estimated size 35.3 KiB, free 364.4 MiB)
26/01/12 03:04:12 INFO BlockManagerInfo: Added broadcast_520_piece0 in memory on 02926ee04bc9:45221 (size: 35.3 KiB, free: 366.0 MiB)
26/01/12 03:04:12 INFO SparkContext: Created broadcast 520 from parquet at <unknown>:0
26/01/12 03:04:12 INFO FileSourceScanExec: Planning scan with bin packing, max size: 29596884 bytes, open cost is considered as scanning 4194304 bytes.
26/01/12 03:04:12 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 03:04:12 INFO DAGScheduler: Got job 347 (parquet at <unknown>:0) with 2 output partitions
26/01/12 03:04:12 INFO DAGScheduler: Final stage: ResultStage 347 (parquet at <unknown>:0)
26/01/12 03:04:12 INFO DAGScheduler: Parents of final stage: List()
26/01/12 03:04:12 INFO DAGScheduler: Missing parents: List()
26/01/12 03:04:12 INFO DAGScheduler: Submitting ResultStage 347 (MapPartitionsRDD[869] at parquet at <unknown>:0), which has no missing parents
26/01/12 03:04:12 INFO MemoryStore: Block broadcast_521 stored as values in memory (estimated size 225.1 KiB, free 364.2 MiB)
26/01/12 03:04:12 INFO MemoryStore: Block broadcast_521_piece0 stored as bytes in memory (estimated size 77.5 KiB, free 364.1 MiB)
26/01/12 03:04:12 INFO BlockManagerInfo: Added broadcast_521_piece0 in memory on 02926ee04bc9:45221 (size: 77.5 KiB, free: 365.9 MiB)
26/01/12 03:04:12 INFO SparkContext: Created broadcast 521 from broadcast at DAGScheduler.scala:1513
26/01/12 03:04:12 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 347 (MapPartitionsRDD[869] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1))
26/01/12 03:04:12 INFO TaskSchedulerImpl: Adding task set 347.0 with 2 tasks resource profile 0
26/01/12 03:04:12 INFO TaskSetManager: Starting task 0.0 in stage 347.0 (TID 567) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 03:04:12 INFO TaskSetManager: Starting task 1.0 in stage 347.0 (TID 568) (172.18.0.5, executor 0, partition 1, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 03:04:12 INFO BlockManagerInfo: Added broadcast_521_piece0 in memory on 172.18.0.5:42453 (size: 77.5 KiB, free: 366.0 MiB)
26/01/12 03:04:12 INFO BlockManagerInfo: Added broadcast_520_piece0 in memory on 172.18.0.5:42453 (size: 35.3 KiB, free: 365.9 MiB)
26/01/12 03:04:12 INFO TaskSetManager: Finished task 1.0 in stage 347.0 (TID 568) in 51 ms on 172.18.0.5 (executor 0) (1/2)
26/01/12 03:04:21 INFO TaskSetManager: Finished task 0.0 in stage 347.0 (TID 567) in 8810 ms on 172.18.0.5 (executor 0) (2/2)
26/01/12 03:04:21 INFO TaskSchedulerImpl: Removed TaskSet 347.0, whose tasks have all completed, from pool 
26/01/12 03:04:21 INFO DAGScheduler: ResultStage 347 (parquet at <unknown>:0) finished in 8.826 s
26/01/12 03:04:21 INFO DAGScheduler: Job 347 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 03:04:21 INFO TaskSchedulerImpl: Killing all running tasks in stage 347: Stage finished
26/01/12 03:04:21 INFO DAGScheduler: Job 347 finished: parquet at <unknown>:0, took 8.830527 s
26/01/12 03:04:21 INFO FileFormatWriter: Start to commit write Job f1b7be69-7a0b-43f8-9580-dac742bb5313.
26/01/12 03:04:21 INFO FileFormatWriter: Write Job f1b7be69-7a0b-43f8-9580-dac742bb5313 committed. Elapsed time: 23 ms.
26/01/12 03:04:21 INFO FileFormatWriter: Finished processing stats for write job f1b7be69-7a0b-43f8-9580-dac742bb5313.
Cargando: yellow_tripdata_2023-07.parquet en hdfs://hadoop-namenode:8020/data/nyc/raw/taxi-trips/2023...
26/01/12 03:04:21 INFO InMemoryFileIndex: It took 6 ms to list leaf files for 1 paths.
26/01/12 03:04:21 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 03:04:21 INFO DAGScheduler: Got job 348 (parquet at <unknown>:0) with 1 output partitions
26/01/12 03:04:21 INFO DAGScheduler: Final stage: ResultStage 348 (parquet at <unknown>:0)
26/01/12 03:04:21 INFO DAGScheduler: Parents of final stage: List()
26/01/12 03:04:21 INFO DAGScheduler: Missing parents: List()
26/01/12 03:04:21 INFO DAGScheduler: Submitting ResultStage 348 (MapPartitionsRDD[871] at parquet at <unknown>:0), which has no missing parents
26/01/12 03:04:21 INFO MemoryStore: Block broadcast_522 stored as values in memory (estimated size 102.6 KiB, free 364.0 MiB)
26/01/12 03:04:21 INFO MemoryStore: Block broadcast_522_piece0 stored as bytes in memory (estimated size 36.8 KiB, free 364.0 MiB)
26/01/12 03:04:21 INFO BlockManagerInfo: Added broadcast_522_piece0 in memory on 02926ee04bc9:45221 (size: 36.8 KiB, free: 365.9 MiB)
26/01/12 03:04:21 INFO SparkContext: Created broadcast 522 from broadcast at DAGScheduler.scala:1513
26/01/12 03:04:21 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 348 (MapPartitionsRDD[871] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0))
26/01/12 03:04:21 INFO TaskSchedulerImpl: Adding task set 348.0 with 1 tasks resource profile 0
26/01/12 03:04:21 INFO TaskSetManager: Starting task 0.0 in stage 348.0 (TID 569) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4607 bytes) taskResourceAssignments Map()
26/01/12 03:04:21 INFO BlockManagerInfo: Added broadcast_522_piece0 in memory on 172.18.0.5:42453 (size: 36.8 KiB, free: 365.9 MiB)
26/01/12 03:04:21 INFO TaskSetManager: Finished task 0.0 in stage 348.0 (TID 569) in 43 ms on 172.18.0.5 (executor 0) (1/1)
26/01/12 03:04:21 INFO TaskSchedulerImpl: Removed TaskSet 348.0, whose tasks have all completed, from pool 
26/01/12 03:04:21 INFO DAGScheduler: ResultStage 348 (parquet at <unknown>:0) finished in 0.057 s
26/01/12 03:04:21 INFO DAGScheduler: Job 348 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 03:04:21 INFO TaskSchedulerImpl: Killing all running tasks in stage 348: Stage finished
26/01/12 03:04:21 INFO DAGScheduler: Job 348 finished: parquet at <unknown>:0, took 0.060035 s
26/01/12 03:04:21 INFO FileSourceStrategy: Pushed Filters: 
26/01/12 03:04:21 INFO FileSourceStrategy: Post-Scan Filters: 
26/01/12 03:04:21 INFO FileSourceStrategy: Output Data Schema: struct<VendorID: int, tpep_pickup_datetime: timestamp, tpep_dropoff_datetime: timestamp, passenger_count: bigint, trip_distance: double ... 17 more fields>
26/01/12 03:04:21 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 03:04:21 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 03:04:21 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 03:04:21 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 03:04:21 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 03:04:21 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 03:04:21 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 03:04:21 INFO MemoryStore: Block broadcast_523 stored as values in memory (estimated size 358.5 KiB, free 363.6 MiB)
26/01/12 03:04:21 INFO MemoryStore: Block broadcast_523_piece0 stored as bytes in memory (estimated size 35.3 KiB, free 363.6 MiB)
26/01/12 03:04:21 INFO BlockManagerInfo: Added broadcast_523_piece0 in memory on 02926ee04bc9:45221 (size: 35.3 KiB, free: 365.9 MiB)
26/01/12 03:04:21 INFO SparkContext: Created broadcast 523 from parquet at <unknown>:0
26/01/12 03:04:21 INFO FileSourceScanExec: Planning scan with bin packing, max size: 26278066 bytes, open cost is considered as scanning 4194304 bytes.
26/01/12 03:04:21 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 03:04:21 INFO DAGScheduler: Got job 349 (parquet at <unknown>:0) with 2 output partitions
26/01/12 03:04:21 INFO DAGScheduler: Final stage: ResultStage 349 (parquet at <unknown>:0)
26/01/12 03:04:21 INFO DAGScheduler: Parents of final stage: List()
26/01/12 03:04:21 INFO DAGScheduler: Missing parents: List()
26/01/12 03:04:21 INFO DAGScheduler: Submitting ResultStage 349 (MapPartitionsRDD[874] at parquet at <unknown>:0), which has no missing parents
26/01/12 03:04:21 INFO MemoryStore: Block broadcast_524 stored as values in memory (estimated size 225.1 KiB, free 363.4 MiB)
26/01/12 03:04:21 INFO MemoryStore: Block broadcast_524_piece0 stored as bytes in memory (estimated size 77.5 KiB, free 363.3 MiB)
26/01/12 03:04:21 INFO BlockManagerInfo: Added broadcast_524_piece0 in memory on 02926ee04bc9:45221 (size: 77.5 KiB, free: 365.8 MiB)
26/01/12 03:04:21 INFO SparkContext: Created broadcast 524 from broadcast at DAGScheduler.scala:1513
26/01/12 03:04:21 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 349 (MapPartitionsRDD[874] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1))
26/01/12 03:04:21 INFO TaskSchedulerImpl: Adding task set 349.0 with 2 tasks resource profile 0
26/01/12 03:04:21 INFO TaskSetManager: Starting task 0.0 in stage 349.0 (TID 570) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 03:04:21 INFO TaskSetManager: Starting task 1.0 in stage 349.0 (TID 571) (172.18.0.5, executor 0, partition 1, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 03:04:21 INFO BlockManagerInfo: Removed broadcast_520_piece0 on 02926ee04bc9:45221 in memory (size: 35.3 KiB, free: 365.8 MiB)
26/01/12 03:04:21 INFO BlockManagerInfo: Removed broadcast_520_piece0 on 172.18.0.5:42453 in memory (size: 35.3 KiB, free: 365.9 MiB)
26/01/12 03:04:21 INFO BlockManagerInfo: Removed broadcast_519_piece0 on 02926ee04bc9:45221 in memory (size: 36.8 KiB, free: 365.9 MiB)
26/01/12 03:04:21 INFO BlockManagerInfo: Added broadcast_524_piece0 in memory on 172.18.0.5:42453 (size: 77.5 KiB, free: 365.9 MiB)
26/01/12 03:04:21 INFO BlockManagerInfo: Removed broadcast_519_piece0 on 172.18.0.5:42453 in memory (size: 36.8 KiB, free: 365.9 MiB)
26/01/12 03:04:21 INFO BlockManagerInfo: Removed broadcast_517_piece0 on 02926ee04bc9:45221 in memory (size: 35.3 KiB, free: 365.9 MiB)
26/01/12 03:04:21 INFO BlockManagerInfo: Removed broadcast_517_piece0 on 172.18.0.5:42453 in memory (size: 35.3 KiB, free: 365.9 MiB)
26/01/12 03:04:21 INFO BlockManagerInfo: Removed broadcast_522_piece0 on 02926ee04bc9:45221 in memory (size: 36.8 KiB, free: 365.9 MiB)
26/01/12 03:04:21 INFO BlockManagerInfo: Removed broadcast_522_piece0 on 172.18.0.5:42453 in memory (size: 36.8 KiB, free: 366.0 MiB)
26/01/12 03:04:21 INFO BlockManagerInfo: Added broadcast_523_piece0 in memory on 172.18.0.5:42453 (size: 35.3 KiB, free: 365.9 MiB)
26/01/12 03:04:21 INFO BlockManagerInfo: Removed broadcast_521_piece0 on 02926ee04bc9:45221 in memory (size: 77.5 KiB, free: 366.0 MiB)
26/01/12 03:04:21 INFO BlockManagerInfo: Removed broadcast_521_piece0 on 172.18.0.5:42453 in memory (size: 77.5 KiB, free: 366.0 MiB)
26/01/12 03:04:21 INFO BlockManagerInfo: Removed broadcast_518_piece0 on 02926ee04bc9:45221 in memory (size: 77.5 KiB, free: 366.1 MiB)
26/01/12 03:04:21 INFO BlockManagerInfo: Removed broadcast_518_piece0 on 172.18.0.5:42453 in memory (size: 77.5 KiB, free: 366.1 MiB)
26/01/12 03:04:21 INFO TaskSetManager: Finished task 1.0 in stage 349.0 (TID 571) in 68 ms on 172.18.0.5 (executor 0) (1/2)
26/01/12 03:04:29 INFO TaskSetManager: Finished task 0.0 in stage 349.0 (TID 570) in 7682 ms on 172.18.0.5 (executor 0) (2/2)
26/01/12 03:04:29 INFO TaskSchedulerImpl: Removed TaskSet 349.0, whose tasks have all completed, from pool 
26/01/12 03:04:29 INFO DAGScheduler: ResultStage 349 (parquet at <unknown>:0) finished in 7.713 s
26/01/12 03:04:29 INFO DAGScheduler: Job 349 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 03:04:29 INFO TaskSchedulerImpl: Killing all running tasks in stage 349: Stage finished
26/01/12 03:04:29 INFO DAGScheduler: Job 349 finished: parquet at <unknown>:0, took 7.717134 s
26/01/12 03:04:29 INFO FileFormatWriter: Start to commit write Job e5aabd5b-5b14-42d6-94cd-acf514f9a75d.
26/01/12 03:04:29 INFO FileFormatWriter: Write Job e5aabd5b-5b14-42d6-94cd-acf514f9a75d committed. Elapsed time: 25 ms.
26/01/12 03:04:29 INFO FileFormatWriter: Finished processing stats for write job e5aabd5b-5b14-42d6-94cd-acf514f9a75d.
Cargando: yellow_tripdata_2023-08.parquet en hdfs://hadoop-namenode:8020/data/nyc/raw/taxi-trips/2023...
26/01/12 03:04:29 INFO InMemoryFileIndex: It took 8 ms to list leaf files for 1 paths.
26/01/12 03:04:29 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 03:04:29 INFO DAGScheduler: Got job 350 (parquet at <unknown>:0) with 1 output partitions
26/01/12 03:04:29 INFO DAGScheduler: Final stage: ResultStage 350 (parquet at <unknown>:0)
26/01/12 03:04:29 INFO DAGScheduler: Parents of final stage: List()
26/01/12 03:04:29 INFO DAGScheduler: Missing parents: List()
26/01/12 03:04:29 INFO DAGScheduler: Submitting ResultStage 350 (MapPartitionsRDD[876] at parquet at <unknown>:0), which has no missing parents
26/01/12 03:04:29 INFO MemoryStore: Block broadcast_525 stored as values in memory (estimated size 102.6 KiB, free 364.8 MiB)
26/01/12 03:04:29 INFO MemoryStore: Block broadcast_525_piece0 stored as bytes in memory (estimated size 36.8 KiB, free 364.8 MiB)
26/01/12 03:04:29 INFO BlockManagerInfo: Added broadcast_525_piece0 in memory on 02926ee04bc9:45221 (size: 36.8 KiB, free: 366.0 MiB)
26/01/12 03:04:29 INFO SparkContext: Created broadcast 525 from broadcast at DAGScheduler.scala:1513
26/01/12 03:04:29 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 350 (MapPartitionsRDD[876] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0))
26/01/12 03:04:29 INFO TaskSchedulerImpl: Adding task set 350.0 with 1 tasks resource profile 0
26/01/12 03:04:29 INFO TaskSetManager: Starting task 0.0 in stage 350.0 (TID 572) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4607 bytes) taskResourceAssignments Map()
26/01/12 03:04:29 INFO BlockManagerInfo: Added broadcast_525_piece0 in memory on 172.18.0.5:42453 (size: 36.8 KiB, free: 366.0 MiB)
26/01/12 03:04:29 INFO TaskSetManager: Finished task 0.0 in stage 350.0 (TID 572) in 46 ms on 172.18.0.5 (executor 0) (1/1)
26/01/12 03:04:29 INFO TaskSchedulerImpl: Removed TaskSet 350.0, whose tasks have all completed, from pool 
26/01/12 03:04:29 INFO DAGScheduler: ResultStage 350 (parquet at <unknown>:0) finished in 0.057 s
26/01/12 03:04:29 INFO DAGScheduler: Job 350 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 03:04:29 INFO TaskSchedulerImpl: Killing all running tasks in stage 350: Stage finished
26/01/12 03:04:29 INFO DAGScheduler: Job 350 finished: parquet at <unknown>:0, took 0.059930 s
26/01/12 03:04:29 INFO FileSourceStrategy: Pushed Filters: 
26/01/12 03:04:29 INFO FileSourceStrategy: Post-Scan Filters: 
26/01/12 03:04:29 INFO FileSourceStrategy: Output Data Schema: struct<VendorID: int, tpep_pickup_datetime: timestamp, tpep_dropoff_datetime: timestamp, passenger_count: bigint, trip_distance: double ... 17 more fields>
26/01/12 03:04:29 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 03:04:29 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 03:04:29 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 03:04:29 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 03:04:29 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 03:04:29 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 03:04:29 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 03:04:29 INFO MemoryStore: Block broadcast_526 stored as values in memory (estimated size 358.5 KiB, free 364.5 MiB)
26/01/12 03:04:29 INFO MemoryStore: Block broadcast_526_piece0 stored as bytes in memory (estimated size 35.3 KiB, free 364.4 MiB)
26/01/12 03:04:29 INFO BlockManagerInfo: Added broadcast_526_piece0 in memory on 02926ee04bc9:45221 (size: 35.3 KiB, free: 366.0 MiB)
26/01/12 03:04:29 INFO SparkContext: Created broadcast 526 from parquet at <unknown>:0
26/01/12 03:04:29 INFO FileSourceScanExec: Planning scan with bin packing, max size: 26173328 bytes, open cost is considered as scanning 4194304 bytes.
26/01/12 03:04:29 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 03:04:29 INFO DAGScheduler: Got job 351 (parquet at <unknown>:0) with 2 output partitions
26/01/12 03:04:29 INFO DAGScheduler: Final stage: ResultStage 351 (parquet at <unknown>:0)
26/01/12 03:04:29 INFO DAGScheduler: Parents of final stage: List()
26/01/12 03:04:29 INFO DAGScheduler: Missing parents: List()
26/01/12 03:04:29 INFO DAGScheduler: Submitting ResultStage 351 (MapPartitionsRDD[879] at parquet at <unknown>:0), which has no missing parents
26/01/12 03:04:29 INFO MemoryStore: Block broadcast_527 stored as values in memory (estimated size 225.1 KiB, free 364.2 MiB)
26/01/12 03:04:29 INFO MemoryStore: Block broadcast_527_piece0 stored as bytes in memory (estimated size 77.5 KiB, free 364.1 MiB)
26/01/12 03:04:29 INFO BlockManagerInfo: Added broadcast_527_piece0 in memory on 02926ee04bc9:45221 (size: 77.5 KiB, free: 365.9 MiB)
26/01/12 03:04:29 INFO SparkContext: Created broadcast 527 from broadcast at DAGScheduler.scala:1513
26/01/12 03:04:29 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 351 (MapPartitionsRDD[879] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1))
26/01/12 03:04:29 INFO TaskSchedulerImpl: Adding task set 351.0 with 2 tasks resource profile 0
26/01/12 03:04:29 INFO TaskSetManager: Starting task 0.0 in stage 351.0 (TID 573) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 03:04:29 INFO TaskSetManager: Starting task 1.0 in stage 351.0 (TID 574) (172.18.0.5, executor 0, partition 1, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 03:04:29 INFO BlockManagerInfo: Added broadcast_527_piece0 in memory on 172.18.0.5:42453 (size: 77.5 KiB, free: 366.0 MiB)
26/01/12 03:04:29 INFO BlockManagerInfo: Added broadcast_526_piece0 in memory on 172.18.0.5:42453 (size: 35.3 KiB, free: 365.9 MiB)
26/01/12 03:04:33 INFO TaskSetManager: Finished task 0.0 in stage 351.0 (TID 573) in 3611 ms on 172.18.0.5 (executor 0) (1/2)
26/01/12 03:04:35 INFO TaskSetManager: Finished task 1.0 in stage 351.0 (TID 574) in 5521 ms on 172.18.0.5 (executor 0) (2/2)
26/01/12 03:04:35 INFO TaskSchedulerImpl: Removed TaskSet 351.0, whose tasks have all completed, from pool 
26/01/12 03:04:35 INFO DAGScheduler: ResultStage 351 (parquet at <unknown>:0) finished in 5.538 s
26/01/12 03:04:35 INFO DAGScheduler: Job 351 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 03:04:35 INFO TaskSchedulerImpl: Killing all running tasks in stage 351: Stage finished
26/01/12 03:04:35 INFO DAGScheduler: Job 351 finished: parquet at <unknown>:0, took 5.544867 s
26/01/12 03:04:35 INFO FileFormatWriter: Start to commit write Job 376cc900-5350-422e-b2e3-a4d6874e3317.
26/01/12 03:04:35 INFO FileFormatWriter: Write Job 376cc900-5350-422e-b2e3-a4d6874e3317 committed. Elapsed time: 30 ms.
26/01/12 03:04:35 INFO FileFormatWriter: Finished processing stats for write job 376cc900-5350-422e-b2e3-a4d6874e3317.
Cargando: yellow_tripdata_2023-09.parquet en hdfs://hadoop-namenode:8020/data/nyc/raw/taxi-trips/2023...
26/01/12 03:04:35 INFO InMemoryFileIndex: It took 6 ms to list leaf files for 1 paths.
26/01/12 03:04:35 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 03:04:35 INFO DAGScheduler: Got job 352 (parquet at <unknown>:0) with 1 output partitions
26/01/12 03:04:35 INFO DAGScheduler: Final stage: ResultStage 352 (parquet at <unknown>:0)
26/01/12 03:04:35 INFO DAGScheduler: Parents of final stage: List()
26/01/12 03:04:35 INFO DAGScheduler: Missing parents: List()
26/01/12 03:04:35 INFO DAGScheduler: Submitting ResultStage 352 (MapPartitionsRDD[881] at parquet at <unknown>:0), which has no missing parents
26/01/12 03:04:35 INFO MemoryStore: Block broadcast_528 stored as values in memory (estimated size 102.6 KiB, free 364.0 MiB)
26/01/12 03:04:35 INFO MemoryStore: Block broadcast_528_piece0 stored as bytes in memory (estimated size 36.8 KiB, free 364.0 MiB)
26/01/12 03:04:35 INFO BlockManagerInfo: Added broadcast_528_piece0 in memory on 02926ee04bc9:45221 (size: 36.8 KiB, free: 365.9 MiB)
26/01/12 03:04:35 INFO SparkContext: Created broadcast 528 from broadcast at DAGScheduler.scala:1513
26/01/12 03:04:35 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 352 (MapPartitionsRDD[881] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0))
26/01/12 03:04:35 INFO TaskSchedulerImpl: Adding task set 352.0 with 1 tasks resource profile 0
26/01/12 03:04:35 INFO TaskSetManager: Starting task 0.0 in stage 352.0 (TID 575) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4607 bytes) taskResourceAssignments Map()
26/01/12 03:04:35 INFO BlockManagerInfo: Added broadcast_528_piece0 in memory on 172.18.0.5:42453 (size: 36.8 KiB, free: 365.9 MiB)
26/01/12 03:04:35 INFO TaskSetManager: Finished task 0.0 in stage 352.0 (TID 575) in 44 ms on 172.18.0.5 (executor 0) (1/1)
26/01/12 03:04:35 INFO TaskSchedulerImpl: Removed TaskSet 352.0, whose tasks have all completed, from pool 
26/01/12 03:04:35 INFO DAGScheduler: ResultStage 352 (parquet at <unknown>:0) finished in 0.054 s
26/01/12 03:04:35 INFO DAGScheduler: Job 352 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 03:04:35 INFO TaskSchedulerImpl: Killing all running tasks in stage 352: Stage finished
26/01/12 03:04:35 INFO DAGScheduler: Job 352 finished: parquet at <unknown>:0, took 0.057585 s
26/01/12 03:04:35 INFO FileSourceStrategy: Pushed Filters: 
26/01/12 03:04:35 INFO FileSourceStrategy: Post-Scan Filters: 
26/01/12 03:04:35 INFO FileSourceStrategy: Output Data Schema: struct<VendorID: int, tpep_pickup_datetime: timestamp, tpep_dropoff_datetime: timestamp, passenger_count: bigint, trip_distance: double ... 17 more fields>
26/01/12 03:04:35 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 03:04:35 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 03:04:35 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 03:04:35 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 03:04:35 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 03:04:35 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 03:04:35 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 03:04:35 INFO MemoryStore: Block broadcast_529 stored as values in memory (estimated size 358.5 KiB, free 363.6 MiB)
26/01/12 03:04:35 INFO MemoryStore: Block broadcast_529_piece0 stored as bytes in memory (estimated size 35.3 KiB, free 363.6 MiB)
26/01/12 03:04:35 INFO BlockManagerInfo: Added broadcast_529_piece0 in memory on 02926ee04bc9:45221 (size: 35.3 KiB, free: 365.9 MiB)
26/01/12 03:04:35 INFO SparkContext: Created broadcast 529 from parquet at <unknown>:0
26/01/12 03:04:35 INFO FileSourceScanExec: Planning scan with bin packing, max size: 26044909 bytes, open cost is considered as scanning 4194304 bytes.
26/01/12 03:04:35 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 03:04:35 INFO DAGScheduler: Got job 353 (parquet at <unknown>:0) with 2 output partitions
26/01/12 03:04:35 INFO DAGScheduler: Final stage: ResultStage 353 (parquet at <unknown>:0)
26/01/12 03:04:35 INFO DAGScheduler: Parents of final stage: List()
26/01/12 03:04:35 INFO DAGScheduler: Missing parents: List()
26/01/12 03:04:35 INFO DAGScheduler: Submitting ResultStage 353 (MapPartitionsRDD[884] at parquet at <unknown>:0), which has no missing parents
26/01/12 03:04:35 INFO MemoryStore: Block broadcast_530 stored as values in memory (estimated size 225.1 KiB, free 363.4 MiB)
26/01/12 03:04:35 INFO MemoryStore: Block broadcast_530_piece0 stored as bytes in memory (estimated size 77.5 KiB, free 363.3 MiB)
26/01/12 03:04:35 INFO BlockManagerInfo: Added broadcast_530_piece0 in memory on 02926ee04bc9:45221 (size: 77.5 KiB, free: 365.8 MiB)
26/01/12 03:04:35 INFO SparkContext: Created broadcast 530 from broadcast at DAGScheduler.scala:1513
26/01/12 03:04:35 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 353 (MapPartitionsRDD[884] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1))
26/01/12 03:04:35 INFO TaskSchedulerImpl: Adding task set 353.0 with 2 tasks resource profile 0
26/01/12 03:04:35 INFO TaskSetManager: Starting task 0.0 in stage 353.0 (TID 576) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 03:04:35 INFO TaskSetManager: Starting task 1.0 in stage 353.0 (TID 577) (172.18.0.5, executor 0, partition 1, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 03:04:35 INFO BlockManagerInfo: Added broadcast_530_piece0 in memory on 172.18.0.5:42453 (size: 77.5 KiB, free: 365.8 MiB)
26/01/12 03:04:35 INFO BlockManagerInfo: Added broadcast_529_piece0 in memory on 172.18.0.5:42453 (size: 35.3 KiB, free: 365.8 MiB)
26/01/12 03:04:38 INFO TaskSetManager: Finished task 0.0 in stage 353.0 (TID 576) in 3449 ms on 172.18.0.5 (executor 0) (1/2)
26/01/12 03:04:40 INFO TaskSetManager: Finished task 1.0 in stage 353.0 (TID 577) in 4739 ms on 172.18.0.5 (executor 0) (2/2)
26/01/12 03:04:40 INFO TaskSchedulerImpl: Removed TaskSet 353.0, whose tasks have all completed, from pool 
26/01/12 03:04:40 INFO DAGScheduler: ResultStage 353 (parquet at <unknown>:0) finished in 4.758 s
26/01/12 03:04:40 INFO DAGScheduler: Job 353 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 03:04:40 INFO TaskSchedulerImpl: Killing all running tasks in stage 353: Stage finished
26/01/12 03:04:40 INFO DAGScheduler: Job 353 finished: parquet at <unknown>:0, took 4.761744 s
26/01/12 03:04:40 INFO FileFormatWriter: Start to commit write Job 75efb791-5d01-4c77-9a7c-dcfd9859bd6c.
26/01/12 03:04:40 INFO FileFormatWriter: Write Job 75efb791-5d01-4c77-9a7c-dcfd9859bd6c committed. Elapsed time: 23 ms.
26/01/12 03:04:40 INFO FileFormatWriter: Finished processing stats for write job 75efb791-5d01-4c77-9a7c-dcfd9859bd6c.
Cargando: yellow_tripdata_2023-10.parquet en hdfs://hadoop-namenode:8020/data/nyc/raw/taxi-trips/2023...
26/01/12 03:04:40 INFO InMemoryFileIndex: It took 7 ms to list leaf files for 1 paths.
26/01/12 03:04:40 INFO BlockManagerInfo: Removed broadcast_523_piece0 on 172.18.0.5:42453 in memory (size: 35.3 KiB, free: 365.8 MiB)
26/01/12 03:04:40 INFO BlockManagerInfo: Removed broadcast_523_piece0 on 02926ee04bc9:45221 in memory (size: 35.3 KiB, free: 365.8 MiB)
26/01/12 03:04:40 INFO BlockManagerInfo: Removed broadcast_530_piece0 on 02926ee04bc9:45221 in memory (size: 77.5 KiB, free: 365.9 MiB)
26/01/12 03:04:40 INFO BlockManagerInfo: Removed broadcast_530_piece0 on 172.18.0.5:42453 in memory (size: 77.5 KiB, free: 365.9 MiB)
26/01/12 03:04:40 INFO BlockManagerInfo: Removed broadcast_528_piece0 on 02926ee04bc9:45221 in memory (size: 36.8 KiB, free: 365.9 MiB)
26/01/12 03:04:40 INFO BlockManagerInfo: Removed broadcast_528_piece0 on 172.18.0.5:42453 in memory (size: 36.8 KiB, free: 365.9 MiB)
26/01/12 03:04:40 INFO BlockManagerInfo: Removed broadcast_525_piece0 on 02926ee04bc9:45221 in memory (size: 36.8 KiB, free: 366.0 MiB)
26/01/12 03:04:40 INFO BlockManagerInfo: Removed broadcast_525_piece0 on 172.18.0.5:42453 in memory (size: 36.8 KiB, free: 366.0 MiB)
26/01/12 03:04:40 INFO BlockManagerInfo: Removed broadcast_524_piece0 on 02926ee04bc9:45221 in memory (size: 77.5 KiB, free: 366.0 MiB)
26/01/12 03:04:40 INFO BlockManagerInfo: Removed broadcast_524_piece0 on 172.18.0.5:42453 in memory (size: 77.5 KiB, free: 366.0 MiB)
26/01/12 03:04:40 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 03:04:40 INFO DAGScheduler: Got job 354 (parquet at <unknown>:0) with 1 output partitions
26/01/12 03:04:40 INFO DAGScheduler: Final stage: ResultStage 354 (parquet at <unknown>:0)
26/01/12 03:04:40 INFO DAGScheduler: Parents of final stage: List()
26/01/12 03:04:40 INFO DAGScheduler: Missing parents: List()
26/01/12 03:04:40 INFO DAGScheduler: Submitting ResultStage 354 (MapPartitionsRDD[886] at parquet at <unknown>:0), which has no missing parents
26/01/12 03:04:40 INFO BlockManagerInfo: Removed broadcast_527_piece0 on 02926ee04bc9:45221 in memory (size: 77.5 KiB, free: 366.1 MiB)
26/01/12 03:04:40 INFO BlockManagerInfo: Removed broadcast_527_piece0 on 172.18.0.5:42453 in memory (size: 77.5 KiB, free: 366.1 MiB)
26/01/12 03:04:40 INFO BlockManagerInfo: Removed broadcast_526_piece0 on 02926ee04bc9:45221 in memory (size: 35.3 KiB, free: 366.2 MiB)
26/01/12 03:04:40 INFO BlockManagerInfo: Removed broadcast_526_piece0 on 172.18.0.5:42453 in memory (size: 35.3 KiB, free: 366.2 MiB)
26/01/12 03:04:40 INFO MemoryStore: Block broadcast_531 stored as values in memory (estimated size 102.6 KiB, free 365.1 MiB)
26/01/12 03:04:40 INFO MemoryStore: Block broadcast_531_piece0 stored as bytes in memory (estimated size 36.8 KiB, free 365.1 MiB)
26/01/12 03:04:40 INFO BlockManagerInfo: Added broadcast_531_piece0 in memory on 02926ee04bc9:45221 (size: 36.8 KiB, free: 366.1 MiB)
26/01/12 03:04:40 INFO SparkContext: Created broadcast 531 from broadcast at DAGScheduler.scala:1513
26/01/12 03:04:40 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 354 (MapPartitionsRDD[886] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0))
26/01/12 03:04:40 INFO TaskSchedulerImpl: Adding task set 354.0 with 1 tasks resource profile 0
26/01/12 03:04:40 INFO TaskSetManager: Starting task 0.0 in stage 354.0 (TID 578) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4607 bytes) taskResourceAssignments Map()
26/01/12 03:04:40 INFO BlockManagerInfo: Added broadcast_531_piece0 in memory on 172.18.0.5:42453 (size: 36.8 KiB, free: 366.1 MiB)
26/01/12 03:04:40 INFO TaskSetManager: Finished task 0.0 in stage 354.0 (TID 578) in 44 ms on 172.18.0.5 (executor 0) (1/1)
26/01/12 03:04:40 INFO TaskSchedulerImpl: Removed TaskSet 354.0, whose tasks have all completed, from pool 
26/01/12 03:04:40 INFO DAGScheduler: ResultStage 354 (parquet at <unknown>:0) finished in 0.056 s
26/01/12 03:04:40 INFO DAGScheduler: Job 354 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 03:04:40 INFO TaskSchedulerImpl: Killing all running tasks in stage 354: Stage finished
26/01/12 03:04:40 INFO DAGScheduler: Job 354 finished: parquet at <unknown>:0, took 0.059659 s
26/01/12 03:04:40 INFO FileSourceStrategy: Pushed Filters: 
26/01/12 03:04:40 INFO FileSourceStrategy: Post-Scan Filters: 
26/01/12 03:04:40 INFO FileSourceStrategy: Output Data Schema: struct<VendorID: int, tpep_pickup_datetime: timestamp, tpep_dropoff_datetime: timestamp, passenger_count: bigint, trip_distance: double ... 17 more fields>
26/01/12 03:04:40 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 03:04:40 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 03:04:40 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 03:04:40 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 03:04:40 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 03:04:40 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 03:04:40 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 03:04:40 INFO MemoryStore: Block broadcast_532 stored as values in memory (estimated size 358.5 KiB, free 364.7 MiB)
26/01/12 03:04:40 INFO MemoryStore: Block broadcast_532_piece0 stored as bytes in memory (estimated size 35.3 KiB, free 364.7 MiB)
26/01/12 03:04:40 INFO BlockManagerInfo: Added broadcast_532_piece0 in memory on 02926ee04bc9:45221 (size: 35.3 KiB, free: 366.1 MiB)
26/01/12 03:04:40 INFO SparkContext: Created broadcast 532 from parquet at <unknown>:0
26/01/12 03:04:40 INFO FileSourceScanExec: Planning scan with bin packing, max size: 31601681 bytes, open cost is considered as scanning 4194304 bytes.
26/01/12 03:04:40 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 03:04:40 INFO DAGScheduler: Got job 355 (parquet at <unknown>:0) with 2 output partitions
26/01/12 03:04:40 INFO DAGScheduler: Final stage: ResultStage 355 (parquet at <unknown>:0)
26/01/12 03:04:40 INFO DAGScheduler: Parents of final stage: List()
26/01/12 03:04:40 INFO DAGScheduler: Missing parents: List()
26/01/12 03:04:40 INFO DAGScheduler: Submitting ResultStage 355 (MapPartitionsRDD[889] at parquet at <unknown>:0), which has no missing parents
26/01/12 03:04:40 INFO MemoryStore: Block broadcast_533 stored as values in memory (estimated size 225.1 KiB, free 364.5 MiB)
26/01/12 03:04:40 INFO MemoryStore: Block broadcast_533_piece0 stored as bytes in memory (estimated size 77.5 KiB, free 364.4 MiB)
26/01/12 03:04:40 INFO BlockManagerInfo: Added broadcast_533_piece0 in memory on 02926ee04bc9:45221 (size: 77.5 KiB, free: 366.0 MiB)
26/01/12 03:04:40 INFO SparkContext: Created broadcast 533 from broadcast at DAGScheduler.scala:1513
26/01/12 03:04:40 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 355 (MapPartitionsRDD[889] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1))
26/01/12 03:04:40 INFO TaskSchedulerImpl: Adding task set 355.0 with 2 tasks resource profile 0
26/01/12 03:04:40 INFO TaskSetManager: Starting task 0.0 in stage 355.0 (TID 579) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 03:04:40 INFO TaskSetManager: Starting task 1.0 in stage 355.0 (TID 580) (172.18.0.5, executor 0, partition 1, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 03:04:40 INFO BlockManagerInfo: Added broadcast_533_piece0 in memory on 172.18.0.5:42453 (size: 77.5 KiB, free: 366.0 MiB)
26/01/12 03:04:40 INFO BlockManagerInfo: Added broadcast_532_piece0 in memory on 172.18.0.5:42453 (size: 35.3 KiB, free: 366.0 MiB)
26/01/12 03:04:44 INFO TaskSetManager: Finished task 1.0 in stage 355.0 (TID 580) in 4673 ms on 172.18.0.5 (executor 0) (1/2)
26/01/12 03:04:46 INFO TaskSetManager: Finished task 0.0 in stage 355.0 (TID 579) in 5810 ms on 172.18.0.5 (executor 0) (2/2)
26/01/12 03:04:46 INFO TaskSchedulerImpl: Removed TaskSet 355.0, whose tasks have all completed, from pool 
26/01/12 03:04:46 INFO DAGScheduler: ResultStage 355 (parquet at <unknown>:0) finished in 5.829 s
26/01/12 03:04:46 INFO DAGScheduler: Job 355 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 03:04:46 INFO TaskSchedulerImpl: Killing all running tasks in stage 355: Stage finished
26/01/12 03:04:46 INFO DAGScheduler: Job 355 finished: parquet at <unknown>:0, took 5.834205 s
26/01/12 03:04:46 INFO FileFormatWriter: Start to commit write Job c189050f-0fca-47ea-bc3d-2e1c2385fa6e.
26/01/12 03:04:46 INFO FileFormatWriter: Write Job c189050f-0fca-47ea-bc3d-2e1c2385fa6e committed. Elapsed time: 30 ms.
26/01/12 03:04:46 INFO FileFormatWriter: Finished processing stats for write job c189050f-0fca-47ea-bc3d-2e1c2385fa6e.
Cargando: yellow_tripdata_2023-11.parquet en hdfs://hadoop-namenode:8020/data/nyc/raw/taxi-trips/2023...
26/01/12 03:04:46 INFO InMemoryFileIndex: It took 6 ms to list leaf files for 1 paths.
26/01/12 03:04:46 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 03:04:46 INFO DAGScheduler: Got job 356 (parquet at <unknown>:0) with 1 output partitions
26/01/12 03:04:46 INFO DAGScheduler: Final stage: ResultStage 356 (parquet at <unknown>:0)
26/01/12 03:04:46 INFO DAGScheduler: Parents of final stage: List()
26/01/12 03:04:46 INFO DAGScheduler: Missing parents: List()
26/01/12 03:04:46 INFO DAGScheduler: Submitting ResultStage 356 (MapPartitionsRDD[891] at parquet at <unknown>:0), which has no missing parents
26/01/12 03:04:46 INFO MemoryStore: Block broadcast_534 stored as values in memory (estimated size 102.6 KiB, free 364.3 MiB)
26/01/12 03:04:46 INFO MemoryStore: Block broadcast_534_piece0 stored as bytes in memory (estimated size 36.8 KiB, free 364.3 MiB)
26/01/12 03:04:46 INFO BlockManagerInfo: Added broadcast_534_piece0 in memory on 02926ee04bc9:45221 (size: 36.8 KiB, free: 366.0 MiB)
26/01/12 03:04:46 INFO SparkContext: Created broadcast 534 from broadcast at DAGScheduler.scala:1513
26/01/12 03:04:46 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 356 (MapPartitionsRDD[891] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0))
26/01/12 03:04:46 INFO TaskSchedulerImpl: Adding task set 356.0 with 1 tasks resource profile 0
26/01/12 03:04:46 INFO TaskSetManager: Starting task 0.0 in stage 356.0 (TID 581) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4607 bytes) taskResourceAssignments Map()
26/01/12 03:04:46 INFO BlockManagerInfo: Added broadcast_534_piece0 in memory on 172.18.0.5:42453 (size: 36.8 KiB, free: 366.0 MiB)
26/01/12 03:04:46 INFO TaskSetManager: Finished task 0.0 in stage 356.0 (TID 581) in 43 ms on 172.18.0.5 (executor 0) (1/1)
26/01/12 03:04:46 INFO TaskSchedulerImpl: Removed TaskSet 356.0, whose tasks have all completed, from pool 
26/01/12 03:04:46 INFO DAGScheduler: ResultStage 356 (parquet at <unknown>:0) finished in 0.055 s
26/01/12 03:04:46 INFO DAGScheduler: Job 356 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 03:04:46 INFO TaskSchedulerImpl: Killing all running tasks in stage 356: Stage finished
26/01/12 03:04:46 INFO DAGScheduler: Job 356 finished: parquet at <unknown>:0, took 0.058230 s
26/01/12 03:04:46 INFO FileSourceStrategy: Pushed Filters: 
26/01/12 03:04:46 INFO FileSourceStrategy: Post-Scan Filters: 
26/01/12 03:04:46 INFO FileSourceStrategy: Output Data Schema: struct<VendorID: int, tpep_pickup_datetime: timestamp, tpep_dropoff_datetime: timestamp, passenger_count: bigint, trip_distance: double ... 17 more fields>
26/01/12 03:04:46 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 03:04:46 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 03:04:46 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 03:04:46 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 03:04:46 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 03:04:46 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 03:04:46 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 03:04:46 INFO MemoryStore: Block broadcast_535 stored as values in memory (estimated size 358.5 KiB, free 363.9 MiB)
26/01/12 03:04:46 INFO MemoryStore: Block broadcast_535_piece0 stored as bytes in memory (estimated size 35.3 KiB, free 363.9 MiB)
26/01/12 03:04:46 INFO BlockManagerInfo: Added broadcast_535_piece0 in memory on 02926ee04bc9:45221 (size: 35.3 KiB, free: 365.9 MiB)
26/01/12 03:04:46 INFO SparkContext: Created broadcast 535 from parquet at <unknown>:0
26/01/12 03:04:46 INFO FileSourceScanExec: Planning scan with bin packing, max size: 30144478 bytes, open cost is considered as scanning 4194304 bytes.
26/01/12 03:04:46 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 03:04:46 INFO DAGScheduler: Got job 357 (parquet at <unknown>:0) with 2 output partitions
26/01/12 03:04:46 INFO DAGScheduler: Final stage: ResultStage 357 (parquet at <unknown>:0)
26/01/12 03:04:46 INFO DAGScheduler: Parents of final stage: List()
26/01/12 03:04:46 INFO DAGScheduler: Missing parents: List()
26/01/12 03:04:46 INFO DAGScheduler: Submitting ResultStage 357 (MapPartitionsRDD[894] at parquet at <unknown>:0), which has no missing parents
26/01/12 03:04:46 INFO MemoryStore: Block broadcast_536 stored as values in memory (estimated size 225.1 KiB, free 363.7 MiB)
26/01/12 03:04:46 INFO MemoryStore: Block broadcast_536_piece0 stored as bytes in memory (estimated size 77.5 KiB, free 363.6 MiB)
26/01/12 03:04:46 INFO BlockManagerInfo: Added broadcast_536_piece0 in memory on 02926ee04bc9:45221 (size: 77.5 KiB, free: 365.9 MiB)
26/01/12 03:04:46 INFO SparkContext: Created broadcast 536 from broadcast at DAGScheduler.scala:1513
26/01/12 03:04:46 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 357 (MapPartitionsRDD[894] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1))
26/01/12 03:04:46 INFO TaskSchedulerImpl: Adding task set 357.0 with 2 tasks resource profile 0
26/01/12 03:04:46 INFO TaskSetManager: Starting task 0.0 in stage 357.0 (TID 582) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 03:04:46 INFO TaskSetManager: Starting task 1.0 in stage 357.0 (TID 583) (172.18.0.5, executor 0, partition 1, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 03:04:46 INFO BlockManagerInfo: Added broadcast_536_piece0 in memory on 172.18.0.5:42453 (size: 77.5 KiB, free: 365.9 MiB)
26/01/12 03:04:46 INFO BlockManagerInfo: Added broadcast_535_piece0 in memory on 172.18.0.5:42453 (size: 35.3 KiB, free: 365.9 MiB)
26/01/12 03:04:50 INFO TaskSetManager: Finished task 1.0 in stage 357.0 (TID 583) in 4042 ms on 172.18.0.5 (executor 0) (1/2)
26/01/12 03:04:52 INFO TaskSetManager: Finished task 0.0 in stage 357.0 (TID 582) in 6163 ms on 172.18.0.5 (executor 0) (2/2)
26/01/12 03:04:52 INFO TaskSchedulerImpl: Removed TaskSet 357.0, whose tasks have all completed, from pool 
26/01/12 03:04:52 INFO DAGScheduler: ResultStage 357 (parquet at <unknown>:0) finished in 6.180 s
26/01/12 03:04:52 INFO DAGScheduler: Job 357 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 03:04:52 INFO TaskSchedulerImpl: Killing all running tasks in stage 357: Stage finished
26/01/12 03:04:52 INFO DAGScheduler: Job 357 finished: parquet at <unknown>:0, took 6.183425 s
26/01/12 03:04:52 INFO FileFormatWriter: Start to commit write Job 19ed31c6-7d84-461a-9b95-c4ecaa810ed1.
26/01/12 03:04:52 INFO FileFormatWriter: Write Job 19ed31c6-7d84-461a-9b95-c4ecaa810ed1 committed. Elapsed time: 35 ms.
26/01/12 03:04:52 INFO FileFormatWriter: Finished processing stats for write job 19ed31c6-7d84-461a-9b95-c4ecaa810ed1.
Cargando: yellow_tripdata_2023-12.parquet en hdfs://hadoop-namenode:8020/data/nyc/raw/taxi-trips/2023...
26/01/12 03:04:52 INFO InMemoryFileIndex: It took 7 ms to list leaf files for 1 paths.
26/01/12 03:04:52 INFO BlockManagerInfo: Removed broadcast_529_piece0 on 02926ee04bc9:45221 in memory (size: 35.3 KiB, free: 365.9 MiB)
26/01/12 03:04:52 INFO BlockManagerInfo: Removed broadcast_529_piece0 on 172.18.0.5:42453 in memory (size: 35.3 KiB, free: 365.9 MiB)
26/01/12 03:04:52 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 03:04:52 INFO DAGScheduler: Got job 358 (parquet at <unknown>:0) with 1 output partitions
26/01/12 03:04:52 INFO DAGScheduler: Final stage: ResultStage 358 (parquet at <unknown>:0)
26/01/12 03:04:52 INFO DAGScheduler: Parents of final stage: List()
26/01/12 03:04:52 INFO DAGScheduler: Missing parents: List()
26/01/12 03:04:52 INFO DAGScheduler: Submitting ResultStage 358 (MapPartitionsRDD[896] at parquet at <unknown>:0), which has no missing parents
26/01/12 03:04:52 INFO BlockManagerInfo: Removed broadcast_531_piece0 on 02926ee04bc9:45221 in memory (size: 36.8 KiB, free: 365.9 MiB)
26/01/12 03:04:52 INFO BlockManagerInfo: Removed broadcast_531_piece0 on 172.18.0.5:42453 in memory (size: 36.8 KiB, free: 365.9 MiB)
26/01/12 03:04:52 INFO MemoryStore: Block broadcast_537 stored as values in memory (estimated size 102.6 KiB, free 364.0 MiB)
26/01/12 03:04:52 INFO BlockManagerInfo: Removed broadcast_532_piece0 on 02926ee04bc9:45221 in memory (size: 35.3 KiB, free: 366.0 MiB)
26/01/12 03:04:52 INFO MemoryStore: Block broadcast_537_piece0 stored as bytes in memory (estimated size 36.8 KiB, free 364.4 MiB)
26/01/12 03:04:52 INFO BlockManagerInfo: Removed broadcast_532_piece0 on 172.18.0.5:42453 in memory (size: 35.3 KiB, free: 366.0 MiB)
26/01/12 03:04:52 INFO BlockManagerInfo: Added broadcast_537_piece0 in memory on 02926ee04bc9:45221 (size: 36.8 KiB, free: 365.9 MiB)
26/01/12 03:04:52 INFO SparkContext: Created broadcast 537 from broadcast at DAGScheduler.scala:1513
26/01/12 03:04:52 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 358 (MapPartitionsRDD[896] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0))
26/01/12 03:04:52 INFO TaskSchedulerImpl: Adding task set 358.0 with 1 tasks resource profile 0
26/01/12 03:04:52 INFO TaskSetManager: Starting task 0.0 in stage 358.0 (TID 584) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4607 bytes) taskResourceAssignments Map()
26/01/12 03:04:52 INFO BlockManagerInfo: Removed broadcast_533_piece0 on 02926ee04bc9:45221 in memory (size: 77.5 KiB, free: 366.0 MiB)
26/01/12 03:04:52 INFO BlockManagerInfo: Removed broadcast_533_piece0 on 172.18.0.5:42453 in memory (size: 77.5 KiB, free: 366.0 MiB)
26/01/12 03:04:52 INFO BlockManagerInfo: Added broadcast_537_piece0 in memory on 172.18.0.5:42453 (size: 36.8 KiB, free: 366.0 MiB)
26/01/12 03:04:52 INFO BlockManagerInfo: Removed broadcast_536_piece0 on 02926ee04bc9:45221 in memory (size: 77.5 KiB, free: 366.1 MiB)
26/01/12 03:04:52 INFO BlockManagerInfo: Removed broadcast_536_piece0 on 172.18.0.5:42453 in memory (size: 77.5 KiB, free: 366.1 MiB)
26/01/12 03:04:52 INFO BlockManagerInfo: Removed broadcast_534_piece0 on 02926ee04bc9:45221 in memory (size: 36.8 KiB, free: 366.1 MiB)
26/01/12 03:04:52 INFO BlockManagerInfo: Removed broadcast_534_piece0 on 172.18.0.5:42453 in memory (size: 36.8 KiB, free: 366.1 MiB)
26/01/12 03:04:52 INFO TaskSetManager: Finished task 0.0 in stage 358.0 (TID 584) in 62 ms on 172.18.0.5 (executor 0) (1/1)
26/01/12 03:04:52 INFO TaskSchedulerImpl: Removed TaskSet 358.0, whose tasks have all completed, from pool 
26/01/12 03:04:52 INFO DAGScheduler: ResultStage 358 (parquet at <unknown>:0) finished in 0.075 s
26/01/12 03:04:52 INFO DAGScheduler: Job 358 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 03:04:52 INFO TaskSchedulerImpl: Killing all running tasks in stage 358: Stage finished
26/01/12 03:04:52 INFO DAGScheduler: Job 358 finished: parquet at <unknown>:0, took 0.079084 s
26/01/12 03:04:52 INFO FileSourceStrategy: Pushed Filters: 
26/01/12 03:04:52 INFO FileSourceStrategy: Post-Scan Filters: 
26/01/12 03:04:52 INFO FileSourceStrategy: Output Data Schema: struct<VendorID: int, tpep_pickup_datetime: timestamp, tpep_dropoff_datetime: timestamp, passenger_count: bigint, trip_distance: double ... 17 more fields>
26/01/12 03:04:52 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 03:04:52 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 03:04:52 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 03:04:52 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 03:04:52 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 03:04:52 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 03:04:52 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 03:04:52 INFO MemoryStore: Block broadcast_538 stored as values in memory (estimated size 358.5 KiB, free 364.7 MiB)
26/01/12 03:04:52 INFO MemoryStore: Block broadcast_538_piece0 stored as bytes in memory (estimated size 35.3 KiB, free 364.7 MiB)
26/01/12 03:04:52 INFO BlockManagerInfo: Added broadcast_538_piece0 in memory on 02926ee04bc9:45221 (size: 35.3 KiB, free: 366.1 MiB)
26/01/12 03:04:52 INFO SparkContext: Created broadcast 538 from parquet at <unknown>:0
26/01/12 03:04:52 INFO FileSourceScanExec: Planning scan with bin packing, max size: 30499289 bytes, open cost is considered as scanning 4194304 bytes.
26/01/12 03:04:52 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 03:04:52 INFO DAGScheduler: Got job 359 (parquet at <unknown>:0) with 2 output partitions
26/01/12 03:04:52 INFO DAGScheduler: Final stage: ResultStage 359 (parquet at <unknown>:0)
26/01/12 03:04:52 INFO DAGScheduler: Parents of final stage: List()
26/01/12 03:04:52 INFO DAGScheduler: Missing parents: List()
26/01/12 03:04:52 INFO DAGScheduler: Submitting ResultStage 359 (MapPartitionsRDD[899] at parquet at <unknown>:0), which has no missing parents
26/01/12 03:04:52 INFO MemoryStore: Block broadcast_539 stored as values in memory (estimated size 225.1 KiB, free 364.5 MiB)
26/01/12 03:04:52 INFO MemoryStore: Block broadcast_539_piece0 stored as bytes in memory (estimated size 77.5 KiB, free 364.4 MiB)
26/01/12 03:04:52 INFO BlockManagerInfo: Added broadcast_539_piece0 in memory on 02926ee04bc9:45221 (size: 77.5 KiB, free: 366.0 MiB)
26/01/12 03:04:52 INFO SparkContext: Created broadcast 539 from broadcast at DAGScheduler.scala:1513
26/01/12 03:04:52 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 359 (MapPartitionsRDD[899] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1))
26/01/12 03:04:52 INFO TaskSchedulerImpl: Adding task set 359.0 with 2 tasks resource profile 0
26/01/12 03:04:52 INFO TaskSetManager: Starting task 0.0 in stage 359.0 (TID 585) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 03:04:52 INFO TaskSetManager: Starting task 1.0 in stage 359.0 (TID 586) (172.18.0.5, executor 0, partition 1, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 03:04:52 INFO BlockManagerInfo: Added broadcast_539_piece0 in memory on 172.18.0.5:42453 (size: 77.5 KiB, free: 366.0 MiB)
26/01/12 03:04:52 INFO BlockManagerInfo: Added broadcast_538_piece0 in memory on 172.18.0.5:42453 (size: 35.3 KiB, free: 366.0 MiB)
26/01/12 03:04:56 INFO TaskSetManager: Finished task 1.0 in stage 359.0 (TID 586) in 4128 ms on 172.18.0.5 (executor 0) (1/2)
26/01/12 03:04:58 INFO TaskSetManager: Finished task 0.0 in stage 359.0 (TID 585) in 6121 ms on 172.18.0.5 (executor 0) (2/2)
26/01/12 03:04:58 INFO TaskSchedulerImpl: Removed TaskSet 359.0, whose tasks have all completed, from pool 
26/01/12 03:04:58 INFO DAGScheduler: ResultStage 359 (parquet at <unknown>:0) finished in 6.139 s
26/01/12 03:04:58 INFO DAGScheduler: Job 359 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 03:04:58 INFO TaskSchedulerImpl: Killing all running tasks in stage 359: Stage finished
26/01/12 03:04:58 INFO DAGScheduler: Job 359 finished: parquet at <unknown>:0, took 6.142898 s
26/01/12 03:04:58 INFO FileFormatWriter: Start to commit write Job 03e79408-8c88-4d2f-8bad-889de4e70919.
26/01/12 03:04:58 INFO FileFormatWriter: Write Job 03e79408-8c88-4d2f-8bad-889de4e70919 committed. Elapsed time: 58 ms.
26/01/12 03:04:58 INFO FileFormatWriter: Finished processing stats for write job 03e79408-8c88-4d2f-8bad-889de4e70919.
Cargando: yellow_tripdata_2024-01.parquet en hdfs://hadoop-namenode:8020/data/nyc/raw/taxi-trips/2024...
26/01/12 03:04:58 INFO InMemoryFileIndex: It took 7 ms to list leaf files for 1 paths.
26/01/12 03:04:58 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 03:04:58 INFO DAGScheduler: Got job 360 (parquet at <unknown>:0) with 1 output partitions
26/01/12 03:04:58 INFO DAGScheduler: Final stage: ResultStage 360 (parquet at <unknown>:0)
26/01/12 03:04:58 INFO DAGScheduler: Parents of final stage: List()
26/01/12 03:04:58 INFO DAGScheduler: Missing parents: List()
26/01/12 03:04:58 INFO DAGScheduler: Submitting ResultStage 360 (MapPartitionsRDD[901] at parquet at <unknown>:0), which has no missing parents
26/01/12 03:04:58 INFO MemoryStore: Block broadcast_540 stored as values in memory (estimated size 102.6 KiB, free 364.3 MiB)
26/01/12 03:04:58 INFO MemoryStore: Block broadcast_540_piece0 stored as bytes in memory (estimated size 36.8 KiB, free 364.3 MiB)
26/01/12 03:04:58 INFO BlockManagerInfo: Added broadcast_540_piece0 in memory on 02926ee04bc9:45221 (size: 36.8 KiB, free: 366.0 MiB)
26/01/12 03:04:58 INFO SparkContext: Created broadcast 540 from broadcast at DAGScheduler.scala:1513
26/01/12 03:04:58 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 360 (MapPartitionsRDD[901] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0))
26/01/12 03:04:58 INFO TaskSchedulerImpl: Adding task set 360.0 with 1 tasks resource profile 0
26/01/12 03:04:58 INFO TaskSetManager: Starting task 0.0 in stage 360.0 (TID 587) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4607 bytes) taskResourceAssignments Map()
26/01/12 03:04:58 INFO BlockManagerInfo: Added broadcast_540_piece0 in memory on 172.18.0.5:42453 (size: 36.8 KiB, free: 366.0 MiB)
26/01/12 03:04:58 INFO TaskSetManager: Finished task 0.0 in stage 360.0 (TID 587) in 46 ms on 172.18.0.5 (executor 0) (1/1)
26/01/12 03:04:58 INFO TaskSchedulerImpl: Removed TaskSet 360.0, whose tasks have all completed, from pool 
26/01/12 03:04:58 INFO DAGScheduler: ResultStage 360 (parquet at <unknown>:0) finished in 0.057 s
26/01/12 03:04:58 INFO DAGScheduler: Job 360 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 03:04:58 INFO TaskSchedulerImpl: Killing all running tasks in stage 360: Stage finished
26/01/12 03:04:58 INFO DAGScheduler: Job 360 finished: parquet at <unknown>:0, took 0.060291 s
26/01/12 03:04:58 INFO FileSourceStrategy: Pushed Filters: 
26/01/12 03:04:58 INFO FileSourceStrategy: Post-Scan Filters: 
26/01/12 03:04:58 INFO FileSourceStrategy: Output Data Schema: struct<VendorID: int, tpep_pickup_datetime: timestamp, tpep_dropoff_datetime: timestamp, passenger_count: bigint, trip_distance: double ... 17 more fields>
26/01/12 03:04:58 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 03:04:58 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 03:04:58 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 03:04:58 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 03:04:58 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 03:04:58 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 03:04:58 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 03:04:58 INFO MemoryStore: Block broadcast_541 stored as values in memory (estimated size 358.5 KiB, free 363.9 MiB)
26/01/12 03:04:58 INFO MemoryStore: Block broadcast_541_piece0 stored as bytes in memory (estimated size 35.3 KiB, free 363.9 MiB)
26/01/12 03:04:58 INFO BlockManagerInfo: Added broadcast_541_piece0 in memory on 02926ee04bc9:45221 (size: 35.3 KiB, free: 365.9 MiB)
26/01/12 03:04:58 INFO SparkContext: Created broadcast 541 from parquet at <unknown>:0
26/01/12 03:04:58 INFO FileSourceScanExec: Planning scan with bin packing, max size: 27077972 bytes, open cost is considered as scanning 4194304 bytes.
26/01/12 03:04:58 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 03:04:58 INFO DAGScheduler: Got job 361 (parquet at <unknown>:0) with 2 output partitions
26/01/12 03:04:58 INFO DAGScheduler: Final stage: ResultStage 361 (parquet at <unknown>:0)
26/01/12 03:04:58 INFO DAGScheduler: Parents of final stage: List()
26/01/12 03:04:58 INFO DAGScheduler: Missing parents: List()
26/01/12 03:04:58 INFO DAGScheduler: Submitting ResultStage 361 (MapPartitionsRDD[904] at parquet at <unknown>:0), which has no missing parents
26/01/12 03:04:58 INFO MemoryStore: Block broadcast_542 stored as values in memory (estimated size 225.1 KiB, free 363.7 MiB)
26/01/12 03:04:58 INFO MemoryStore: Block broadcast_542_piece0 stored as bytes in memory (estimated size 77.4 KiB, free 363.6 MiB)
26/01/12 03:04:58 INFO BlockManagerInfo: Added broadcast_542_piece0 in memory on 02926ee04bc9:45221 (size: 77.4 KiB, free: 365.9 MiB)
26/01/12 03:04:59 INFO SparkContext: Created broadcast 542 from broadcast at DAGScheduler.scala:1513
26/01/12 03:04:59 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 361 (MapPartitionsRDD[904] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1))
26/01/12 03:04:59 INFO TaskSchedulerImpl: Adding task set 361.0 with 2 tasks resource profile 0
26/01/12 03:04:59 INFO TaskSetManager: Starting task 0.0 in stage 361.0 (TID 588) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 03:04:59 INFO TaskSetManager: Starting task 1.0 in stage 361.0 (TID 589) (172.18.0.5, executor 0, partition 1, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 03:04:59 INFO BlockManagerInfo: Added broadcast_542_piece0 in memory on 172.18.0.5:42453 (size: 77.4 KiB, free: 365.9 MiB)
26/01/12 03:04:59 INFO BlockManagerInfo: Added broadcast_541_piece0 in memory on 172.18.0.5:42453 (size: 35.3 KiB, free: 365.9 MiB)
26/01/12 03:05:02 INFO TaskSetManager: Finished task 1.0 in stage 361.0 (TID 589) in 3013 ms on 172.18.0.5 (executor 0) (1/2)
26/01/12 03:05:05 INFO TaskSetManager: Finished task 0.0 in stage 361.0 (TID 588) in 6073 ms on 172.18.0.5 (executor 0) (2/2)
26/01/12 03:05:05 INFO TaskSchedulerImpl: Removed TaskSet 361.0, whose tasks have all completed, from pool 
26/01/12 03:05:05 INFO DAGScheduler: ResultStage 361 (parquet at <unknown>:0) finished in 6.088 s
26/01/12 03:05:05 INFO DAGScheduler: Job 361 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 03:05:05 INFO TaskSchedulerImpl: Killing all running tasks in stage 361: Stage finished
26/01/12 03:05:05 INFO DAGScheduler: Job 361 finished: parquet at <unknown>:0, took 6.094471 s
26/01/12 03:05:05 INFO FileFormatWriter: Start to commit write Job ffbee00c-ff50-4182-9177-4052068ea4c2.
26/01/12 03:05:05 INFO FileFormatWriter: Write Job ffbee00c-ff50-4182-9177-4052068ea4c2 committed. Elapsed time: 29 ms.
26/01/12 03:05:05 INFO FileFormatWriter: Finished processing stats for write job ffbee00c-ff50-4182-9177-4052068ea4c2.
Cargando: yellow_tripdata_2024-02.parquet en hdfs://hadoop-namenode:8020/data/nyc/raw/taxi-trips/2024...
26/01/12 03:05:05 INFO InMemoryFileIndex: It took 7 ms to list leaf files for 1 paths.
26/01/12 03:05:05 INFO BlockManagerInfo: Removed broadcast_540_piece0 on 02926ee04bc9:45221 in memory (size: 36.8 KiB, free: 365.9 MiB)
26/01/12 03:05:05 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 03:05:05 INFO BlockManagerInfo: Removed broadcast_540_piece0 on 172.18.0.5:42453 in memory (size: 36.8 KiB, free: 365.9 MiB)
26/01/12 03:05:05 INFO DAGScheduler: Got job 362 (parquet at <unknown>:0) with 1 output partitions
26/01/12 03:05:05 INFO DAGScheduler: Final stage: ResultStage 362 (parquet at <unknown>:0)
26/01/12 03:05:05 INFO DAGScheduler: Parents of final stage: List()
26/01/12 03:05:05 INFO DAGScheduler: Missing parents: List()
26/01/12 03:05:05 INFO DAGScheduler: Submitting ResultStage 362 (MapPartitionsRDD[906] at parquet at <unknown>:0), which has no missing parents
26/01/12 03:05:05 INFO BlockManagerInfo: Removed broadcast_542_piece0 on 02926ee04bc9:45221 in memory (size: 77.4 KiB, free: 366.0 MiB)
26/01/12 03:05:05 INFO BlockManagerInfo: Removed broadcast_542_piece0 on 172.18.0.5:42453 in memory (size: 77.4 KiB, free: 366.0 MiB)
26/01/12 03:05:05 INFO BlockManagerInfo: Removed broadcast_537_piece0 on 02926ee04bc9:45221 in memory (size: 36.8 KiB, free: 366.0 MiB)
26/01/12 03:05:05 INFO MemoryStore: Block broadcast_543 stored as values in memory (estimated size 102.6 KiB, free 364.0 MiB)
26/01/12 03:05:05 INFO BlockManagerInfo: Removed broadcast_537_piece0 on 172.18.0.5:42453 in memory (size: 36.8 KiB, free: 366.0 MiB)
26/01/12 03:05:05 INFO MemoryStore: Block broadcast_543_piece0 stored as bytes in memory (estimated size 36.8 KiB, free 364.0 MiB)
26/01/12 03:05:05 INFO BlockManagerInfo: Added broadcast_543_piece0 in memory on 02926ee04bc9:45221 (size: 36.8 KiB, free: 366.0 MiB)
26/01/12 03:05:05 INFO SparkContext: Created broadcast 543 from broadcast at DAGScheduler.scala:1513
26/01/12 03:05:05 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 362 (MapPartitionsRDD[906] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0))
26/01/12 03:05:05 INFO TaskSchedulerImpl: Adding task set 362.0 with 1 tasks resource profile 0
26/01/12 03:05:05 INFO BlockManagerInfo: Removed broadcast_539_piece0 on 02926ee04bc9:45221 in memory (size: 77.5 KiB, free: 366.1 MiB)
26/01/12 03:05:05 INFO TaskSetManager: Starting task 0.0 in stage 362.0 (TID 590) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4607 bytes) taskResourceAssignments Map()
26/01/12 03:05:05 INFO BlockManagerInfo: Removed broadcast_539_piece0 on 172.18.0.5:42453 in memory (size: 77.5 KiB, free: 366.1 MiB)
26/01/12 03:05:05 INFO BlockManagerInfo: Removed broadcast_538_piece0 on 02926ee04bc9:45221 in memory (size: 35.3 KiB, free: 366.1 MiB)
26/01/12 03:05:05 INFO BlockManagerInfo: Removed broadcast_538_piece0 on 172.18.0.5:42453 in memory (size: 35.3 KiB, free: 366.1 MiB)
26/01/12 03:05:05 INFO BlockManagerInfo: Added broadcast_543_piece0 in memory on 172.18.0.5:42453 (size: 36.8 KiB, free: 366.1 MiB)
26/01/12 03:05:05 INFO BlockManagerInfo: Removed broadcast_535_piece0 on 02926ee04bc9:45221 in memory (size: 35.3 KiB, free: 366.1 MiB)
26/01/12 03:05:05 INFO BlockManagerInfo: Removed broadcast_535_piece0 on 172.18.0.5:42453 in memory (size: 35.3 KiB, free: 366.1 MiB)
26/01/12 03:05:05 INFO TaskSetManager: Finished task 0.0 in stage 362.0 (TID 590) in 47 ms on 172.18.0.5 (executor 0) (1/1)
26/01/12 03:05:05 INFO TaskSchedulerImpl: Removed TaskSet 362.0, whose tasks have all completed, from pool 
26/01/12 03:05:05 INFO DAGScheduler: ResultStage 362 (parquet at <unknown>:0) finished in 0.059 s
26/01/12 03:05:05 INFO DAGScheduler: Job 362 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 03:05:05 INFO TaskSchedulerImpl: Killing all running tasks in stage 362: Stage finished
26/01/12 03:05:05 INFO DAGScheduler: Job 362 finished: parquet at <unknown>:0, took 0.062288 s
26/01/12 03:05:05 INFO FileSourceStrategy: Pushed Filters: 
26/01/12 03:05:05 INFO FileSourceStrategy: Post-Scan Filters: 
26/01/12 03:05:05 INFO FileSourceStrategy: Output Data Schema: struct<VendorID: int, tpep_pickup_datetime: timestamp, tpep_dropoff_datetime: timestamp, passenger_count: bigint, trip_distance: double ... 17 more fields>
26/01/12 03:05:05 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 03:05:05 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 03:05:05 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 03:05:05 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 03:05:05 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 03:05:05 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 03:05:05 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 03:05:05 INFO MemoryStore: Block broadcast_544 stored as values in memory (estimated size 358.5 KiB, free 364.7 MiB)
26/01/12 03:05:05 INFO MemoryStore: Block broadcast_544_piece0 stored as bytes in memory (estimated size 35.3 KiB, free 364.7 MiB)
26/01/12 03:05:05 INFO BlockManagerInfo: Added broadcast_544_piece0 in memory on 02926ee04bc9:45221 (size: 35.3 KiB, free: 366.1 MiB)
26/01/12 03:05:05 INFO SparkContext: Created broadcast 544 from parquet at <unknown>:0
26/01/12 03:05:05 INFO FileSourceScanExec: Planning scan with bin packing, max size: 27271794 bytes, open cost is considered as scanning 4194304 bytes.
26/01/12 03:05:05 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 03:05:05 INFO DAGScheduler: Got job 363 (parquet at <unknown>:0) with 2 output partitions
26/01/12 03:05:05 INFO DAGScheduler: Final stage: ResultStage 363 (parquet at <unknown>:0)
26/01/12 03:05:05 INFO DAGScheduler: Parents of final stage: List()
26/01/12 03:05:05 INFO DAGScheduler: Missing parents: List()
26/01/12 03:05:05 INFO DAGScheduler: Submitting ResultStage 363 (MapPartitionsRDD[909] at parquet at <unknown>:0), which has no missing parents
26/01/12 03:05:05 INFO MemoryStore: Block broadcast_545 stored as values in memory (estimated size 225.1 KiB, free 364.5 MiB)
26/01/12 03:05:05 INFO MemoryStore: Block broadcast_545_piece0 stored as bytes in memory (estimated size 77.5 KiB, free 364.4 MiB)
26/01/12 03:05:05 INFO BlockManagerInfo: Added broadcast_545_piece0 in memory on 02926ee04bc9:45221 (size: 77.5 KiB, free: 366.0 MiB)
26/01/12 03:05:05 INFO SparkContext: Created broadcast 545 from broadcast at DAGScheduler.scala:1513
26/01/12 03:05:05 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 363 (MapPartitionsRDD[909] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1))
26/01/12 03:05:05 INFO TaskSchedulerImpl: Adding task set 363.0 with 2 tasks resource profile 0
26/01/12 03:05:05 INFO TaskSetManager: Starting task 0.0 in stage 363.0 (TID 591) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 03:05:05 INFO TaskSetManager: Starting task 1.0 in stage 363.0 (TID 592) (172.18.0.5, executor 0, partition 1, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 03:05:05 INFO BlockManagerInfo: Added broadcast_545_piece0 in memory on 172.18.0.5:42453 (size: 77.5 KiB, free: 366.0 MiB)
26/01/12 03:05:05 INFO BlockManagerInfo: Added broadcast_544_piece0 in memory on 172.18.0.5:42453 (size: 35.3 KiB, free: 366.0 MiB)
26/01/12 03:05:08 INFO TaskSetManager: Finished task 1.0 in stage 363.0 (TID 592) in 2983 ms on 172.18.0.5 (executor 0) (1/2)
26/01/12 03:05:11 INFO TaskSetManager: Finished task 0.0 in stage 363.0 (TID 591) in 5886 ms on 172.18.0.5 (executor 0) (2/2)
26/01/12 03:05:11 INFO TaskSchedulerImpl: Removed TaskSet 363.0, whose tasks have all completed, from pool 
26/01/12 03:05:11 INFO DAGScheduler: ResultStage 363 (parquet at <unknown>:0) finished in 5.902 s
26/01/12 03:05:11 INFO DAGScheduler: Job 363 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 03:05:11 INFO TaskSchedulerImpl: Killing all running tasks in stage 363: Stage finished
26/01/12 03:05:11 INFO DAGScheduler: Job 363 finished: parquet at <unknown>:0, took 5.905690 s
26/01/12 03:05:11 INFO FileFormatWriter: Start to commit write Job 4a259092-8050-4c35-8b20-ac44b920ad19.
26/01/12 03:05:11 INFO FileFormatWriter: Write Job 4a259092-8050-4c35-8b20-ac44b920ad19 committed. Elapsed time: 37 ms.
26/01/12 03:05:11 INFO FileFormatWriter: Finished processing stats for write job 4a259092-8050-4c35-8b20-ac44b920ad19.
Cargando: yellow_tripdata_2024-03.parquet en hdfs://hadoop-namenode:8020/data/nyc/raw/taxi-trips/2024...
26/01/12 03:05:11 INFO InMemoryFileIndex: It took 6 ms to list leaf files for 1 paths.
26/01/12 03:05:11 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 03:05:11 INFO DAGScheduler: Got job 364 (parquet at <unknown>:0) with 1 output partitions
26/01/12 03:05:11 INFO DAGScheduler: Final stage: ResultStage 364 (parquet at <unknown>:0)
26/01/12 03:05:11 INFO DAGScheduler: Parents of final stage: List()
26/01/12 03:05:11 INFO DAGScheduler: Missing parents: List()
26/01/12 03:05:11 INFO DAGScheduler: Submitting ResultStage 364 (MapPartitionsRDD[911] at parquet at <unknown>:0), which has no missing parents
26/01/12 03:05:11 INFO MemoryStore: Block broadcast_546 stored as values in memory (estimated size 102.6 KiB, free 364.3 MiB)
26/01/12 03:05:11 INFO MemoryStore: Block broadcast_546_piece0 stored as bytes in memory (estimated size 36.8 KiB, free 364.3 MiB)
26/01/12 03:05:11 INFO BlockManagerInfo: Added broadcast_546_piece0 in memory on 02926ee04bc9:45221 (size: 36.8 KiB, free: 366.0 MiB)
26/01/12 03:05:11 INFO SparkContext: Created broadcast 546 from broadcast at DAGScheduler.scala:1513
26/01/12 03:05:11 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 364 (MapPartitionsRDD[911] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0))
26/01/12 03:05:11 INFO TaskSchedulerImpl: Adding task set 364.0 with 1 tasks resource profile 0
26/01/12 03:05:11 INFO TaskSetManager: Starting task 0.0 in stage 364.0 (TID 593) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4607 bytes) taskResourceAssignments Map()
26/01/12 03:05:11 INFO BlockManagerInfo: Added broadcast_546_piece0 in memory on 172.18.0.5:42453 (size: 36.8 KiB, free: 366.0 MiB)
26/01/12 03:05:11 INFO TaskSetManager: Finished task 0.0 in stage 364.0 (TID 593) in 41 ms on 172.18.0.5 (executor 0) (1/1)
26/01/12 03:05:11 INFO TaskSchedulerImpl: Removed TaskSet 364.0, whose tasks have all completed, from pool 
26/01/12 03:05:11 INFO DAGScheduler: ResultStage 364 (parquet at <unknown>:0) finished in 0.052 s
26/01/12 03:05:11 INFO DAGScheduler: Job 364 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 03:05:11 INFO TaskSchedulerImpl: Killing all running tasks in stage 364: Stage finished
26/01/12 03:05:11 INFO DAGScheduler: Job 364 finished: parquet at <unknown>:0, took 0.054583 s
26/01/12 03:05:11 INFO FileSourceStrategy: Pushed Filters: 
26/01/12 03:05:11 INFO FileSourceStrategy: Post-Scan Filters: 
26/01/12 03:05:11 INFO FileSourceStrategy: Output Data Schema: struct<VendorID: int, tpep_pickup_datetime: timestamp, tpep_dropoff_datetime: timestamp, passenger_count: bigint, trip_distance: double ... 17 more fields>
26/01/12 03:05:11 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 03:05:11 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 03:05:11 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 03:05:11 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 03:05:11 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 03:05:11 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 03:05:11 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 03:05:11 INFO MemoryStore: Block broadcast_547 stored as values in memory (estimated size 358.5 KiB, free 363.9 MiB)
26/01/12 03:05:11 INFO MemoryStore: Block broadcast_547_piece0 stored as bytes in memory (estimated size 35.3 KiB, free 363.9 MiB)
26/01/12 03:05:11 INFO BlockManagerInfo: Added broadcast_547_piece0 in memory on 02926ee04bc9:45221 (size: 35.3 KiB, free: 365.9 MiB)
26/01/12 03:05:11 INFO SparkContext: Created broadcast 547 from parquet at <unknown>:0
26/01/12 03:05:11 INFO FileSourceScanExec: Planning scan with bin packing, max size: 32136292 bytes, open cost is considered as scanning 4194304 bytes.
26/01/12 03:05:11 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 03:05:11 INFO DAGScheduler: Got job 365 (parquet at <unknown>:0) with 2 output partitions
26/01/12 03:05:11 INFO DAGScheduler: Final stage: ResultStage 365 (parquet at <unknown>:0)
26/01/12 03:05:11 INFO DAGScheduler: Parents of final stage: List()
26/01/12 03:05:11 INFO DAGScheduler: Missing parents: List()
26/01/12 03:05:11 INFO DAGScheduler: Submitting ResultStage 365 (MapPartitionsRDD[914] at parquet at <unknown>:0), which has no missing parents
26/01/12 03:05:11 INFO MemoryStore: Block broadcast_548 stored as values in memory (estimated size 225.1 KiB, free 363.7 MiB)
26/01/12 03:05:11 INFO MemoryStore: Block broadcast_548_piece0 stored as bytes in memory (estimated size 77.4 KiB, free 363.6 MiB)
26/01/12 03:05:11 INFO BlockManagerInfo: Added broadcast_548_piece0 in memory on 02926ee04bc9:45221 (size: 77.4 KiB, free: 365.9 MiB)
26/01/12 03:05:11 INFO SparkContext: Created broadcast 548 from broadcast at DAGScheduler.scala:1513
26/01/12 03:05:11 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 365 (MapPartitionsRDD[914] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1))
26/01/12 03:05:11 INFO TaskSchedulerImpl: Adding task set 365.0 with 2 tasks resource profile 0
26/01/12 03:05:11 INFO TaskSetManager: Starting task 0.0 in stage 365.0 (TID 594) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 03:05:11 INFO TaskSetManager: Starting task 1.0 in stage 365.0 (TID 595) (172.18.0.5, executor 0, partition 1, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 03:05:11 INFO BlockManagerInfo: Added broadcast_548_piece0 in memory on 172.18.0.5:42453 (size: 77.4 KiB, free: 365.9 MiB)
26/01/12 03:05:11 INFO BlockManagerInfo: Added broadcast_547_piece0 in memory on 172.18.0.5:42453 (size: 35.3 KiB, free: 365.9 MiB)
26/01/12 03:05:15 INFO TaskSetManager: Finished task 1.0 in stage 365.0 (TID 595) in 4511 ms on 172.18.0.5 (executor 0) (1/2)
26/01/12 03:05:17 INFO TaskSetManager: Finished task 0.0 in stage 365.0 (TID 594) in 6123 ms on 172.18.0.5 (executor 0) (2/2)
26/01/12 03:05:17 INFO TaskSchedulerImpl: Removed TaskSet 365.0, whose tasks have all completed, from pool 
26/01/12 03:05:17 INFO DAGScheduler: ResultStage 365 (parquet at <unknown>:0) finished in 6.143 s
26/01/12 03:05:17 INFO DAGScheduler: Job 365 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 03:05:17 INFO TaskSchedulerImpl: Killing all running tasks in stage 365: Stage finished
26/01/12 03:05:17 INFO DAGScheduler: Job 365 finished: parquet at <unknown>:0, took 6.147011 s
26/01/12 03:05:17 INFO FileFormatWriter: Start to commit write Job 2625fa6c-3469-499f-8ae7-8854e46b13f7.
26/01/12 03:05:17 INFO FileFormatWriter: Write Job 2625fa6c-3469-499f-8ae7-8854e46b13f7 committed. Elapsed time: 28 ms.
26/01/12 03:05:17 INFO FileFormatWriter: Finished processing stats for write job 2625fa6c-3469-499f-8ae7-8854e46b13f7.
Cargando: yellow_tripdata_2024-04.parquet en hdfs://hadoop-namenode:8020/data/nyc/raw/taxi-trips/2024...
26/01/12 03:05:17 INFO InMemoryFileIndex: It took 5 ms to list leaf files for 1 paths.
26/01/12 03:05:17 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 03:05:17 INFO DAGScheduler: Got job 366 (parquet at <unknown>:0) with 1 output partitions
26/01/12 03:05:17 INFO DAGScheduler: Final stage: ResultStage 366 (parquet at <unknown>:0)
26/01/12 03:05:17 INFO DAGScheduler: Parents of final stage: List()
26/01/12 03:05:17 INFO DAGScheduler: Missing parents: List()
26/01/12 03:05:17 INFO DAGScheduler: Submitting ResultStage 366 (MapPartitionsRDD[916] at parquet at <unknown>:0), which has no missing parents
26/01/12 03:05:17 INFO MemoryStore: Block broadcast_549 stored as values in memory (estimated size 102.6 KiB, free 363.5 MiB)
26/01/12 03:05:17 INFO BlockManagerInfo: Removed broadcast_547_piece0 on 02926ee04bc9:45221 in memory (size: 35.3 KiB, free: 365.9 MiB)
26/01/12 03:05:17 INFO MemoryStore: Block broadcast_549_piece0 stored as bytes in memory (estimated size 36.8 KiB, free 363.5 MiB)
26/01/12 03:05:17 INFO BlockManagerInfo: Added broadcast_549_piece0 in memory on 02926ee04bc9:45221 (size: 36.8 KiB, free: 365.9 MiB)
26/01/12 03:05:17 INFO SparkContext: Created broadcast 549 from broadcast at DAGScheduler.scala:1513
26/01/12 03:05:17 INFO BlockManagerInfo: Removed broadcast_547_piece0 on 172.18.0.5:42453 in memory (size: 35.3 KiB, free: 365.9 MiB)
26/01/12 03:05:17 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 366 (MapPartitionsRDD[916] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0))
26/01/12 03:05:17 INFO TaskSchedulerImpl: Adding task set 366.0 with 1 tasks resource profile 0
26/01/12 03:05:17 INFO TaskSetManager: Starting task 0.0 in stage 366.0 (TID 596) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4607 bytes) taskResourceAssignments Map()
26/01/12 03:05:17 INFO BlockManagerInfo: Removed broadcast_544_piece0 on 02926ee04bc9:45221 in memory (size: 35.3 KiB, free: 365.9 MiB)
26/01/12 03:05:17 INFO BlockManagerInfo: Removed broadcast_544_piece0 on 172.18.0.5:42453 in memory (size: 35.3 KiB, free: 365.9 MiB)
26/01/12 03:05:17 INFO BlockManagerInfo: Removed broadcast_545_piece0 on 02926ee04bc9:45221 in memory (size: 77.5 KiB, free: 366.0 MiB)
26/01/12 03:05:17 INFO BlockManagerInfo: Added broadcast_549_piece0 in memory on 172.18.0.5:42453 (size: 36.8 KiB, free: 365.9 MiB)
26/01/12 03:05:17 INFO BlockManagerInfo: Removed broadcast_545_piece0 on 172.18.0.5:42453 in memory (size: 77.5 KiB, free: 366.0 MiB)
26/01/12 03:05:17 INFO BlockManagerInfo: Removed broadcast_546_piece0 on 02926ee04bc9:45221 in memory (size: 36.8 KiB, free: 366.0 MiB)
26/01/12 03:05:17 INFO BlockManagerInfo: Removed broadcast_546_piece0 on 172.18.0.5:42453 in memory (size: 36.8 KiB, free: 366.0 MiB)
26/01/12 03:05:17 INFO BlockManagerInfo: Removed broadcast_541_piece0 on 02926ee04bc9:45221 in memory (size: 35.3 KiB, free: 366.0 MiB)
26/01/12 03:05:17 INFO BlockManagerInfo: Removed broadcast_541_piece0 on 172.18.0.5:42453 in memory (size: 35.3 KiB, free: 366.0 MiB)
26/01/12 03:05:17 INFO BlockManagerInfo: Removed broadcast_548_piece0 on 02926ee04bc9:45221 in memory (size: 77.4 KiB, free: 366.1 MiB)
26/01/12 03:05:17 INFO BlockManagerInfo: Removed broadcast_548_piece0 on 172.18.0.5:42453 in memory (size: 77.4 KiB, free: 366.1 MiB)
26/01/12 03:05:17 INFO BlockManagerInfo: Removed broadcast_543_piece0 on 02926ee04bc9:45221 in memory (size: 36.8 KiB, free: 366.2 MiB)
26/01/12 03:05:17 INFO BlockManagerInfo: Removed broadcast_543_piece0 on 172.18.0.5:42453 in memory (size: 36.8 KiB, free: 366.2 MiB)
26/01/12 03:05:17 INFO TaskSetManager: Finished task 0.0 in stage 366.0 (TID 596) in 47 ms on 172.18.0.5 (executor 0) (1/1)
26/01/12 03:05:17 INFO TaskSchedulerImpl: Removed TaskSet 366.0, whose tasks have all completed, from pool 
26/01/12 03:05:17 INFO DAGScheduler: ResultStage 366 (parquet at <unknown>:0) finished in 0.077 s
26/01/12 03:05:17 INFO DAGScheduler: Job 366 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 03:05:17 INFO TaskSchedulerImpl: Killing all running tasks in stage 366: Stage finished
26/01/12 03:05:17 INFO DAGScheduler: Job 366 finished: parquet at <unknown>:0, took 0.079542 s
26/01/12 03:05:17 INFO FileSourceStrategy: Pushed Filters: 
26/01/12 03:05:17 INFO FileSourceStrategy: Post-Scan Filters: 
26/01/12 03:05:17 INFO FileSourceStrategy: Output Data Schema: struct<VendorID: int, tpep_pickup_datetime: timestamp, tpep_dropoff_datetime: timestamp, passenger_count: bigint, trip_distance: double ... 17 more fields>
26/01/12 03:05:17 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 03:05:17 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 03:05:17 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 03:05:17 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 03:05:17 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 03:05:17 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 03:05:17 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 03:05:17 INFO MemoryStore: Block broadcast_550 stored as values in memory (estimated size 358.5 KiB, free 365.1 MiB)
26/01/12 03:05:17 INFO MemoryStore: Block broadcast_550_piece0 stored as bytes in memory (estimated size 35.3 KiB, free 365.1 MiB)
26/01/12 03:05:17 INFO BlockManagerInfo: Added broadcast_550_piece0 in memory on 02926ee04bc9:45221 (size: 35.3 KiB, free: 366.1 MiB)
26/01/12 03:05:17 INFO SparkContext: Created broadcast 550 from parquet at <unknown>:0
26/01/12 03:05:17 INFO FileSourceScanExec: Planning scan with bin packing, max size: 31663964 bytes, open cost is considered as scanning 4194304 bytes.
26/01/12 03:05:17 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 03:05:17 INFO DAGScheduler: Got job 367 (parquet at <unknown>:0) with 2 output partitions
26/01/12 03:05:17 INFO DAGScheduler: Final stage: ResultStage 367 (parquet at <unknown>:0)
26/01/12 03:05:17 INFO DAGScheduler: Parents of final stage: List()
26/01/12 03:05:17 INFO DAGScheduler: Missing parents: List()
26/01/12 03:05:17 INFO DAGScheduler: Submitting ResultStage 367 (MapPartitionsRDD[919] at parquet at <unknown>:0), which has no missing parents
26/01/12 03:05:17 INFO MemoryStore: Block broadcast_551 stored as values in memory (estimated size 225.1 KiB, free 364.9 MiB)
26/01/12 03:05:17 INFO MemoryStore: Block broadcast_551_piece0 stored as bytes in memory (estimated size 77.5 KiB, free 364.8 MiB)
26/01/12 03:05:17 INFO BlockManagerInfo: Added broadcast_551_piece0 in memory on 02926ee04bc9:45221 (size: 77.5 KiB, free: 366.0 MiB)
26/01/12 03:05:17 INFO SparkContext: Created broadcast 551 from broadcast at DAGScheduler.scala:1513
26/01/12 03:05:17 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 367 (MapPartitionsRDD[919] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1))
26/01/12 03:05:17 INFO TaskSchedulerImpl: Adding task set 367.0 with 2 tasks resource profile 0
26/01/12 03:05:17 INFO TaskSetManager: Starting task 0.0 in stage 367.0 (TID 597) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 03:05:17 INFO TaskSetManager: Starting task 1.0 in stage 367.0 (TID 598) (172.18.0.5, executor 0, partition 1, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 03:05:17 INFO BlockManagerInfo: Added broadcast_551_piece0 in memory on 172.18.0.5:42453 (size: 77.5 KiB, free: 366.1 MiB)
26/01/12 03:05:17 INFO BlockManagerInfo: Added broadcast_550_piece0 in memory on 172.18.0.5:42453 (size: 35.3 KiB, free: 366.0 MiB)
26/01/12 03:05:22 INFO TaskSetManager: Finished task 1.0 in stage 367.0 (TID 598) in 4285 ms on 172.18.0.5 (executor 0) (1/2)
26/01/12 03:05:23 INFO TaskSetManager: Finished task 0.0 in stage 367.0 (TID 597) in 6098 ms on 172.18.0.5 (executor 0) (2/2)
26/01/12 03:05:23 INFO TaskSchedulerImpl: Removed TaskSet 367.0, whose tasks have all completed, from pool 
26/01/12 03:05:23 INFO DAGScheduler: ResultStage 367 (parquet at <unknown>:0) finished in 6.115 s
26/01/12 03:05:23 INFO DAGScheduler: Job 367 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 03:05:23 INFO TaskSchedulerImpl: Killing all running tasks in stage 367: Stage finished
26/01/12 03:05:23 INFO DAGScheduler: Job 367 finished: parquet at <unknown>:0, took 6.119910 s
26/01/12 03:05:23 INFO FileFormatWriter: Start to commit write Job bf67c218-5550-449e-9089-a84ab1717753.
26/01/12 03:05:23 INFO FileFormatWriter: Write Job bf67c218-5550-449e-9089-a84ab1717753 committed. Elapsed time: 31 ms.
26/01/12 03:05:23 INFO FileFormatWriter: Finished processing stats for write job bf67c218-5550-449e-9089-a84ab1717753.
Cargando: yellow_tripdata_2024-05.parquet en hdfs://hadoop-namenode:8020/data/nyc/raw/taxi-trips/2024...
26/01/12 03:05:23 INFO InMemoryFileIndex: It took 6 ms to list leaf files for 1 paths.
26/01/12 03:05:23 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 03:05:23 INFO DAGScheduler: Got job 368 (parquet at <unknown>:0) with 1 output partitions
26/01/12 03:05:23 INFO DAGScheduler: Final stage: ResultStage 368 (parquet at <unknown>:0)
26/01/12 03:05:23 INFO DAGScheduler: Parents of final stage: List()
26/01/12 03:05:23 INFO DAGScheduler: Missing parents: List()
26/01/12 03:05:23 INFO DAGScheduler: Submitting ResultStage 368 (MapPartitionsRDD[921] at parquet at <unknown>:0), which has no missing parents
26/01/12 03:05:23 INFO MemoryStore: Block broadcast_552 stored as values in memory (estimated size 102.6 KiB, free 364.7 MiB)
26/01/12 03:05:23 INFO MemoryStore: Block broadcast_552_piece0 stored as bytes in memory (estimated size 36.8 KiB, free 364.7 MiB)
26/01/12 03:05:23 INFO BlockManagerInfo: Added broadcast_552_piece0 in memory on 02926ee04bc9:45221 (size: 36.8 KiB, free: 366.0 MiB)
26/01/12 03:05:23 INFO SparkContext: Created broadcast 552 from broadcast at DAGScheduler.scala:1513
26/01/12 03:05:23 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 368 (MapPartitionsRDD[921] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0))
26/01/12 03:05:23 INFO TaskSchedulerImpl: Adding task set 368.0 with 1 tasks resource profile 0
26/01/12 03:05:23 INFO TaskSetManager: Starting task 0.0 in stage 368.0 (TID 599) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4607 bytes) taskResourceAssignments Map()
26/01/12 03:05:23 INFO BlockManagerInfo: Added broadcast_552_piece0 in memory on 172.18.0.5:42453 (size: 36.8 KiB, free: 366.0 MiB)
26/01/12 03:05:23 INFO TaskSetManager: Finished task 0.0 in stage 368.0 (TID 599) in 51 ms on 172.18.0.5 (executor 0) (1/1)
26/01/12 03:05:23 INFO TaskSchedulerImpl: Removed TaskSet 368.0, whose tasks have all completed, from pool 
26/01/12 03:05:23 INFO DAGScheduler: ResultStage 368 (parquet at <unknown>:0) finished in 0.061 s
26/01/12 03:05:23 INFO DAGScheduler: Job 368 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 03:05:23 INFO TaskSchedulerImpl: Killing all running tasks in stage 368: Stage finished
26/01/12 03:05:23 INFO DAGScheduler: Job 368 finished: parquet at <unknown>:0, took 0.064763 s
26/01/12 03:05:23 INFO FileSourceStrategy: Pushed Filters: 
26/01/12 03:05:23 INFO FileSourceStrategy: Post-Scan Filters: 
26/01/12 03:05:23 INFO FileSourceStrategy: Output Data Schema: struct<VendorID: int, tpep_pickup_datetime: timestamp, tpep_dropoff_datetime: timestamp, passenger_count: bigint, trip_distance: double ... 17 more fields>
26/01/12 03:05:23 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 03:05:23 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 03:05:23 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 03:05:23 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 03:05:23 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 03:05:23 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 03:05:23 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 03:05:23 INFO MemoryStore: Block broadcast_553 stored as values in memory (estimated size 358.5 KiB, free 364.3 MiB)
26/01/12 03:05:23 INFO MemoryStore: Block broadcast_553_piece0 stored as bytes in memory (estimated size 35.3 KiB, free 364.3 MiB)
26/01/12 03:05:23 INFO BlockManagerInfo: Added broadcast_553_piece0 in memory on 02926ee04bc9:45221 (size: 35.3 KiB, free: 366.0 MiB)
26/01/12 03:05:23 INFO SparkContext: Created broadcast 553 from parquet at <unknown>:0
26/01/12 03:05:23 INFO FileSourceScanExec: Planning scan with bin packing, max size: 33373716 bytes, open cost is considered as scanning 4194304 bytes.
26/01/12 03:05:24 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 03:05:24 INFO DAGScheduler: Got job 369 (parquet at <unknown>:0) with 2 output partitions
26/01/12 03:05:24 INFO DAGScheduler: Final stage: ResultStage 369 (parquet at <unknown>:0)
26/01/12 03:05:24 INFO DAGScheduler: Parents of final stage: List()
26/01/12 03:05:24 INFO DAGScheduler: Missing parents: List()
26/01/12 03:05:24 INFO DAGScheduler: Submitting ResultStage 369 (MapPartitionsRDD[924] at parquet at <unknown>:0), which has no missing parents
26/01/12 03:05:24 INFO MemoryStore: Block broadcast_554 stored as values in memory (estimated size 225.1 KiB, free 364.1 MiB)
26/01/12 03:05:24 INFO MemoryStore: Block broadcast_554_piece0 stored as bytes in memory (estimated size 77.5 KiB, free 364.0 MiB)
26/01/12 03:05:24 INFO BlockManagerInfo: Added broadcast_554_piece0 in memory on 02926ee04bc9:45221 (size: 77.5 KiB, free: 365.9 MiB)
26/01/12 03:05:24 INFO SparkContext: Created broadcast 554 from broadcast at DAGScheduler.scala:1513
26/01/12 03:05:24 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 369 (MapPartitionsRDD[924] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1))
26/01/12 03:05:24 INFO TaskSchedulerImpl: Adding task set 369.0 with 2 tasks resource profile 0
26/01/12 03:05:24 INFO TaskSetManager: Starting task 0.0 in stage 369.0 (TID 600) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 03:05:24 INFO TaskSetManager: Starting task 1.0 in stage 369.0 (TID 601) (172.18.0.5, executor 0, partition 1, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 03:05:24 INFO BlockManagerInfo: Added broadcast_554_piece0 in memory on 172.18.0.5:42453 (size: 77.5 KiB, free: 365.9 MiB)
26/01/12 03:05:24 INFO BlockManagerInfo: Added broadcast_553_piece0 in memory on 172.18.0.5:42453 (size: 35.3 KiB, free: 365.9 MiB)
26/01/12 03:05:28 INFO TaskSetManager: Finished task 1.0 in stage 369.0 (TID 601) in 4447 ms on 172.18.0.5 (executor 0) (1/2)
26/01/12 03:05:30 INFO TaskSetManager: Finished task 0.0 in stage 369.0 (TID 600) in 6095 ms on 172.18.0.5 (executor 0) (2/2)
26/01/12 03:05:30 INFO TaskSchedulerImpl: Removed TaskSet 369.0, whose tasks have all completed, from pool 
26/01/12 03:05:30 INFO DAGScheduler: ResultStage 369 (parquet at <unknown>:0) finished in 6.113 s
26/01/12 03:05:30 INFO DAGScheduler: Job 369 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 03:05:30 INFO TaskSchedulerImpl: Killing all running tasks in stage 369: Stage finished
26/01/12 03:05:30 INFO DAGScheduler: Job 369 finished: parquet at <unknown>:0, took 6.116656 s
26/01/12 03:05:30 INFO FileFormatWriter: Start to commit write Job 637935f0-ced5-4932-92f2-e821965329d4.
26/01/12 03:05:30 INFO FileFormatWriter: Write Job 637935f0-ced5-4932-92f2-e821965329d4 committed. Elapsed time: 33 ms.
26/01/12 03:05:30 INFO FileFormatWriter: Finished processing stats for write job 637935f0-ced5-4932-92f2-e821965329d4.
Cargando: yellow_tripdata_2024-06.parquet en hdfs://hadoop-namenode:8020/data/nyc/raw/taxi-trips/2024...
26/01/12 03:05:30 INFO InMemoryFileIndex: It took 6 ms to list leaf files for 1 paths.
26/01/12 03:05:30 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 03:05:30 INFO DAGScheduler: Got job 370 (parquet at <unknown>:0) with 1 output partitions
26/01/12 03:05:30 INFO DAGScheduler: Final stage: ResultStage 370 (parquet at <unknown>:0)
26/01/12 03:05:30 INFO DAGScheduler: Parents of final stage: List()
26/01/12 03:05:30 INFO DAGScheduler: Missing parents: List()
26/01/12 03:05:30 INFO DAGScheduler: Submitting ResultStage 370 (MapPartitionsRDD[926] at parquet at <unknown>:0), which has no missing parents
26/01/12 03:05:30 INFO BlockManagerInfo: Removed broadcast_551_piece0 on 02926ee04bc9:45221 in memory (size: 77.5 KiB, free: 366.0 MiB)
26/01/12 03:05:30 INFO BlockManagerInfo: Removed broadcast_551_piece0 on 172.18.0.5:42453 in memory (size: 77.5 KiB, free: 366.0 MiB)
26/01/12 03:05:30 INFO MemoryStore: Block broadcast_555 stored as values in memory (estimated size 102.6 KiB, free 364.2 MiB)
26/01/12 03:05:30 INFO MemoryStore: Block broadcast_555_piece0 stored as bytes in memory (estimated size 36.8 KiB, free 364.1 MiB)
26/01/12 03:05:30 INFO BlockManagerInfo: Added broadcast_555_piece0 in memory on 02926ee04bc9:45221 (size: 36.8 KiB, free: 365.9 MiB)
26/01/12 03:05:30 INFO SparkContext: Created broadcast 555 from broadcast at DAGScheduler.scala:1513
26/01/12 03:05:30 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 370 (MapPartitionsRDD[926] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0))
26/01/12 03:05:30 INFO TaskSchedulerImpl: Adding task set 370.0 with 1 tasks resource profile 0
26/01/12 03:05:30 INFO BlockManagerInfo: Removed broadcast_554_piece0 on 02926ee04bc9:45221 in memory (size: 77.5 KiB, free: 366.0 MiB)
26/01/12 03:05:30 INFO BlockManagerInfo: Removed broadcast_554_piece0 on 172.18.0.5:42453 in memory (size: 77.5 KiB, free: 366.0 MiB)
26/01/12 03:05:30 INFO TaskSetManager: Starting task 0.0 in stage 370.0 (TID 602) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4607 bytes) taskResourceAssignments Map()
26/01/12 03:05:30 INFO BlockManagerInfo: Removed broadcast_552_piece0 on 02926ee04bc9:45221 in memory (size: 36.8 KiB, free: 366.0 MiB)
26/01/12 03:05:30 INFO BlockManagerInfo: Removed broadcast_552_piece0 on 172.18.0.5:42453 in memory (size: 36.8 KiB, free: 366.1 MiB)
26/01/12 03:05:30 INFO BlockManagerInfo: Added broadcast_555_piece0 in memory on 172.18.0.5:42453 (size: 36.8 KiB, free: 366.0 MiB)
26/01/12 03:05:30 INFO BlockManagerInfo: Removed broadcast_549_piece0 on 02926ee04bc9:45221 in memory (size: 36.8 KiB, free: 366.1 MiB)
26/01/12 03:05:30 INFO BlockManagerInfo: Removed broadcast_549_piece0 on 172.18.0.5:42453 in memory (size: 36.8 KiB, free: 366.1 MiB)
26/01/12 03:05:30 INFO BlockManagerInfo: Removed broadcast_550_piece0 on 02926ee04bc9:45221 in memory (size: 35.3 KiB, free: 366.1 MiB)
26/01/12 03:05:30 INFO BlockManagerInfo: Removed broadcast_550_piece0 on 172.18.0.5:42453 in memory (size: 35.3 KiB, free: 366.1 MiB)
26/01/12 03:05:30 INFO BlockManagerInfo: Removed broadcast_553_piece0 on 02926ee04bc9:45221 in memory (size: 35.3 KiB, free: 366.2 MiB)
26/01/12 03:05:30 INFO BlockManagerInfo: Removed broadcast_553_piece0 on 172.18.0.5:42453 in memory (size: 35.3 KiB, free: 366.2 MiB)
26/01/12 03:05:30 INFO TaskSetManager: Finished task 0.0 in stage 370.0 (TID 602) in 42 ms on 172.18.0.5 (executor 0) (1/1)
26/01/12 03:05:30 INFO TaskSchedulerImpl: Removed TaskSet 370.0, whose tasks have all completed, from pool 
26/01/12 03:05:30 INFO DAGScheduler: ResultStage 370 (parquet at <unknown>:0) finished in 0.058 s
26/01/12 03:05:30 INFO DAGScheduler: Job 370 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 03:05:30 INFO TaskSchedulerImpl: Killing all running tasks in stage 370: Stage finished
26/01/12 03:05:30 INFO DAGScheduler: Job 370 finished: parquet at <unknown>:0, took 0.077013 s
26/01/12 03:05:30 INFO FileSourceStrategy: Pushed Filters: 
26/01/12 03:05:30 INFO FileSourceStrategy: Post-Scan Filters: 
26/01/12 03:05:30 INFO FileSourceStrategy: Output Data Schema: struct<VendorID: int, tpep_pickup_datetime: timestamp, tpep_dropoff_datetime: timestamp, passenger_count: bigint, trip_distance: double ... 17 more fields>
26/01/12 03:05:30 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 03:05:30 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 03:05:30 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 03:05:30 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 03:05:30 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 03:05:30 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 03:05:30 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 03:05:30 INFO MemoryStore: Block broadcast_556 stored as values in memory (estimated size 358.5 KiB, free 365.1 MiB)
26/01/12 03:05:30 INFO MemoryStore: Block broadcast_556_piece0 stored as bytes in memory (estimated size 35.3 KiB, free 365.1 MiB)
26/01/12 03:05:30 INFO BlockManagerInfo: Added broadcast_556_piece0 in memory on 02926ee04bc9:45221 (size: 35.3 KiB, free: 366.1 MiB)
26/01/12 03:05:30 INFO SparkContext: Created broadcast 556 from parquet at <unknown>:0
26/01/12 03:05:30 INFO FileSourceScanExec: Planning scan with bin packing, max size: 32027113 bytes, open cost is considered as scanning 4194304 bytes.
26/01/12 03:05:30 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 03:05:30 INFO DAGScheduler: Got job 371 (parquet at <unknown>:0) with 2 output partitions
26/01/12 03:05:30 INFO DAGScheduler: Final stage: ResultStage 371 (parquet at <unknown>:0)
26/01/12 03:05:30 INFO DAGScheduler: Parents of final stage: List()
26/01/12 03:05:30 INFO DAGScheduler: Missing parents: List()
26/01/12 03:05:30 INFO DAGScheduler: Submitting ResultStage 371 (MapPartitionsRDD[929] at parquet at <unknown>:0), which has no missing parents
26/01/12 03:05:30 INFO MemoryStore: Block broadcast_557 stored as values in memory (estimated size 225.1 KiB, free 364.9 MiB)
26/01/12 03:05:30 INFO MemoryStore: Block broadcast_557_piece0 stored as bytes in memory (estimated size 77.5 KiB, free 364.8 MiB)
26/01/12 03:05:30 INFO BlockManagerInfo: Added broadcast_557_piece0 in memory on 02926ee04bc9:45221 (size: 77.5 KiB, free: 366.0 MiB)
26/01/12 03:05:30 INFO SparkContext: Created broadcast 557 from broadcast at DAGScheduler.scala:1513
26/01/12 03:05:30 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 371 (MapPartitionsRDD[929] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1))
26/01/12 03:05:30 INFO TaskSchedulerImpl: Adding task set 371.0 with 2 tasks resource profile 0
26/01/12 03:05:30 INFO TaskSetManager: Starting task 0.0 in stage 371.0 (TID 603) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 03:05:30 INFO TaskSetManager: Starting task 1.0 in stage 371.0 (TID 604) (172.18.0.5, executor 0, partition 1, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 03:05:30 INFO BlockManagerInfo: Added broadcast_557_piece0 in memory on 172.18.0.5:42453 (size: 77.5 KiB, free: 366.1 MiB)
26/01/12 03:05:30 INFO BlockManagerInfo: Added broadcast_556_piece0 in memory on 172.18.0.5:42453 (size: 35.3 KiB, free: 366.0 MiB)
26/01/12 03:05:34 INFO TaskSetManager: Finished task 1.0 in stage 371.0 (TID 604) in 4548 ms on 172.18.0.5 (executor 0) (1/2)
26/01/12 03:05:36 INFO TaskSetManager: Finished task 0.0 in stage 371.0 (TID 603) in 5968 ms on 172.18.0.5 (executor 0) (2/2)
26/01/12 03:05:36 INFO TaskSchedulerImpl: Removed TaskSet 371.0, whose tasks have all completed, from pool 
26/01/12 03:05:36 INFO DAGScheduler: ResultStage 371 (parquet at <unknown>:0) finished in 5.984 s
26/01/12 03:05:36 INFO DAGScheduler: Job 371 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 03:05:36 INFO TaskSchedulerImpl: Killing all running tasks in stage 371: Stage finished
26/01/12 03:05:36 INFO DAGScheduler: Job 371 finished: parquet at <unknown>:0, took 5.988729 s
26/01/12 03:05:36 INFO FileFormatWriter: Start to commit write Job d4366363-ea80-4b01-8def-e8046345d02d.
26/01/12 03:05:36 INFO FileFormatWriter: Write Job d4366363-ea80-4b01-8def-e8046345d02d committed. Elapsed time: 35 ms.
26/01/12 03:05:36 INFO FileFormatWriter: Finished processing stats for write job d4366363-ea80-4b01-8def-e8046345d02d.
Cargando: yellow_tripdata_2024-07.parquet en hdfs://hadoop-namenode:8020/data/nyc/raw/taxi-trips/2024...
26/01/12 03:05:36 INFO InMemoryFileIndex: It took 7 ms to list leaf files for 1 paths.
26/01/12 03:05:36 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 03:05:36 INFO DAGScheduler: Got job 372 (parquet at <unknown>:0) with 1 output partitions
26/01/12 03:05:36 INFO DAGScheduler: Final stage: ResultStage 372 (parquet at <unknown>:0)
26/01/12 03:05:36 INFO DAGScheduler: Parents of final stage: List()
26/01/12 03:05:36 INFO DAGScheduler: Missing parents: List()
26/01/12 03:05:36 INFO DAGScheduler: Submitting ResultStage 372 (MapPartitionsRDD[931] at parquet at <unknown>:0), which has no missing parents
26/01/12 03:05:36 INFO MemoryStore: Block broadcast_558 stored as values in memory (estimated size 102.6 KiB, free 364.7 MiB)
26/01/12 03:05:36 INFO MemoryStore: Block broadcast_558_piece0 stored as bytes in memory (estimated size 36.8 KiB, free 364.7 MiB)
26/01/12 03:05:36 INFO BlockManagerInfo: Added broadcast_558_piece0 in memory on 02926ee04bc9:45221 (size: 36.8 KiB, free: 366.0 MiB)
26/01/12 03:05:36 INFO SparkContext: Created broadcast 558 from broadcast at DAGScheduler.scala:1513
26/01/12 03:05:36 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 372 (MapPartitionsRDD[931] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0))
26/01/12 03:05:36 INFO TaskSchedulerImpl: Adding task set 372.0 with 1 tasks resource profile 0
26/01/12 03:05:36 INFO TaskSetManager: Starting task 0.0 in stage 372.0 (TID 605) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4607 bytes) taskResourceAssignments Map()
26/01/12 03:05:36 INFO BlockManagerInfo: Added broadcast_558_piece0 in memory on 172.18.0.5:42453 (size: 36.8 KiB, free: 366.0 MiB)
26/01/12 03:05:36 INFO TaskSetManager: Finished task 0.0 in stage 372.0 (TID 605) in 43 ms on 172.18.0.5 (executor 0) (1/1)
26/01/12 03:05:36 INFO TaskSchedulerImpl: Removed TaskSet 372.0, whose tasks have all completed, from pool 
26/01/12 03:05:36 INFO DAGScheduler: ResultStage 372 (parquet at <unknown>:0) finished in 0.054 s
26/01/12 03:05:36 INFO DAGScheduler: Job 372 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 03:05:36 INFO TaskSchedulerImpl: Killing all running tasks in stage 372: Stage finished
26/01/12 03:05:36 INFO DAGScheduler: Job 372 finished: parquet at <unknown>:0, took 0.058039 s
26/01/12 03:05:36 INFO FileSourceStrategy: Pushed Filters: 
26/01/12 03:05:36 INFO FileSourceStrategy: Post-Scan Filters: 
26/01/12 03:05:36 INFO FileSourceStrategy: Output Data Schema: struct<VendorID: int, tpep_pickup_datetime: timestamp, tpep_dropoff_datetime: timestamp, passenger_count: bigint, trip_distance: double ... 17 more fields>
26/01/12 03:05:36 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 03:05:36 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 03:05:36 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 03:05:36 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 03:05:36 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 03:05:36 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 03:05:36 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 03:05:36 INFO MemoryStore: Block broadcast_559 stored as values in memory (estimated size 358.5 KiB, free 364.3 MiB)
26/01/12 03:05:36 INFO MemoryStore: Block broadcast_559_piece0 stored as bytes in memory (estimated size 35.3 KiB, free 364.3 MiB)
26/01/12 03:05:36 INFO BlockManagerInfo: Added broadcast_559_piece0 in memory on 02926ee04bc9:45221 (size: 35.3 KiB, free: 366.0 MiB)
26/01/12 03:05:36 INFO SparkContext: Created broadcast 559 from parquet at <unknown>:0
26/01/12 03:05:36 INFO FileSourceScanExec: Planning scan with bin packing, max size: 28246868 bytes, open cost is considered as scanning 4194304 bytes.
26/01/12 03:05:36 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 03:05:36 INFO DAGScheduler: Got job 373 (parquet at <unknown>:0) with 2 output partitions
26/01/12 03:05:36 INFO DAGScheduler: Final stage: ResultStage 373 (parquet at <unknown>:0)
26/01/12 03:05:36 INFO DAGScheduler: Parents of final stage: List()
26/01/12 03:05:36 INFO DAGScheduler: Missing parents: List()
26/01/12 03:05:36 INFO DAGScheduler: Submitting ResultStage 373 (MapPartitionsRDD[934] at parquet at <unknown>:0), which has no missing parents
26/01/12 03:05:36 INFO MemoryStore: Block broadcast_560 stored as values in memory (estimated size 225.1 KiB, free 364.1 MiB)
26/01/12 03:05:36 INFO MemoryStore: Block broadcast_560_piece0 stored as bytes in memory (estimated size 77.5 KiB, free 364.0 MiB)
26/01/12 03:05:36 INFO BlockManagerInfo: Added broadcast_560_piece0 in memory on 02926ee04bc9:45221 (size: 77.5 KiB, free: 365.9 MiB)
26/01/12 03:05:36 INFO SparkContext: Created broadcast 560 from broadcast at DAGScheduler.scala:1513
26/01/12 03:05:36 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 373 (MapPartitionsRDD[934] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1))
26/01/12 03:05:36 INFO TaskSchedulerImpl: Adding task set 373.0 with 2 tasks resource profile 0
26/01/12 03:05:36 INFO TaskSetManager: Starting task 0.0 in stage 373.0 (TID 606) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 03:05:36 INFO TaskSetManager: Starting task 1.0 in stage 373.0 (TID 607) (172.18.0.5, executor 0, partition 1, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 03:05:36 INFO BlockManagerInfo: Added broadcast_560_piece0 in memory on 172.18.0.5:42453 (size: 77.5 KiB, free: 365.9 MiB)
26/01/12 03:05:36 INFO BlockManagerInfo: Added broadcast_559_piece0 in memory on 172.18.0.5:42453 (size: 35.3 KiB, free: 365.9 MiB)
26/01/12 03:05:39 INFO TaskSetManager: Finished task 1.0 in stage 373.0 (TID 607) in 3284 ms on 172.18.0.5 (executor 0) (1/2)
26/01/12 03:05:42 INFO TaskSetManager: Finished task 0.0 in stage 373.0 (TID 606) in 6246 ms on 172.18.0.5 (executor 0) (2/2)
26/01/12 03:05:42 INFO TaskSchedulerImpl: Removed TaskSet 373.0, whose tasks have all completed, from pool 
26/01/12 03:05:42 INFO DAGScheduler: ResultStage 373 (parquet at <unknown>:0) finished in 6.264 s
26/01/12 03:05:42 INFO DAGScheduler: Job 373 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 03:05:42 INFO TaskSchedulerImpl: Killing all running tasks in stage 373: Stage finished
26/01/12 03:05:42 INFO DAGScheduler: Job 373 finished: parquet at <unknown>:0, took 6.268257 s
26/01/12 03:05:42 INFO FileFormatWriter: Start to commit write Job 52e093c3-d0e9-4b5d-938f-efb5ddd2afc1.
26/01/12 03:05:42 INFO FileFormatWriter: Write Job 52e093c3-d0e9-4b5d-938f-efb5ddd2afc1 committed. Elapsed time: 29 ms.
26/01/12 03:05:42 INFO FileFormatWriter: Finished processing stats for write job 52e093c3-d0e9-4b5d-938f-efb5ddd2afc1.
Cargando: yellow_tripdata_2024-08.parquet en hdfs://hadoop-namenode:8020/data/nyc/raw/taxi-trips/2024...
26/01/12 03:05:42 INFO InMemoryFileIndex: It took 6 ms to list leaf files for 1 paths.
26/01/12 03:05:42 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 03:05:42 INFO DAGScheduler: Got job 374 (parquet at <unknown>:0) with 1 output partitions
26/01/12 03:05:42 INFO DAGScheduler: Final stage: ResultStage 374 (parquet at <unknown>:0)
26/01/12 03:05:42 INFO BlockManagerInfo: Removed broadcast_560_piece0 on 02926ee04bc9:45221 in memory (size: 77.5 KiB, free: 366.0 MiB)
26/01/12 03:05:42 INFO DAGScheduler: Parents of final stage: List()
26/01/12 03:05:42 INFO DAGScheduler: Missing parents: List()
26/01/12 03:05:42 INFO BlockManagerInfo: Removed broadcast_560_piece0 on 172.18.0.5:42453 in memory (size: 77.5 KiB, free: 366.0 MiB)
26/01/12 03:05:42 INFO DAGScheduler: Submitting ResultStage 374 (MapPartitionsRDD[936] at parquet at <unknown>:0), which has no missing parents
26/01/12 03:05:42 INFO BlockManagerInfo: Removed broadcast_557_piece0 on 02926ee04bc9:45221 in memory (size: 77.5 KiB, free: 366.0 MiB)
26/01/12 03:05:42 INFO BlockManagerInfo: Removed broadcast_557_piece0 on 172.18.0.5:42453 in memory (size: 77.5 KiB, free: 366.0 MiB)
26/01/12 03:05:42 INFO MemoryStore: Block broadcast_561 stored as values in memory (estimated size 102.6 KiB, free 364.5 MiB)
26/01/12 03:05:42 INFO BlockManagerInfo: Removed broadcast_558_piece0 on 02926ee04bc9:45221 in memory (size: 36.8 KiB, free: 366.1 MiB)
26/01/12 03:05:42 INFO BlockManagerInfo: Removed broadcast_558_piece0 on 172.18.0.5:42453 in memory (size: 36.8 KiB, free: 366.1 MiB)
26/01/12 03:05:42 INFO MemoryStore: Block broadcast_561_piece0 stored as bytes in memory (estimated size 36.8 KiB, free 364.6 MiB)
26/01/12 03:05:42 INFO BlockManagerInfo: Added broadcast_561_piece0 in memory on 02926ee04bc9:45221 (size: 36.8 KiB, free: 366.0 MiB)
26/01/12 03:05:42 INFO SparkContext: Created broadcast 561 from broadcast at DAGScheduler.scala:1513
26/01/12 03:05:42 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 374 (MapPartitionsRDD[936] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0))
26/01/12 03:05:42 INFO TaskSchedulerImpl: Adding task set 374.0 with 1 tasks resource profile 0
26/01/12 03:05:42 INFO TaskSetManager: Starting task 0.0 in stage 374.0 (TID 608) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4607 bytes) taskResourceAssignments Map()
26/01/12 03:05:42 INFO BlockManagerInfo: Removed broadcast_555_piece0 on 02926ee04bc9:45221 in memory (size: 36.8 KiB, free: 366.1 MiB)
26/01/12 03:05:42 INFO BlockManagerInfo: Removed broadcast_555_piece0 on 172.18.0.5:42453 in memory (size: 36.8 KiB, free: 366.1 MiB)
26/01/12 03:05:42 INFO BlockManagerInfo: Removed broadcast_556_piece0 on 02926ee04bc9:45221 in memory (size: 35.3 KiB, free: 366.1 MiB)
26/01/12 03:05:42 INFO BlockManagerInfo: Added broadcast_561_piece0 in memory on 172.18.0.5:42453 (size: 36.8 KiB, free: 366.1 MiB)
26/01/12 03:05:42 INFO BlockManagerInfo: Removed broadcast_556_piece0 on 172.18.0.5:42453 in memory (size: 35.3 KiB, free: 366.1 MiB)
26/01/12 03:05:42 INFO TaskSetManager: Finished task 0.0 in stage 374.0 (TID 608) in 45 ms on 172.18.0.5 (executor 0) (1/1)
26/01/12 03:05:42 INFO TaskSchedulerImpl: Removed TaskSet 374.0, whose tasks have all completed, from pool 
26/01/12 03:05:42 INFO DAGScheduler: ResultStage 374 (parquet at <unknown>:0) finished in 0.059 s
26/01/12 03:05:42 INFO DAGScheduler: Job 374 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 03:05:42 INFO TaskSchedulerImpl: Killing all running tasks in stage 374: Stage finished
26/01/12 03:05:42 INFO DAGScheduler: Job 374 finished: parquet at <unknown>:0, took 0.063740 s
26/01/12 03:05:42 INFO FileSourceStrategy: Pushed Filters: 
26/01/12 03:05:42 INFO FileSourceStrategy: Post-Scan Filters: 
26/01/12 03:05:42 INFO FileSourceStrategy: Output Data Schema: struct<VendorID: int, tpep_pickup_datetime: timestamp, tpep_dropoff_datetime: timestamp, passenger_count: bigint, trip_distance: double ... 17 more fields>
26/01/12 03:05:42 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 03:05:42 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 03:05:42 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 03:05:42 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 03:05:42 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 03:05:42 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 03:05:42 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 03:05:42 INFO MemoryStore: Block broadcast_562 stored as values in memory (estimated size 358.5 KiB, free 364.7 MiB)
26/01/12 03:05:42 INFO MemoryStore: Block broadcast_562_piece0 stored as bytes in memory (estimated size 35.3 KiB, free 364.7 MiB)
26/01/12 03:05:42 INFO BlockManagerInfo: Added broadcast_562_piece0 in memory on 02926ee04bc9:45221 (size: 35.3 KiB, free: 366.1 MiB)
26/01/12 03:05:42 INFO SparkContext: Created broadcast 562 from parquet at <unknown>:0
26/01/12 03:05:42 INFO FileSourceScanExec: Planning scan with bin packing, max size: 27630827 bytes, open cost is considered as scanning 4194304 bytes.
26/01/12 03:05:42 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 03:05:42 INFO DAGScheduler: Got job 375 (parquet at <unknown>:0) with 2 output partitions
26/01/12 03:05:42 INFO DAGScheduler: Final stage: ResultStage 375 (parquet at <unknown>:0)
26/01/12 03:05:42 INFO DAGScheduler: Parents of final stage: List()
26/01/12 03:05:42 INFO DAGScheduler: Missing parents: List()
26/01/12 03:05:42 INFO DAGScheduler: Submitting ResultStage 375 (MapPartitionsRDD[939] at parquet at <unknown>:0), which has no missing parents
26/01/12 03:05:42 INFO MemoryStore: Block broadcast_563 stored as values in memory (estimated size 225.1 KiB, free 364.5 MiB)
26/01/12 03:05:42 INFO MemoryStore: Block broadcast_563_piece0 stored as bytes in memory (estimated size 77.5 KiB, free 364.4 MiB)
26/01/12 03:05:42 INFO BlockManagerInfo: Added broadcast_563_piece0 in memory on 02926ee04bc9:45221 (size: 77.5 KiB, free: 366.0 MiB)
26/01/12 03:05:42 INFO SparkContext: Created broadcast 563 from broadcast at DAGScheduler.scala:1513
26/01/12 03:05:42 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 375 (MapPartitionsRDD[939] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1))
26/01/12 03:05:42 INFO TaskSchedulerImpl: Adding task set 375.0 with 2 tasks resource profile 0
26/01/12 03:05:42 INFO TaskSetManager: Starting task 0.0 in stage 375.0 (TID 609) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 03:05:42 INFO TaskSetManager: Starting task 1.0 in stage 375.0 (TID 610) (172.18.0.5, executor 0, partition 1, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 03:05:42 INFO BlockManagerInfo: Added broadcast_563_piece0 in memory on 172.18.0.5:42453 (size: 77.5 KiB, free: 366.0 MiB)
26/01/12 03:05:43 INFO BlockManagerInfo: Added broadcast_562_piece0 in memory on 172.18.0.5:42453 (size: 35.3 KiB, free: 366.0 MiB)
26/01/12 03:05:45 INFO TaskSetManager: Finished task 1.0 in stage 375.0 (TID 610) in 2892 ms on 172.18.0.5 (executor 0) (1/2)
26/01/12 03:05:48 INFO TaskSetManager: Finished task 0.0 in stage 375.0 (TID 609) in 5470 ms on 172.18.0.5 (executor 0) (2/2)
26/01/12 03:05:48 INFO TaskSchedulerImpl: Removed TaskSet 375.0, whose tasks have all completed, from pool 
26/01/12 03:05:48 INFO DAGScheduler: ResultStage 375 (parquet at <unknown>:0) finished in 5.486 s
26/01/12 03:05:48 INFO DAGScheduler: Job 375 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 03:05:48 INFO TaskSchedulerImpl: Killing all running tasks in stage 375: Stage finished
26/01/12 03:05:48 INFO DAGScheduler: Job 375 finished: parquet at <unknown>:0, took 5.489912 s
26/01/12 03:05:48 INFO FileFormatWriter: Start to commit write Job 944fabbf-2089-41ae-bf93-dbf407c16c91.
26/01/12 03:05:48 INFO FileFormatWriter: Write Job 944fabbf-2089-41ae-bf93-dbf407c16c91 committed. Elapsed time: 26 ms.
26/01/12 03:05:48 INFO FileFormatWriter: Finished processing stats for write job 944fabbf-2089-41ae-bf93-dbf407c16c91.
Cargando: yellow_tripdata_2024-09.parquet en hdfs://hadoop-namenode:8020/data/nyc/raw/taxi-trips/2024...
26/01/12 03:05:48 INFO InMemoryFileIndex: It took 6 ms to list leaf files for 1 paths.
26/01/12 03:05:48 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 03:05:48 INFO DAGScheduler: Got job 376 (parquet at <unknown>:0) with 1 output partitions
26/01/12 03:05:48 INFO DAGScheduler: Final stage: ResultStage 376 (parquet at <unknown>:0)
26/01/12 03:05:48 INFO DAGScheduler: Parents of final stage: List()
26/01/12 03:05:48 INFO DAGScheduler: Missing parents: List()
26/01/12 03:05:48 INFO DAGScheduler: Submitting ResultStage 376 (MapPartitionsRDD[941] at parquet at <unknown>:0), which has no missing parents
26/01/12 03:05:48 INFO MemoryStore: Block broadcast_564 stored as values in memory (estimated size 102.6 KiB, free 364.3 MiB)
26/01/12 03:05:48 INFO MemoryStore: Block broadcast_564_piece0 stored as bytes in memory (estimated size 36.8 KiB, free 364.3 MiB)
26/01/12 03:05:48 INFO BlockManagerInfo: Added broadcast_564_piece0 in memory on 02926ee04bc9:45221 (size: 36.8 KiB, free: 366.0 MiB)
26/01/12 03:05:48 INFO SparkContext: Created broadcast 564 from broadcast at DAGScheduler.scala:1513
26/01/12 03:05:48 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 376 (MapPartitionsRDD[941] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0))
26/01/12 03:05:48 INFO TaskSchedulerImpl: Adding task set 376.0 with 1 tasks resource profile 0
26/01/12 03:05:48 INFO TaskSetManager: Starting task 0.0 in stage 376.0 (TID 611) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4607 bytes) taskResourceAssignments Map()
26/01/12 03:05:48 INFO BlockManagerInfo: Added broadcast_564_piece0 in memory on 172.18.0.5:42453 (size: 36.8 KiB, free: 366.0 MiB)
26/01/12 03:05:48 INFO TaskSetManager: Finished task 0.0 in stage 376.0 (TID 611) in 46 ms on 172.18.0.5 (executor 0) (1/1)
26/01/12 03:05:48 INFO TaskSchedulerImpl: Removed TaskSet 376.0, whose tasks have all completed, from pool 
26/01/12 03:05:48 INFO DAGScheduler: ResultStage 376 (parquet at <unknown>:0) finished in 0.056 s
26/01/12 03:05:48 INFO DAGScheduler: Job 376 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 03:05:48 INFO TaskSchedulerImpl: Killing all running tasks in stage 376: Stage finished
26/01/12 03:05:48 INFO DAGScheduler: Job 376 finished: parquet at <unknown>:0, took 0.058918 s
26/01/12 03:05:48 INFO FileSourceStrategy: Pushed Filters: 
26/01/12 03:05:48 INFO FileSourceStrategy: Post-Scan Filters: 
26/01/12 03:05:48 INFO FileSourceStrategy: Output Data Schema: struct<VendorID: int, tpep_pickup_datetime: timestamp, tpep_dropoff_datetime: timestamp, passenger_count: bigint, trip_distance: double ... 17 more fields>
26/01/12 03:05:48 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 03:05:48 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 03:05:48 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 03:05:48 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 03:05:48 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 03:05:48 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 03:05:48 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 03:05:48 INFO MemoryStore: Block broadcast_565 stored as values in memory (estimated size 358.5 KiB, free 363.9 MiB)
26/01/12 03:05:48 INFO MemoryStore: Block broadcast_565_piece0 stored as bytes in memory (estimated size 35.3 KiB, free 363.9 MiB)
26/01/12 03:05:48 INFO BlockManagerInfo: Added broadcast_565_piece0 in memory on 02926ee04bc9:45221 (size: 35.3 KiB, free: 365.9 MiB)
26/01/12 03:05:48 INFO SparkContext: Created broadcast 565 from parquet at <unknown>:0
26/01/12 03:05:48 INFO FileSourceScanExec: Planning scan with bin packing, max size: 32682245 bytes, open cost is considered as scanning 4194304 bytes.
26/01/12 03:05:48 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 03:05:48 INFO DAGScheduler: Got job 377 (parquet at <unknown>:0) with 2 output partitions
26/01/12 03:05:48 INFO DAGScheduler: Final stage: ResultStage 377 (parquet at <unknown>:0)
26/01/12 03:05:48 INFO DAGScheduler: Parents of final stage: List()
26/01/12 03:05:48 INFO DAGScheduler: Missing parents: List()
26/01/12 03:05:48 INFO DAGScheduler: Submitting ResultStage 377 (MapPartitionsRDD[944] at parquet at <unknown>:0), which has no missing parents
26/01/12 03:05:48 INFO MemoryStore: Block broadcast_566 stored as values in memory (estimated size 225.1 KiB, free 363.7 MiB)
26/01/12 03:05:48 INFO MemoryStore: Block broadcast_566_piece0 stored as bytes in memory (estimated size 77.4 KiB, free 363.6 MiB)
26/01/12 03:05:48 INFO BlockManagerInfo: Added broadcast_566_piece0 in memory on 02926ee04bc9:45221 (size: 77.4 KiB, free: 365.9 MiB)
26/01/12 03:05:48 INFO SparkContext: Created broadcast 566 from broadcast at DAGScheduler.scala:1513
26/01/12 03:05:48 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 377 (MapPartitionsRDD[944] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1))
26/01/12 03:05:48 INFO TaskSchedulerImpl: Adding task set 377.0 with 2 tasks resource profile 0
26/01/12 03:05:48 INFO TaskSetManager: Starting task 0.0 in stage 377.0 (TID 612) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 03:05:48 INFO TaskSetManager: Starting task 1.0 in stage 377.0 (TID 613) (172.18.0.5, executor 0, partition 1, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 03:05:48 INFO BlockManagerInfo: Added broadcast_566_piece0 in memory on 172.18.0.5:42453 (size: 77.4 KiB, free: 365.9 MiB)
26/01/12 03:05:48 INFO BlockManagerInfo: Added broadcast_565_piece0 in memory on 172.18.0.5:42453 (size: 35.3 KiB, free: 365.9 MiB)
26/01/12 03:05:53 INFO TaskSetManager: Finished task 1.0 in stage 377.0 (TID 613) in 4584 ms on 172.18.0.5 (executor 0) (1/2)
26/01/12 03:05:54 INFO TaskSetManager: Finished task 0.0 in stage 377.0 (TID 612) in 6072 ms on 172.18.0.5 (executor 0) (2/2)
26/01/12 03:05:54 INFO TaskSchedulerImpl: Removed TaskSet 377.0, whose tasks have all completed, from pool 
26/01/12 03:05:54 INFO DAGScheduler: ResultStage 377 (parquet at <unknown>:0) finished in 6.088 s
26/01/12 03:05:54 INFO DAGScheduler: Job 377 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 03:05:54 INFO TaskSchedulerImpl: Killing all running tasks in stage 377: Stage finished
26/01/12 03:05:54 INFO DAGScheduler: Job 377 finished: parquet at <unknown>:0, took 6.093123 s
26/01/12 03:05:54 INFO FileFormatWriter: Start to commit write Job 7a648f30-ef37-4a5b-be45-917c9570591f.
26/01/12 03:05:54 INFO FileFormatWriter: Write Job 7a648f30-ef37-4a5b-be45-917c9570591f committed. Elapsed time: 30 ms.
26/01/12 03:05:54 INFO FileFormatWriter: Finished processing stats for write job 7a648f30-ef37-4a5b-be45-917c9570591f.
Cargando: yellow_tripdata_2024-10.parquet en hdfs://hadoop-namenode:8020/data/nyc/raw/taxi-trips/2024...
26/01/12 03:05:54 INFO InMemoryFileIndex: It took 6 ms to list leaf files for 1 paths.
26/01/12 03:05:54 INFO BlockManagerInfo: Removed broadcast_562_piece0 on 02926ee04bc9:45221 in memory (size: 35.3 KiB, free: 365.9 MiB)
26/01/12 03:05:54 INFO BlockManagerInfo: Removed broadcast_562_piece0 on 172.18.0.5:42453 in memory (size: 35.3 KiB, free: 365.9 MiB)
26/01/12 03:05:54 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 03:05:54 INFO DAGScheduler: Got job 378 (parquet at <unknown>:0) with 1 output partitions
26/01/12 03:05:54 INFO DAGScheduler: Final stage: ResultStage 378 (parquet at <unknown>:0)
26/01/12 03:05:54 INFO DAGScheduler: Parents of final stage: List()
26/01/12 03:05:54 INFO DAGScheduler: Missing parents: List()
26/01/12 03:05:54 INFO BlockManagerInfo: Removed broadcast_563_piece0 on 02926ee04bc9:45221 in memory (size: 77.5 KiB, free: 366.0 MiB)
26/01/12 03:05:54 INFO DAGScheduler: Submitting ResultStage 378 (MapPartitionsRDD[946] at parquet at <unknown>:0), which has no missing parents
26/01/12 03:05:54 INFO BlockManagerInfo: Removed broadcast_563_piece0 on 172.18.0.5:42453 in memory (size: 77.5 KiB, free: 366.0 MiB)
26/01/12 03:05:54 INFO BlockManagerInfo: Removed broadcast_564_piece0 on 02926ee04bc9:45221 in memory (size: 36.8 KiB, free: 366.0 MiB)
26/01/12 03:05:54 INFO BlockManagerInfo: Removed broadcast_564_piece0 on 172.18.0.5:42453 in memory (size: 36.8 KiB, free: 366.0 MiB)
26/01/12 03:05:54 INFO MemoryStore: Block broadcast_567 stored as values in memory (estimated size 102.6 KiB, free 364.3 MiB)
26/01/12 03:05:54 INFO BlockManagerInfo: Removed broadcast_559_piece0 on 02926ee04bc9:45221 in memory (size: 35.3 KiB, free: 366.0 MiB)
26/01/12 03:05:54 INFO MemoryStore: Block broadcast_567_piece0 stored as bytes in memory (estimated size 36.8 KiB, free 364.7 MiB)
26/01/12 03:05:54 INFO BlockManagerInfo: Removed broadcast_559_piece0 on 172.18.0.5:42453 in memory (size: 35.3 KiB, free: 366.0 MiB)
26/01/12 03:05:54 INFO BlockManagerInfo: Added broadcast_567_piece0 in memory on 02926ee04bc9:45221 (size: 36.8 KiB, free: 366.0 MiB)
26/01/12 03:05:54 INFO SparkContext: Created broadcast 567 from broadcast at DAGScheduler.scala:1513
26/01/12 03:05:54 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 378 (MapPartitionsRDD[946] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0))
26/01/12 03:05:54 INFO TaskSchedulerImpl: Adding task set 378.0 with 1 tasks resource profile 0
26/01/12 03:05:54 INFO TaskSetManager: Starting task 0.0 in stage 378.0 (TID 614) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4607 bytes) taskResourceAssignments Map()
26/01/12 03:05:54 INFO BlockManagerInfo: Removed broadcast_561_piece0 on 02926ee04bc9:45221 in memory (size: 36.8 KiB, free: 366.0 MiB)
26/01/12 03:05:54 INFO BlockManagerInfo: Removed broadcast_561_piece0 on 172.18.0.5:42453 in memory (size: 36.8 KiB, free: 366.1 MiB)
26/01/12 03:05:54 INFO BlockManagerInfo: Removed broadcast_566_piece0 on 02926ee04bc9:45221 in memory (size: 77.4 KiB, free: 366.1 MiB)
26/01/12 03:05:54 INFO BlockManagerInfo: Added broadcast_567_piece0 in memory on 172.18.0.5:42453 (size: 36.8 KiB, free: 366.0 MiB)
26/01/12 03:05:54 INFO BlockManagerInfo: Removed broadcast_566_piece0 on 172.18.0.5:42453 in memory (size: 77.4 KiB, free: 366.1 MiB)
26/01/12 03:05:54 INFO TaskSetManager: Finished task 0.0 in stage 378.0 (TID 614) in 40 ms on 172.18.0.5 (executor 0) (1/1)
26/01/12 03:05:54 INFO TaskSchedulerImpl: Removed TaskSet 378.0, whose tasks have all completed, from pool 
26/01/12 03:05:54 INFO DAGScheduler: ResultStage 378 (parquet at <unknown>:0) finished in 0.053 s
26/01/12 03:05:54 INFO DAGScheduler: Job 378 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 03:05:54 INFO TaskSchedulerImpl: Killing all running tasks in stage 378: Stage finished
26/01/12 03:05:54 INFO DAGScheduler: Job 378 finished: parquet at <unknown>:0, took 0.056085 s
26/01/12 03:05:54 INFO FileSourceStrategy: Pushed Filters: 
26/01/12 03:05:54 INFO FileSourceStrategy: Post-Scan Filters: 
26/01/12 03:05:54 INFO FileSourceStrategy: Output Data Schema: struct<VendorID: int, tpep_pickup_datetime: timestamp, tpep_dropoff_datetime: timestamp, passenger_count: bigint, trip_distance: double ... 17 more fields>
26/01/12 03:05:54 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 03:05:54 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 03:05:54 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 03:05:54 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 03:05:54 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 03:05:54 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 03:05:54 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 03:05:54 INFO MemoryStore: Block broadcast_568 stored as values in memory (estimated size 358.5 KiB, free 364.7 MiB)
26/01/12 03:05:54 INFO MemoryStore: Block broadcast_568_piece0 stored as bytes in memory (estimated size 35.3 KiB, free 364.7 MiB)
26/01/12 03:05:54 INFO BlockManagerInfo: Added broadcast_568_piece0 in memory on 02926ee04bc9:45221 (size: 35.3 KiB, free: 366.1 MiB)
26/01/12 03:05:54 INFO SparkContext: Created broadcast 568 from parquet at <unknown>:0
26/01/12 03:05:54 INFO FileSourceScanExec: Planning scan with bin packing, max size: 34270187 bytes, open cost is considered as scanning 4194304 bytes.
26/01/12 03:05:54 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 03:05:54 INFO DAGScheduler: Got job 379 (parquet at <unknown>:0) with 2 output partitions
26/01/12 03:05:54 INFO DAGScheduler: Final stage: ResultStage 379 (parquet at <unknown>:0)
26/01/12 03:05:54 INFO DAGScheduler: Parents of final stage: List()
26/01/12 03:05:54 INFO DAGScheduler: Missing parents: List()
26/01/12 03:05:54 INFO DAGScheduler: Submitting ResultStage 379 (MapPartitionsRDD[949] at parquet at <unknown>:0), which has no missing parents
26/01/12 03:05:54 INFO MemoryStore: Block broadcast_569 stored as values in memory (estimated size 225.1 KiB, free 364.5 MiB)
26/01/12 03:05:54 INFO MemoryStore: Block broadcast_569_piece0 stored as bytes in memory (estimated size 77.4 KiB, free 364.4 MiB)
26/01/12 03:05:54 INFO BlockManagerInfo: Added broadcast_569_piece0 in memory on 02926ee04bc9:45221 (size: 77.4 KiB, free: 366.0 MiB)
26/01/12 03:05:54 INFO SparkContext: Created broadcast 569 from broadcast at DAGScheduler.scala:1513
26/01/12 03:05:54 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 379 (MapPartitionsRDD[949] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1))
26/01/12 03:05:54 INFO TaskSchedulerImpl: Adding task set 379.0 with 2 tasks resource profile 0
26/01/12 03:05:54 INFO TaskSetManager: Starting task 0.0 in stage 379.0 (TID 615) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 03:05:54 INFO TaskSetManager: Starting task 1.0 in stage 379.0 (TID 616) (172.18.0.5, executor 0, partition 1, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 03:05:54 INFO BlockManagerInfo: Added broadcast_569_piece0 in memory on 172.18.0.5:42453 (size: 77.4 KiB, free: 366.0 MiB)
26/01/12 03:05:54 INFO BlockManagerInfo: Added broadcast_568_piece0 in memory on 172.18.0.5:42453 (size: 35.3 KiB, free: 366.0 MiB)
26/01/12 03:06:00 INFO TaskSetManager: Finished task 1.0 in stage 379.0 (TID 616) in 5150 ms on 172.18.0.5 (executor 0) (1/2)
26/01/12 03:06:01 INFO TaskSetManager: Finished task 0.0 in stage 379.0 (TID 615) in 6218 ms on 172.18.0.5 (executor 0) (2/2)
26/01/12 03:06:01 INFO TaskSchedulerImpl: Removed TaskSet 379.0, whose tasks have all completed, from pool 
26/01/12 03:06:01 INFO DAGScheduler: ResultStage 379 (parquet at <unknown>:0) finished in 6.236 s
26/01/12 03:06:01 INFO DAGScheduler: Job 379 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 03:06:01 INFO TaskSchedulerImpl: Killing all running tasks in stage 379: Stage finished
26/01/12 03:06:01 INFO DAGScheduler: Job 379 finished: parquet at <unknown>:0, took 6.244375 s
26/01/12 03:06:01 INFO FileFormatWriter: Start to commit write Job 3017d017-30f5-4e8f-b3a8-e02d2eadff1f.
26/01/12 03:06:01 INFO FileFormatWriter: Write Job 3017d017-30f5-4e8f-b3a8-e02d2eadff1f committed. Elapsed time: 49 ms.
26/01/12 03:06:01 INFO FileFormatWriter: Finished processing stats for write job 3017d017-30f5-4e8f-b3a8-e02d2eadff1f.
Cargando: yellow_tripdata_2024-11.parquet en hdfs://hadoop-namenode:8020/data/nyc/raw/taxi-trips/2024...
26/01/12 03:06:01 INFO InMemoryFileIndex: It took 8 ms to list leaf files for 1 paths.
26/01/12 03:06:01 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 03:06:01 INFO DAGScheduler: Got job 380 (parquet at <unknown>:0) with 1 output partitions
26/01/12 03:06:01 INFO DAGScheduler: Final stage: ResultStage 380 (parquet at <unknown>:0)
26/01/12 03:06:01 INFO DAGScheduler: Parents of final stage: List()
26/01/12 03:06:01 INFO DAGScheduler: Missing parents: List()
26/01/12 03:06:01 INFO DAGScheduler: Submitting ResultStage 380 (MapPartitionsRDD[951] at parquet at <unknown>:0), which has no missing parents
26/01/12 03:06:01 INFO MemoryStore: Block broadcast_570 stored as values in memory (estimated size 102.6 KiB, free 364.3 MiB)
26/01/12 03:06:01 INFO MemoryStore: Block broadcast_570_piece0 stored as bytes in memory (estimated size 36.8 KiB, free 364.3 MiB)
26/01/12 03:06:01 INFO BlockManagerInfo: Added broadcast_570_piece0 in memory on 02926ee04bc9:45221 (size: 36.8 KiB, free: 366.0 MiB)
26/01/12 03:06:01 INFO SparkContext: Created broadcast 570 from broadcast at DAGScheduler.scala:1513
26/01/12 03:06:01 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 380 (MapPartitionsRDD[951] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0))
26/01/12 03:06:01 INFO TaskSchedulerImpl: Adding task set 380.0 with 1 tasks resource profile 0
26/01/12 03:06:01 INFO TaskSetManager: Starting task 0.0 in stage 380.0 (TID 617) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4607 bytes) taskResourceAssignments Map()
26/01/12 03:06:01 INFO BlockManagerInfo: Added broadcast_570_piece0 in memory on 172.18.0.5:42453 (size: 36.8 KiB, free: 366.0 MiB)
26/01/12 03:06:01 INFO TaskSetManager: Finished task 0.0 in stage 380.0 (TID 617) in 64 ms on 172.18.0.5 (executor 0) (1/1)
26/01/12 03:06:01 INFO TaskSchedulerImpl: Removed TaskSet 380.0, whose tasks have all completed, from pool 
26/01/12 03:06:01 INFO DAGScheduler: ResultStage 380 (parquet at <unknown>:0) finished in 0.075 s
26/01/12 03:06:01 INFO DAGScheduler: Job 380 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 03:06:01 INFO TaskSchedulerImpl: Killing all running tasks in stage 380: Stage finished
26/01/12 03:06:01 INFO DAGScheduler: Job 380 finished: parquet at <unknown>:0, took 0.078748 s
26/01/12 03:06:01 INFO FileSourceStrategy: Pushed Filters: 
26/01/12 03:06:01 INFO FileSourceStrategy: Post-Scan Filters: 
26/01/12 03:06:01 INFO FileSourceStrategy: Output Data Schema: struct<VendorID: int, tpep_pickup_datetime: timestamp, tpep_dropoff_datetime: timestamp, passenger_count: bigint, trip_distance: double ... 17 more fields>
26/01/12 03:06:01 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 03:06:01 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 03:06:01 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 03:06:01 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 03:06:01 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 03:06:01 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 03:06:01 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 03:06:01 INFO MemoryStore: Block broadcast_571 stored as values in memory (estimated size 358.5 KiB, free 363.9 MiB)
26/01/12 03:06:01 INFO MemoryStore: Block broadcast_571_piece0 stored as bytes in memory (estimated size 35.3 KiB, free 363.9 MiB)
26/01/12 03:06:01 INFO BlockManagerInfo: Added broadcast_571_piece0 in memory on 02926ee04bc9:45221 (size: 35.3 KiB, free: 365.9 MiB)
26/01/12 03:06:01 INFO SparkContext: Created broadcast 571 from parquet at <unknown>:0
26/01/12 03:06:01 INFO FileSourceScanExec: Planning scan with bin packing, max size: 32426506 bytes, open cost is considered as scanning 4194304 bytes.
26/01/12 03:06:01 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 03:06:01 INFO DAGScheduler: Got job 381 (parquet at <unknown>:0) with 2 output partitions
26/01/12 03:06:01 INFO DAGScheduler: Final stage: ResultStage 381 (parquet at <unknown>:0)
26/01/12 03:06:01 INFO DAGScheduler: Parents of final stage: List()
26/01/12 03:06:01 INFO DAGScheduler: Missing parents: List()
26/01/12 03:06:01 INFO DAGScheduler: Submitting ResultStage 381 (MapPartitionsRDD[954] at parquet at <unknown>:0), which has no missing parents
26/01/12 03:06:01 INFO MemoryStore: Block broadcast_572 stored as values in memory (estimated size 225.1 KiB, free 363.7 MiB)
26/01/12 03:06:01 INFO MemoryStore: Block broadcast_572_piece0 stored as bytes in memory (estimated size 77.5 KiB, free 363.6 MiB)
26/01/12 03:06:01 INFO BlockManagerInfo: Added broadcast_572_piece0 in memory on 02926ee04bc9:45221 (size: 77.5 KiB, free: 365.9 MiB)
26/01/12 03:06:01 INFO SparkContext: Created broadcast 572 from broadcast at DAGScheduler.scala:1513
26/01/12 03:06:01 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 381 (MapPartitionsRDD[954] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1))
26/01/12 03:06:01 INFO TaskSchedulerImpl: Adding task set 381.0 with 2 tasks resource profile 0
26/01/12 03:06:01 INFO TaskSetManager: Starting task 0.0 in stage 381.0 (TID 618) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 03:06:01 INFO TaskSetManager: Starting task 1.0 in stage 381.0 (TID 619) (172.18.0.5, executor 0, partition 1, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 03:06:01 INFO BlockManagerInfo: Added broadcast_572_piece0 in memory on 172.18.0.5:42453 (size: 77.5 KiB, free: 365.9 MiB)
26/01/12 03:06:01 INFO BlockManagerInfo: Added broadcast_571_piece0 in memory on 172.18.0.5:42453 (size: 35.3 KiB, free: 365.9 MiB)
26/01/12 03:06:06 INFO TaskSetManager: Finished task 1.0 in stage 381.0 (TID 619) in 4614 ms on 172.18.0.5 (executor 0) (1/2)
26/01/12 03:06:07 INFO TaskSetManager: Finished task 0.0 in stage 381.0 (TID 618) in 6069 ms on 172.18.0.5 (executor 0) (2/2)
26/01/12 03:06:07 INFO TaskSchedulerImpl: Removed TaskSet 381.0, whose tasks have all completed, from pool 
26/01/12 03:06:07 INFO DAGScheduler: ResultStage 381 (parquet at <unknown>:0) finished in 6.085 s
26/01/12 03:06:07 INFO DAGScheduler: Job 381 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 03:06:07 INFO TaskSchedulerImpl: Killing all running tasks in stage 381: Stage finished
26/01/12 03:06:07 INFO DAGScheduler: Job 381 finished: parquet at <unknown>:0, took 6.088683 s
26/01/12 03:06:07 INFO FileFormatWriter: Start to commit write Job 7ef82daf-dd77-4b8e-8695-ea71c78d50bb.
26/01/12 03:06:07 INFO FileFormatWriter: Write Job 7ef82daf-dd77-4b8e-8695-ea71c78d50bb committed. Elapsed time: 30 ms.
26/01/12 03:06:07 INFO FileFormatWriter: Finished processing stats for write job 7ef82daf-dd77-4b8e-8695-ea71c78d50bb.
Cargando: yellow_tripdata_2024-12.parquet en hdfs://hadoop-namenode:8020/data/nyc/raw/taxi-trips/2024...
26/01/12 03:06:07 INFO InMemoryFileIndex: It took 7 ms to list leaf files for 1 paths.
26/01/12 03:06:07 INFO BlockManagerInfo: Removed broadcast_569_piece0 on 02926ee04bc9:45221 in memory (size: 77.4 KiB, free: 365.9 MiB)
26/01/12 03:06:07 INFO BlockManagerInfo: Removed broadcast_569_piece0 on 172.18.0.5:42453 in memory (size: 77.4 KiB, free: 365.9 MiB)
26/01/12 03:06:07 INFO BlockManagerInfo: Removed broadcast_568_piece0 on 02926ee04bc9:45221 in memory (size: 35.3 KiB, free: 366.0 MiB)
26/01/12 03:06:07 INFO BlockManagerInfo: Removed broadcast_568_piece0 on 172.18.0.5:42453 in memory (size: 35.3 KiB, free: 366.0 MiB)
26/01/12 03:06:07 INFO BlockManagerInfo: Removed broadcast_565_piece0 on 02926ee04bc9:45221 in memory (size: 35.3 KiB, free: 366.0 MiB)
26/01/12 03:06:07 INFO BlockManagerInfo: Removed broadcast_565_piece0 on 172.18.0.5:42453 in memory (size: 35.3 KiB, free: 366.0 MiB)
26/01/12 03:06:07 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 03:06:07 INFO DAGScheduler: Got job 382 (parquet at <unknown>:0) with 1 output partitions
26/01/12 03:06:07 INFO DAGScheduler: Final stage: ResultStage 382 (parquet at <unknown>:0)
26/01/12 03:06:07 INFO DAGScheduler: Parents of final stage: List()
26/01/12 03:06:07 INFO DAGScheduler: Missing parents: List()
26/01/12 03:06:07 INFO DAGScheduler: Submitting ResultStage 382 (MapPartitionsRDD[956] at parquet at <unknown>:0), which has no missing parents
26/01/12 03:06:07 INFO BlockManagerInfo: Removed broadcast_570_piece0 on 02926ee04bc9:45221 in memory (size: 36.8 KiB, free: 366.0 MiB)
26/01/12 03:06:07 INFO BlockManagerInfo: Removed broadcast_570_piece0 on 172.18.0.5:42453 in memory (size: 36.8 KiB, free: 366.0 MiB)
26/01/12 03:06:07 INFO BlockManagerInfo: Removed broadcast_567_piece0 on 02926ee04bc9:45221 in memory (size: 36.8 KiB, free: 366.1 MiB)
26/01/12 03:06:07 INFO BlockManagerInfo: Removed broadcast_567_piece0 on 172.18.0.5:42453 in memory (size: 36.8 KiB, free: 366.1 MiB)
26/01/12 03:06:07 INFO MemoryStore: Block broadcast_573 stored as values in memory (estimated size 102.6 KiB, free 364.8 MiB)
26/01/12 03:06:07 INFO BlockManagerInfo: Removed broadcast_572_piece0 on 02926ee04bc9:45221 in memory (size: 77.5 KiB, free: 366.2 MiB)
26/01/12 03:06:07 INFO MemoryStore: Block broadcast_573_piece0 stored as bytes in memory (estimated size 36.8 KiB, free 365.1 MiB)
26/01/12 03:06:07 INFO BlockManagerInfo: Added broadcast_573_piece0 in memory on 02926ee04bc9:45221 (size: 36.8 KiB, free: 366.1 MiB)
26/01/12 03:06:07 INFO BlockManagerInfo: Removed broadcast_572_piece0 on 172.18.0.5:42453 in memory (size: 77.5 KiB, free: 366.2 MiB)
26/01/12 03:06:07 INFO SparkContext: Created broadcast 573 from broadcast at DAGScheduler.scala:1513
26/01/12 03:06:07 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 382 (MapPartitionsRDD[956] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0))
26/01/12 03:06:07 INFO TaskSchedulerImpl: Adding task set 382.0 with 1 tasks resource profile 0
26/01/12 03:06:07 INFO TaskSetManager: Starting task 0.0 in stage 382.0 (TID 620) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4607 bytes) taskResourceAssignments Map()
26/01/12 03:06:07 INFO BlockManagerInfo: Added broadcast_573_piece0 in memory on 172.18.0.5:42453 (size: 36.8 KiB, free: 366.1 MiB)
26/01/12 03:06:07 INFO TaskSetManager: Finished task 0.0 in stage 382.0 (TID 620) in 40 ms on 172.18.0.5 (executor 0) (1/1)
26/01/12 03:06:07 INFO TaskSchedulerImpl: Removed TaskSet 382.0, whose tasks have all completed, from pool 
26/01/12 03:06:07 INFO DAGScheduler: ResultStage 382 (parquet at <unknown>:0) finished in 0.052 s
26/01/12 03:06:07 INFO DAGScheduler: Job 382 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 03:06:07 INFO TaskSchedulerImpl: Killing all running tasks in stage 382: Stage finished
26/01/12 03:06:07 INFO DAGScheduler: Job 382 finished: parquet at <unknown>:0, took 0.054402 s
26/01/12 03:06:07 INFO FileSourceStrategy: Pushed Filters: 
26/01/12 03:06:07 INFO FileSourceStrategy: Post-Scan Filters: 
26/01/12 03:06:07 INFO FileSourceStrategy: Output Data Schema: struct<VendorID: int, tpep_pickup_datetime: timestamp, tpep_dropoff_datetime: timestamp, passenger_count: bigint, trip_distance: double ... 17 more fields>
26/01/12 03:06:07 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 03:06:07 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 03:06:07 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 03:06:07 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 03:06:07 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 03:06:07 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 03:06:07 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 03:06:07 INFO MemoryStore: Block broadcast_574 stored as values in memory (estimated size 358.5 KiB, free 364.7 MiB)
26/01/12 03:06:07 INFO MemoryStore: Block broadcast_574_piece0 stored as bytes in memory (estimated size 35.3 KiB, free 364.7 MiB)
26/01/12 03:06:07 INFO BlockManagerInfo: Added broadcast_574_piece0 in memory on 02926ee04bc9:45221 (size: 35.3 KiB, free: 366.1 MiB)
26/01/12 03:06:07 INFO SparkContext: Created broadcast 574 from parquet at <unknown>:0
26/01/12 03:06:07 INFO FileSourceScanExec: Planning scan with bin packing, max size: 32859194 bytes, open cost is considered as scanning 4194304 bytes.
26/01/12 03:06:07 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 03:06:07 INFO DAGScheduler: Got job 383 (parquet at <unknown>:0) with 2 output partitions
26/01/12 03:06:07 INFO DAGScheduler: Final stage: ResultStage 383 (parquet at <unknown>:0)
26/01/12 03:06:07 INFO DAGScheduler: Parents of final stage: List()
26/01/12 03:06:07 INFO DAGScheduler: Missing parents: List()
26/01/12 03:06:07 INFO DAGScheduler: Submitting ResultStage 383 (MapPartitionsRDD[959] at parquet at <unknown>:0), which has no missing parents
26/01/12 03:06:07 INFO MemoryStore: Block broadcast_575 stored as values in memory (estimated size 225.1 KiB, free 364.5 MiB)
26/01/12 03:06:07 INFO MemoryStore: Block broadcast_575_piece0 stored as bytes in memory (estimated size 77.5 KiB, free 364.4 MiB)
26/01/12 03:06:07 INFO BlockManagerInfo: Added broadcast_575_piece0 in memory on 02926ee04bc9:45221 (size: 77.5 KiB, free: 366.0 MiB)
26/01/12 03:06:07 INFO SparkContext: Created broadcast 575 from broadcast at DAGScheduler.scala:1513
26/01/12 03:06:07 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 383 (MapPartitionsRDD[959] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1))
26/01/12 03:06:07 INFO TaskSchedulerImpl: Adding task set 383.0 with 2 tasks resource profile 0
26/01/12 03:06:07 INFO TaskSetManager: Starting task 0.0 in stage 383.0 (TID 621) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 03:06:07 INFO TaskSetManager: Starting task 1.0 in stage 383.0 (TID 622) (172.18.0.5, executor 0, partition 1, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 03:06:07 INFO BlockManagerInfo: Added broadcast_575_piece0 in memory on 172.18.0.5:42453 (size: 77.5 KiB, free: 366.0 MiB)
26/01/12 03:06:07 INFO BlockManagerInfo: Added broadcast_574_piece0 in memory on 172.18.0.5:42453 (size: 35.3 KiB, free: 366.0 MiB)
26/01/12 03:06:12 INFO TaskSetManager: Finished task 1.0 in stage 383.0 (TID 622) in 4994 ms on 172.18.0.5 (executor 0) (1/2)
26/01/12 03:06:14 INFO TaskSetManager: Finished task 0.0 in stage 383.0 (TID 621) in 6415 ms on 172.18.0.5 (executor 0) (2/2)
26/01/12 03:06:14 INFO TaskSchedulerImpl: Removed TaskSet 383.0, whose tasks have all completed, from pool 
26/01/12 03:06:14 INFO DAGScheduler: ResultStage 383 (parquet at <unknown>:0) finished in 6.433 s
26/01/12 03:06:14 INFO DAGScheduler: Job 383 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 03:06:14 INFO TaskSchedulerImpl: Killing all running tasks in stage 383: Stage finished
26/01/12 03:06:14 INFO DAGScheduler: Job 383 finished: parquet at <unknown>:0, took 6.437665 s
26/01/12 03:06:14 INFO FileFormatWriter: Start to commit write Job 8eef4294-5c57-4c51-b7d6-38e932f50f9c.
26/01/12 03:06:14 INFO FileFormatWriter: Write Job 8eef4294-5c57-4c51-b7d6-38e932f50f9c committed. Elapsed time: 33 ms.
26/01/12 03:06:14 INFO FileFormatWriter: Finished processing stats for write job 8eef4294-5c57-4c51-b7d6-38e932f50f9c.
Cargando: yellow_tripdata_2025-01.parquet en hdfs://hadoop-namenode:8020/data/nyc/raw/taxi-trips/2025...
26/01/12 03:06:14 INFO InMemoryFileIndex: It took 7 ms to list leaf files for 1 paths.
26/01/12 03:06:14 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 03:06:14 INFO DAGScheduler: Got job 384 (parquet at <unknown>:0) with 1 output partitions
26/01/12 03:06:14 INFO DAGScheduler: Final stage: ResultStage 384 (parquet at <unknown>:0)
26/01/12 03:06:14 INFO DAGScheduler: Parents of final stage: List()
26/01/12 03:06:14 INFO DAGScheduler: Missing parents: List()
26/01/12 03:06:14 INFO DAGScheduler: Submitting ResultStage 384 (MapPartitionsRDD[961] at parquet at <unknown>:0), which has no missing parents
26/01/12 03:06:14 INFO MemoryStore: Block broadcast_576 stored as values in memory (estimated size 102.6 KiB, free 364.3 MiB)
26/01/12 03:06:14 INFO MemoryStore: Block broadcast_576_piece0 stored as bytes in memory (estimated size 36.8 KiB, free 364.3 MiB)
26/01/12 03:06:14 INFO BlockManagerInfo: Added broadcast_576_piece0 in memory on 02926ee04bc9:45221 (size: 36.8 KiB, free: 366.0 MiB)
26/01/12 03:06:14 INFO SparkContext: Created broadcast 576 from broadcast at DAGScheduler.scala:1513
26/01/12 03:06:14 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 384 (MapPartitionsRDD[961] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0))
26/01/12 03:06:14 INFO TaskSchedulerImpl: Adding task set 384.0 with 1 tasks resource profile 0
26/01/12 03:06:14 INFO TaskSetManager: Starting task 0.0 in stage 384.0 (TID 623) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4607 bytes) taskResourceAssignments Map()
26/01/12 03:06:14 INFO BlockManagerInfo: Added broadcast_576_piece0 in memory on 172.18.0.5:42453 (size: 36.8 KiB, free: 366.0 MiB)
26/01/12 03:06:14 INFO TaskSetManager: Finished task 0.0 in stage 384.0 (TID 623) in 49 ms on 172.18.0.5 (executor 0) (1/1)
26/01/12 03:06:14 INFO TaskSchedulerImpl: Removed TaskSet 384.0, whose tasks have all completed, from pool 
26/01/12 03:06:14 INFO DAGScheduler: ResultStage 384 (parquet at <unknown>:0) finished in 0.062 s
26/01/12 03:06:14 INFO DAGScheduler: Job 384 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 03:06:14 INFO TaskSchedulerImpl: Killing all running tasks in stage 384: Stage finished
26/01/12 03:06:14 INFO DAGScheduler: Job 384 finished: parquet at <unknown>:0, took 0.065665 s
26/01/12 03:06:14 INFO FileSourceStrategy: Pushed Filters: 
26/01/12 03:06:14 INFO FileSourceStrategy: Post-Scan Filters: 
26/01/12 03:06:14 INFO FileSourceStrategy: Output Data Schema: struct<VendorID: int, tpep_pickup_datetime: timestamp, tpep_dropoff_datetime: timestamp, passenger_count: bigint, trip_distance: double ... 18 more fields>
26/01/12 03:06:14 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 03:06:14 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 03:06:14 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 03:06:14 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 03:06:14 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 03:06:14 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 03:06:14 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 03:06:14 INFO CodeGenerator: Code generated in 13.70181 ms
26/01/12 03:06:14 INFO MemoryStore: Block broadcast_577 stored as values in memory (estimated size 358.8 KiB, free 363.9 MiB)
26/01/12 03:06:14 INFO MemoryStore: Block broadcast_577_piece0 stored as bytes in memory (estimated size 35.3 KiB, free 363.9 MiB)
26/01/12 03:06:14 INFO BlockManagerInfo: Added broadcast_577_piece0 in memory on 02926ee04bc9:45221 (size: 35.3 KiB, free: 365.9 MiB)
26/01/12 03:06:14 INFO SparkContext: Created broadcast 577 from parquet at <unknown>:0
26/01/12 03:06:14 INFO FileSourceScanExec: Planning scan with bin packing, max size: 31676271 bytes, open cost is considered as scanning 4194304 bytes.
26/01/12 03:06:14 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 03:06:14 INFO DAGScheduler: Got job 385 (parquet at <unknown>:0) with 2 output partitions
26/01/12 03:06:14 INFO DAGScheduler: Final stage: ResultStage 385 (parquet at <unknown>:0)
26/01/12 03:06:14 INFO DAGScheduler: Parents of final stage: List()
26/01/12 03:06:14 INFO DAGScheduler: Missing parents: List()
26/01/12 03:06:14 INFO DAGScheduler: Submitting ResultStage 385 (MapPartitionsRDD[964] at parquet at <unknown>:0), which has no missing parents
26/01/12 03:06:14 INFO MemoryStore: Block broadcast_578 stored as values in memory (estimated size 225.8 KiB, free 363.7 MiB)
26/01/12 03:06:14 INFO MemoryStore: Block broadcast_578_piece0 stored as bytes in memory (estimated size 77.8 KiB, free 363.6 MiB)
26/01/12 03:06:14 INFO BlockManagerInfo: Added broadcast_578_piece0 in memory on 02926ee04bc9:45221 (size: 77.8 KiB, free: 365.9 MiB)
26/01/12 03:06:14 INFO BlockManagerInfo: Removed broadcast_574_piece0 on 02926ee04bc9:45221 in memory (size: 35.3 KiB, free: 365.9 MiB)
26/01/12 03:06:14 INFO SparkContext: Created broadcast 578 from broadcast at DAGScheduler.scala:1513
26/01/12 03:06:14 INFO BlockManagerInfo: Removed broadcast_574_piece0 on 172.18.0.5:42453 in memory (size: 35.3 KiB, free: 366.0 MiB)
26/01/12 03:06:14 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 385 (MapPartitionsRDD[964] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1))
26/01/12 03:06:14 INFO TaskSchedulerImpl: Adding task set 385.0 with 2 tasks resource profile 0
26/01/12 03:06:14 INFO TaskSetManager: Starting task 0.0 in stage 385.0 (TID 624) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 03:06:14 INFO TaskSetManager: Starting task 1.0 in stage 385.0 (TID 625) (172.18.0.5, executor 0, partition 1, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 03:06:14 INFO BlockManagerInfo: Removed broadcast_575_piece0 on 02926ee04bc9:45221 in memory (size: 77.5 KiB, free: 366.0 MiB)
26/01/12 03:06:14 INFO BlockManagerInfo: Removed broadcast_575_piece0 on 172.18.0.5:42453 in memory (size: 77.5 KiB, free: 366.1 MiB)
26/01/12 03:06:14 INFO BlockManagerInfo: Removed broadcast_573_piece0 on 02926ee04bc9:45221 in memory (size: 36.8 KiB, free: 366.0 MiB)
26/01/12 03:06:14 INFO BlockManagerInfo: Removed broadcast_573_piece0 on 172.18.0.5:42453 in memory (size: 36.8 KiB, free: 366.1 MiB)
26/01/12 03:06:14 INFO BlockManagerInfo: Added broadcast_578_piece0 in memory on 172.18.0.5:42453 (size: 77.8 KiB, free: 366.0 MiB)
26/01/12 03:06:14 INFO BlockManagerInfo: Removed broadcast_576_piece0 on 02926ee04bc9:45221 in memory (size: 36.8 KiB, free: 366.0 MiB)
26/01/12 03:06:14 INFO BlockManagerInfo: Removed broadcast_576_piece0 on 172.18.0.5:42453 in memory (size: 36.8 KiB, free: 366.1 MiB)
26/01/12 03:06:14 INFO BlockManagerInfo: Removed broadcast_571_piece0 on 02926ee04bc9:45221 in memory (size: 35.3 KiB, free: 366.1 MiB)
26/01/12 03:06:14 INFO BlockManagerInfo: Removed broadcast_571_piece0 on 172.18.0.5:42453 in memory (size: 35.3 KiB, free: 366.1 MiB)
26/01/12 03:06:14 INFO BlockManagerInfo: Added broadcast_577_piece0 in memory on 172.18.0.5:42453 (size: 35.3 KiB, free: 366.1 MiB)
26/01/12 03:06:18 INFO TaskSetManager: Finished task 1.0 in stage 385.0 (TID 625) in 4211 ms on 172.18.0.5 (executor 0) (1/2)
26/01/12 03:06:21 INFO TaskSetManager: Finished task 0.0 in stage 385.0 (TID 624) in 6880 ms on 172.18.0.5 (executor 0) (2/2)
26/01/12 03:06:21 INFO TaskSchedulerImpl: Removed TaskSet 385.0, whose tasks have all completed, from pool 
26/01/12 03:06:21 INFO DAGScheduler: ResultStage 385 (parquet at <unknown>:0) finished in 6.920 s
26/01/12 03:06:21 INFO DAGScheduler: Job 385 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 03:06:21 INFO TaskSchedulerImpl: Killing all running tasks in stage 385: Stage finished
26/01/12 03:06:21 INFO DAGScheduler: Job 385 finished: parquet at <unknown>:0, took 6.924176 s
26/01/12 03:06:21 INFO FileFormatWriter: Start to commit write Job 4181b7d3-8351-4a1f-bef1-3a417e753c65.
26/01/12 03:06:21 INFO FileFormatWriter: Write Job 4181b7d3-8351-4a1f-bef1-3a417e753c65 committed. Elapsed time: 36 ms.
26/01/12 03:06:21 INFO FileFormatWriter: Finished processing stats for write job 4181b7d3-8351-4a1f-bef1-3a417e753c65.
Cargando: yellow_tripdata_2025-02.parquet en hdfs://hadoop-namenode:8020/data/nyc/raw/taxi-trips/2025...
26/01/12 03:06:21 INFO InMemoryFileIndex: It took 9 ms to list leaf files for 1 paths.
26/01/12 03:06:21 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 03:06:21 INFO DAGScheduler: Got job 386 (parquet at <unknown>:0) with 1 output partitions
26/01/12 03:06:21 INFO DAGScheduler: Final stage: ResultStage 386 (parquet at <unknown>:0)
26/01/12 03:06:21 INFO DAGScheduler: Parents of final stage: List()
26/01/12 03:06:21 INFO DAGScheduler: Missing parents: List()
26/01/12 03:06:21 INFO DAGScheduler: Submitting ResultStage 386 (MapPartitionsRDD[966] at parquet at <unknown>:0), which has no missing parents
26/01/12 03:06:21 INFO MemoryStore: Block broadcast_579 stored as values in memory (estimated size 102.6 KiB, free 364.8 MiB)
26/01/12 03:06:21 INFO MemoryStore: Block broadcast_579_piece0 stored as bytes in memory (estimated size 36.8 KiB, free 364.8 MiB)
26/01/12 03:06:21 INFO BlockManagerInfo: Added broadcast_579_piece0 in memory on 02926ee04bc9:45221 (size: 36.8 KiB, free: 366.0 MiB)
26/01/12 03:06:21 INFO SparkContext: Created broadcast 579 from broadcast at DAGScheduler.scala:1513
26/01/12 03:06:21 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 386 (MapPartitionsRDD[966] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0))
26/01/12 03:06:21 INFO TaskSchedulerImpl: Adding task set 386.0 with 1 tasks resource profile 0
26/01/12 03:06:21 INFO TaskSetManager: Starting task 0.0 in stage 386.0 (TID 626) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4607 bytes) taskResourceAssignments Map()
26/01/12 03:06:21 INFO BlockManagerInfo: Added broadcast_579_piece0 in memory on 172.18.0.5:42453 (size: 36.8 KiB, free: 366.0 MiB)
26/01/12 03:06:21 INFO TaskSetManager: Finished task 0.0 in stage 386.0 (TID 626) in 61 ms on 172.18.0.5 (executor 0) (1/1)
26/01/12 03:06:21 INFO TaskSchedulerImpl: Removed TaskSet 386.0, whose tasks have all completed, from pool 
26/01/12 03:06:21 INFO DAGScheduler: ResultStage 386 (parquet at <unknown>:0) finished in 0.074 s
26/01/12 03:06:21 INFO DAGScheduler: Job 386 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 03:06:21 INFO TaskSchedulerImpl: Killing all running tasks in stage 386: Stage finished
26/01/12 03:06:21 INFO DAGScheduler: Job 386 finished: parquet at <unknown>:0, took 0.078001 s
26/01/12 03:06:21 INFO FileSourceStrategy: Pushed Filters: 
26/01/12 03:06:21 INFO FileSourceStrategy: Post-Scan Filters: 
26/01/12 03:06:21 INFO FileSourceStrategy: Output Data Schema: struct<VendorID: int, tpep_pickup_datetime: timestamp, tpep_dropoff_datetime: timestamp, passenger_count: bigint, trip_distance: double ... 18 more fields>
26/01/12 03:06:21 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 03:06:21 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 03:06:21 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 03:06:21 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 03:06:21 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 03:06:21 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 03:06:21 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 03:06:21 INFO MemoryStore: Block broadcast_580 stored as values in memory (estimated size 358.8 KiB, free 364.5 MiB)
26/01/12 03:06:21 INFO MemoryStore: Block broadcast_580_piece0 stored as bytes in memory (estimated size 35.3 KiB, free 364.4 MiB)
26/01/12 03:06:21 INFO BlockManagerInfo: Added broadcast_580_piece0 in memory on 02926ee04bc9:45221 (size: 35.3 KiB, free: 366.0 MiB)
26/01/12 03:06:21 INFO SparkContext: Created broadcast 580 from parquet at <unknown>:0
26/01/12 03:06:21 INFO FileSourceScanExec: Planning scan with bin packing, max size: 32268695 bytes, open cost is considered as scanning 4194304 bytes.
26/01/12 03:06:21 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 03:06:21 INFO DAGScheduler: Got job 387 (parquet at <unknown>:0) with 2 output partitions
26/01/12 03:06:21 INFO DAGScheduler: Final stage: ResultStage 387 (parquet at <unknown>:0)
26/01/12 03:06:21 INFO DAGScheduler: Parents of final stage: List()
26/01/12 03:06:21 INFO DAGScheduler: Missing parents: List()
26/01/12 03:06:21 INFO DAGScheduler: Submitting ResultStage 387 (MapPartitionsRDD[969] at parquet at <unknown>:0), which has no missing parents
26/01/12 03:06:21 INFO MemoryStore: Block broadcast_581 stored as values in memory (estimated size 225.8 KiB, free 364.2 MiB)
26/01/12 03:06:21 INFO MemoryStore: Block broadcast_581_piece0 stored as bytes in memory (estimated size 77.8 KiB, free 364.1 MiB)
26/01/12 03:06:21 INFO BlockManagerInfo: Added broadcast_581_piece0 in memory on 02926ee04bc9:45221 (size: 77.8 KiB, free: 365.9 MiB)
26/01/12 03:06:21 INFO SparkContext: Created broadcast 581 from broadcast at DAGScheduler.scala:1513
26/01/12 03:06:21 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 387 (MapPartitionsRDD[969] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1))
26/01/12 03:06:21 INFO TaskSchedulerImpl: Adding task set 387.0 with 2 tasks resource profile 0
26/01/12 03:06:21 INFO TaskSetManager: Starting task 0.0 in stage 387.0 (TID 627) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 03:06:21 INFO TaskSetManager: Starting task 1.0 in stage 387.0 (TID 628) (172.18.0.5, executor 0, partition 1, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 03:06:21 INFO BlockManagerInfo: Added broadcast_581_piece0 in memory on 172.18.0.5:42453 (size: 77.8 KiB, free: 366.0 MiB)
26/01/12 03:06:21 INFO BlockManagerInfo: Added broadcast_580_piece0 in memory on 172.18.0.5:42453 (size: 35.3 KiB, free: 365.9 MiB)
26/01/12 03:06:26 INFO TaskSetManager: Finished task 1.0 in stage 387.0 (TID 628) in 4680 ms on 172.18.0.5 (executor 0) (1/2)
26/01/12 03:06:27 INFO TaskSetManager: Finished task 0.0 in stage 387.0 (TID 627) in 6187 ms on 172.18.0.5 (executor 0) (2/2)
26/01/12 03:06:27 INFO TaskSchedulerImpl: Removed TaskSet 387.0, whose tasks have all completed, from pool 
26/01/12 03:06:27 INFO DAGScheduler: ResultStage 387 (parquet at <unknown>:0) finished in 6.207 s
26/01/12 03:06:27 INFO DAGScheduler: Job 387 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 03:06:27 INFO TaskSchedulerImpl: Killing all running tasks in stage 387: Stage finished
26/01/12 03:06:27 INFO DAGScheduler: Job 387 finished: parquet at <unknown>:0, took 6.210903 s
26/01/12 03:06:27 INFO FileFormatWriter: Start to commit write Job 6e47f4d9-81b0-48f3-907e-39c7d8cad23e.
26/01/12 03:06:27 INFO FileFormatWriter: Write Job 6e47f4d9-81b0-48f3-907e-39c7d8cad23e committed. Elapsed time: 33 ms.
26/01/12 03:06:27 INFO FileFormatWriter: Finished processing stats for write job 6e47f4d9-81b0-48f3-907e-39c7d8cad23e.
Cargando: yellow_tripdata_2025-03.parquet en hdfs://hadoop-namenode:8020/data/nyc/raw/taxi-trips/2025...
26/01/12 03:06:27 INFO InMemoryFileIndex: It took 6 ms to list leaf files for 1 paths.
26/01/12 03:06:27 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 03:06:27 INFO DAGScheduler: Got job 388 (parquet at <unknown>:0) with 1 output partitions
26/01/12 03:06:27 INFO DAGScheduler: Final stage: ResultStage 388 (parquet at <unknown>:0)
26/01/12 03:06:27 INFO DAGScheduler: Parents of final stage: List()
26/01/12 03:06:27 INFO DAGScheduler: Missing parents: List()
26/01/12 03:06:27 INFO DAGScheduler: Submitting ResultStage 388 (MapPartitionsRDD[971] at parquet at <unknown>:0), which has no missing parents
26/01/12 03:06:27 INFO MemoryStore: Block broadcast_582 stored as values in memory (estimated size 102.6 KiB, free 364.0 MiB)
26/01/12 03:06:27 INFO MemoryStore: Block broadcast_582_piece0 stored as bytes in memory (estimated size 36.8 KiB, free 364.0 MiB)
26/01/12 03:06:27 INFO BlockManagerInfo: Added broadcast_582_piece0 in memory on 02926ee04bc9:45221 (size: 36.8 KiB, free: 365.9 MiB)
26/01/12 03:06:27 INFO SparkContext: Created broadcast 582 from broadcast at DAGScheduler.scala:1513
26/01/12 03:06:27 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 388 (MapPartitionsRDD[971] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0))
26/01/12 03:06:27 INFO TaskSchedulerImpl: Adding task set 388.0 with 1 tasks resource profile 0
26/01/12 03:06:27 INFO TaskSetManager: Starting task 0.0 in stage 388.0 (TID 629) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4607 bytes) taskResourceAssignments Map()
26/01/12 03:06:27 INFO BlockManagerInfo: Added broadcast_582_piece0 in memory on 172.18.0.5:42453 (size: 36.8 KiB, free: 365.9 MiB)
26/01/12 03:06:28 INFO TaskSetManager: Finished task 0.0 in stage 388.0 (TID 629) in 44 ms on 172.18.0.5 (executor 0) (1/1)
26/01/12 03:06:28 INFO TaskSchedulerImpl: Removed TaskSet 388.0, whose tasks have all completed, from pool 
26/01/12 03:06:28 INFO DAGScheduler: ResultStage 388 (parquet at <unknown>:0) finished in 0.054 s
26/01/12 03:06:28 INFO DAGScheduler: Job 388 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 03:06:28 INFO TaskSchedulerImpl: Killing all running tasks in stage 388: Stage finished
26/01/12 03:06:28 INFO DAGScheduler: Job 388 finished: parquet at <unknown>:0, took 0.056937 s
26/01/12 03:06:28 INFO FileSourceStrategy: Pushed Filters: 
26/01/12 03:06:28 INFO FileSourceStrategy: Post-Scan Filters: 
26/01/12 03:06:28 INFO FileSourceStrategy: Output Data Schema: struct<VendorID: int, tpep_pickup_datetime: timestamp, tpep_dropoff_datetime: timestamp, passenger_count: bigint, trip_distance: double ... 18 more fields>
26/01/12 03:06:28 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 03:06:28 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 03:06:28 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 03:06:28 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 03:06:28 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 03:06:28 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 03:06:28 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 03:06:28 INFO MemoryStore: Block broadcast_583 stored as values in memory (estimated size 358.8 KiB, free 363.6 MiB)
26/01/12 03:06:28 INFO MemoryStore: Block broadcast_583_piece0 stored as bytes in memory (estimated size 35.3 KiB, free 363.6 MiB)
26/01/12 03:06:28 INFO BlockManagerInfo: Added broadcast_583_piece0 in memory on 02926ee04bc9:45221 (size: 35.3 KiB, free: 365.9 MiB)
26/01/12 03:06:28 INFO SparkContext: Created broadcast 583 from parquet at <unknown>:0
26/01/12 03:06:28 INFO FileSourceScanExec: Planning scan with bin packing, max size: 37079524 bytes, open cost is considered as scanning 4194304 bytes.
26/01/12 03:06:28 INFO BlockManagerInfo: Removed broadcast_582_piece0 on 02926ee04bc9:45221 in memory (size: 36.8 KiB, free: 365.9 MiB)
26/01/12 03:06:28 INFO BlockManagerInfo: Removed broadcast_582_piece0 on 172.18.0.5:42453 in memory (size: 36.8 KiB, free: 365.9 MiB)
26/01/12 03:06:28 INFO BlockManagerInfo: Removed broadcast_581_piece0 on 02926ee04bc9:45221 in memory (size: 77.8 KiB, free: 366.0 MiB)
26/01/12 03:06:28 INFO BlockManagerInfo: Removed broadcast_581_piece0 on 172.18.0.5:42453 in memory (size: 77.8 KiB, free: 366.0 MiB)
26/01/12 03:06:28 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 03:06:28 INFO DAGScheduler: Got job 389 (parquet at <unknown>:0) with 2 output partitions
26/01/12 03:06:28 INFO DAGScheduler: Final stage: ResultStage 389 (parquet at <unknown>:0)
26/01/12 03:06:28 INFO DAGScheduler: Parents of final stage: List()
26/01/12 03:06:28 INFO DAGScheduler: Missing parents: List()
26/01/12 03:06:28 INFO DAGScheduler: Submitting ResultStage 389 (MapPartitionsRDD[974] at parquet at <unknown>:0), which has no missing parents
26/01/12 03:06:28 INFO BlockManagerInfo: Removed broadcast_577_piece0 on 02926ee04bc9:45221 in memory (size: 35.3 KiB, free: 366.0 MiB)
26/01/12 03:06:28 INFO BlockManagerInfo: Removed broadcast_577_piece0 on 172.18.0.5:42453 in memory (size: 35.3 KiB, free: 366.0 MiB)
26/01/12 03:06:28 INFO BlockManagerInfo: Removed broadcast_580_piece0 on 02926ee04bc9:45221 in memory (size: 35.3 KiB, free: 366.0 MiB)
26/01/12 03:06:28 INFO BlockManagerInfo: Removed broadcast_580_piece0 on 172.18.0.5:42453 in memory (size: 35.3 KiB, free: 366.1 MiB)
26/01/12 03:06:28 INFO BlockManagerInfo: Removed broadcast_578_piece0 on 02926ee04bc9:45221 in memory (size: 77.8 KiB, free: 366.1 MiB)
26/01/12 03:06:28 INFO BlockManagerInfo: Removed broadcast_578_piece0 on 172.18.0.5:42453 in memory (size: 77.8 KiB, free: 366.2 MiB)
26/01/12 03:06:28 INFO BlockManagerInfo: Removed broadcast_579_piece0 on 02926ee04bc9:45221 in memory (size: 36.8 KiB, free: 366.2 MiB)
26/01/12 03:06:28 INFO MemoryStore: Block broadcast_584 stored as values in memory (estimated size 225.8 KiB, free 364.9 MiB)
26/01/12 03:06:28 INFO BlockManagerInfo: Removed broadcast_579_piece0 on 172.18.0.5:42453 in memory (size: 36.8 KiB, free: 366.2 MiB)
26/01/12 03:06:28 INFO MemoryStore: Block broadcast_584_piece0 stored as bytes in memory (estimated size 77.8 KiB, free 364.9 MiB)
26/01/12 03:06:28 INFO BlockManagerInfo: Added broadcast_584_piece0 in memory on 02926ee04bc9:45221 (size: 77.8 KiB, free: 366.1 MiB)
26/01/12 03:06:28 INFO SparkContext: Created broadcast 584 from broadcast at DAGScheduler.scala:1513
26/01/12 03:06:28 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 389 (MapPartitionsRDD[974] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1))
26/01/12 03:06:28 INFO TaskSchedulerImpl: Adding task set 389.0 with 2 tasks resource profile 0
26/01/12 03:06:28 INFO TaskSetManager: Starting task 0.0 in stage 389.0 (TID 630) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 03:06:28 INFO TaskSetManager: Starting task 1.0 in stage 389.0 (TID 631) (172.18.0.5, executor 0, partition 1, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 03:06:28 INFO BlockManagerInfo: Added broadcast_584_piece0 in memory on 172.18.0.5:42453 (size: 77.8 KiB, free: 366.1 MiB)
26/01/12 03:06:28 INFO BlockManagerInfo: Added broadcast_583_piece0 in memory on 172.18.0.5:42453 (size: 35.3 KiB, free: 366.1 MiB)
26/01/12 03:06:34 INFO TaskSetManager: Finished task 1.0 in stage 389.0 (TID 631) in 5950 ms on 172.18.0.5 (executor 0) (1/2)
26/01/12 03:06:34 INFO TaskSetManager: Finished task 0.0 in stage 389.0 (TID 630) in 6327 ms on 172.18.0.5 (executor 0) (2/2)
26/01/12 03:06:34 INFO TaskSchedulerImpl: Removed TaskSet 389.0, whose tasks have all completed, from pool 
26/01/12 03:06:34 INFO DAGScheduler: ResultStage 389 (parquet at <unknown>:0) finished in 6.349 s
26/01/12 03:06:34 INFO DAGScheduler: Job 389 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 03:06:34 INFO TaskSchedulerImpl: Killing all running tasks in stage 389: Stage finished
26/01/12 03:06:34 INFO DAGScheduler: Job 389 finished: parquet at <unknown>:0, took 6.353001 s
26/01/12 03:06:34 INFO FileFormatWriter: Start to commit write Job b500db97-e451-4e55-9410-43cf391c75cb.
26/01/12 03:06:34 INFO FileFormatWriter: Write Job b500db97-e451-4e55-9410-43cf391c75cb committed. Elapsed time: 28 ms.
26/01/12 03:06:34 INFO FileFormatWriter: Finished processing stats for write job b500db97-e451-4e55-9410-43cf391c75cb.
Cargando: yellow_tripdata_2025-04.parquet en hdfs://hadoop-namenode:8020/data/nyc/raw/taxi-trips/2025...
26/01/12 03:06:34 INFO InMemoryFileIndex: It took 5 ms to list leaf files for 1 paths.
26/01/12 03:06:34 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 03:06:34 INFO DAGScheduler: Got job 390 (parquet at <unknown>:0) with 1 output partitions
26/01/12 03:06:34 INFO DAGScheduler: Final stage: ResultStage 390 (parquet at <unknown>:0)
26/01/12 03:06:34 INFO DAGScheduler: Parents of final stage: List()
26/01/12 03:06:34 INFO DAGScheduler: Missing parents: List()
26/01/12 03:06:34 INFO DAGScheduler: Submitting ResultStage 390 (MapPartitionsRDD[976] at parquet at <unknown>:0), which has no missing parents
26/01/12 03:06:34 INFO MemoryStore: Block broadcast_585 stored as values in memory (estimated size 102.6 KiB, free 364.8 MiB)
26/01/12 03:06:34 INFO MemoryStore: Block broadcast_585_piece0 stored as bytes in memory (estimated size 36.8 KiB, free 364.8 MiB)
26/01/12 03:06:34 INFO BlockManagerInfo: Added broadcast_585_piece0 in memory on 02926ee04bc9:45221 (size: 36.8 KiB, free: 366.0 MiB)
26/01/12 03:06:34 INFO SparkContext: Created broadcast 585 from broadcast at DAGScheduler.scala:1513
26/01/12 03:06:34 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 390 (MapPartitionsRDD[976] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0))
26/01/12 03:06:34 INFO TaskSchedulerImpl: Adding task set 390.0 with 1 tasks resource profile 0
26/01/12 03:06:34 INFO TaskSetManager: Starting task 0.0 in stage 390.0 (TID 632) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4607 bytes) taskResourceAssignments Map()
26/01/12 03:06:34 INFO BlockManagerInfo: Added broadcast_585_piece0 in memory on 172.18.0.5:42453 (size: 36.8 KiB, free: 366.0 MiB)
26/01/12 03:06:34 INFO TaskSetManager: Finished task 0.0 in stage 390.0 (TID 632) in 44 ms on 172.18.0.5 (executor 0) (1/1)
26/01/12 03:06:34 INFO TaskSchedulerImpl: Removed TaskSet 390.0, whose tasks have all completed, from pool 
26/01/12 03:06:34 INFO DAGScheduler: ResultStage 390 (parquet at <unknown>:0) finished in 0.054 s
26/01/12 03:06:34 INFO DAGScheduler: Job 390 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 03:06:34 INFO TaskSchedulerImpl: Killing all running tasks in stage 390: Stage finished
26/01/12 03:06:34 INFO DAGScheduler: Job 390 finished: parquet at <unknown>:0, took 0.056698 s
26/01/12 03:06:34 INFO FileSourceStrategy: Pushed Filters: 
26/01/12 03:06:34 INFO FileSourceStrategy: Post-Scan Filters: 
26/01/12 03:06:34 INFO FileSourceStrategy: Output Data Schema: struct<VendorID: int, tpep_pickup_datetime: timestamp, tpep_dropoff_datetime: timestamp, passenger_count: bigint, trip_distance: double ... 18 more fields>
26/01/12 03:06:34 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 03:06:34 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 03:06:34 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 03:06:34 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 03:06:34 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 03:06:34 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 03:06:34 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 03:06:34 INFO MemoryStore: Block broadcast_586 stored as values in memory (estimated size 358.8 KiB, free 364.5 MiB)
26/01/12 03:06:34 INFO MemoryStore: Block broadcast_586_piece0 stored as bytes in memory (estimated size 35.3 KiB, free 364.4 MiB)
26/01/12 03:06:34 INFO BlockManagerInfo: Added broadcast_586_piece0 in memory on 02926ee04bc9:45221 (size: 35.3 KiB, free: 366.0 MiB)
26/01/12 03:06:34 INFO SparkContext: Created broadcast 586 from parquet at <unknown>:0
26/01/12 03:06:34 INFO FileSourceScanExec: Planning scan with bin packing, max size: 35773564 bytes, open cost is considered as scanning 4194304 bytes.
26/01/12 03:06:34 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 03:06:34 INFO DAGScheduler: Got job 391 (parquet at <unknown>:0) with 2 output partitions
26/01/12 03:06:34 INFO DAGScheduler: Final stage: ResultStage 391 (parquet at <unknown>:0)
26/01/12 03:06:34 INFO DAGScheduler: Parents of final stage: List()
26/01/12 03:06:34 INFO DAGScheduler: Missing parents: List()
26/01/12 03:06:34 INFO DAGScheduler: Submitting ResultStage 391 (MapPartitionsRDD[979] at parquet at <unknown>:0), which has no missing parents
26/01/12 03:06:34 INFO MemoryStore: Block broadcast_587 stored as values in memory (estimated size 225.8 KiB, free 364.2 MiB)
26/01/12 03:06:34 INFO MemoryStore: Block broadcast_587_piece0 stored as bytes in memory (estimated size 77.8 KiB, free 364.1 MiB)
26/01/12 03:06:34 INFO BlockManagerInfo: Added broadcast_587_piece0 in memory on 02926ee04bc9:45221 (size: 77.8 KiB, free: 365.9 MiB)
26/01/12 03:06:34 INFO SparkContext: Created broadcast 587 from broadcast at DAGScheduler.scala:1513
26/01/12 03:06:34 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 391 (MapPartitionsRDD[979] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1))
26/01/12 03:06:34 INFO TaskSchedulerImpl: Adding task set 391.0 with 2 tasks resource profile 0
26/01/12 03:06:34 INFO TaskSetManager: Starting task 0.0 in stage 391.0 (TID 633) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 03:06:34 INFO TaskSetManager: Starting task 1.0 in stage 391.0 (TID 634) (172.18.0.5, executor 0, partition 1, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 03:06:34 INFO BlockManagerInfo: Added broadcast_587_piece0 in memory on 172.18.0.5:42453 (size: 77.8 KiB, free: 366.0 MiB)
26/01/12 03:06:34 INFO BlockManagerInfo: Added broadcast_586_piece0 in memory on 172.18.0.5:42453 (size: 35.3 KiB, free: 365.9 MiB)
26/01/12 03:06:40 INFO TaskSetManager: Finished task 1.0 in stage 391.0 (TID 634) in 5595 ms on 172.18.0.5 (executor 0) (1/2)
26/01/12 03:06:41 INFO TaskSetManager: Finished task 0.0 in stage 391.0 (TID 633) in 6551 ms on 172.18.0.5 (executor 0) (2/2)
26/01/12 03:06:41 INFO TaskSchedulerImpl: Removed TaskSet 391.0, whose tasks have all completed, from pool 
26/01/12 03:06:41 INFO DAGScheduler: ResultStage 391 (parquet at <unknown>:0) finished in 6.571 s
26/01/12 03:06:41 INFO DAGScheduler: Job 391 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 03:06:41 INFO TaskSchedulerImpl: Killing all running tasks in stage 391: Stage finished
26/01/12 03:06:41 INFO DAGScheduler: Job 391 finished: parquet at <unknown>:0, took 6.575075 s
26/01/12 03:06:41 INFO FileFormatWriter: Start to commit write Job aa1bce71-a5c9-488b-8c70-137d7cd422dd.
26/01/12 03:06:41 INFO FileFormatWriter: Write Job aa1bce71-a5c9-488b-8c70-137d7cd422dd committed. Elapsed time: 25 ms.
26/01/12 03:06:41 INFO FileFormatWriter: Finished processing stats for write job aa1bce71-a5c9-488b-8c70-137d7cd422dd.
Cargando: yellow_tripdata_2025-05.parquet en hdfs://hadoop-namenode:8020/data/nyc/raw/taxi-trips/2025...
26/01/12 03:06:41 INFO InMemoryFileIndex: It took 6 ms to list leaf files for 1 paths.
26/01/12 03:06:41 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 03:06:41 INFO DAGScheduler: Got job 392 (parquet at <unknown>:0) with 1 output partitions
26/01/12 03:06:41 INFO DAGScheduler: Final stage: ResultStage 392 (parquet at <unknown>:0)
26/01/12 03:06:41 INFO DAGScheduler: Parents of final stage: List()
26/01/12 03:06:41 INFO DAGScheduler: Missing parents: List()
26/01/12 03:06:41 INFO DAGScheduler: Submitting ResultStage 392 (MapPartitionsRDD[981] at parquet at <unknown>:0), which has no missing parents
26/01/12 03:06:41 INFO MemoryStore: Block broadcast_588 stored as values in memory (estimated size 102.6 KiB, free 364.0 MiB)
26/01/12 03:06:41 INFO MemoryStore: Block broadcast_588_piece0 stored as bytes in memory (estimated size 36.8 KiB, free 364.0 MiB)
26/01/12 03:06:41 INFO BlockManagerInfo: Added broadcast_588_piece0 in memory on 02926ee04bc9:45221 (size: 36.8 KiB, free: 365.9 MiB)
26/01/12 03:06:41 INFO SparkContext: Created broadcast 588 from broadcast at DAGScheduler.scala:1513
26/01/12 03:06:41 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 392 (MapPartitionsRDD[981] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0))
26/01/12 03:06:41 INFO TaskSchedulerImpl: Adding task set 392.0 with 1 tasks resource profile 0
26/01/12 03:06:41 INFO TaskSetManager: Starting task 0.0 in stage 392.0 (TID 635) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4607 bytes) taskResourceAssignments Map()
26/01/12 03:06:41 INFO BlockManagerInfo: Added broadcast_588_piece0 in memory on 172.18.0.5:42453 (size: 36.8 KiB, free: 365.9 MiB)
26/01/12 03:06:41 INFO TaskSetManager: Finished task 0.0 in stage 392.0 (TID 635) in 44 ms on 172.18.0.5 (executor 0) (1/1)
26/01/12 03:06:41 INFO TaskSchedulerImpl: Removed TaskSet 392.0, whose tasks have all completed, from pool 
26/01/12 03:06:41 INFO DAGScheduler: ResultStage 392 (parquet at <unknown>:0) finished in 0.055 s
26/01/12 03:06:41 INFO DAGScheduler: Job 392 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 03:06:41 INFO TaskSchedulerImpl: Killing all running tasks in stage 392: Stage finished
26/01/12 03:06:41 INFO DAGScheduler: Job 392 finished: parquet at <unknown>:0, took 0.057376 s
26/01/12 03:06:41 INFO FileSourceStrategy: Pushed Filters: 
26/01/12 03:06:41 INFO FileSourceStrategy: Post-Scan Filters: 
26/01/12 03:06:41 INFO FileSourceStrategy: Output Data Schema: struct<VendorID: int, tpep_pickup_datetime: timestamp, tpep_dropoff_datetime: timestamp, passenger_count: bigint, trip_distance: double ... 18 more fields>
26/01/12 03:06:41 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 03:06:41 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 03:06:41 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 03:06:41 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 03:06:41 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 03:06:41 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 03:06:41 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 03:06:41 INFO MemoryStore: Block broadcast_589 stored as values in memory (estimated size 358.8 KiB, free 363.6 MiB)
26/01/12 03:06:41 INFO BlockManagerInfo: Removed broadcast_586_piece0 on 02926ee04bc9:45221 in memory (size: 35.3 KiB, free: 365.9 MiB)
26/01/12 03:06:41 INFO MemoryStore: Block broadcast_589_piece0 stored as bytes in memory (estimated size 35.3 KiB, free 363.6 MiB)
26/01/12 03:06:41 INFO BlockManagerInfo: Removed broadcast_586_piece0 on 172.18.0.5:42453 in memory (size: 35.3 KiB, free: 365.9 MiB)
26/01/12 03:06:41 INFO BlockManagerInfo: Added broadcast_589_piece0 in memory on 02926ee04bc9:45221 (size: 35.3 KiB, free: 365.9 MiB)
26/01/12 03:06:41 INFO SparkContext: Created broadcast 589 from parquet at <unknown>:0
26/01/12 03:06:41 INFO FileSourceScanExec: Planning scan with bin packing, max size: 41016084 bytes, open cost is considered as scanning 4194304 bytes.
26/01/12 03:06:41 INFO BlockManagerInfo: Removed broadcast_585_piece0 on 02926ee04bc9:45221 in memory (size: 36.8 KiB, free: 365.9 MiB)
26/01/12 03:06:41 INFO BlockManagerInfo: Removed broadcast_585_piece0 on 172.18.0.5:42453 in memory (size: 36.8 KiB, free: 366.0 MiB)
26/01/12 03:06:41 INFO BlockManagerInfo: Removed broadcast_584_piece0 on 02926ee04bc9:45221 in memory (size: 77.8 KiB, free: 366.0 MiB)
26/01/12 03:06:41 INFO BlockManagerInfo: Removed broadcast_584_piece0 on 172.18.0.5:42453 in memory (size: 77.8 KiB, free: 366.0 MiB)
26/01/12 03:06:41 INFO BlockManagerInfo: Removed broadcast_587_piece0 on 02926ee04bc9:45221 in memory (size: 77.8 KiB, free: 366.1 MiB)
26/01/12 03:06:41 INFO BlockManagerInfo: Removed broadcast_587_piece0 on 172.18.0.5:42453 in memory (size: 77.8 KiB, free: 366.1 MiB)
26/01/12 03:06:41 INFO BlockManagerInfo: Removed broadcast_583_piece0 on 02926ee04bc9:45221 in memory (size: 35.3 KiB, free: 366.1 MiB)
26/01/12 03:06:41 INFO BlockManagerInfo: Removed broadcast_583_piece0 on 172.18.0.5:42453 in memory (size: 35.3 KiB, free: 366.2 MiB)
26/01/12 03:06:41 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 03:06:41 INFO DAGScheduler: Got job 393 (parquet at <unknown>:0) with 2 output partitions
26/01/12 03:06:41 INFO DAGScheduler: Final stage: ResultStage 393 (parquet at <unknown>:0)
26/01/12 03:06:41 INFO DAGScheduler: Parents of final stage: List()
26/01/12 03:06:41 INFO DAGScheduler: Missing parents: List()
26/01/12 03:06:41 INFO DAGScheduler: Submitting ResultStage 393 (MapPartitionsRDD[984] at parquet at <unknown>:0), which has no missing parents
26/01/12 03:06:41 INFO BlockManagerInfo: Removed broadcast_588_piece0 on 02926ee04bc9:45221 in memory (size: 36.8 KiB, free: 366.2 MiB)
26/01/12 03:06:41 INFO BlockManagerInfo: Removed broadcast_588_piece0 on 172.18.0.5:42453 in memory (size: 36.8 KiB, free: 366.2 MiB)
26/01/12 03:06:41 INFO MemoryStore: Block broadcast_590 stored as values in memory (estimated size 225.8 KiB, free 365.0 MiB)
26/01/12 03:06:41 INFO MemoryStore: Block broadcast_590_piece0 stored as bytes in memory (estimated size 77.8 KiB, free 364.9 MiB)
26/01/12 03:06:41 INFO BlockManagerInfo: Added broadcast_590_piece0 in memory on 02926ee04bc9:45221 (size: 77.8 KiB, free: 366.1 MiB)
26/01/12 03:06:41 INFO SparkContext: Created broadcast 590 from broadcast at DAGScheduler.scala:1513
26/01/12 03:06:41 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 393 (MapPartitionsRDD[984] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1))
26/01/12 03:06:41 INFO TaskSchedulerImpl: Adding task set 393.0 with 2 tasks resource profile 0
26/01/12 03:06:41 INFO TaskSetManager: Starting task 0.0 in stage 393.0 (TID 636) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 03:06:41 INFO TaskSetManager: Starting task 1.0 in stage 393.0 (TID 637) (172.18.0.5, executor 0, partition 1, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 03:06:41 INFO BlockManagerInfo: Added broadcast_590_piece0 in memory on 172.18.0.5:42453 (size: 77.8 KiB, free: 366.1 MiB)
26/01/12 03:06:41 INFO BlockManagerInfo: Added broadcast_589_piece0 in memory on 172.18.0.5:42453 (size: 35.3 KiB, free: 366.1 MiB)
26/01/12 03:06:47 INFO TaskSetManager: Finished task 0.0 in stage 393.0 (TID 636) in 6383 ms on 172.18.0.5 (executor 0) (1/2)
26/01/12 03:06:48 INFO TaskSetManager: Finished task 1.0 in stage 393.0 (TID 637) in 7235 ms on 172.18.0.5 (executor 0) (2/2)
26/01/12 03:06:48 INFO TaskSchedulerImpl: Removed TaskSet 393.0, whose tasks have all completed, from pool 
26/01/12 03:06:48 INFO DAGScheduler: ResultStage 393 (parquet at <unknown>:0) finished in 7.253 s
26/01/12 03:06:48 INFO DAGScheduler: Job 393 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 03:06:48 INFO TaskSchedulerImpl: Killing all running tasks in stage 393: Stage finished
26/01/12 03:06:48 INFO DAGScheduler: Job 393 finished: parquet at <unknown>:0, took 7.255640 s
26/01/12 03:06:48 INFO FileFormatWriter: Start to commit write Job 22a959d8-97f3-4cb0-9484-0fe0dc66d082.
26/01/12 03:06:48 INFO FileFormatWriter: Write Job 22a959d8-97f3-4cb0-9484-0fe0dc66d082 committed. Elapsed time: 33 ms.
26/01/12 03:06:48 INFO FileFormatWriter: Finished processing stats for write job 22a959d8-97f3-4cb0-9484-0fe0dc66d082.
Cargando: yellow_tripdata_2025-06.parquet en hdfs://hadoop-namenode:8020/data/nyc/raw/taxi-trips/2025...
26/01/12 03:06:48 INFO InMemoryFileIndex: It took 6 ms to list leaf files for 1 paths.
26/01/12 03:06:48 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 03:06:48 INFO DAGScheduler: Got job 394 (parquet at <unknown>:0) with 1 output partitions
26/01/12 03:06:48 INFO DAGScheduler: Final stage: ResultStage 394 (parquet at <unknown>:0)
26/01/12 03:06:48 INFO DAGScheduler: Parents of final stage: List()
26/01/12 03:06:48 INFO DAGScheduler: Missing parents: List()
26/01/12 03:06:48 INFO DAGScheduler: Submitting ResultStage 394 (MapPartitionsRDD[986] at parquet at <unknown>:0), which has no missing parents
26/01/12 03:06:48 INFO MemoryStore: Block broadcast_591 stored as values in memory (estimated size 102.6 KiB, free 364.8 MiB)
26/01/12 03:06:48 INFO MemoryStore: Block broadcast_591_piece0 stored as bytes in memory (estimated size 36.8 KiB, free 364.8 MiB)
26/01/12 03:06:48 INFO BlockManagerInfo: Added broadcast_591_piece0 in memory on 02926ee04bc9:45221 (size: 36.8 KiB, free: 366.0 MiB)
26/01/12 03:06:48 INFO SparkContext: Created broadcast 591 from broadcast at DAGScheduler.scala:1513
26/01/12 03:06:48 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 394 (MapPartitionsRDD[986] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0))
26/01/12 03:06:48 INFO TaskSchedulerImpl: Adding task set 394.0 with 1 tasks resource profile 0
26/01/12 03:06:48 INFO TaskSetManager: Starting task 0.0 in stage 394.0 (TID 638) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4607 bytes) taskResourceAssignments Map()
26/01/12 03:06:48 INFO BlockManagerInfo: Added broadcast_591_piece0 in memory on 172.18.0.5:42453 (size: 36.8 KiB, free: 366.0 MiB)
26/01/12 03:06:48 INFO TaskSetManager: Finished task 0.0 in stage 394.0 (TID 638) in 41 ms on 172.18.0.5 (executor 0) (1/1)
26/01/12 03:06:48 INFO TaskSchedulerImpl: Removed TaskSet 394.0, whose tasks have all completed, from pool 
26/01/12 03:06:48 INFO DAGScheduler: ResultStage 394 (parquet at <unknown>:0) finished in 0.051 s
26/01/12 03:06:48 INFO DAGScheduler: Job 394 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 03:06:48 INFO TaskSchedulerImpl: Killing all running tasks in stage 394: Stage finished
26/01/12 03:06:48 INFO DAGScheduler: Job 394 finished: parquet at <unknown>:0, took 0.053600 s
26/01/12 03:06:48 INFO FileSourceStrategy: Pushed Filters: 
26/01/12 03:06:48 INFO FileSourceStrategy: Post-Scan Filters: 
26/01/12 03:06:48 INFO FileSourceStrategy: Output Data Schema: struct<VendorID: int, tpep_pickup_datetime: timestamp, tpep_dropoff_datetime: timestamp, passenger_count: bigint, trip_distance: double ... 18 more fields>
26/01/12 03:06:48 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 03:06:48 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 03:06:48 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 03:06:48 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 03:06:48 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 03:06:48 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 03:06:48 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 03:06:48 INFO MemoryStore: Block broadcast_592 stored as values in memory (estimated size 358.8 KiB, free 364.5 MiB)
26/01/12 03:06:48 INFO MemoryStore: Block broadcast_592_piece0 stored as bytes in memory (estimated size 35.3 KiB, free 364.4 MiB)
26/01/12 03:06:48 INFO BlockManagerInfo: Added broadcast_592_piece0 in memory on 02926ee04bc9:45221 (size: 35.3 KiB, free: 366.0 MiB)
26/01/12 03:06:48 INFO SparkContext: Created broadcast 592 from parquet at <unknown>:0
26/01/12 03:06:48 INFO FileSourceScanExec: Planning scan with bin packing, max size: 38868629 bytes, open cost is considered as scanning 4194304 bytes.
26/01/12 03:06:48 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 03:06:48 INFO DAGScheduler: Got job 395 (parquet at <unknown>:0) with 2 output partitions
26/01/12 03:06:48 INFO DAGScheduler: Final stage: ResultStage 395 (parquet at <unknown>:0)
26/01/12 03:06:48 INFO DAGScheduler: Parents of final stage: List()
26/01/12 03:06:48 INFO DAGScheduler: Missing parents: List()
26/01/12 03:06:48 INFO DAGScheduler: Submitting ResultStage 395 (MapPartitionsRDD[989] at parquet at <unknown>:0), which has no missing parents
26/01/12 03:06:48 INFO MemoryStore: Block broadcast_593 stored as values in memory (estimated size 225.8 KiB, free 364.2 MiB)
26/01/12 03:06:48 INFO MemoryStore: Block broadcast_593_piece0 stored as bytes in memory (estimated size 77.8 KiB, free 364.1 MiB)
26/01/12 03:06:48 INFO BlockManagerInfo: Added broadcast_593_piece0 in memory on 02926ee04bc9:45221 (size: 77.8 KiB, free: 365.9 MiB)
26/01/12 03:06:48 INFO SparkContext: Created broadcast 593 from broadcast at DAGScheduler.scala:1513
26/01/12 03:06:48 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 395 (MapPartitionsRDD[989] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1))
26/01/12 03:06:48 INFO TaskSchedulerImpl: Adding task set 395.0 with 2 tasks resource profile 0
26/01/12 03:06:48 INFO TaskSetManager: Starting task 0.0 in stage 395.0 (TID 639) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 03:06:48 INFO TaskSetManager: Starting task 1.0 in stage 395.0 (TID 640) (172.18.0.5, executor 0, partition 1, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 03:06:48 INFO BlockManagerInfo: Added broadcast_593_piece0 in memory on 172.18.0.5:42453 (size: 77.8 KiB, free: 366.0 MiB)
26/01/12 03:06:48 INFO BlockManagerInfo: Added broadcast_592_piece0 in memory on 172.18.0.5:42453 (size: 35.3 KiB, free: 365.9 MiB)
26/01/12 03:06:55 INFO TaskSetManager: Finished task 1.0 in stage 395.0 (TID 640) in 6307 ms on 172.18.0.5 (executor 0) (1/2)
26/01/12 03:06:55 INFO TaskSetManager: Finished task 0.0 in stage 395.0 (TID 639) in 6753 ms on 172.18.0.5 (executor 0) (2/2)
26/01/12 03:06:55 INFO TaskSchedulerImpl: Removed TaskSet 395.0, whose tasks have all completed, from pool 
26/01/12 03:06:55 INFO DAGScheduler: ResultStage 395 (parquet at <unknown>:0) finished in 6.769 s
26/01/12 03:06:55 INFO DAGScheduler: Job 395 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 03:06:55 INFO TaskSchedulerImpl: Killing all running tasks in stage 395: Stage finished
26/01/12 03:06:55 INFO DAGScheduler: Job 395 finished: parquet at <unknown>:0, took 6.774600 s
26/01/12 03:06:55 INFO FileFormatWriter: Start to commit write Job 597070af-bbfe-4260-98ef-77cbf11d3639.
26/01/12 03:06:55 INFO FileFormatWriter: Write Job 597070af-bbfe-4260-98ef-77cbf11d3639 committed. Elapsed time: 35 ms.
26/01/12 03:06:55 INFO FileFormatWriter: Finished processing stats for write job 597070af-bbfe-4260-98ef-77cbf11d3639.
Cargando: yellow_tripdata_2025-07.parquet en hdfs://hadoop-namenode:8020/data/nyc/raw/taxi-trips/2025...
26/01/12 03:06:55 INFO InMemoryFileIndex: It took 6 ms to list leaf files for 1 paths.
26/01/12 03:06:55 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 03:06:55 INFO DAGScheduler: Got job 396 (parquet at <unknown>:0) with 1 output partitions
26/01/12 03:06:55 INFO DAGScheduler: Final stage: ResultStage 396 (parquet at <unknown>:0)
26/01/12 03:06:55 INFO DAGScheduler: Parents of final stage: List()
26/01/12 03:06:55 INFO DAGScheduler: Missing parents: List()
26/01/12 03:06:55 INFO DAGScheduler: Submitting ResultStage 396 (MapPartitionsRDD[991] at parquet at <unknown>:0), which has no missing parents
26/01/12 03:06:55 INFO MemoryStore: Block broadcast_594 stored as values in memory (estimated size 102.6 KiB, free 364.0 MiB)
26/01/12 03:06:55 INFO MemoryStore: Block broadcast_594_piece0 stored as bytes in memory (estimated size 36.8 KiB, free 364.0 MiB)
26/01/12 03:06:55 INFO BlockManagerInfo: Added broadcast_594_piece0 in memory on 02926ee04bc9:45221 (size: 36.8 KiB, free: 365.9 MiB)
26/01/12 03:06:55 INFO SparkContext: Created broadcast 594 from broadcast at DAGScheduler.scala:1513
26/01/12 03:06:55 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 396 (MapPartitionsRDD[991] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0))
26/01/12 03:06:55 INFO TaskSchedulerImpl: Adding task set 396.0 with 1 tasks resource profile 0
26/01/12 03:06:55 INFO BlockManagerInfo: Removed broadcast_593_piece0 on 02926ee04bc9:45221 in memory (size: 77.8 KiB, free: 366.0 MiB)
26/01/12 03:06:55 INFO BlockManagerInfo: Removed broadcast_593_piece0 on 172.18.0.5:42453 in memory (size: 77.8 KiB, free: 366.0 MiB)
26/01/12 03:06:55 INFO TaskSetManager: Starting task 0.0 in stage 396.0 (TID 641) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4607 bytes) taskResourceAssignments Map()
26/01/12 03:06:55 INFO BlockManagerInfo: Removed broadcast_589_piece0 on 02926ee04bc9:45221 in memory (size: 35.3 KiB, free: 366.0 MiB)
26/01/12 03:06:55 INFO BlockManagerInfo: Removed broadcast_589_piece0 on 172.18.0.5:42453 in memory (size: 35.3 KiB, free: 366.0 MiB)
26/01/12 03:06:55 INFO BlockManagerInfo: Added broadcast_594_piece0 in memory on 172.18.0.5:42453 (size: 36.8 KiB, free: 366.0 MiB)
26/01/12 03:06:55 INFO BlockManagerInfo: Removed broadcast_591_piece0 on 02926ee04bc9:45221 in memory (size: 36.8 KiB, free: 366.0 MiB)
26/01/12 03:06:55 INFO BlockManagerInfo: Removed broadcast_591_piece0 on 172.18.0.5:42453 in memory (size: 36.8 KiB, free: 366.0 MiB)
26/01/12 03:06:55 INFO BlockManagerInfo: Removed broadcast_592_piece0 on 02926ee04bc9:45221 in memory (size: 35.3 KiB, free: 366.1 MiB)
26/01/12 03:06:55 INFO BlockManagerInfo: Removed broadcast_592_piece0 on 172.18.0.5:42453 in memory (size: 35.3 KiB, free: 366.1 MiB)
26/01/12 03:06:55 INFO BlockManagerInfo: Removed broadcast_590_piece0 on 02926ee04bc9:45221 in memory (size: 77.8 KiB, free: 366.2 MiB)
26/01/12 03:06:55 INFO BlockManagerInfo: Removed broadcast_590_piece0 on 172.18.0.5:42453 in memory (size: 77.8 KiB, free: 366.2 MiB)
26/01/12 03:06:55 INFO TaskSetManager: Finished task 0.0 in stage 396.0 (TID 641) in 48 ms on 172.18.0.5 (executor 0) (1/1)
26/01/12 03:06:55 INFO TaskSchedulerImpl: Removed TaskSet 396.0, whose tasks have all completed, from pool 
26/01/12 03:06:55 INFO DAGScheduler: ResultStage 396 (parquet at <unknown>:0) finished in 0.077 s
26/01/12 03:06:55 INFO DAGScheduler: Job 396 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 03:06:55 INFO TaskSchedulerImpl: Killing all running tasks in stage 396: Stage finished
26/01/12 03:06:55 INFO DAGScheduler: Job 396 finished: parquet at <unknown>:0, took 0.080626 s
26/01/12 03:06:55 INFO FileSourceStrategy: Pushed Filters: 
26/01/12 03:06:55 INFO FileSourceStrategy: Post-Scan Filters: 
26/01/12 03:06:55 INFO FileSourceStrategy: Output Data Schema: struct<VendorID: int, tpep_pickup_datetime: timestamp, tpep_dropoff_datetime: timestamp, passenger_count: bigint, trip_distance: double ... 18 more fields>
26/01/12 03:06:55 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 03:06:55 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 03:06:55 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 03:06:55 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 03:06:55 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 03:06:55 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 03:06:55 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 03:06:55 INFO MemoryStore: Block broadcast_595 stored as values in memory (estimated size 358.8 KiB, free 365.1 MiB)
26/01/12 03:06:55 INFO MemoryStore: Block broadcast_595_piece0 stored as bytes in memory (estimated size 35.3 KiB, free 365.1 MiB)
26/01/12 03:06:55 INFO BlockManagerInfo: Added broadcast_595_piece0 in memory on 02926ee04bc9:45221 (size: 35.3 KiB, free: 366.1 MiB)
26/01/12 03:06:55 INFO SparkContext: Created broadcast 595 from parquet at <unknown>:0
26/01/12 03:06:55 INFO FileSourceScanExec: Planning scan with bin packing, max size: 35569016 bytes, open cost is considered as scanning 4194304 bytes.
26/01/12 03:06:55 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 03:06:55 INFO DAGScheduler: Got job 397 (parquet at <unknown>:0) with 2 output partitions
26/01/12 03:06:55 INFO DAGScheduler: Final stage: ResultStage 397 (parquet at <unknown>:0)
26/01/12 03:06:55 INFO DAGScheduler: Parents of final stage: List()
26/01/12 03:06:55 INFO DAGScheduler: Missing parents: List()
26/01/12 03:06:55 INFO DAGScheduler: Submitting ResultStage 397 (MapPartitionsRDD[994] at parquet at <unknown>:0), which has no missing parents
26/01/12 03:06:55 INFO MemoryStore: Block broadcast_596 stored as values in memory (estimated size 225.8 KiB, free 364.9 MiB)
26/01/12 03:06:55 INFO MemoryStore: Block broadcast_596_piece0 stored as bytes in memory (estimated size 77.8 KiB, free 364.8 MiB)
26/01/12 03:06:55 INFO BlockManagerInfo: Added broadcast_596_piece0 in memory on 02926ee04bc9:45221 (size: 77.8 KiB, free: 366.0 MiB)
26/01/12 03:06:55 INFO SparkContext: Created broadcast 596 from broadcast at DAGScheduler.scala:1513
26/01/12 03:06:55 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 397 (MapPartitionsRDD[994] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1))
26/01/12 03:06:55 INFO TaskSchedulerImpl: Adding task set 397.0 with 2 tasks resource profile 0
26/01/12 03:06:55 INFO TaskSetManager: Starting task 0.0 in stage 397.0 (TID 642) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 03:06:55 INFO TaskSetManager: Starting task 1.0 in stage 397.0 (TID 643) (172.18.0.5, executor 0, partition 1, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 03:06:55 INFO BlockManagerInfo: Added broadcast_596_piece0 in memory on 172.18.0.5:42453 (size: 77.8 KiB, free: 366.1 MiB)
26/01/12 03:06:55 INFO BlockManagerInfo: Added broadcast_595_piece0 in memory on 172.18.0.5:42453 (size: 35.3 KiB, free: 366.0 MiB)
26/01/12 03:07:01 INFO TaskSetManager: Finished task 1.0 in stage 397.0 (TID 643) in 5387 ms on 172.18.0.5 (executor 0) (1/2)
26/01/12 03:07:02 INFO TaskSetManager: Finished task 0.0 in stage 397.0 (TID 642) in 6663 ms on 172.18.0.5 (executor 0) (2/2)
26/01/12 03:07:02 INFO TaskSchedulerImpl: Removed TaskSet 397.0, whose tasks have all completed, from pool 
26/01/12 03:07:02 INFO DAGScheduler: ResultStage 397 (parquet at <unknown>:0) finished in 6.679 s
26/01/12 03:07:02 INFO DAGScheduler: Job 397 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 03:07:02 INFO TaskSchedulerImpl: Killing all running tasks in stage 397: Stage finished
26/01/12 03:07:02 INFO DAGScheduler: Job 397 finished: parquet at <unknown>:0, took 6.686965 s
26/01/12 03:07:02 INFO FileFormatWriter: Start to commit write Job f0354a0c-fc27-4b33-8e1d-b4d306a1a741.
26/01/12 03:07:02 INFO FileFormatWriter: Write Job f0354a0c-fc27-4b33-8e1d-b4d306a1a741 committed. Elapsed time: 30 ms.
26/01/12 03:07:02 INFO FileFormatWriter: Finished processing stats for write job f0354a0c-fc27-4b33-8e1d-b4d306a1a741.
Cargando: yellow_tripdata_2025-08.parquet en hdfs://hadoop-namenode:8020/data/nyc/raw/taxi-trips/2025...
26/01/12 03:07:02 INFO InMemoryFileIndex: It took 6 ms to list leaf files for 1 paths.
26/01/12 03:07:02 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 03:07:02 INFO DAGScheduler: Got job 398 (parquet at <unknown>:0) with 1 output partitions
26/01/12 03:07:02 INFO DAGScheduler: Final stage: ResultStage 398 (parquet at <unknown>:0)
26/01/12 03:07:02 INFO DAGScheduler: Parents of final stage: List()
26/01/12 03:07:02 INFO DAGScheduler: Missing parents: List()
26/01/12 03:07:02 INFO DAGScheduler: Submitting ResultStage 398 (MapPartitionsRDD[996] at parquet at <unknown>:0), which has no missing parents
26/01/12 03:07:02 INFO MemoryStore: Block broadcast_597 stored as values in memory (estimated size 102.6 KiB, free 364.7 MiB)
26/01/12 03:07:02 INFO MemoryStore: Block broadcast_597_piece0 stored as bytes in memory (estimated size 36.8 KiB, free 364.7 MiB)
26/01/12 03:07:02 INFO BlockManagerInfo: Added broadcast_597_piece0 in memory on 02926ee04bc9:45221 (size: 36.8 KiB, free: 366.0 MiB)
26/01/12 03:07:02 INFO SparkContext: Created broadcast 597 from broadcast at DAGScheduler.scala:1513
26/01/12 03:07:02 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 398 (MapPartitionsRDD[996] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0))
26/01/12 03:07:02 INFO TaskSchedulerImpl: Adding task set 398.0 with 1 tasks resource profile 0
26/01/12 03:07:02 INFO TaskSetManager: Starting task 0.0 in stage 398.0 (TID 644) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4607 bytes) taskResourceAssignments Map()
26/01/12 03:07:02 INFO BlockManagerInfo: Added broadcast_597_piece0 in memory on 172.18.0.5:42453 (size: 36.8 KiB, free: 366.0 MiB)
26/01/12 03:07:02 INFO TaskSetManager: Finished task 0.0 in stage 398.0 (TID 644) in 44 ms on 172.18.0.5 (executor 0) (1/1)
26/01/12 03:07:02 INFO TaskSchedulerImpl: Removed TaskSet 398.0, whose tasks have all completed, from pool 
26/01/12 03:07:02 INFO DAGScheduler: ResultStage 398 (parquet at <unknown>:0) finished in 0.054 s
26/01/12 03:07:02 INFO DAGScheduler: Job 398 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 03:07:02 INFO TaskSchedulerImpl: Killing all running tasks in stage 398: Stage finished
26/01/12 03:07:02 INFO DAGScheduler: Job 398 finished: parquet at <unknown>:0, took 0.057807 s
26/01/12 03:07:02 INFO FileSourceStrategy: Pushed Filters: 
26/01/12 03:07:02 INFO FileSourceStrategy: Post-Scan Filters: 
26/01/12 03:07:02 INFO FileSourceStrategy: Output Data Schema: struct<VendorID: int, tpep_pickup_datetime: timestamp, tpep_dropoff_datetime: timestamp, passenger_count: bigint, trip_distance: double ... 18 more fields>
26/01/12 03:07:02 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 03:07:02 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 03:07:02 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 03:07:02 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 03:07:02 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 03:07:02 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 03:07:02 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 03:07:02 INFO MemoryStore: Block broadcast_598 stored as values in memory (estimated size 358.8 KiB, free 364.3 MiB)
26/01/12 03:07:02 INFO MemoryStore: Block broadcast_598_piece0 stored as bytes in memory (estimated size 35.3 KiB, free 364.3 MiB)
26/01/12 03:07:02 INFO BlockManagerInfo: Added broadcast_598_piece0 in memory on 02926ee04bc9:45221 (size: 35.3 KiB, free: 366.0 MiB)
26/01/12 03:07:02 INFO SparkContext: Created broadcast 598 from parquet at <unknown>:0
26/01/12 03:07:02 INFO FileSourceScanExec: Planning scan with bin packing, max size: 33244023 bytes, open cost is considered as scanning 4194304 bytes.
26/01/12 03:07:02 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 03:07:02 INFO DAGScheduler: Got job 399 (parquet at <unknown>:0) with 2 output partitions
26/01/12 03:07:02 INFO DAGScheduler: Final stage: ResultStage 399 (parquet at <unknown>:0)
26/01/12 03:07:02 INFO DAGScheduler: Parents of final stage: List()
26/01/12 03:07:02 INFO DAGScheduler: Missing parents: List()
26/01/12 03:07:02 INFO DAGScheduler: Submitting ResultStage 399 (MapPartitionsRDD[999] at parquet at <unknown>:0), which has no missing parents
26/01/12 03:07:02 INFO MemoryStore: Block broadcast_599 stored as values in memory (estimated size 225.8 KiB, free 364.1 MiB)
26/01/12 03:07:02 INFO MemoryStore: Block broadcast_599_piece0 stored as bytes in memory (estimated size 77.8 KiB, free 364.0 MiB)
26/01/12 03:07:02 INFO BlockManagerInfo: Added broadcast_599_piece0 in memory on 02926ee04bc9:45221 (size: 77.8 KiB, free: 365.9 MiB)
26/01/12 03:07:02 INFO SparkContext: Created broadcast 599 from broadcast at DAGScheduler.scala:1513
26/01/12 03:07:02 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 399 (MapPartitionsRDD[999] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1))
26/01/12 03:07:02 INFO TaskSchedulerImpl: Adding task set 399.0 with 2 tasks resource profile 0
26/01/12 03:07:02 INFO TaskSetManager: Starting task 0.0 in stage 399.0 (TID 645) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 03:07:02 INFO TaskSetManager: Starting task 1.0 in stage 399.0 (TID 646) (172.18.0.5, executor 0, partition 1, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 03:07:02 INFO BlockManagerInfo: Added broadcast_599_piece0 in memory on 172.18.0.5:42453 (size: 77.8 KiB, free: 365.9 MiB)
26/01/12 03:07:02 INFO BlockManagerInfo: Added broadcast_598_piece0 in memory on 172.18.0.5:42453 (size: 35.3 KiB, free: 365.9 MiB)
26/01/12 03:07:07 INFO TaskSetManager: Finished task 1.0 in stage 399.0 (TID 646) in 4591 ms on 172.18.0.5 (executor 0) (1/2)
26/01/12 03:07:09 INFO TaskSetManager: Finished task 0.0 in stage 399.0 (TID 645) in 6448 ms on 172.18.0.5 (executor 0) (2/2)
26/01/12 03:07:09 INFO TaskSchedulerImpl: Removed TaskSet 399.0, whose tasks have all completed, from pool 
26/01/12 03:07:09 INFO DAGScheduler: ResultStage 399 (parquet at <unknown>:0) finished in 6.465 s
26/01/12 03:07:09 INFO DAGScheduler: Job 399 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 03:07:09 INFO TaskSchedulerImpl: Killing all running tasks in stage 399: Stage finished
26/01/12 03:07:09 INFO DAGScheduler: Job 399 finished: parquet at <unknown>:0, took 6.469625 s
26/01/12 03:07:09 INFO FileFormatWriter: Start to commit write Job b75b212f-1bf2-47af-8ea7-e2907c468646.
26/01/12 03:07:09 INFO FileFormatWriter: Write Job b75b212f-1bf2-47af-8ea7-e2907c468646 committed. Elapsed time: 31 ms.
26/01/12 03:07:09 INFO FileFormatWriter: Finished processing stats for write job b75b212f-1bf2-47af-8ea7-e2907c468646.
Cargando: yellow_tripdata_2025-09.parquet en hdfs://hadoop-namenode:8020/data/nyc/raw/taxi-trips/2025...
26/01/12 03:07:09 INFO InMemoryFileIndex: It took 6 ms to list leaf files for 1 paths.
26/01/12 03:07:09 INFO BlockManagerInfo: Removed broadcast_594_piece0 on 02926ee04bc9:45221 in memory (size: 36.8 KiB, free: 365.9 MiB)
26/01/12 03:07:09 INFO BlockManagerInfo: Removed broadcast_594_piece0 on 172.18.0.5:42453 in memory (size: 36.8 KiB, free: 365.9 MiB)
26/01/12 03:07:09 INFO BlockManagerInfo: Removed broadcast_596_piece0 on 02926ee04bc9:45221 in memory (size: 77.8 KiB, free: 366.0 MiB)
26/01/12 03:07:09 INFO BlockManagerInfo: Removed broadcast_596_piece0 on 172.18.0.5:42453 in memory (size: 77.8 KiB, free: 366.0 MiB)
26/01/12 03:07:09 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 03:07:09 INFO DAGScheduler: Got job 400 (parquet at <unknown>:0) with 1 output partitions
26/01/12 03:07:09 INFO DAGScheduler: Final stage: ResultStage 400 (parquet at <unknown>:0)
26/01/12 03:07:09 INFO DAGScheduler: Parents of final stage: List()
26/01/12 03:07:09 INFO DAGScheduler: Missing parents: List()
26/01/12 03:07:09 INFO DAGScheduler: Submitting ResultStage 400 (MapPartitionsRDD[1001] at parquet at <unknown>:0), which has no missing parents
26/01/12 03:07:09 INFO BlockManagerInfo: Removed broadcast_599_piece0 on 02926ee04bc9:45221 in memory (size: 77.8 KiB, free: 366.1 MiB)
26/01/12 03:07:09 INFO BlockManagerInfo: Removed broadcast_599_piece0 on 172.18.0.5:42453 in memory (size: 77.8 KiB, free: 366.1 MiB)
26/01/12 03:07:09 INFO BlockManagerInfo: Removed broadcast_595_piece0 on 02926ee04bc9:45221 in memory (size: 35.3 KiB, free: 366.1 MiB)
26/01/12 03:07:09 INFO BlockManagerInfo: Removed broadcast_595_piece0 on 172.18.0.5:42453 in memory (size: 35.3 KiB, free: 366.1 MiB)
26/01/12 03:07:09 INFO MemoryStore: Block broadcast_600 stored as values in memory (estimated size 102.6 KiB, free 365.0 MiB)
26/01/12 03:07:09 INFO MemoryStore: Block broadcast_600_piece0 stored as bytes in memory (estimated size 36.8 KiB, free 365.0 MiB)
26/01/12 03:07:09 INFO BlockManagerInfo: Added broadcast_600_piece0 in memory on 02926ee04bc9:45221 (size: 36.8 KiB, free: 366.1 MiB)
26/01/12 03:07:09 INFO SparkContext: Created broadcast 600 from broadcast at DAGScheduler.scala:1513
26/01/12 03:07:09 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 400 (MapPartitionsRDD[1001] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0))
26/01/12 03:07:09 INFO TaskSchedulerImpl: Adding task set 400.0 with 1 tasks resource profile 0
26/01/12 03:07:09 INFO BlockManagerInfo: Removed broadcast_597_piece0 on 02926ee04bc9:45221 in memory (size: 36.8 KiB, free: 366.1 MiB)
26/01/12 03:07:09 INFO TaskSetManager: Starting task 0.0 in stage 400.0 (TID 647) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4607 bytes) taskResourceAssignments Map()
26/01/12 03:07:09 INFO BlockManagerInfo: Removed broadcast_597_piece0 on 172.18.0.5:42453 in memory (size: 36.8 KiB, free: 366.2 MiB)
26/01/12 03:07:09 INFO BlockManagerInfo: Added broadcast_600_piece0 in memory on 172.18.0.5:42453 (size: 36.8 KiB, free: 366.1 MiB)
26/01/12 03:07:09 INFO TaskSetManager: Finished task 0.0 in stage 400.0 (TID 647) in 42 ms on 172.18.0.5 (executor 0) (1/1)
26/01/12 03:07:09 INFO TaskSchedulerImpl: Removed TaskSet 400.0, whose tasks have all completed, from pool 
26/01/12 03:07:09 INFO DAGScheduler: ResultStage 400 (parquet at <unknown>:0) finished in 0.054 s
26/01/12 03:07:09 INFO DAGScheduler: Job 400 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 03:07:09 INFO TaskSchedulerImpl: Killing all running tasks in stage 400: Stage finished
26/01/12 03:07:09 INFO DAGScheduler: Job 400 finished: parquet at <unknown>:0, took 0.058069 s
26/01/12 03:07:09 INFO FileSourceStrategy: Pushed Filters: 
26/01/12 03:07:09 INFO FileSourceStrategy: Post-Scan Filters: 
26/01/12 03:07:09 INFO FileSourceStrategy: Output Data Schema: struct<VendorID: int, tpep_pickup_datetime: timestamp, tpep_dropoff_datetime: timestamp, passenger_count: bigint, trip_distance: double ... 18 more fields>
26/01/12 03:07:09 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 03:07:09 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 03:07:09 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 03:07:09 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 03:07:09 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 03:07:09 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 03:07:09 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 03:07:09 INFO MemoryStore: Block broadcast_601 stored as values in memory (estimated size 358.8 KiB, free 364.7 MiB)
26/01/12 03:07:09 INFO MemoryStore: Block broadcast_601_piece0 stored as bytes in memory (estimated size 35.3 KiB, free 364.7 MiB)
26/01/12 03:07:09 INFO BlockManagerInfo: Added broadcast_601_piece0 in memory on 02926ee04bc9:45221 (size: 35.3 KiB, free: 366.1 MiB)
26/01/12 03:07:09 INFO SparkContext: Created broadcast 601 from parquet at <unknown>:0
26/01/12 03:07:09 INFO FileSourceScanExec: Planning scan with bin packing, max size: 38313624 bytes, open cost is considered as scanning 4194304 bytes.
26/01/12 03:07:09 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 03:07:09 INFO DAGScheduler: Got job 401 (parquet at <unknown>:0) with 2 output partitions
26/01/12 03:07:09 INFO DAGScheduler: Final stage: ResultStage 401 (parquet at <unknown>:0)
26/01/12 03:07:09 INFO DAGScheduler: Parents of final stage: List()
26/01/12 03:07:09 INFO DAGScheduler: Missing parents: List()
26/01/12 03:07:09 INFO DAGScheduler: Submitting ResultStage 401 (MapPartitionsRDD[1004] at parquet at <unknown>:0), which has no missing parents
26/01/12 03:07:09 INFO MemoryStore: Block broadcast_602 stored as values in memory (estimated size 225.8 KiB, free 364.5 MiB)
26/01/12 03:07:09 INFO MemoryStore: Block broadcast_602_piece0 stored as bytes in memory (estimated size 77.8 KiB, free 364.4 MiB)
26/01/12 03:07:09 INFO BlockManagerInfo: Added broadcast_602_piece0 in memory on 02926ee04bc9:45221 (size: 77.8 KiB, free: 366.0 MiB)
26/01/12 03:07:09 INFO SparkContext: Created broadcast 602 from broadcast at DAGScheduler.scala:1513
26/01/12 03:07:09 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 401 (MapPartitionsRDD[1004] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1))
26/01/12 03:07:09 INFO TaskSchedulerImpl: Adding task set 401.0 with 2 tasks resource profile 0
26/01/12 03:07:09 INFO TaskSetManager: Starting task 0.0 in stage 401.0 (TID 648) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 03:07:09 INFO TaskSetManager: Starting task 1.0 in stage 401.0 (TID 649) (172.18.0.5, executor 0, partition 1, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 03:07:09 INFO BlockManagerInfo: Added broadcast_602_piece0 in memory on 172.18.0.5:42453 (size: 77.8 KiB, free: 366.0 MiB)
26/01/12 03:07:09 INFO BlockManagerInfo: Added broadcast_601_piece0 in memory on 172.18.0.5:42453 (size: 35.3 KiB, free: 366.0 MiB)
26/01/12 03:07:15 INFO TaskSetManager: Finished task 1.0 in stage 401.0 (TID 649) in 6074 ms on 172.18.0.5 (executor 0) (1/2)
26/01/12 03:07:15 INFO TaskSetManager: Finished task 0.0 in stage 401.0 (TID 648) in 6446 ms on 172.18.0.5 (executor 0) (2/2)
26/01/12 03:07:15 INFO TaskSchedulerImpl: Removed TaskSet 401.0, whose tasks have all completed, from pool 
26/01/12 03:07:15 INFO DAGScheduler: ResultStage 401 (parquet at <unknown>:0) finished in 6.463 s
26/01/12 03:07:15 INFO DAGScheduler: Job 401 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 03:07:15 INFO TaskSchedulerImpl: Killing all running tasks in stage 401: Stage finished
26/01/12 03:07:15 INFO DAGScheduler: Job 401 finished: parquet at <unknown>:0, took 6.467499 s
26/01/12 03:07:15 INFO FileFormatWriter: Start to commit write Job 132a04da-62e6-44e7-8957-71648058c20a.
26/01/12 03:07:15 INFO FileFormatWriter: Write Job 132a04da-62e6-44e7-8957-71648058c20a committed. Elapsed time: 33 ms.
26/01/12 03:07:15 INFO FileFormatWriter: Finished processing stats for write job 132a04da-62e6-44e7-8957-71648058c20a.
Cargando: yellow_tripdata_2025-10.parquet en hdfs://hadoop-namenode:8020/data/nyc/raw/taxi-trips/2025...
26/01/12 03:07:15 INFO InMemoryFileIndex: It took 6 ms to list leaf files for 1 paths.
26/01/12 03:07:15 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 03:07:15 INFO DAGScheduler: Got job 402 (parquet at <unknown>:0) with 1 output partitions
26/01/12 03:07:15 INFO DAGScheduler: Final stage: ResultStage 402 (parquet at <unknown>:0)
26/01/12 03:07:15 INFO DAGScheduler: Parents of final stage: List()
26/01/12 03:07:15 INFO DAGScheduler: Missing parents: List()
26/01/12 03:07:15 INFO DAGScheduler: Submitting ResultStage 402 (MapPartitionsRDD[1006] at parquet at <unknown>:0), which has no missing parents
26/01/12 03:07:15 INFO MemoryStore: Block broadcast_603 stored as values in memory (estimated size 102.6 KiB, free 364.3 MiB)
26/01/12 03:07:15 INFO MemoryStore: Block broadcast_603_piece0 stored as bytes in memory (estimated size 36.8 KiB, free 364.3 MiB)
26/01/12 03:07:15 INFO BlockManagerInfo: Added broadcast_603_piece0 in memory on 02926ee04bc9:45221 (size: 36.8 KiB, free: 366.0 MiB)
26/01/12 03:07:15 INFO SparkContext: Created broadcast 603 from broadcast at DAGScheduler.scala:1513
26/01/12 03:07:15 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 402 (MapPartitionsRDD[1006] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0))
26/01/12 03:07:15 INFO TaskSchedulerImpl: Adding task set 402.0 with 1 tasks resource profile 0
26/01/12 03:07:15 INFO TaskSetManager: Starting task 0.0 in stage 402.0 (TID 650) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4607 bytes) taskResourceAssignments Map()
26/01/12 03:07:15 INFO BlockManagerInfo: Added broadcast_603_piece0 in memory on 172.18.0.5:42453 (size: 36.8 KiB, free: 366.0 MiB)
26/01/12 03:07:15 INFO TaskSetManager: Finished task 0.0 in stage 402.0 (TID 650) in 46 ms on 172.18.0.5 (executor 0) (1/1)
26/01/12 03:07:15 INFO TaskSchedulerImpl: Removed TaskSet 402.0, whose tasks have all completed, from pool 
26/01/12 03:07:15 INFO DAGScheduler: ResultStage 402 (parquet at <unknown>:0) finished in 0.060 s
26/01/12 03:07:15 INFO DAGScheduler: Job 402 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 03:07:15 INFO TaskSchedulerImpl: Killing all running tasks in stage 402: Stage finished
26/01/12 03:07:15 INFO DAGScheduler: Job 402 finished: parquet at <unknown>:0, took 0.063896 s
26/01/12 03:07:15 INFO FileSourceStrategy: Pushed Filters: 
26/01/12 03:07:15 INFO FileSourceStrategy: Post-Scan Filters: 
26/01/12 03:07:15 INFO FileSourceStrategy: Output Data Schema: struct<VendorID: int, tpep_pickup_datetime: timestamp, tpep_dropoff_datetime: timestamp, passenger_count: bigint, trip_distance: double ... 18 more fields>
26/01/12 03:07:15 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 03:07:15 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 03:07:15 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 03:07:15 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 03:07:15 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 03:07:15 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 03:07:15 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 03:07:15 INFO MemoryStore: Block broadcast_604 stored as values in memory (estimated size 358.8 KiB, free 363.9 MiB)
26/01/12 03:07:15 INFO MemoryStore: Block broadcast_604_piece0 stored as bytes in memory (estimated size 35.3 KiB, free 363.9 MiB)
26/01/12 03:07:15 INFO BlockManagerInfo: Added broadcast_604_piece0 in memory on 02926ee04bc9:45221 (size: 35.3 KiB, free: 365.9 MiB)
26/01/12 03:07:15 INFO SparkContext: Created broadcast 604 from parquet at <unknown>:0
26/01/12 03:07:15 INFO FileSourceScanExec: Planning scan with bin packing, max size: 39730946 bytes, open cost is considered as scanning 4194304 bytes.
26/01/12 03:07:16 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 03:07:16 INFO DAGScheduler: Got job 403 (parquet at <unknown>:0) with 2 output partitions
26/01/12 03:07:16 INFO DAGScheduler: Final stage: ResultStage 403 (parquet at <unknown>:0)
26/01/12 03:07:16 INFO DAGScheduler: Parents of final stage: List()
26/01/12 03:07:16 INFO DAGScheduler: Missing parents: List()
26/01/12 03:07:16 INFO DAGScheduler: Submitting ResultStage 403 (MapPartitionsRDD[1009] at parquet at <unknown>:0), which has no missing parents
26/01/12 03:07:16 INFO MemoryStore: Block broadcast_605 stored as values in memory (estimated size 225.8 KiB, free 363.7 MiB)
26/01/12 03:07:16 INFO BlockManagerInfo: Removed broadcast_603_piece0 on 02926ee04bc9:45221 in memory (size: 36.8 KiB, free: 366.0 MiB)
26/01/12 03:07:16 INFO MemoryStore: Block broadcast_605_piece0 stored as bytes in memory (estimated size 77.8 KiB, free 363.7 MiB)
26/01/12 03:07:16 INFO BlockManagerInfo: Removed broadcast_603_piece0 on 172.18.0.5:42453 in memory (size: 36.8 KiB, free: 366.0 MiB)
26/01/12 03:07:16 INFO BlockManagerInfo: Added broadcast_605_piece0 in memory on 02926ee04bc9:45221 (size: 77.8 KiB, free: 365.9 MiB)
26/01/12 03:07:16 INFO SparkContext: Created broadcast 605 from broadcast at DAGScheduler.scala:1513
26/01/12 03:07:16 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 403 (MapPartitionsRDD[1009] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1))
26/01/12 03:07:16 INFO TaskSchedulerImpl: Adding task set 403.0 with 2 tasks resource profile 0
26/01/12 03:07:16 INFO TaskSetManager: Starting task 0.0 in stage 403.0 (TID 651) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 03:07:16 INFO TaskSetManager: Starting task 1.0 in stage 403.0 (TID 652) (172.18.0.5, executor 0, partition 1, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 03:07:16 INFO BlockManagerInfo: Removed broadcast_602_piece0 on 02926ee04bc9:45221 in memory (size: 77.8 KiB, free: 366.0 MiB)
26/01/12 03:07:16 INFO BlockManagerInfo: Removed broadcast_602_piece0 on 172.18.0.5:42453 in memory (size: 77.8 KiB, free: 366.1 MiB)
26/01/12 03:07:16 INFO BlockManagerInfo: Removed broadcast_601_piece0 on 02926ee04bc9:45221 in memory (size: 35.3 KiB, free: 366.0 MiB)
26/01/12 03:07:16 INFO BlockManagerInfo: Removed broadcast_601_piece0 on 172.18.0.5:42453 in memory (size: 35.3 KiB, free: 366.1 MiB)
26/01/12 03:07:16 INFO BlockManagerInfo: Added broadcast_605_piece0 in memory on 172.18.0.5:42453 (size: 77.8 KiB, free: 366.0 MiB)
26/01/12 03:07:16 INFO BlockManagerInfo: Removed broadcast_600_piece0 on 02926ee04bc9:45221 in memory (size: 36.8 KiB, free: 366.0 MiB)
26/01/12 03:07:16 INFO BlockManagerInfo: Removed broadcast_600_piece0 on 172.18.0.5:42453 in memory (size: 36.8 KiB, free: 366.1 MiB)
26/01/12 03:07:16 INFO BlockManagerInfo: Removed broadcast_598_piece0 on 02926ee04bc9:45221 in memory (size: 35.3 KiB, free: 366.1 MiB)
26/01/12 03:07:16 INFO BlockManagerInfo: Removed broadcast_598_piece0 on 172.18.0.5:42453 in memory (size: 35.3 KiB, free: 366.1 MiB)
26/01/12 03:07:16 INFO BlockManagerInfo: Added broadcast_604_piece0 in memory on 172.18.0.5:42453 (size: 35.3 KiB, free: 366.1 MiB)
26/01/12 03:07:22 INFO TaskSetManager: Finished task 0.0 in stage 403.0 (TID 651) in 6811 ms on 172.18.0.5 (executor 0) (1/2)
26/01/12 03:07:23 INFO TaskSetManager: Finished task 1.0 in stage 403.0 (TID 652) in 6982 ms on 172.18.0.5 (executor 0) (2/2)
26/01/12 03:07:23 INFO TaskSchedulerImpl: Removed TaskSet 403.0, whose tasks have all completed, from pool 
26/01/12 03:07:23 INFO DAGScheduler: ResultStage 403 (parquet at <unknown>:0) finished in 7.016 s
26/01/12 03:07:23 INFO DAGScheduler: Job 403 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 03:07:23 INFO TaskSchedulerImpl: Killing all running tasks in stage 403: Stage finished
26/01/12 03:07:23 INFO DAGScheduler: Job 403 finished: parquet at <unknown>:0, took 7.021447 s
26/01/12 03:07:23 INFO FileFormatWriter: Start to commit write Job 3b207c5a-9c11-4a81-8761-cff8ff4a7cee.
26/01/12 03:07:23 INFO FileFormatWriter: Write Job 3b207c5a-9c11-4a81-8761-cff8ff4a7cee committed. Elapsed time: 37 ms.
26/01/12 03:07:23 INFO FileFormatWriter: Finished processing stats for write job 3b207c5a-9c11-4a81-8761-cff8ff4a7cee.
Cargando: yellow_tripdata_2025-11.parquet en hdfs://hadoop-namenode:8020/data/nyc/raw/taxi-trips/2025...
26/01/12 03:07:23 INFO InMemoryFileIndex: It took 6 ms to list leaf files for 1 paths.
26/01/12 03:07:23 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 03:07:23 INFO DAGScheduler: Got job 404 (parquet at <unknown>:0) with 1 output partitions
26/01/12 03:07:23 INFO DAGScheduler: Final stage: ResultStage 404 (parquet at <unknown>:0)
26/01/12 03:07:23 INFO DAGScheduler: Parents of final stage: List()
26/01/12 03:07:23 INFO DAGScheduler: Missing parents: List()
26/01/12 03:07:23 INFO DAGScheduler: Submitting ResultStage 404 (MapPartitionsRDD[1011] at parquet at <unknown>:0), which has no missing parents
26/01/12 03:07:23 INFO MemoryStore: Block broadcast_606 stored as values in memory (estimated size 102.6 KiB, free 364.8 MiB)
26/01/12 03:07:23 INFO MemoryStore: Block broadcast_606_piece0 stored as bytes in memory (estimated size 36.8 KiB, free 364.8 MiB)
26/01/12 03:07:23 INFO BlockManagerInfo: Added broadcast_606_piece0 in memory on 02926ee04bc9:45221 (size: 36.8 KiB, free: 366.0 MiB)
26/01/12 03:07:23 INFO SparkContext: Created broadcast 606 from broadcast at DAGScheduler.scala:1513
26/01/12 03:07:23 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 404 (MapPartitionsRDD[1011] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0))
26/01/12 03:07:23 INFO TaskSchedulerImpl: Adding task set 404.0 with 1 tasks resource profile 0
26/01/12 03:07:23 INFO TaskSetManager: Starting task 0.0 in stage 404.0 (TID 653) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4607 bytes) taskResourceAssignments Map()
26/01/12 03:07:23 INFO BlockManagerInfo: Added broadcast_606_piece0 in memory on 172.18.0.5:42453 (size: 36.8 KiB, free: 366.0 MiB)
26/01/12 03:07:23 INFO TaskSetManager: Finished task 0.0 in stage 404.0 (TID 653) in 42 ms on 172.18.0.5 (executor 0) (1/1)
26/01/12 03:07:23 INFO TaskSchedulerImpl: Removed TaskSet 404.0, whose tasks have all completed, from pool 
26/01/12 03:07:23 INFO DAGScheduler: ResultStage 404 (parquet at <unknown>:0) finished in 0.053 s
26/01/12 03:07:23 INFO DAGScheduler: Job 404 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 03:07:23 INFO TaskSchedulerImpl: Killing all running tasks in stage 404: Stage finished
26/01/12 03:07:23 INFO DAGScheduler: Job 404 finished: parquet at <unknown>:0, took 0.056639 s
26/01/12 03:07:23 INFO FileSourceStrategy: Pushed Filters: 
26/01/12 03:07:23 INFO FileSourceStrategy: Post-Scan Filters: 
26/01/12 03:07:23 INFO FileSourceStrategy: Output Data Schema: struct<VendorID: int, tpep_pickup_datetime: timestamp, tpep_dropoff_datetime: timestamp, passenger_count: bigint, trip_distance: double ... 18 more fields>
26/01/12 03:07:23 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 03:07:23 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 03:07:23 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 03:07:23 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 03:07:23 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
26/01/12 03:07:23 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
26/01/12 03:07:23 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
26/01/12 03:07:23 INFO MemoryStore: Block broadcast_607 stored as values in memory (estimated size 358.8 KiB, free 364.5 MiB)
26/01/12 03:07:23 INFO MemoryStore: Block broadcast_607_piece0 stored as bytes in memory (estimated size 35.3 KiB, free 364.4 MiB)
26/01/12 03:07:23 INFO BlockManagerInfo: Added broadcast_607_piece0 in memory on 02926ee04bc9:45221 (size: 35.3 KiB, free: 366.0 MiB)
26/01/12 03:07:23 INFO SparkContext: Created broadcast 607 from parquet at <unknown>:0
26/01/12 03:07:23 INFO FileSourceScanExec: Planning scan with bin packing, max size: 37664279 bytes, open cost is considered as scanning 4194304 bytes.
26/01/12 03:07:23 INFO SparkContext: Starting job: parquet at <unknown>:0
26/01/12 03:07:23 INFO DAGScheduler: Got job 405 (parquet at <unknown>:0) with 2 output partitions
26/01/12 03:07:23 INFO DAGScheduler: Final stage: ResultStage 405 (parquet at <unknown>:0)
26/01/12 03:07:23 INFO DAGScheduler: Parents of final stage: List()
26/01/12 03:07:23 INFO DAGScheduler: Missing parents: List()
26/01/12 03:07:23 INFO DAGScheduler: Submitting ResultStage 405 (MapPartitionsRDD[1014] at parquet at <unknown>:0), which has no missing parents
26/01/12 03:07:23 INFO MemoryStore: Block broadcast_608 stored as values in memory (estimated size 225.8 KiB, free 364.2 MiB)
26/01/12 03:07:23 INFO MemoryStore: Block broadcast_608_piece0 stored as bytes in memory (estimated size 77.8 KiB, free 364.1 MiB)
26/01/12 03:07:23 INFO BlockManagerInfo: Added broadcast_608_piece0 in memory on 02926ee04bc9:45221 (size: 77.8 KiB, free: 365.9 MiB)
26/01/12 03:07:23 INFO SparkContext: Created broadcast 608 from broadcast at DAGScheduler.scala:1513
26/01/12 03:07:23 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 405 (MapPartitionsRDD[1014] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1))
26/01/12 03:07:23 INFO TaskSchedulerImpl: Adding task set 405.0 with 2 tasks resource profile 0
26/01/12 03:07:23 INFO TaskSetManager: Starting task 0.0 in stage 405.0 (TID 654) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 03:07:23 INFO TaskSetManager: Starting task 1.0 in stage 405.0 (TID 655) (172.18.0.5, executor 0, partition 1, PROCESS_LOCAL, 4932 bytes) taskResourceAssignments Map()
26/01/12 03:07:23 INFO BlockManagerInfo: Added broadcast_608_piece0 in memory on 172.18.0.5:42453 (size: 77.8 KiB, free: 366.0 MiB)
26/01/12 03:07:23 INFO BlockManagerInfo: Added broadcast_607_piece0 in memory on 172.18.0.5:42453 (size: 35.3 KiB, free: 365.9 MiB)
26/01/12 03:07:29 INFO TaskSetManager: Finished task 1.0 in stage 405.0 (TID 655) in 5789 ms on 172.18.0.5 (executor 0) (1/2)
26/01/12 03:07:29 INFO TaskSetManager: Finished task 0.0 in stage 405.0 (TID 654) in 6680 ms on 172.18.0.5 (executor 0) (2/2)
26/01/12 03:07:29 INFO TaskSchedulerImpl: Removed TaskSet 405.0, whose tasks have all completed, from pool 
26/01/12 03:07:29 INFO DAGScheduler: ResultStage 405 (parquet at <unknown>:0) finished in 6.698 s
26/01/12 03:07:29 INFO DAGScheduler: Job 405 is finished. Cancelling potential speculative or zombie tasks for this job
26/01/12 03:07:29 INFO TaskSchedulerImpl: Killing all running tasks in stage 405: Stage finished
26/01/12 03:07:29 INFO DAGScheduler: Job 405 finished: parquet at <unknown>:0, took 6.702044 s
26/01/12 03:07:29 INFO FileFormatWriter: Start to commit write Job a48e23f2-3a3e-44b4-a6b2-fac12c45dc67.
26/01/12 03:07:29 INFO FileFormatWriter: Write Job a48e23f2-3a3e-44b4-a6b2-fac12c45dc67 committed. Elapsed time: 32 ms.
26/01/12 03:07:29 INFO FileFormatWriter: Finished processing stats for write job a48e23f2-3a3e-44b4-a6b2-fac12c45dc67.
Reporte generado en: /opt/data/outputs-data/load_report_2026-01-12_01-49-42.txt
26/01/12 03:07:30 INFO SparkContext: Invoking stop() from shutdown hook
26/01/12 03:07:30 INFO SparkUI: Stopped Spark web UI at http://02926ee04bc9:4040
26/01/12 03:07:30 INFO StandaloneSchedulerBackend: Shutting down all executors
26/01/12 03:07:30 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Asking each executor to shut down
26/01/12 03:07:30 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
26/01/12 03:07:30 INFO MemoryStore: MemoryStore cleared
26/01/12 03:07:30 INFO BlockManager: BlockManager stopped
26/01/12 03:07:30 INFO BlockManagerMaster: BlockManagerMaster stopped
26/01/12 03:07:30 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
26/01/12 03:07:30 INFO SparkContext: Successfully stopped SparkContext
26/01/12 03:07:30 INFO ShutdownHookManager: Shutdown hook called
26/01/12 03:07:30 INFO ShutdownHookManager: Deleting directory /tmp/spark-633dbe07-a221-4f43-8079-75626ff6b68b
26/01/12 03:07:30 INFO ShutdownHookManager: Deleting directory /tmp/spark-e0788cff-cfd1-4eec-87a7-30c33344711f
26/01/12 03:07:30 INFO ShutdownHookManager: Deleting directory /tmp/spark-e0788cff-cfd1-4eec-87a7-30c33344711f/pyspark-5e16a9ea-a1a3-4c07-88e0-632e5ba26d83
